{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to spotPython","text":"<p>For official information see SPOTSeven</p>"},{"location":"about/","title":"Contact/Privacy Policy","text":""},{"location":"about/#address","title":"Address","text":"<p>Prof. Dr. Thomas Bartz-Beielstein TH K\u00f6ln Raum 1.519 Steinm\u00fcllerallee 6 51643 Gummersbach +49 (0)2261 8196 6391 thomas.bartz-beielstein [at] th-koeln.de www.spotseven.de</p>"},{"location":"about/#privacy-policy","title":"Privacy Policy","text":"<p>We are very delighted that you have shown interest in our enterprise. Data protection is of a particularly high priority for the management of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. The use of the Internet pages of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is possible without any indication of personal data; however, if a data subject wants to use special enterprise services via our website, processing of personal data could become necessary. If the processing of personal data is necessary and there is no statutory basis for such processing, we generally obtain consent from the data subject.</p> <p>The processing of personal data, such as the name, address, e-mail address, or telephone number of a data subject shall always be in line with the General Data Protection Regulation (GDPR), and in accordance with the country-specific data protection regulations applicable to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. By means of this data protection declaration, our enterprise would like to inform the general public of the nature, scope, and purpose of the personal data we collect, use and process. Furthermore, data subjects are informed, by means of this data protection declaration, of the rights to which they are entitled.</p> <p>As the controller, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab has implemented numerous technical and organizational measures to ensure the most complete protection of personal data processed through this website. However, Internet-based data transmissions may in principle have security gaps, so absolute protection may not be guaranteed. For this reason, every data subject is free to transfer personal data to us via alternative means, e.g. by telephone.</p> <ol> <li>Definitions</li> </ol> <p>The data protection declaration of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is based on the terms used by the European legislator for the adoption of the General Data Protection Regulation (GDPR). Our data protection declaration should be legible and understandable for the general public, as well as our customers and business partners. To ensure this, we would like to first explain the terminology used.</p> <p>In this data protection declaration, we use, inter alia, the following terms:</p> <p>a)    Personal data</p> <p>Personal data means any information relating to an identified or identifiable natural person (\u201cdata subject\u201d). An identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.</p> <p>b) Data subject</p> <p>Data subject is any identified or identifiable natural person, whose personal data is processed by the controller responsible for the processing.</p> <p>c)    Processing</p> <p>Processing is any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction.</p> <p>d)    Restriction of processing</p> <p>Restriction of processing is the marking of stored personal data with the aim of limiting their processing in the future.</p> <p>e)    Profiling</p> <p>Profiling means any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person, in particular to analyse or predict aspects concerning that natural person\u2019s performance at work, economic situation, health, personal preferences, interests, reliability, behaviour, location or movements.</p> <p>f)     Pseudonymisation</p> <p>Pseudonymisation is the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organisational measures to ensure that the personal data are not attributed to an identified or identifiable natural person.</p> <p>g)    Controller or controller responsible for the processing</p> <p>Controller or controller responsible for the processing is the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data; where the purposes and means of such processing are determined by Union or Member State law, the controller or the specific criteria for its nomination may be provided for by Union or Member State law.</p> <p>h)    Processor</p> <p>Processor is a natural or legal person, public authority, agency or other body which processes personal data on behalf of the controller.</p> <p>i)      Recipient</p> <p>Recipient is a natural or legal person, public authority, agency or another body, to which the personal data are disclosed, whether a third party or not. However, public authorities which may receive personal data in the framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing.</p> <p>j)      Third party</p> <p>Third party is a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data.</p> <p>k)    Consent</p> <p>Consent of the data subject is any freely given, specific, informed and unambiguous indication of the data subject\u2019s wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her.</p> <ol> <li>Name and Address of the controller</li> </ol> <p>Controller for the purposes of the General Data Protection Regulation (GDPR), other data protection laws applicable in Member states of the European Union and other provisions related to data protection is:</p> <p>TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab</p> <p>Steinm\u00fcllerallee 1</p> <p>51643 Gummersbach</p> <p>Deutschland</p> <p>Phone: +49 2261 81966391</p> <p>Email: thomas.bartz-beielstein@th-koeln.de</p> <p>Website: www.spotseven.de</p> <ol> <li>Collection of general data and information</li> </ol> <p>The website of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab collects a series of general data and information when a data subject or automated system calls up the website. This general data and information are stored in the server log files. Collected may be (1) the browser types and versions used, (2) the operating system used by the accessing system, (3) the website from which an accessing system reaches our website (so-called referrers), (4) the sub-websites, (5) the date and time of access to the Internet site, (6) an Internet protocol address (IP address), (7) the Internet service provider of the accessing system, and (8) any other similar data and information that may be used in the event of attacks on our information technology systems.</p> <p>When using these general data and information, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab does not draw any conclusions about the data subject. Rather, this information is needed to (1) deliver the content of our website correctly, (2) optimize the content of our website as well as its advertisement, (3) ensure the long-term viability of our information technology systems and website technology, and (4) provide law enforcement authorities with the information necessary for criminal prosecution in case of a cyber-attack. Therefore, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab analyzes anonymously collected data and information statistically, with the aim of increasing the data protection and data security of our enterprise, and to ensure an optimal level of protection for the personal data we process. The anonymous data of the server log files are stored separately from all personal data provided by a data subject.</p> <ol> <li>Comments function in the blog on the website</li> </ol> <p>The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab offers users the possibility to leave individual comments on individual blog contributions on a blog, which is on the website of the controller. A blog is a web-based, publicly-accessible portal, through which one or more people called bloggers or web-bloggers may post articles or write down thoughts in so-called blogposts. Blogposts may usually be commented by third parties.</p> <p>If a data subject leaves a comment on the blog published on this website, the comments made by the data subject are also stored and published, as well as information on the date of the commentary and on the user\u2019s (pseudonym) chosen by the data subject. In addition, the IP address assigned by the Internet service provider (ISP) to the data subject is also logged. This storage of the IP address takes place for security reasons, and in case the data subject violates the rights of third parties, or posts illegal content through a given comment. The storage of these personal data is, therefore, in the own interest of the data controller, so that he can exculpate in the event of an infringement. This collected personal data will not be passed to third parties, unless such a transfer is required by law or serves the aim of the defense of the data controller.</p> <ol> <li>Routine erasure and blocking of personal data</li> </ol> <p>The data controller shall process and store the personal data of the data subject only for the period necessary to achieve the purpose of storage, or as far as this is granted by the European legislator or other legislators in laws or regulations to which the controller is subject to.</p> <p>If the storage purpose is not applicable, or if a storage period prescribed by the European legislator or another competent legislator expires, the personal data are routinely blocked or erased in accordance with legal requirements.</p> <ol> <li>Rights of the data subject</li> </ol> <p>a) Right of confirmation</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller the confirmation as to whether or not personal data concerning him or her are being processed. If a data subject wishes to avail himself of this right of confirmation, he or she may, at any time, contact our Data Protection Officer or another employee of the controller.</p> <p>b) Right of access</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller free information about his or her personal data stored at any time and a copy of this information. Furthermore, the European directives and regulations grant the data subject access to the following information:</p> <p>the purposes of the processing; the categories of personal data concerned; the recipients or categories of recipients to whom the personal data have been or will be disclosed, in particular recipients in third countries or international organisations; where possible, the envisaged period for which the personal data will be stored, or, if not possible, the criteria used to determine that period; the existence of the right to request from the controller rectification or erasure of personal data, or restriction of processing of personal data concerning the data subject, or to object to such processing; the existence of the right to lodge a complaint with a supervisory authority; where the personal data are not collected from the data subject, any available information as to their source; the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) of the GDPR and, at least in those cases, meaningful information about the logic involved, as well as the significance and envisaged consequences of such processing for the data subject. Furthermore, the data subject shall have a right to obtain information as to whether personal data are transferred to a third country or to an international organisation. Where this is the case, the data subject shall have the right to be informed of the appropriate safeguards relating to the transfer.</p> <p>If a data subject wishes to avail himself of this right of access, he or she may at any time contact our Data Protection Officer or another employee of the controller.</p> <p>c) Right to rectification</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller without undue delay the rectification of inaccurate personal data concerning him or her. Taking into account the purposes of the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement.</p> <p>If a data subject wishes to exercise this right to rectification, he or she may, at any time, contact our Data Protection Officer or another employee of the controller.</p> <p>d) Right to erasure (Right to be forgotten)</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller the erasure of personal data concerning him or her without undue delay, and the controller shall have the obligation to erase personal data without undue delay where one of the following grounds applies, as long as the processing is not necessary:</p> <p>The personal data are no longer necessary in relation to the purposes for which they were collected or otherwise processed. The data subject withdraws consent to which the processing is based according to point (a) of Article 6(1) of the GDPR, or point (a) of Article 9(2) of the GDPR, and where there is no other legal ground for the processing. The data subject objects to the processing pursuant to Article 21(1) of the GDPR and there are no overriding legitimate grounds for the processing, or the data subject objects to the processing pursuant to Article 21(2) of the GDPR. The personal data have been unlawfully processed. The personal data must be erased for compliance with a legal obligation in Union or Member State law to which the controller is subject. The personal data have been collected in relation to the offer of information society services referred to in Article 8(1) of the GDPR. If one of the aforementioned reasons applies, and a data subject wishes to request the erasure of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee shall promptly ensure that the erasure request is complied with immediately.</p> <p>Where the controller has made personal data public and is obliged pursuant to Article 17(1) to erase the personal data, the controller, taking account of available technology and the cost of implementation, shall take reasonable steps, including technical measures, to inform other controllers processing the personal data that the data subject has requested erasure by such controllers of any links to, or copy or replication of, those personal data, as far as processing is not required. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the necessary measures in individual cases.</p> <p>e) Right of restriction of processing</p> <p>Each data subject shall have the right granted by the European legislator to obtain from the controller restriction of processing where one of the following applies:</p> <p>The accuracy of the personal data is contested by the data subject, for a period enabling the controller to verify the accuracy of the personal data. The processing is unlawful and the data subject opposes the erasure of the personal data and requests instead the restriction of their use instead. The controller no longer needs the personal data for the purposes of the processing, but they are required by the data subject for the establishment, exercise or defence of legal claims. The data subject has objected to processing pursuant to Article 21(1) of the GDPR pending the verification whether the legitimate grounds of the controller override those of the data subject. If one of the aforementioned conditions is met, and a data subject wishes to request the restriction of the processing of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the restriction of the processing.</p> <p>f) Right to data portability</p> <p>Each data subject shall have the right granted by the European legislator, to receive the personal data concerning him or her, which was provided to a controller, in a structured, commonly used and machine-readable format. He or she shall have the right to transmit those data to another controller without hindrance from the controller to which the personal data have been provided, as long as the processing is based on consent pursuant to point (a) of Article 6(1) of the GDPR or point (a) of Article 9(2) of the GDPR, or on a contract pursuant to point (b) of Article 6(1) of the GDPR, and the processing is carried out by automated means, as long as the processing is not necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller.</p> <p>Furthermore, in exercising his or her right to data portability pursuant to Article 20(1) of the GDPR, the data subject shall have the right to have personal data transmitted directly from one controller to another, where technically feasible and when doing so does not adversely affect the rights and freedoms of others.</p> <p>In order to assert the right to data portability, the data subject may at any time contact the Data Protection Officer designated by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee.</p> <p>g) Right to object</p> <p>Each data subject shall have the right granted by the European legislator to object, on grounds relating to his or her particular situation, at any time, to processing of personal data concerning him or her, which is based on point (e) or (f) of Article 6(1) of the GDPR. This also applies to profiling based on these provisions.</p> <p>The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall no longer process the personal data in the event of the objection, unless we can demonstrate compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject, or for the establishment, exercise or defence of legal claims.</p> <p>If the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab processes personal data for direct marketing purposes, the data subject shall have the right to object at any time to processing of personal data concerning him or her for such marketing. This applies to profiling to the extent that it is related to such direct marketing. If the data subject objects to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab to the processing for direct marketing purposes, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab will no longer process the personal data for these purposes.</p> <p>In addition, the data subject has the right, on grounds relating to his or her particular situation, to object to processing of personal data concerning him or her by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab for scientific or historical research purposes, or for statistical purposes pursuant to Article 89(1) of the GDPR, unless the processing is necessary for the performance of a task carried out for reasons of public interest.</p> <p>In order to exercise the right to object, the data subject may directly contact the Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. In addition, the data subject is free in the context of the use of information society services, and notwithstanding Directive 2002/58/EC, to use his or her right to object by automated means using technical specifications.</p> <p>h) Automated individual decision-making, including profiling</p> <p>Each data subject shall have the right granted by the European legislator not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects concerning him or her, or similarly significantly affects him or her, as long as the decision (1) is not is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) is not authorised by Union or Member State law to which the controller is subject and which also lays down suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, or (3) is not based on the data subject\u2019s explicit consent.</p> <p>If the decision (1) is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) it is based on the data subject\u2019s explicit consent, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall implement suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, at least the right to obtain human intervention on the part of the controller, to express his or her point of view and contest the decision.</p> <p>If the data subject wishes to exercise the rights concerning automated individual decision-making, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller.</p> <p>i) Right to withdraw data protection consent</p> <p>Each data subject shall have the right granted by the European legislator to withdraw his or her consent to processing of his or her personal data at any time.</p> <p>f the data subject wishes to exercise the right to withdraw the consent, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller.</p> <ol> <li>Data protection provisions about the application and use of Facebook</li> </ol> <p>On this website, the controller has integrated components of the enterprise Facebook. Facebook is a social network.</p> <p>A social network is a place for social meetings on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Facebook allows social network users to include the creation of private profiles, upload photos, and network through friend requests.</p> <p>The operating company of Facebook is Facebook, Inc., 1 Hacker Way, Menlo Park, CA 94025, United States. If a person lives outside of the United States or Canada, the controller is the Facebook Ireland Ltd., 4 Grand Canal Square, Grand Canal Harbour, Dublin 2, Ireland.</p> <p>With each call-up to one of the individual pages of this Internet website, which is operated by the controller and into which a Facebook component (Facebook plug-ins) was integrated, the web browser on the information technology system of the data subject is automatically prompted to download display of the corresponding Facebook component from Facebook through the Facebook component. An overview of all the Facebook Plug-ins may be accessed under https://developers.facebook.com/docs/plugins/. During the course of this technical procedure, Facebook is made aware of what specific sub-site of our website was visited by the data subject.</p> <p>If the data subject is logged in at the same time on Facebook, Facebook detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-site of our Internet page was visited by the data subject. This information is collected through the Facebook component and associated with the respective Facebook account of the data subject. If the data subject clicks on one of the Facebook buttons integrated into our website, e.g. the \u201cLike\u201d button, or if the data subject submits a comment, then Facebook matches this information with the personal Facebook user account of the data subject and stores the personal data.</p> <p>Facebook always receives, through the Facebook component, information about a visit to our website by the data subject, whenever the data subject is logged in at the same time on Facebook during the time of the call-up to our website. This occurs regardless of whether the data subject clicks on the Facebook component or not. If such a transmission of information to Facebook is not desirable for the data subject, then he or she may prevent this by logging off from their Facebook account before a call-up to our website is made.</p> <p>The data protection guideline published by Facebook, which is available at https://facebook.com/about/privacy/, provides information about the collection, processing and use of personal data by Facebook. In addition, it is explained there what setting options Facebook offers to protect the privacy of the data subject. In addition, different configuration options are made available to allow the elimination of data transmission to Facebook, e.g. the Facebook blocker of the provider Webgraph, which may be obtained under http://webgraph.com/resources/facebookblocker/. These applications may be used by the data subject to eliminate a data transmission to Facebook.</p> <ol> <li>Data protection provisions about the application and use of Google+</li> </ol> <p>On this website, the controller has integrated the Google+ button as a component. Google+ is a so-called social network. A social network is a social meeting place on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Google+ allows users of the social network to include the creation of private profiles, upload photos and network through friend requests.</p> <p>The operating company of Google+ is Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES.</p> <p>With each call-up to one of the individual pages of this website, which is operated by the controller and on which a Google+ button has been integrated, the Internet browser on the information technology system of the data subject automatically downloads a display of the corresponding Google+ button of Google through the respective Google+ button component. During the course of this technical procedure, Google is made aware of what specific sub-page of our website was visited by the data subject. More detailed information about Google+ is available under https://developers.google.com/+/.</p> <p>If the data subject is logged in at the same time to Google+, Google recognizes with each call-up to our website by the data subject and for the entire duration of his or her stay on our Internet site, which specific sub-pages of our Internet page were visited by the data subject. This information is collected through the Google+ button and Google matches this with the respective Google+ account associated with the data subject.</p> <p>If the data subject clicks on the Google+ button integrated on our website and thus gives a Google+ 1 recommendation, then Google assigns this information to the personal Google+ user account of the data subject and stores the personal data. Google stores the Google+ 1 recommendation of the data subject, making it publicly available in accordance with the terms and conditions accepted by the data subject in this regard. Subsequently, a Google+ 1 recommendation given by the data subject on this website together with other personal data, such as the Google+ account name used by the data subject and the stored photo, is stored and processed on other Google services, such as search-engine results of the Google search engine, the Google account of the data subject or in other places, e.g. on Internet pages, or in relation to advertisements. Google is also able to link the visit to this website with other personal data stored on Google. Google further records this personal information with the purpose of improving or optimizing the various Google services.</p> <p>Through the Google+ button, Google receives information that the data subject visited our website, if the data subject at the time of the call-up to our website is logged in to Google+. This occurs regardless of whether the data subject clicks or doesn\u2019t click on the Google+ button.</p> <p>If the data subject does not wish to transmit personal data to Google, he or she may prevent such transmission by logging out of his Google+ account before calling up our website.</p> <p>Further information and the data protection provisions of Google may be retrieved under https://www.google.com/intl/en/policies/privacy/. More references from Google about the Google+ 1 button may be obtained under https://developers.google.com/+/web/buttons-policy.</p> <ol> <li>Data protection provisions about the application and use of Jetpack for WordPress</li> </ol> <p>On this website, the controller has integrated Jetpack. Jetpack is a WordPress plug-in, which provides additional features to the operator of a website based on WordPress. Jetpack allows the Internet site operator, inter alia, an overview of the visitors of the site. By displaying related posts and publications, or the ability to share content on the page, it is also possible to increase visitor numbers. In addition, security features are integrated into Jetpack, so a Jetpack-using site is better protected against brute-force attacks. Jetpack also optimizes and accelerates the loading of images on the website.</p> <p>The operating company of Jetpack Plug-Ins for WordPress is the Automattic Inc., 132 Hawthorne Street, San Francisco, CA 94107, UNITED STATES. The operating enterprise uses the tracking technology created by Quantcast Inc., 201 Third Street, San Francisco, CA 94103, UNITED STATES.</p> <p>Jetpack sets a cookie on the information technology system used by the data subject. The definition of cookies is explained above. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Jetpack component was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to submit data through the Jetpack component for analysis purposes to Automattic. During the course of this technical procedure Automattic receives data that is used to create an overview of website visits. The data obtained in this way serves the analysis of the behaviour of the data subject, which has access to the Internet page of the controller and is analyzed with the aim to optimize the website. The data collected through the Jetpack component is not used to identify the data subject without a prior obtaining of a separate express consent of the data subject. The data comes also to the notice of Quantcast. Quantcast uses the data for the same purposes as Automattic.</p> <p>The data subject can, as stated above, prevent the setting of cookies through our website at any time by means of a corresponding adjustment of the web browser used and thus permanently deny the setting of cookies. Such an adjustment to the Internet browser used would also prevent Automattic/Quantcast from setting a cookie on the information technology system of the data subject. In addition, cookies already in use by Automattic/Quantcast may be deleted at any time via a web browser or other software programs.</p> <p>In addition, the data subject has the possibility of objecting to a collection of data relating to a use of this Internet site that are generated by the Jetpack cookie as well as the processing of these data by Automattic/Quantcast and the chance to preclude any such. For this purpose, the data subject must press the \u2018opt-out\u2019 button under the link https://www.quantcast.com/opt-out/ which sets an opt-out cookie. The opt-out cookie set with this purpose is placed on the information technology system used by the data subject. If the cookies are deleted on the system of the data subject, then the data subject must call up the link again and set a new opt-out cookie.</p> <p>With the setting of the opt-out cookie, however, the possibility exists that the websites of the controller are not fully usable anymore by the data subject.</p> <p>The applicable data protection provisions of Automattic may be accessed under https://automattic.com/privacy/. The applicable data protection provisions of Quantcast can be accessed under https://www.quantcast.com/privacy/.</p> <ol> <li>Data protection provisions about the application and use of LinkedIn</li> </ol> <p>The controller has integrated components of the LinkedIn Corporation on this website. LinkedIn is a web-based social network that enables users with existing business contacts to connect and to make new business contacts. Over 400 million registered people in more than 200 countries use LinkedIn. Thus, LinkedIn is currently the largest platform for business contacts and one of the most visited websites in the world.</p> <p>The operating company of LinkedIn is LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, UNITED STATES. For privacy matters outside of the UNITED STATES LinkedIn Ireland, Privacy Policy Issues, Wilton Plaza, Wilton Place, Dublin 2, Ireland, is responsible.</p> <p>With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a LinkedIn component (LinkedIn plug-in) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to the download of a display of the corresponding LinkedIn component of LinkedIn. Further information about the LinkedIn plug-in may be accessed under https://developer.linkedin.com/plugins. During the course of this technical procedure, LinkedIn gains knowledge of what specific sub-page of our website was visited by the data subject.</p> <p>If the data subject is logged in at the same time on LinkedIn, LinkedIn detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-page of our Internet page was visited by the data subject. This information is collected through the LinkedIn component and associated with the respective LinkedIn account of the data subject. If the data subject clicks on one of the LinkedIn buttons integrated on our website, then LinkedIn assigns this information to the personal LinkedIn user account of the data subject and stores the personal data.</p> <p>LinkedIn receives information via the LinkedIn component that the data subject has visited our website, provided that the data subject is logged in at LinkedIn at the time of the call-up to our website. This occurs regardless of whether the person clicks on the LinkedIn button or not. If such a transmission of information to LinkedIn is not desirable for the data subject, then he or she may prevent this by logging off from their LinkedIn account before a call-up to our website is made.</p> <p>LinkedIn provides under https://www.linkedin.com/psettings/guest-controls the possibility to unsubscribe from e-mail messages, SMS messages and targeted ads, as well as the ability to manage ad settings. LinkedIn also uses affiliates such as Eire, Google Analytics, BlueKai, DoubleClick, Nielsen, Comscore, Eloqua, and Lotame. The setting of such cookies may be denied under https://www.linkedin.com/legal/cookie-policy. The applicable privacy policy for LinkedIn is available under https://www.linkedin.com/legal/privacy-policy. The LinkedIn Cookie Policy is available under https://www.linkedin.com/legal/cookie-policy.</p> <ol> <li>Data protection provisions about the application and use of Twitter</li> </ol> <p>On this website, the controller has integrated components of Twitter. Twitter is a multilingual, publicly-accessible microblogging service on which users may publish and spread so-called \u2018tweets,\u2019 e.g. short messages, which are limited to 140 characters. These short messages are available for everyone, including those who are not logged on to Twitter. The tweets are also displayed to so-called followers of the respective user. Followers are other Twitter users who follow a user\u2019s tweets. Furthermore, Twitter allows you to address a wide audience via hashtags, links or retweets.</p> <p>The operating company of Twitter is Twitter, Inc., 1355 Market Street, Suite 900, San Francisco, CA 94103, UNITED STATES.</p> <p>With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Twitter component (Twitter button) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding Twitter component of Twitter. Further information about the Twitter buttons is available under https://about.twitter.com/de/resources/buttons. During the course of this technical procedure, Twitter gains knowledge of what specific sub-page of our website was visited by the data subject. The purpose of the integration of the Twitter component is a retransmission of the contents of this website to allow our users to introduce this web page to the digital world and increase our visitor numbers.</p> <p>If the data subject is logged in at the same time on Twitter, Twitter detects with every call-up to our website by the data subject and for the entire duration of their stay on our Internet site which specific sub-page of our Internet page was visited by the data subject. This information is collected through the Twitter component and associated with the respective Twitter account of the data subject. If the data subject clicks on one of the Twitter buttons integrated on our website, then Twitter assigns this information to the personal Twitter user account of the data subject and stores the personal data.</p> <p>Twitter receives information via the Twitter component that the data subject has visited our website, provided that the data subject is logged in on Twitter at the time of the call-up to our website. This occurs regardless of whether the person clicks on the Twitter component or not. If such a transmission of information to Twitter is not desirable for the data subject, then he or she may prevent this by logging off from their Twitter account before a call-up to our website is made.</p> <p>The applicable data protection provisions of Twitter may be accessed under https://twitter.com/privacy?lang=en.</p> <ol> <li>Data protection provisions about the application and use of YouTube</li> </ol> <p>On this website, the controller has integrated components of YouTube. YouTube is an Internet video portal that enables video publishers to set video clips and other users free of charge, which also provides free viewing, review and commenting on them. YouTube allows you to publish all kinds of videos, so you can access both full movies and TV broadcasts, as well as music videos, trailers, and videos made by users via the Internet portal.</p> <p>The operating company of YouTube is YouTube, LLC, 901 Cherry Ave., San Bruno, CA 94066, UNITED STATES. The YouTube, LLC is a subsidiary of Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES.</p> <p>With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a YouTube component (YouTube video) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding YouTube component. Further information about YouTube may be obtained under https://www.youtube.com/yt/about/en/. During the course of this technical procedure, YouTube and Google gain knowledge of what specific sub-page of our website was visited by the data subject.</p> <p>If the data subject is logged in on YouTube, YouTube recognizes with each call-up to a sub-page that contains a YouTube video, which specific sub-page of our Internet site was visited by the data subject. This information is collected by YouTube and Google and assigned to the respective YouTube account of the data subject.</p> <p>YouTube and Google will receive information through the YouTube component that the data subject has visited our website, if the data subject at the time of the call to our website is logged in on YouTube; this occurs regardless of whether the person clicks on a YouTube video or not. If such a transmission of this information to YouTube and Google is not desirable for the data subject, the delivery may be prevented if the data subject logs off from their own YouTube account before a call-up to our website is made.</p> <p>YouTube\u2019s data protection provisions, available at https://www.google.com/intl/en/policies/privacy/, provide information about the collection, processing and use of personal data by YouTube and Google.</p> <ol> <li>Legal basis for the processing</li> </ol> <p>Art. 6(1) lit. a GDPR serves as the legal basis for processing operations for which we obtain consent for a specific processing purpose. If the processing of personal data is necessary for the performance of a contract to which the data subject is party, as is the case, for example, when processing operations are necessary for the supply of goods or to provide any other service, the processing is based on Article 6(1) lit. b GDPR. The same applies to such processing operations which are necessary for carrying out pre-contractual measures, for example in the case of inquiries concerning our products or services. Is our company subject to a legal obligation by which processing of personal data is required, such as for the fulfillment of tax obligations, the processing is based on Art. 6(1) lit. c GDPR. In rare cases, the processing of personal data may be necessary to protect the vital interests of the data subject or of another natural person. This would be the case, for example, if a visitor were injured in our company and his name, age, health insurance data or other vital information would have to be passed on to a doctor, hospital or other third party. Then the processing would be based on Art. 6(1) lit. d GDPR. Finally, processing operations could be based on Article 6(1) lit. f GDPR. This legal basis is used for processing operations which are not covered by any of the abovementioned legal grounds, if processing is necessary for the purposes of the legitimate interests pursued by our company or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data. Such processing operations are particularly permissible because they have been specifically mentioned by the European legislator. He considered that a legitimate interest could be assumed if the data subject is a client of the controller (Recital 47 Sentence 2 GDPR).</p> <ol> <li>The legitimate interests pursued by the controller or by a third party</li> </ol> <p>Where the processing of personal data is based on Article 6(1) lit. f GDPR our legitimate interest is to carry out our business in favor of the well-being of all our employees and the shareholders.</p> <ol> <li>Period for which the personal data will be stored</li> </ol> <p>The criteria used to determine the period of storage of personal data is the respective statutory retention period. After expiration of that period, the corresponding data is routinely deleted, as long as it is no longer necessary for the fulfillment of the contract or the initiation of a contract.</p> <ol> <li>Provision of personal data as statutory or contractual requirement; Requirement necessary to enter into a contract; Obligation of the data subject to provide the personal data; possible consequences of failure to provide such data</li> </ol> <p>We clarify that the provision of personal data is partly required by law (e.g. tax regulations) or can also result from contractual provisions (e.g. information on the contractual partner). Sometimes it may be necessary to conclude a contract that the data subject provides us with personal data, which must subsequently be processed by us. The data subject is, for example, obliged to provide us with personal data when our company signs a contract with him or her. The non-provision of the personal data would have the consequence that the contract with the data subject could not be concluded. Before personal data is provided by the data subject, the data subject must contact our Data Protection Officer. Our Data Protection Officer clarifies to the data subject whether the provision of the personal data is required by law or contract or is necessary for the conclusion of the contract, whether there is an obligation to provide the personal data and the consequences of non-provision of the personal data.</p> <ol> <li>Existence of automated decision-making</li> </ol> <p>As a responsible company, we do not use automatic decision-making or profiling.</p> <p>This Privacy Policy has been generated by the Privacy Policy Generator of the External Data Protection Officers that was developed in cooperation with RC GmbH, which sells used notebooks and the Media Law Lawyers from WBS-LAW.</p>"},{"location":"download/","title":"Install spotPython","text":"<pre><code>pip install spotPython\n</code></pre>"},{"location":"examples/","title":"SPOT Examples","text":""},{"location":"examples/#simple-spotpython-run","title":"Simple spotPython run","text":"<p>import numpy as np from spotPython.fun.objectivefunctions import analytical from spotPython.spot import spot import numpy as np from math import inf</p>"},{"location":"examples/#number-of-initial-points","title":"number of initial points:","text":"<p>ni = 7</p>"},{"location":"examples/#number-of-points","title":"number of points","text":"<p>n = 10</p> <p>fun = analytical().fun_sphere lower = np.array([-1]) upper = np.array([1]) design_control={\u201cinit_size\u201d: ni}</p> <p>spot_1 = spot.Spot(fun=fun,             lower = lower,             upper= upper,             fun_evals = n,             show_progress=True,             design_control=design_control,) spot_1.run()</p>"},{"location":"hyperparameter-tuning-cookbook/","title":"Hyperparameter Tuning Cookbook","text":"<p>The following is a cookbook of hyperparameter tuning recipes. It is not meant to be exhaustive, but instead act as a place to capture a number of the common patterns used in hyperparameter tuning.</p> <p>Hyperparameter Tuning Cookbook</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>spotPython<ul> <li>_version</li> <li>budget<ul> <li>ocba</li> </ul> </li> <li>build<ul> <li>kriging</li> <li>surrogates</li> </ul> </li> <li>data<ul> <li>base</li> <li>light_hyper_dict</li> <li>sklearn_hyper_dict</li> <li>torch_hyper_dict</li> <li>torchdata</li> <li>vbdp</li> </ul> </li> <li>design<ul> <li>designs</li> <li>factorial</li> <li>spacefilling</li> </ul> </li> <li>fun<ul> <li>hyperlight</li> <li>hypersklearn</li> <li>hypertorch</li> <li>objectivefunctions</li> </ul> </li> <li>hyperparameters<ul> <li>categorical</li> <li>optimizer</li> <li>values</li> </ul> </li> <li>light<ul> <li>crossvalidationdatamodule</li> <li>csvdatamodule</li> <li>csvdataset</li> <li>litmodel</li> <li>mnistdatamodule</li> <li>netlightbase</li> <li>traintest</li> <li>utils</li> </ul> </li> <li>plot<ul> <li>contour</li> <li>validation</li> </ul> </li> <li>sklearn<ul> <li>traintest</li> </ul> </li> <li>spot<ul> <li>spot</li> </ul> </li> <li>torch<ul> <li>activation</li> <li>dataframedataset</li> <li>initialization</li> <li>mapk</li> <li>netcifar10</li> <li>netcore</li> <li>netfashionMNIST</li> <li>netregression</li> <li>netvbdp</li> <li>traintest</li> </ul> </li> <li>utils<ul> <li>aggregate</li> <li>classes</li> <li>compare</li> <li>convert</li> <li>device</li> <li>eda</li> <li>file</li> <li>init</li> <li>metrics</li> <li>progress</li> <li>repair</li> <li>transform</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/spotPython/_version/","title":"_version","text":""},{"location":"reference/spotPython/budget/ocba/","title":"ocba","text":"<p>OCBA: Optimal Computing Budget Allocation</p>"},{"location":"reference/spotPython/budget/ocba/#spotPython.budget.ocba.get_ocba","title":"<code>get_ocba(means, vars, delta)</code>","text":"<p>Optimal Computer Budget Allocation (OCBA)</p> <p>This function calculates the budget recommendations for a given set of means, variances, and incremental budget using the OCBA algorithm.</p> References <p>Chun-Hung Chen and Loo Hay Lee: Stochastic Simulation Optimization: An Optimal Computer Budget Allocation, pp. 49 and pp. 215</p> <p>C.S.M Currie and T. Monks: How to choose the best setup for a system. A tutorial for the Simulation Workshop 2021, see: https://colab.research.google.com/github/TomMonks/sim-tools/blob/master/examples/sw21_tutorial.ipynb and https://github.com/TomMonks/sim-tools</p> <p>Parameters:</p> Name Type Description Default <code>means</code> <code>numpy.array</code> <p>An array of means.</p> required <code>vars</code> <code>numpy.array</code> <p>An array of variances.</p> required <code>delta</code> <code>int</code> <p>The incremental budget.</p> required <p>Returns:</p> Type Description <code>int32</code> <p>numpy.array: An array of budget recommendations.</p> Note <p>The implementation is based on the pseudo-code in the Chen et al. book (p. 49).</p> <p>Examples:</p> <p>From the Chen et al. book (p. 49): mean_y = np.array([1,2,3,4,5]) var_y = np.array([1,1,9,9,4]) get_ocba(mean_y, var_y, 50)</p> <p>[11  9 19  9  2]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/budget/ocba.py</code> <pre><code>def get_ocba(means, vars, delta) -&gt; int32:\n\"\"\"\n    Optimal Computer Budget Allocation (OCBA)\n\n    This function calculates the budget recommendations for a given set of means,\n    variances, and incremental budget using the OCBA algorithm.\n\n    References:\n        Chun-Hung Chen and Loo Hay Lee:\n        Stochastic Simulation Optimization: An Optimal Computer Budget Allocation,\n        pp. 49 and pp. 215\n\n        C.S.M Currie and T. Monks:\n        How to choose the best setup for a system. A tutorial for the Simulation Workshop 2021,\n        see:\n        https://colab.research.google.com/github/TomMonks/sim-tools/blob/master/examples/sw21_tutorial.ipynb\n        and\n        https://github.com/TomMonks/sim-tools\n\n    Args:\n        means (numpy.array): An array of means.\n        vars (numpy.array): An array of variances.\n        delta (int): The incremental budget.\n\n    Returns:\n        numpy.array: An array of budget recommendations.\n\n    Note:\n        The implementation is based on the pseudo-code in the Chen et al. book (p. 49).\n\n    Examples:\n\n        From the Chen et al. book (p. 49):\n        mean_y = np.array([1,2,3,4,5])\n        var_y = np.array([1,1,9,9,4])\n        get_ocba(mean_y, var_y, 50)\n\n        [11  9 19  9  2]\n    \"\"\"\n    n_designs = means.shape[0]\n    allocations = zeros(n_designs, int32)\n    ratios = zeros(n_designs, float64)\n    budget = delta\n    ranks = get_ranks(means)\n    best, second_best = argpartition(ranks, 2)[:2]\n    ratios[second_best] = 1.0\n    select = [i for i in range(n_designs) if i not in [best, second_best]]\n    temp = (means[best] - means[second_best]) / (means[best] - means[select])\n    ratios[select] = square(temp) * (vars[select] / vars[second_best])\n    select = [i for i in range(n_designs) if i not in [best]]\n    temp = (square(ratios[select]) / vars[select]).sum()\n    ratios[best] = sqrt(vars[best] * temp)\n    more_runs = full(n_designs, True, dtype=bool)\n    add_budget = zeros(n_designs, dtype=float)\n    more_alloc = True\n    while more_alloc:\n        more_alloc = False\n        ratio_s = (more_runs * ratios).sum()\n        add_budget[more_runs] = (budget / ratio_s) * ratios[more_runs]\n        add_budget = around(add_budget).astype(int)\n        mask = add_budget &lt; allocations\n        add_budget[mask] = allocations[mask]\n        more_runs[mask] = 0\n        if mask.sum() &gt; 0:\n            more_alloc = True\n        if more_alloc:\n            budget = allocations.sum() + delta\n            budget -= (add_budget * ~more_runs).sum()\n    t_budget = add_budget.sum()\n    add_budget[best] += allocations.sum() + delta - t_budget\n    return add_budget - allocations\n</code></pre>"},{"location":"reference/spotPython/budget/ocba/#spotPython.budget.ocba.get_ocba_X","title":"<code>get_ocba_X(X, means, vars, delta)</code>","text":"<p>This function calculates the OCBA allocation and repeats the input array X along the specified axis.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>numpy.ndarray</code> <p>Input array to be repeated.</p> required <code>means</code> <code>list</code> <p>List of means for each alternative.</p> required <code>vars</code> <code>list</code> <p>List of variances for each alternative.</p> required <code>delta</code> <code>float</code> <p>Indifference zone parameter.</p> required <p>Returns:</p> Type Description <code>float64</code> <p>numpy.ndarray: Repeated array of X along the specified axis based on the OCBA allocation.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/budget/ocba.py</code> <pre><code>def get_ocba_X(X, means, vars, delta) -&gt; float64:\n\"\"\"\n    This function calculates the OCBA allocation and repeats the input array X along the specified axis.\n\n    Args:\n        X (numpy.ndarray): Input array to be repeated.\n        means (list): List of means for each alternative.\n        vars (list): List of variances for each alternative.\n        delta (float): Indifference zone parameter.\n\n    Returns:\n        numpy.ndarray: Repeated array of X along the specified axis based on the OCBA allocation.\n\n    \"\"\"\n    o = get_ocba(means=means, vars=vars, delta=delta)\n    return repeat(X, o, axis=0)\n</code></pre>"},{"location":"reference/spotPython/build/kriging/","title":"kriging","text":""},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging","title":"<code>Kriging</code>","text":"<p>         Bases: <code>surrogates</code></p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>class Kriging(surrogates):\n    def __init__(\n            self,\n            noise=False,\n            cod_type=\"norm\",\n            var_type=[\"num\"],\n            use_cod_y=False,\n            name=\"kriging\",\n            seed=124,\n            model_optimizer=None,\n            model_fun_evals=None,\n            min_theta=-3,  # TODO\n            max_theta=2,  # TODO\n            n_theta=1,\n            n_p=1,\n            optim_p=False,\n            log_level=50,\n            spot_writer=None,\n            counter=None,\n            **kwargs\n    ):\n\"\"\"\n        Kriging surrogate.\n\n        Args:\n            noise (bool):\n                use regression instead of interpolation kriging. Defaults to \"False\".\n            cod_type (bool):\n                normalize or standardize X and values. Can be None, \"norm\", or \"std\". Defaults to \"norm\".\n            var_type (str):\n                variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor).\n                Defaults to `\"num\"`.\n            use_cod_y (bool):\n                use coded y values (instead of natural one). Defaults to `False`.\n            name (str):\n                Surrogate name. Defaults to `\"kriging\"`.\n            seed (int):\n                Random seed. Defaults to `124`.\n            model_optimizer (object):\n                Optimizer on the surrogate. If `None`, `differential_evolution` is selected.\n            model_fun_evals (int):\n                Number of iterations used by the optimizer on the surrogate.\n            min_theta (float):\n                min log10 theta value. Defaults to `-6.`.\n            max_theta (float):\n                max log10 theta value. Defaults to `3.`.\n            n_theta (int):\n                number of theta values. Defaults to `1`.\n            n_p (int):\n                number of p values. Defaults to `1`.\n            optim_p (bool):\n                Determines whether `p` should be optimized.\n            log_level (int):\n                logging level, e.g., `20` is `\"INFO\"`. Defaults to `50` (`\"CRITICAL\"`).\n\n        Attributes:\n            nat_range_X (list):\n                List of X natural ranges.\n            nat_range_y (list):\n                List of y nat ranges.\n            noise (bool):\n                noisy objective function. Default: False. If `True`, regression kriging will be used.\n            var_type (str):\n                variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor).\n            num_mask (array):\n                array of bool variables. `True` represent numerical (float) variables.\n            factor_mask (array):\n                array of factor variables. `True` represents factor (unordered) variables.\n            int_mask (array):\n                array of integer variables. `True` represents integers (ordered) variables.\n            ordered_mask (array):\n                array of ordered variables. `True` represents integers or float (ordered) variables.\n                Set of veriables which an order relation, i.e., they are either num (float) or int.\n            name (str):\n                Surrogate name\n            seed (int):\n                Random seed.\n            use_cod_y (bool):\n                Use coded y values.\n            sigma (float):\n                Kriging sigma.\n            gen (method):\n                Design generator, e.g., spotPython.design.spacefilling.spacefilling.\n            min_theta (float):\n                min log10 theta value. Defaults: -6.\n            max_theta (float):\n                max log10 theta value. Defaults: 3.\n            min_p (float):\n                min p value. Default: 1.\n            max_p (float):\n                max p value. Default: 2.\n\n        Examples:\n            Surrogate of the x*sin(x) function.\n            See:\n            [scikit-learn](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html)\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; import matplotlib.pyplot as plt\n            &gt;&gt;&gt; rng = np.random.RandomState(1)\n            &gt;&gt;&gt; X = linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\n            &gt;&gt;&gt; y = np.squeeze(X * np.sin(X))\n            &gt;&gt;&gt; training_indices = rng.choice(arange(y.size), size=6, replace=False)\n            &gt;&gt;&gt; X_train, y_train = X[training_indices], y[training_indices]\n            &gt;&gt;&gt; S = Kriging(name='kriging', seed=124)\n            &gt;&gt;&gt; S.fit(X_train, y_train)\n            &gt;&gt;&gt; mean_prediction, std_prediction = S.predict(X)\n            &gt;&gt;&gt; plt.plot(X, y, label=r\"$f(x)$\", linestyle=\"dotted\")\n            &gt;&gt;&gt; plt.scatter(X_train, y_train, label=\"Observations\")\n            &gt;&gt;&gt; plt.plot(X, mean_prediction, label=\"Mean prediction\")\n            &gt;&gt;&gt; plt.fill_between(\n                X.ravel(),\n                mean_prediction - 1.96 * std_prediction,\n                mean_prediction + 1.96 * std_prediction,\n                alpha=0.5,\n                label=r\"95% confidence interval\",\n                )\n            &gt;&gt;&gt; plt.legend()\n            &gt;&gt;&gt; plt.xlabel(\"$x$\")\n            &gt;&gt;&gt; plt.ylabel(\"$f(x)$\")\n            &gt;&gt;&gt; _ = plt.title(\"Gaussian process regression on noise-free dataset\")\n\n        \"\"\"\n        super().__init__(name, seed, log_level)\n\n        self.noise = noise\n        self.var_type = var_type\n        self.cod_type = cod_type\n        self.use_cod_y = use_cod_y\n        self.name = name\n        self.seed = seed\n        self.log_level = log_level\n        self.spot_writer = spot_writer\n        self.counter = counter\n\n        self.sigma = 0\n        self.eps = sqrt(spacing(1))\n        self.min_theta = min_theta\n        self.max_theta = max_theta\n        self.min_p = 1\n        self.max_p = 2\n        self.min_Lambda = 1e-9\n        self.max_Lambda = 1.\n        self.n_theta = n_theta\n        self.n_p = n_p\n        self.optim_p = optim_p\n        # Psi matrix condition:\n        self.cnd_Psi = 0\n        self.inf_Psi = False\n\n        self.model_optimizer = model_optimizer\n        if self.model_optimizer is None:\n            self.model_optimizer = differential_evolution\n        self.model_fun_evals = model_fun_evals\n        # differential evaluation uses maxiter = 1000\n        # and sets the number of function evaluations to\n        # (maxiter + 1) * popsize * N, which results in\n        # 1000 * 15 * k, because the default popsize is 15 and\n        # N is the number of parameters. This seems to be quite large:\n        # for k=2 these are 30 000 iterations. Therefore we set this value to\n        # 100\n        if self.model_fun_evals is None:\n            self.model_fun_evals = 100\n\n        # Logging information\n        self.log[\"negLnLike\"] = []\n        self.log[\"theta\"] = []\n        self.log[\"p\"] = []\n        self.log[\"Lambda\"] = []\n        # Logger\n        logger.setLevel(self.log_level)\n        logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n\n    def exp_imp(self, y0: float, s0: float) -&gt; float:\n\"\"\"\n        Calculates the expected improvement for a given function value and error in coded units.\n\n        Args:\n            y0 (float): The function value in coded units.\n            s0 (float): The error value.\n\n        Returns:\n            float: The expected improvement value.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; S = Kriging(name='kriging', seed=124)\n            &gt;&gt;&gt; S.cod_y = [0.0, 0.0, 0.0, 0.0, 0.0]\n            &gt;&gt;&gt; S.mean_cod_y = [0.0, 0.0, 0.0, 0.0, 0.0]\n            &gt;&gt;&gt; S.exp_imp(1.0, 2.0)\n            0.0\n\n        \"\"\"\n        # y_min = min(self.cod_y)\n        y_min = min(self.mean_cod_y)\n        if s0 &lt;= 0.0:\n            EI = 0.0\n        elif s0 &gt; 0.0:\n            EI_one = (y_min - y0) * (\n                    0.5 + 0.5 * erf((1.0 / sqrt(2.0)) * ((y_min - y0) / s0))\n            )\n            EI_two = (s0 * (1.0 / sqrt(2.0 * pi))) * (\n                exp(-(1.0 / 2.0) * ((y_min - y0) ** 2.0 / s0 ** 2.0))\n            )\n            EI = EI_one + EI_two\n        return EI\n\n    def set_de_bounds(self) -&gt; None:\n\"\"\"\n        Determine search bounds for model_optimizer, e.g., differential evolution.\n\n        This method sets the attribute `de_bounds` of the object to a list of lists,\n        where each inner list represents the lower and upper bounds for a parameter\n        being optimized. The number of inner lists is determined by the number of\n        parameters being optimized (`n_theta` and `n_p`), as well as whether noise is\n        being considered (`noise`).\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n            &gt;&gt;&gt; obj = MyClass()\n            &gt;&gt;&gt; obj.set_de_bounds()\n            &gt;&gt;&gt; print(obj.de_bounds)\n            [[min_theta, max_theta], [min_theta, max_theta], ..., [min_p, max_p], [min_Lambda, max_Lambda]]\n\n        Returns:\n            None\n        \"\"\"\n        de_bounds = [[self.min_theta, self.max_theta] for _ in range(self.n_theta)]\n        if self.optim_p:\n            de_bounds += [[self.min_p, self.max_p] for _ in range(self.n_p)]\n            if self.noise:\n                de_bounds.append([self.min_Lambda, self.max_Lambda])\n        else:\n            if self.noise:\n                de_bounds.append([self.min_Lambda, self.max_Lambda])\n        self.de_bounds = de_bounds\n\n    def extract_from_bounds(self, new_theta_p_Lambda: np.ndarray) -&gt; None:\n\"\"\"\n        Extract `theta`, `p`, and `Lambda` from bounds. The kriging object stores\n        `theta` as an array,  `p` as an array, and `Lambda` as a float.\n\n        Args:\n            new_theta_p_Lambda (np.ndarray):\n                1d-array with theta, p, and Lambda values. Order is important.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n            &gt;&gt;&gt; obj = MyClass()\n            &gt;&gt;&gt; obj.extract_from_bounds(np.array([1, 2, 3]))\n            &gt;&gt;&gt; print(obj.theta)\n            [1]\n            &gt;&gt;&gt; print(obj.p)\n            [2]\n            &gt;&gt;&gt; print(obj.Lambda)\n            3\n\n        Returns:\n            None\n        \"\"\"\n        self.theta = new_theta_p_Lambda[:self.n_theta]\n        if self.optim_p:\n            self.p = new_theta_p_Lambda[self.n_theta:self.n_theta + self.n_p]\n            if self.noise:\n                self.Lambda = new_theta_p_Lambda[self.n_theta + self.n_p]\n        else:\n            if self.noise:\n                self.Lambda = new_theta_p_Lambda[self.n_theta]\n\n    def optimize_model(self) -&gt; Union[List[float], Tuple[float]]:\n\"\"\"\n        Optimize the model using the specified model_optimizer.\n\n        This method uses the specified model_optimizer to optimize the\n        likelihood function (`fun_likelihood`) with respect to the model parameters.\n        The optimization is performed within the bounds specified by the attribute\n        `de_bounds`.\n        The result of the optimization is returned as a list or tuple of optimized parameter values.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n            &gt;&gt;&gt; obj = MyClass()\n            &gt;&gt;&gt; result = obj.optimize_model()\n            &gt;&gt;&gt; print(result)\n            [optimized_theta, optimized_p, optimized_Lambda]\n\n        Returns:\n            result[\"x\"] (Union[List[float], Tuple[float]]):\n                A list or tuple of optimized parameter values.\n        \"\"\"\n        if self.model_optimizer.__name__ == 'dual_annealing':\n            result = self.model_optimizer(func=self.fun_likelihood,\n                                          bounds=self.de_bounds)\n        elif self.model_optimizer.__name__ == 'differential_evolution':\n            result = self.model_optimizer(func=self.fun_likelihood,\n                                          bounds=self.de_bounds,\n                                          maxiter=self.model_fun_evals,\n                                          seed=self.seed)\n        elif self.model_optimizer.__name__ == 'direct':\n            result = self.model_optimizer(func=self.fun_likelihood,\n                                          bounds=self.de_bounds,\n                                          # maxfun=self.model_fun_evals,\n                                          eps=1e-2)\n        elif self.model_optimizer.__name__ == 'shgo':\n            result = self.model_optimizer(func=self.fun_likelihood,\n                                          bounds=self.de_bounds)\n        elif self.model_optimizer.__name__ == 'basinhopping':\n            result = self.model_optimizer(func=self.fun_likelihood,\n                                          x0=mean(self.de_bounds, axis=1))\n        else:\n            result = self.model_optimizer(func=self.fun_likelihood, bounds=self.de_bounds)\n        return result[\"x\"]\n\n    def update_log(self) -&gt; None:\n\"\"\"\n        Update the log with the current values of negLnLike, theta, p, and Lambda.\n\n        This method appends the current values of negLnLike, theta, p (if optim_p is True),\n        and Lambda (if noise is True)\n        to their respective lists in the log dictionary.\n        It also updates the log_length attribute with the current length\n        of the negLnLike list in the log.\n\n        If spot_writer is not None, this method also writes the current values of\n        negLnLike, theta, p (if optim_p is True),\n        and Lambda (if noise is True) to the spot_writer object.\n\n        Returns:\n            None\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n            &gt;&gt;&gt; obj = MyClass()\n            &gt;&gt;&gt; obj.update_log()\n            &gt;&gt;&gt; print(obj.log)\n            {'negLnLike': [0.5], 'theta': [0.1], 'p': [0.2], 'Lambda': [0.3]}\n        \"\"\"\n        self.log[\"negLnLike\"] = append(self.log[\"negLnLike\"], self.negLnLike)\n        self.log[\"theta\"] = append(self.log[\"theta\"], self.theta)\n        if self.optim_p:\n            self.log[\"p\"] = append(self.log[\"p\"], self.p)\n        if self.noise:\n            self.log[\"Lambda\"] = append(self.log[\"Lambda\"], self.Lambda)\n        # get the length of the log\n        self.log_length = len(self.log[\"negLnLike\"])\n        if self.spot_writer is not None:\n            writer = self.spot_writer\n            negLnLike = self.negLnLike.copy()\n            writer.add_scalar(\"spot_negLnLike\", negLnLike, self.counter+self.log_length)\n            # add the self.n_theta theta values to the writer with one key \"theta\",\n            # i.e, the same key for all theta values\n            theta = self.theta.copy()\n            writer.add_scalars(\"spot_theta\", {f\"theta_{i}\": theta[i] for i in range(self.n_theta)},\n                               self.counter+self.log_length)\n            if self.noise:\n                Lambda = self.Lambda.copy()\n                writer.add_scalar(\"spot_Lambda\", Lambda, self.counter+self.log_length)\n            if self.optim_p:\n                p = self.p.copy()\n                writer.add_scalars(\"spot_p\", {f\"p_{i}\": p[i] for i in range(self.n_p)}, self.counter+self.log_length)\n            writer.flush()\n\n    def fit(self, nat_X: np.ndarray, nat_y: np.ndarray) -&gt; object:\n\"\"\"\n        Fits the hyperparameters (`theta`, `p`, `Lambda`) of the Kriging model.\n\n        The function computes the following internal values:\n        1. `theta`, `p`, and `Lambda` values via optimization of the function `fun_likelihood()`.\n        2. Correlation matrix `Psi` via `rebuildPsi()`.\n\n        Args:\n            nat_X (np.ndarray): Sample points.\n            nat_y (np.ndarray): Function values.\n\n        Returns:\n            object: Fitted estimator.\n\n        Attributes:\n            theta (np.ndarray): Kriging theta values. Shape (k,).\n            p (np.ndarray): Kriging p values. Shape (k,).\n            LnDetPsi (np.float64): Determinant Psi matrix.\n            Psi (np.matrix): Correlation matrix Psi. Shape (n,n).\n            psi (np.ndarray): psi vector. Shape (n,).\n            one (np.ndarray): vector of ones. Shape (n,).\n            mu (np.float64): Kriging expected mean value mu.\n            U (np.matrix): Kriging U matrix, Cholesky decomposition. Shape (n,n).\n            SigmaSqr (np.float64): Sigma squared value.\n            Lambda (float): lambda noise value.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; nat_X = np.array([[1, 2], [3, 4]])\n            &gt;&gt;&gt; nat_y = np.array([1, 2])\n            &gt;&gt;&gt; surrogate = Kriging()\n            &gt;&gt;&gt; surrogate.fit(nat_X, nat_y)\n        \"\"\"\n        self.initialize_variables(nat_X, nat_y)\n        self.set_variable_types()\n        self.nat_to_cod_init()\n        self.set_theta_values()\n        self.initialize_matrices()\n        # build_Psi() and build_U() are called in fun_likelihood\n        self.set_de_bounds()\n        # Finally, set new theta and p values and update the surrogate again\n        # for new_theta_p_Lambda in de_results[\"x\"]:\n        new_theta_p_Lambda = self.optimize_model()\n        self.extract_from_bounds(new_theta_p_Lambda)\n        self.build_Psi()\n        self.build_U()\n        # TODO: check if the following line is necessary!\n        self.likelihood()\n        self.update_log()\n\n    def initialize_variables(self, nat_X: np.ndarray, nat_y: np.ndarray) -&gt; None:\n\"\"\"\n        Initialize variables for the class instance.\n\n        This method takes in the independent and dependent variable data as input\n        and initializes the class instance variables.\n        It creates deep copies of the input data and stores them in the\n        instance variables `nat_X` and `nat_y`.\n        It also calculates the number of observations `n` and\n        the number of independent variables `k` from the shape of `nat_X`.\n        Finally, it creates empty arrays with the same shape as `nat_X`\n        and `nat_y` and stores them in the instance variables `cod_X` and `cod_y`.\n\n        Args:\n            nat_X (np.ndarray): The independent variable data.\n            nat_y (np.ndarray): The dependent variable data.\n\n        Returns:\n            None\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; surrogate = Kriging()\n            &gt;&gt;&gt; nat_X = np.array([[1, 2], [3, 4]])\n            &gt;&gt;&gt; nat_y = np.array([1, 2])\n            &gt;&gt;&gt; surrogate.initialize_variables(nat_X, nat_y)\n            &gt;&gt;&gt; surrogate.nat_X\n            array([[1, 2],\n                     [3, 4]])\n            &gt;&gt;&gt; surrogate.nat_y\n            array([1, 2])\n\n        \"\"\"\n        self.nat_X = copy.deepcopy(nat_X)\n        self.nat_y = copy.deepcopy(nat_y)\n        self.n = self.nat_X.shape[0]\n        self.k = self.nat_X.shape[1]\n        self.cod_X = np.empty_like(self.nat_X)\n        self.cod_y = np.empty_like(self.nat_y)\n\n    def set_variable_types(self) -&gt; None:\n\"\"\"\n        Set the variable types for the class instance.\n\n        This method sets the variable types for the class instance based\n        on the `var_type` attribute. If the length of `var_type` is less\n        than `k`, all variable types are forced to 'num' and a warning is logged.\n        The method then creates masks for each variable\n        type ('num', 'factor', 'int', 'float') using numpy arrays.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.var_type = [\"num\", \"factor\"]\n            &gt;&gt;&gt; instance = MyClass()\n            &gt;&gt;&gt; instance.set_variable_types()\n            &gt;&gt;&gt; instance.num_mask\n            array([ True, False])\n\n        Returns:\n            None\n        \"\"\"\n        # assume all variable types are \"num\" if \"num\" is\n        # specified once:\n        if len(self.var_type) &lt; self.k:\n            self.var_type = self.var_type * self.k\n            logger.warning(\"Warning: All variable types forced to 'num'.\")\n        self.num_mask = np.array(list(map(lambda x: x == \"num\", self.var_type)))\n        self.factor_mask = np.array(list(map(lambda x: x == \"factor\", self.var_type)))\n        self.int_mask = np.array(list(map(lambda x: x == \"int\", self.var_type)))\n        self.ordered_mask = np.array(list(map(lambda x: x == \"int\" or x == \"num\" or x == \"float\", self.var_type)))\n\n    def set_theta_values(self) -&gt; None:\n\"\"\"\n        Set the theta values for the class instance.\n\n        This method sets the theta values for the class instance based\n        on the `n_theta` and `k` attributes. If `n_theta` is greater than\n        `k`, `n_theta` is set to `k` and a warning is logged.\n        The method then initializes the `theta` attribute as a list\n        of zeros with length `n_theta`.\n        The `x0_theta` attribute is also initialized as a list of ones\n        with length `n_theta`, multiplied by `n / (100 * k)`.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.n_theta = 3\n            &gt;&gt;&gt;         self.k = 2\n            &gt;&gt;&gt; instance = MyClass()\n            &gt;&gt;&gt; instance.set_theta_values()\n\n        Returns:\n            None\n        \"\"\"\n        if self.n_theta &gt; self.k:\n            self.n_theta = self.k\n            logger.warning(\"More theta values than dimensions. `n_theta` set to `k`.\")\n        self.theta: List[float] = zeros(self.n_theta)\n        # TODO: Currently not used:\n        self.x0_theta: List[float] = ones((self.n_theta,)) * self.n / (100 * self.k)\n\n    def initialize_matrices(self) -&gt; None:\n\"\"\"\n        Initialize the matrices for the class instance.\n\n        This method initializes several matrices and attributes for the class instance.\n        The `p` attribute is initialized as a list of ones with length `n_p`, multiplied by 2.0.\n        The `pen_val` attribute is initialized as the natural logarithm of the\n        variance of `nat_y`, multiplied by `n`, plus 1e4.\n        The `negLnLike`, `LnDetPsi`, `mu`, `U`, `SigmaSqr`, and `Lambda` attributes are all set to None.\n        The `gen` attribute is initialized using the `spacefilling` function with arguments `k` and `seed`.\n        The `Psi` attribute is initialized as a zero matrix with shape `(n, n)` and dtype `float64`.\n        The `psi` attribute is initialized as a zero matrix with shape `(n, 1)`.\n        The `one` attribute is initialized as a list of ones with length `n`.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.n_p = 2\n            &gt;&gt;&gt;         self.n = 3\n            &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n            &gt;&gt;&gt;         self.k = 2\n            &gt;&gt;&gt;         self.seed = 1\n            &gt;&gt;&gt; instance = MyClass()\n            &gt;&gt;&gt; instance.initialize_matrices()\n\n        Returns:\n            None\n        \"\"\"\n        self.p = ones(self.n_p) * 2.0\n        self.pen_val = self.n * log(var(self.nat_y)) + 1e4\n        self.negLnLike = None\n        self.gen = spacefilling(k=self.k, seed=self.seed)\n        self.LnDetPsi = None\n        self.Psi = zeros((self.n, self.n), dtype=float64)\n        self.psi = zeros((self.n, 1))\n        self.one = ones(self.n)\n        self.mu = None\n        self.U = None\n        self.SigmaSqr = None\n        self.Lambda = None\n\n    def fun_likelihood(self, new_theta_p_Lambda: np.ndarray) -&gt; float:\n\"\"\"\n        Compute log likelihood for a set of hyperparameters (theta, p, Lambda).\n\n        This method computes the log likelihood for a set of hyperparameters\n        (theta, p, Lambda) by performing the following steps:\n        1. Extracts the hyperparameters from the input array using `extract_from_bounds()`.\n        2. Checks if any element in `10^theta` is equal to 0. If so, logs a warning and\n        returns the penalty value (`pen_val`).\n        3. Builds the `Psi` matrix using `build_Psi()`.\n        4. Checks if `Psi` is ill-conditioned or infinite. If so, logs a warning and returns\n        the penalty value (`pen_val`).\n        5. Builds the `U` matrix using `build_U()`. If an exception occurs, logs an error and\n        returns the penalty value (`pen_val`).\n        6. Computes the negative log likelihood using `likelihood()`.\n        7. Returns the computed negative log likelihood (`negLnLike`).\n\n        Args:\n            new_theta_p_Lambda (np.ndarray):\n                An array containing the `theta`, `p`, and `Lambda` values.\n\n        Returns:\n            float:\n                The negative log likelihood of the surface at the specified hyperparameters.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.n_p = 2\n            &gt;&gt;&gt;         self.n = 3\n            &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n            &gt;&gt;&gt;         self.k = 2\n            &gt;&gt;&gt;         self.seed = 1\n            &gt;&gt;&gt; instance = MyClass()\n            &gt;&gt;&gt; negLnLike = instance.fun_likelihood(new_theta_p_Lambda)\n            &gt;&gt;&gt; print(negLnLike)\n\n        \"\"\"\n        self.extract_from_bounds(new_theta_p_Lambda)\n        if self.__is_any__(power(10.0, self.theta), 0):\n            logger.warning(\"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to %s\", self.pen_val)\n            return self.pen_val\n        self.build_Psi()\n        if (self.inf_Psi or self.cnd_Psi &gt; 1e9):\n            logger.warning(\"Failure in fun_likelihood: Psi is ill conditioned: %s\", self.cnd_Psi)\n            logger.warning(\"Setting negLnLike to: %s\", self.pen_val)\n            return self.pen_val\n\n        try:\n            self.build_U()\n        except Exception as error:\n            penalty_value = self.pen_val\n            print(\"Error in fun_likelihood(). Call to build_U() failed.\")\n            print(\"error=%s, type(error)=%s\" % (error, type(error)))\n            print(\"Setting negLnLike to %.2f.\" % self.pen_val)\n            return penalty_value\n        self.likelihood()\n        return self.negLnLike\n\n    def __is_any__(self, x: Union[np.ndarray, Any], v: Any) -&gt; bool:\n\"\"\"\n        Check if any element in `x` is equal to `v`.\n\n        This method checks if any element in the input array `x` is equal to the value `v`.\n        If `x` is not an instance of `ndarray`, it is first converted to a numpy array using\n        the `array()` function.\n\n        Args:\n            x (np.ndarray or array-like):\n                The input array to check for the presence of value `v`.\n            v (scalar):\n                The value to check for in the input array `x`.\n\n        Returns:\n            bool:\n                True if any element in `x` is equal to `v`, False otherwise.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.n_p = 2\n            &gt;&gt;&gt;         self.n = 3\n            &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n            &gt;&gt;&gt;         self.k = 2\n            &gt;&gt;&gt;         self.seed = 1\n\n            &gt;&gt;&gt; instance = MyClass()\n            &gt;&gt;&gt; result = instance.__is_any__(x, v)\n            &gt;&gt;&gt; print(result)\n\n        \"\"\"\n        if not isinstance(x, ndarray):\n            x = array([x])\n        return any(x == v)\n\n    def build_Psi(self) -&gt; None:\n\"\"\"\n        Constructs a new (n x n) correlation matrix Psi to reflect new data\n        or a change in hyperparameters.\n\n        This method uses `theta`, `p`, and coded `X` values to construct the\n        correlation matrix as described in [Forr08a, p.57].\n\n        Args:\n            self: The object instance.\n\n        Returns:\n            None\n\n        Raises:\n            LinAlgError: If building Psi fails.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.n_p = 2\n            &gt;&gt;&gt;         self.n = 3\n            &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n            &gt;&gt;&gt;         self.k = 2\n            &gt;&gt;&gt;         self.seed = 1\n\n            &gt;&gt;&gt; obj = MyClass()\n            &gt;&gt;&gt; obj.build_Psi()\n\n        \"\"\"\n        self.Psi = zeros((self.n, self.n), dtype=float64)\n        theta = power(10.0, self.theta)\n        if self.n_theta == 1:\n            theta = theta * ones(self.k)\n        try:\n            D = zeros((self.n, self.n))\n            if self.ordered_mask.any():\n                X_ordered = self.cod_X[:, self.ordered_mask]\n                D = squareform(\n                    pdist(\n                        X_ordered, metric='sqeuclidean', out=None, w=theta[self.ordered_mask]))\n            if self.factor_mask.any():\n                X_factor = self.cod_X[:, self.factor_mask]\n                D = (D + squareform(\n                    pdist(X_factor,\n                          metric='hamming',\n                          out=None,\n                          w=theta[self.factor_mask])))\n            self.Psi = exp(-D)\n        except LinAlgError as err:\n            print(f\"Building Psi failed:\\n {self.Psi}. {err=}, {type(err)=}\")\n        if self.noise:\n            self.Psi[diag_indices_from(self.Psi)] += self.Lambda\n        else:\n            self.Psi[diag_indices_from(self.Psi)] += self.eps\n        if (isinf(self.Psi)).any():\n            self.inf_Psi = True\n        self.cnd_Psi = cond(self.Psi)\n\n    def build_U(self, scipy: bool = True) -&gt; None:\n\"\"\"\n        Performs Cholesky factorization of Psi as U as described in [Forr08a, p.57].\n\n        This method uses either `scipy_cholesky` or numpy's `cholesky` to perform the Cholesky factorization of Psi.\n\n        Args:\n            self: The object instance.\n            scipy (bool): If True, use `scipy_cholesky`. If False, use numpy's `cholesky`. Defaults to True.\n\n        Returns:\n            None\n\n        Raises:\n            LinAlgError: If Cholesky factorization fails for Psi.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.n_p = 2\n            &gt;&gt;&gt;         self.n = 3\n            &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n            &gt;&gt;&gt;         self.k = 2\n            &gt;&gt;&gt;         self.seed = 1\n\n            &gt;&gt;&gt; obj = MyClass()\n            &gt;&gt;&gt; obj.build_U()\n        \"\"\"\n        try:\n            self.U = scipy_cholesky(self.Psi, lower=True) if scipy else cholesky(self.Psi)\n            self.U = self.U.T\n        except LinAlgError as err:\n            print(f\"build_U() Cholesky failed for Psi:\\n {self.Psi}. {err=}, {type(err)=}\")\n\n    def likelihood(self) -&gt; None:\n\"\"\"\n        Calculates the negative of the concentrated log-likelihood.\n\n        This method implements equation (2.32) in [Forr08a] to calculate\n        the negative of the concentrated log-likelihood. It also modifies `mu`,\n        `SigmaSqr`, `LnDetPsi`, and `negLnLike`.\n\n        Note:\n            `build_Psi` and `build_U` should be called first.\n\n        Args:\n            self: The object instance.\n\n        Returns:\n            None\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.n_p = 2\n            &gt;&gt;&gt;         self.n = 3\n            &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n            &gt;&gt;&gt;         self.k = 2\n            &gt;&gt;&gt;         self.seed = 1\n\n            &gt;&gt;&gt; obj = MyClass()\n            &gt;&gt;&gt; obj.build_Psi()\n            &gt;&gt;&gt; obj.build_U()\n            &gt;&gt;&gt; obj.likelihood()\n        \"\"\"\n        # (2.20) in [Forr08a]:\n        U_T_inv_one = solve(self.U.T, self.one)\n        U_T_inv_cod_y = solve(self.U.T, self.cod_y)\n        mu = self.one.T.dot(solve(self.U, U_T_inv_cod_y)) / self.one.T.dot(solve(self.U, U_T_inv_one))\n        self.mu = mu\n        # (2.31) in [Forr08a]\n        cod_y_minus_mu = self.cod_y - self.one.dot(self.mu)\n        self.SigmaSqr = cod_y_minus_mu.T.dot(solve(self.U, solve(self.U.T, cod_y_minus_mu))) / self.n\n        # (2.32) in [Forr08a]\n        self.LnDetPsi = 2.0 * sum(log(abs(diag(self.U))))\n        self.negLnLike = -1.0 * (-(self.n / 2.0) * log(self.SigmaSqr) - 0.5 * self.LnDetPsi)\n\n    def plot(self, show: Optional[bool] = True) -&gt; None:\n\"\"\"\n        This function plots 1D and 2D surrogates.\n\n        Args:\n            show (bool): If `True`, the plots are displayed.\n            If `False`, `plt.show()` should be called outside this function.\n\n        Returns:\n            None\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; class MyClass(Kriging):\n            &gt;&gt;&gt;     def __init__(self):\n            &gt;&gt;&gt;         super().__init__()\n            &gt;&gt;&gt;         self.n_p = 2\n            &gt;&gt;&gt;         self.n = 3\n            &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n            &gt;&gt;&gt;         self.k = 2\n            &gt;&gt;&gt;         self.seed = 1\n\n            &gt;&gt;&gt; plot(show=True)\n        \"\"\"\n        if self.k == 1:\n            # TODO: Improve plot (add conf. interval etc.)\n            fig = pylab.figure(figsize=(9, 6))\n            # t1 = array(arange(0.0, 1.0, 0.01))\n            # y1 = array([self.predict(array([x]), return_val=\"y\") for x in t1])\n            # plt.figure()\n            # plt.plot(t1, y1, \"k\")\n            # if show:\n            #     plt.show()\n            #\n            n_grid = 100\n            x = linspace(\n                self.nat_range_X[0][0], self.nat_range_X[0][1], num=n_grid\n            )\n            y = self.predict(x)\n            plt.figure()\n            plt.plot(x, y, \"k\")\n            if show:\n                plt.show()\n\n        if self.k == 2:\n            fig = pylab.figure(figsize=(9, 6))\n            n_grid = 100\n            x = linspace(\n                self.nat_range_X[0][0], self.nat_range_X[0][1], num=n_grid\n            )\n            y = linspace(\n                self.nat_range_X[1][0], self.nat_range_X[1][1], num=n_grid\n            )\n            X, Y = meshgrid(x, y)\n            # Predict based on the optimized results\n            zz = array(\n                [self.predict(array([x, y]), return_val=\"all\") for x, y in zip(ravel(X), ravel(Y))]\n            )\n            zs = zz[:, 0, :]\n            zse = zz[:, 1, :]\n            Z = zs.reshape(X.shape)\n            Ze = zse.reshape(X.shape)\n\n            if self.cod_type == \"norm\":\n                nat_point_X = (\n                                      self.cod_X[:, 0] * (self.nat_range_X[0][1] - self.nat_range_X[0][0])\n                              ) + self.nat_range_X[0][0]\n                nat_point_Y = (\n                                      self.cod_X[:, 1] * (self.nat_range_X[1][1] - self.nat_range_X[1][0])\n                              ) + self.nat_range_X[1][0]\n            elif self.cod_type == \"std\":\n                nat_point_X = self.cod_X[:, 0] * self.nat_std_X[0] + self.nat_mean_X[0]\n                nat_point_Y = self.cod_X[:, 1] * self.nat_std_X[1] + self.nat_mean_X[1]\n            else:\n                nat_point_X = self.cod_X[:, 0]\n                nat_point_Y = self.cod_X[:, 1]\n            contour_levels = 30\n            ax = fig.add_subplot(224)\n            # plot predicted values:\n            pylab.contourf(X, Y, Ze, contour_levels, cmap=\"jet\")\n            pylab.title(\"Error\")\n            pylab.colorbar()\n            # plot observed points:\n            pylab.plot(nat_point_X, nat_point_Y, \"ow\")\n            #\n            ax = fig.add_subplot(223)\n            # plot predicted values:\n            plt.contourf(X, Y, Z, contour_levels, zorder=1, cmap=\"jet\")\n            plt.title(\"Surrogate\")\n            # plot observed points:\n            pylab.plot(nat_point_X, nat_point_Y, \"ow\", zorder=3)\n            pylab.colorbar()\n            #\n            ax = fig.add_subplot(221, projection=\"3d\")\n            ax.plot_surface(X, Y, Z, rstride=3, cstride=3, alpha=0.9, cmap=\"jet\")\n            #\n            ax = fig.add_subplot(222, projection=\"3d\")\n            ax.plot_surface(X, Y, Ze, rstride=3, cstride=3, alpha=0.9, cmap=\"jet\")\n            #\n            pylab.show()\n\n    def predict(self, nat_X: ndarray, nat: bool = True, return_val: str = \"y\") -&gt; Union[float,\n                                                                                        Tuple[float,\n                                                                                              float,\n                                                                                              float]]:\n\"\"\"\n        This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X.\n\n        Args:\n            nat_X (ndarray): Design variable to evaluate in natural units.\n            nat (bool): argument `nat_X` is in natural range. Default: `True`.\n                If set to `False`, `nat_X` will not be normalized (which might be useful\n                if already normalized y values are used).\n            return_val (str): whether `y`, `s`, neg. `ei` (negative expected improvement),\n            or all three values are returned.\n                Default is (for compatibility with sklearn) \"y\". To return `s`, select \"s\",\n                to return neg. `ei`, select \"ei\".\n                To return the tuple `(y, s, ei)`, select \"all\".\n\n        Returns:\n            float: The predicted value in natural units if return_val is \"y\".\n            float: predicted error if return_val is \"s\".\n            float: expected improvement if return_val is \"ei\".\n            Tuple[float, float, float]: The predicted value in natural units, predicted error\n            and expected improvement if return_val is \"all\".\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; from numpy import array\n            &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n            &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n            &gt;&gt;&gt; k = Kriging(X, y)\n            &gt;&gt;&gt; k.predict(array([[0.3, 0.3]]))\n            array([0.09])\n\n        \"\"\"\n        # Check for the shape and the type of the Input\n        if isinstance(nat_X, ndarray):\n            try:\n                X = nat_X.reshape(-1, self.nat_X.shape[1])\n                X = repair_non_numeric(X, self.var_type)\n            except Exception:\n                raise TypeError(\"13.1: Input to predict was not convertible to the size of X\")\n        else:\n            raise TypeError(f\"type of the given input is an {type(nat_X)} instead of an ndarray\")\n        n = X.shape[0]\n        y = empty(n, dtype=float)\n        s = empty(n, dtype=float)\n        ei = empty(n, dtype=float)\n        for i in range(n):\n            if nat:\n                x = self.nat_to_cod_x(X[i, :])\n            else:\n                x = X[i, :]\n            y[i], s[i], ei[i] = self.predict_coded(x)\n        if return_val == \"y\":\n            return y\n        elif return_val == \"s\":\n            return s\n        elif return_val == \"ei\":\n            return -1.0 * ei\n        else:\n            return y, s, -1.0 * ei\n\n    def build_psi_vec(self, cod_x: ndarray) -&gt; None:\n\"\"\"\n        Build the psi vector. Needed by `predict_cod`, `predict_err_coded`,\n        `regression_predict_coded`. Modifies `self.psi`.\n\n        Args:\n            cod_x (ndarray): point to calculate psi\n\n        Returns:\n            None\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; from numpy import array\n            &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n            &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n            &gt;&gt;&gt; k = Kriging(X, y)\n            &gt;&gt;&gt; cod_x = array([0.3, 0.3])\n            &gt;&gt;&gt; build_psi_vec(cod_x)\n\n        \"\"\"\n        self.psi = zeros((self.n))\n        # theta = self.theta  # TODO:\n        theta = power(10.0, self.theta)\n        if self.n_theta == 1:\n            theta = theta * ones(self.k)\n        try:\n            D = zeros((self.n))\n            if self.ordered_mask.any():\n                X_ordered = self.cod_X[:, self.ordered_mask]\n                x_ordered = cod_x[self.ordered_mask]\n                D = cdist(x_ordered.reshape(-1, sum(self.ordered_mask)),\n                          X_ordered.reshape(-1, sum(self.ordered_mask)),\n                          metric='sqeuclidean',\n                          out=None,\n                          w=theta[self.ordered_mask])\n            if self.factor_mask.any():\n                X_factor = self.cod_X[:, self.factor_mask]\n                x_factor = cod_x[self.factor_mask]\n                D = (D + cdist(x_factor.reshape(-1, sum(self.factor_mask)),\n                               X_factor.reshape(-1, sum(self.factor_mask)),\n                               metric='hamming',\n                               out=None,\n                               w=theta[self.factor_mask]))\n            self.psi = exp(-D).T\n        except LinAlgError as err:\n            print(f\"Building psi failed:\\n {self.psi}. {err=}, {type(err)=}\")\n\n    def predict_coded(self, cod_x: np.ndarray) -&gt; Tuple[float, float, float]:\n\"\"\"\n        Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a].\n        The error is returned as well.\n\n        Args:\n            cod_x (np.ndarray): Point in coded units to make prediction at.\n\n        Returns:\n            f (float): Predicted value in coded units.\n            SSqr (float): Predicted error.\n            EI (float): Expected improvement.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; from numpy import array\n            &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n            &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n            &gt;&gt;&gt; k = Kriging(X, y)\n            &gt;&gt;&gt; cod_x = array([0.3, 0.3])\n            &gt;&gt;&gt; k.predict_coded(cod_x)\n            (0.09, 0.0, 0.0)\n\n        Note:\n            `self.mu` and `self.SigmaSqr` are computed in `likelihood`, not here.\n            See also [Forr08a, p.60].\n        \"\"\"\n        self.build_psi_vec(cod_x)\n        U_T_inv = solve(self.U.T, self.cod_y - self.one.dot(self.mu))\n        f = self.mu + self.psi.T.dot(solve(self.U, U_T_inv))\n        if self.noise:\n            Lambda = self.Lambda\n        else:\n            Lambda = 0.0\n        # Error in [Forr08a, p.87]:\n        SSqr = self.SigmaSqr * (1 + Lambda - self.psi.T.dot(solve(self.U, solve(self.U.T, self.psi))))\n        SSqr = power(abs(SSqr[0]), 0.5)[0]\n        EI = self.exp_imp(y0=f[0], s0=SSqr)\n        return f[0], SSqr, EI\n\n    def weighted_exp_imp(self, cod_x: np.ndarray, w: float) -&gt; float:\n\"\"\"\n        Weighted expected improvement.\n\n        Args:\n            cod_x (np.ndarray): A coded design vector.\n            w (float): Weight.\n\n        Returns:\n            EI (float): Weighted expected improvement.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; from numpy import array\n            &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n            &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n            &gt;&gt;&gt; k = Kriging(X, y)\n            &gt;&gt;&gt; cod_x = array([0.3, 0.3])\n            &gt;&gt;&gt; w = 0.5\n            &gt;&gt;&gt; k.weighted_exp_imp(cod_x, w)\n            0.0\n\n        References:\n\n            [Sobester et al. 2005].\n        \"\"\"\n        y0, s0 = self.predict_coded(cod_x)\n        y_min = min(self.cod_y)\n        if s0 &lt;= 0.0:\n            EI = 0.0\n        else:\n            y_min_y0 = y_min - y0\n            EI_one = w * (\n                    y_min_y0\n                    * (0.5 + 0.5 * erf((1.0 / sqrt(2.0)) * (y_min_y0 / s0)))\n            )\n            EI_two = (\n                    (1.0 - w)\n                    * (s0 * (1.0 / sqrt(2.0 * pi)))\n                    * (exp(-(1.0 / 2.0) * ((y_min_y0) ** 2.0 / s0 ** 2.0)))\n            )\n            EI = EI_one + EI_two\n        return EI\n\n    def calculate_mean_MSE(self, n_samples: int = 200, points: Optional[np.ndarray] = None) -&gt; Tuple[float, float]:\n\"\"\"\n        Calculates the mean MSE metric of the model by evaluating MSE at a number of points.\n\n        Args:\n            n_samples (int): Number of points to sample the mean squared error at.\n            Ignored if the points argument is specified.\n            points (np.ndarray): An array of points to sample the model at.\n\n        Returns:\n            mean_MSE (float): The mean value of MSE.\n            std_MSE (float): The standard deviation of the MSE points.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; from numpy import array\n            &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n            &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n            &gt;&gt;&gt; k = Kriging(X, y)\n            &gt;&gt;&gt; n_samples = 200\n            &gt;&gt;&gt; mean_MSE, std_MSE = k.calculate_mean_MSE(n_samples)\n            &gt;&gt;&gt; print(f\"Mean MSE: {mean_MSE}, Standard deviation of MSE: {std_MSE}\")\n\n        \"\"\"\n        if points is None:\n            points = self.gen.lhd(n_samples)\n        values = [self.predict(cod_X=point, nat=True, return_val=\"s\") for point in points]\n        return mean(values), std(values)\n\n    def cod_to_nat_x(self, cod_X: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n        Converts an array representing one point in normalized (coded) units to natural (physical or real world) units.\n\n        Args:\n            cod_X (np.ndarray): An array representing one point (self.k long) in normalized (coded) units.\n\n        Returns:\n            X (np.ndarray): An array of natural (physical or real world) units.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; from numpy import array\n            &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n            &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n            &gt;&gt;&gt; k = Kriging(X, y)\n            &gt;&gt;&gt; cod_X = array([0.3, 0.3])\n            &gt;&gt;&gt; nat_X = k.cod_to_nat_x(cod_X)\n            &gt;&gt;&gt; print(f\"Natural units: {nat_X}\")\n\n        \"\"\"\n        X = copy.deepcopy(cod_X)\n        if self.cod_type == \"norm\":\n            for i in range(self.k):\n                X[i] = (\n                    X[i] * float(self.nat_range_X[i][1] - self.nat_range_X[i][0])\n                ) + self.nat_range_X[i][0]\n            return X\n        elif self.cod_type == \"std\":\n            for i in range(self.k):\n                X[i] = X[i] * self.nat_std_X[i] + self.nat_mean_X[i]\n            return X\n        else:\n            return cod_X\n\n    def cod_to_nat_y(self, cod_y: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n        Converts a normalized array of coded (model) units in the range of [0,1]\n        to an array of observed values in real-world units.\n\n        Args:\n            cod_y (np.ndarray): A normalized array of coded (model) units in the range of [0,1].\n\n        Returns:\n            y (np.ndarray): An array of observed values in real-world units.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; from numpy import array\n            &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n            &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n            &gt;&gt;&gt; k = Kriging(X, y)\n            &gt;&gt;&gt; cod_y = array([0.5, 0.5])\n            &gt;&gt;&gt; nat_y = k.cod_to_nat_y(cod_y)\n            &gt;&gt;&gt; print(f\"Real-world units: {nat_y}\")\n\n        \"\"\"\n        return (\n            cod_y * (self.nat_range_y[1] - self.nat_range_y[0]) + self.nat_range_y[0]\n            if self.cod_type == \"norm\"\n            else cod_y * self.nat_std_y + self.nat_mean_y\n            if self.cod_type == \"std\"\n            else cod_y\n        )\n\n    def nat_to_cod_x(self, nat_X: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n        Normalizes one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated.\n\n        Args:\n            nat_X (np.ndarray): An array representing one point (self.k long) in natural (physical or real world) units.\n\n        Returns:\n            X (np.ndarray): An array of coded values in the range of [0,1] for each dimension.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; from numpy import array\n            &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n            &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n            &gt;&gt;&gt; k = Kriging(X, y)\n            &gt;&gt;&gt; nat_X = array([5.0, 5.0])\n            &gt;&gt;&gt; cod_X = k.nat_to_cod_x(nat_X)\n            &gt;&gt;&gt; print(f\"Coded values: {cod_X}\")\n\n        \"\"\"\n        X = copy.deepcopy(nat_X)\n        if self.cod_type == \"norm\":\n            for i in range(self.k):\n                # TODO: Check Implementation of range correction if range == 0:\n                # rangex &lt;- xmax - xmin\n                # rangey &lt;- ymax - ymin\n                # xmin[rangex == 0] &lt;- xmin[rangex == 0] - 0.5\n                # xmax[rangex == 0] &lt;- xmax[rangex == 0] + 0.5\n                # rangex[rangex == 0] &lt;- 1\n                # logger.debug(f\"self.nat_range_X[{i}]:\\n {self.nat_range_X[i]}\")\n                # logger.debug(f\"X[{i}]:\\n {X[i]}\")\n                rangex = float(self.nat_range_X[i][1] - self.nat_range_X[i][0])\n                if rangex == 0:\n                    self.nat_range_X[i][0] = self.nat_range_X[i][0] - 0.5\n                    self.nat_range_X[i][1] = self.nat_range_X[i][1] + 0.5\n                X[i] = (X[i] - self.nat_range_X[i][0]) / float(\n                    self.nat_range_X[i][1] - self.nat_range_X[i][0]\n                )\n            return X\n        elif self.cod_type == \"std\":\n            for i in range(self.k):\n                X[i] = (X[i] - self.nat_mean_X[i]) / self.nat_std_X[i]\n            return X\n        else:\n            return nat_X\n\n    def nat_to_cod_y(self, nat_y: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n        Normalizes natural y values to [0,1].\n\n        Args:\n            nat_y (np.ndarray): An array of observed values in natural (real-world) units.\n\n        Returns:\n            y (np.ndarray): A normalized array of coded (model) units in the range of [0,1].\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; kriging = Kriging()\n            &gt;&gt;&gt; nat_y = np.array([5.0, 5.0])\n            &gt;&gt;&gt; cod_y = kriging.nat_to_cod_y(nat_y)\n            &gt;&gt;&gt; print(f\"Coded values: {cod_y}\")\n        \"\"\"\n        return (\n            (nat_y - self.nat_range_y[0]) / (self.nat_range_y[1] - self.nat_range_y[0])\n            if self.use_cod_y and self.cod_type == \"norm\"\n            else (nat_y - self.nat_mean_y) / self.nat_std_y\n            if self.use_cod_y and self.cod_type == \"std\"\n            else nat_y\n        )\n\n    def nat_to_cod_init(self) -&gt; None:\n\"\"\"\n        Determines max and min of each dimension and normalizes that axis to a range of [0,1].\n        Called when 1) surrogate is initialized and 2) new points arrive, i.e.,\n        suggested by the surrogate as infill points.\n        This method calls `nat_to_cod_x` and `nat_to_cod_y` and updates the ranges `nat_range_X` and `nat_range_y`.\n\n        Examples:\n\n            &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n            &gt;&gt;&gt; kriging = Kriging()\n            &gt;&gt;&gt; kriging.nat_to_cod_init()\n        \"\"\"\n        self.nat_range_X = []\n        self.nat_range_y = []\n        for i in range(self.k):\n            self.nat_range_X.append([min(self.nat_X[:, i]), max(self.nat_X[:, i])])\n        self.nat_range_y.append(min(self.nat_y))\n        self.nat_range_y.append(max(self.nat_y))\n        self.nat_mean_X = mean(self.nat_X, axis=0)\n        self.nat_std_X = std(self.nat_X, axis=0)\n        self.nat_mean_y = mean(self.nat_y)\n        self.nat_std_y = std(self.nat_y)\n        Z = aggregate_mean_var(X=self.nat_X, y=self.nat_y)\n        mu = Z[1]\n        self.mean_cod_y = empty_like(mu)\n\n        for i in range(self.n):\n            self.cod_X[i] = self.nat_to_cod_x(self.nat_X[i])\n        for i in range(self.n):\n            self.cod_y[i] = self.nat_to_cod_y(self.nat_y[i])\n        for i in range(mu.shape[0]):\n            self.mean_cod_y[i] = self.nat_to_cod_y(mu[i])\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.__init__","title":"<code>__init__(noise=False, cod_type='norm', var_type=['num'], use_cod_y=False, name='kriging', seed=124, model_optimizer=None, model_fun_evals=None, min_theta=-3, max_theta=2, n_theta=1, n_p=1, optim_p=False, log_level=50, spot_writer=None, counter=None, **kwargs)</code>","text":"<p>Kriging surrogate.</p> <p>Parameters:</p> Name Type Description Default <code>noise</code> <code>bool</code> <p>use regression instead of interpolation kriging. Defaults to \u201cFalse\u201d.</p> <code>False</code> <code>cod_type</code> <code>bool</code> <p>normalize or standardize X and values. Can be None, \u201cnorm\u201d, or \u201cstd\u201d. Defaults to \u201cnorm\u201d.</p> <code>'norm'</code> <code>var_type</code> <code>str</code> <p>variable type. Can be either <code>\"num</code>\u201d (numerical) of <code>\"factor\"</code> (factor). Defaults to <code>\"num\"</code>.</p> <code>['num']</code> <code>use_cod_y</code> <code>bool</code> <p>use coded y values (instead of natural one). Defaults to <code>False</code>.</p> <code>False</code> <code>name</code> <code>str</code> <p>Surrogate name. Defaults to <code>\"kriging\"</code>.</p> <code>'kriging'</code> <code>seed</code> <code>int</code> <p>Random seed. Defaults to <code>124</code>.</p> <code>124</code> <code>model_optimizer</code> <code>object</code> <p>Optimizer on the surrogate. If <code>None</code>, <code>differential_evolution</code> is selected.</p> <code>None</code> <code>model_fun_evals</code> <code>int</code> <p>Number of iterations used by the optimizer on the surrogate.</p> <code>None</code> <code>min_theta</code> <code>float</code> <p>min log10 theta value. Defaults to <code>-6.</code>.</p> <code>-3</code> <code>max_theta</code> <code>float</code> <p>max log10 theta value. Defaults to <code>3.</code>.</p> <code>2</code> <code>n_theta</code> <code>int</code> <p>number of theta values. Defaults to <code>1</code>.</p> <code>1</code> <code>n_p</code> <code>int</code> <p>number of p values. Defaults to <code>1</code>.</p> <code>1</code> <code>optim_p</code> <code>bool</code> <p>Determines whether <code>p</code> should be optimized.</p> <code>False</code> <code>log_level</code> <code>int</code> <p>logging level, e.g., <code>20</code> is <code>\"INFO\"</code>. Defaults to <code>50</code> (<code>\"CRITICAL\"</code>).</p> <code>50</code> <p>Attributes:</p> Name Type Description <code>nat_range_X</code> <code>list</code> <p>List of X natural ranges.</p> <code>nat_range_y</code> <code>list</code> <p>List of y nat ranges.</p> <code>noise</code> <code>bool</code> <p>noisy objective function. Default: False. If <code>True</code>, regression kriging will be used.</p> <code>var_type</code> <code>str</code> <p>variable type. Can be either <code>\"num</code>\u201d (numerical) of <code>\"factor\"</code> (factor).</p> <code>num_mask</code> <code>array</code> <p>array of bool variables. <code>True</code> represent numerical (float) variables.</p> <code>factor_mask</code> <code>array</code> <p>array of factor variables. <code>True</code> represents factor (unordered) variables.</p> <code>int_mask</code> <code>array</code> <p>array of integer variables. <code>True</code> represents integers (ordered) variables.</p> <code>ordered_mask</code> <code>array</code> <p>array of ordered variables. <code>True</code> represents integers or float (ordered) variables. Set of veriables which an order relation, i.e., they are either num (float) or int.</p> <code>name</code> <code>str</code> <p>Surrogate name</p> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>use_cod_y</code> <code>bool</code> <p>Use coded y values.</p> <code>sigma</code> <code>float</code> <p>Kriging sigma.</p> <code>gen</code> <code>method</code> <p>Design generator, e.g., spotPython.design.spacefilling.spacefilling.</p> <code>min_theta</code> <code>float</code> <p>min log10 theta value. Defaults: -6.</p> <code>max_theta</code> <code>float</code> <p>max log10 theta value. Defaults: 3.</p> <code>min_p</code> <code>float</code> <p>min p value. Default: 1.</p> <code>max_p</code> <code>float</code> <p>max p value. Default: 2.</p> <p>Examples:</p> <p>Surrogate of the x*sin(x) function. See: scikit-learn</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; rng = np.random.RandomState(1)\n&gt;&gt;&gt; X = linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\n&gt;&gt;&gt; y = np.squeeze(X * np.sin(X))\n&gt;&gt;&gt; training_indices = rng.choice(arange(y.size), size=6, replace=False)\n&gt;&gt;&gt; X_train, y_train = X[training_indices], y[training_indices]\n&gt;&gt;&gt; S = Kriging(name='kriging', seed=124)\n&gt;&gt;&gt; S.fit(X_train, y_train)\n&gt;&gt;&gt; mean_prediction, std_prediction = S.predict(X)\n&gt;&gt;&gt; plt.plot(X, y, label=r\"$f(x)$\", linestyle=\"dotted\")\n&gt;&gt;&gt; plt.scatter(X_train, y_train, label=\"Observations\")\n&gt;&gt;&gt; plt.plot(X, mean_prediction, label=\"Mean prediction\")\n&gt;&gt;&gt; plt.fill_between(\n    X.ravel(),\n    mean_prediction - 1.96 * std_prediction,\n    mean_prediction + 1.96 * std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n    )\n&gt;&gt;&gt; plt.legend()\n&gt;&gt;&gt; plt.xlabel(\"$x$\")\n&gt;&gt;&gt; plt.ylabel(\"$f(x)$\")\n&gt;&gt;&gt; _ = plt.title(\"Gaussian process regression on noise-free dataset\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def __init__(\n        self,\n        noise=False,\n        cod_type=\"norm\",\n        var_type=[\"num\"],\n        use_cod_y=False,\n        name=\"kriging\",\n        seed=124,\n        model_optimizer=None,\n        model_fun_evals=None,\n        min_theta=-3,  # TODO\n        max_theta=2,  # TODO\n        n_theta=1,\n        n_p=1,\n        optim_p=False,\n        log_level=50,\n        spot_writer=None,\n        counter=None,\n        **kwargs\n):\n\"\"\"\n    Kriging surrogate.\n\n    Args:\n        noise (bool):\n            use regression instead of interpolation kriging. Defaults to \"False\".\n        cod_type (bool):\n            normalize or standardize X and values. Can be None, \"norm\", or \"std\". Defaults to \"norm\".\n        var_type (str):\n            variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor).\n            Defaults to `\"num\"`.\n        use_cod_y (bool):\n            use coded y values (instead of natural one). Defaults to `False`.\n        name (str):\n            Surrogate name. Defaults to `\"kriging\"`.\n        seed (int):\n            Random seed. Defaults to `124`.\n        model_optimizer (object):\n            Optimizer on the surrogate. If `None`, `differential_evolution` is selected.\n        model_fun_evals (int):\n            Number of iterations used by the optimizer on the surrogate.\n        min_theta (float):\n            min log10 theta value. Defaults to `-6.`.\n        max_theta (float):\n            max log10 theta value. Defaults to `3.`.\n        n_theta (int):\n            number of theta values. Defaults to `1`.\n        n_p (int):\n            number of p values. Defaults to `1`.\n        optim_p (bool):\n            Determines whether `p` should be optimized.\n        log_level (int):\n            logging level, e.g., `20` is `\"INFO\"`. Defaults to `50` (`\"CRITICAL\"`).\n\n    Attributes:\n        nat_range_X (list):\n            List of X natural ranges.\n        nat_range_y (list):\n            List of y nat ranges.\n        noise (bool):\n            noisy objective function. Default: False. If `True`, regression kriging will be used.\n        var_type (str):\n            variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor).\n        num_mask (array):\n            array of bool variables. `True` represent numerical (float) variables.\n        factor_mask (array):\n            array of factor variables. `True` represents factor (unordered) variables.\n        int_mask (array):\n            array of integer variables. `True` represents integers (ordered) variables.\n        ordered_mask (array):\n            array of ordered variables. `True` represents integers or float (ordered) variables.\n            Set of veriables which an order relation, i.e., they are either num (float) or int.\n        name (str):\n            Surrogate name\n        seed (int):\n            Random seed.\n        use_cod_y (bool):\n            Use coded y values.\n        sigma (float):\n            Kriging sigma.\n        gen (method):\n            Design generator, e.g., spotPython.design.spacefilling.spacefilling.\n        min_theta (float):\n            min log10 theta value. Defaults: -6.\n        max_theta (float):\n            max log10 theta value. Defaults: 3.\n        min_p (float):\n            min p value. Default: 1.\n        max_p (float):\n            max p value. Default: 2.\n\n    Examples:\n        Surrogate of the x*sin(x) function.\n        See:\n        [scikit-learn](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html)\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; import matplotlib.pyplot as plt\n        &gt;&gt;&gt; rng = np.random.RandomState(1)\n        &gt;&gt;&gt; X = linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\n        &gt;&gt;&gt; y = np.squeeze(X * np.sin(X))\n        &gt;&gt;&gt; training_indices = rng.choice(arange(y.size), size=6, replace=False)\n        &gt;&gt;&gt; X_train, y_train = X[training_indices], y[training_indices]\n        &gt;&gt;&gt; S = Kriging(name='kriging', seed=124)\n        &gt;&gt;&gt; S.fit(X_train, y_train)\n        &gt;&gt;&gt; mean_prediction, std_prediction = S.predict(X)\n        &gt;&gt;&gt; plt.plot(X, y, label=r\"$f(x)$\", linestyle=\"dotted\")\n        &gt;&gt;&gt; plt.scatter(X_train, y_train, label=\"Observations\")\n        &gt;&gt;&gt; plt.plot(X, mean_prediction, label=\"Mean prediction\")\n        &gt;&gt;&gt; plt.fill_between(\n            X.ravel(),\n            mean_prediction - 1.96 * std_prediction,\n            mean_prediction + 1.96 * std_prediction,\n            alpha=0.5,\n            label=r\"95% confidence interval\",\n            )\n        &gt;&gt;&gt; plt.legend()\n        &gt;&gt;&gt; plt.xlabel(\"$x$\")\n        &gt;&gt;&gt; plt.ylabel(\"$f(x)$\")\n        &gt;&gt;&gt; _ = plt.title(\"Gaussian process regression on noise-free dataset\")\n\n    \"\"\"\n    super().__init__(name, seed, log_level)\n\n    self.noise = noise\n    self.var_type = var_type\n    self.cod_type = cod_type\n    self.use_cod_y = use_cod_y\n    self.name = name\n    self.seed = seed\n    self.log_level = log_level\n    self.spot_writer = spot_writer\n    self.counter = counter\n\n    self.sigma = 0\n    self.eps = sqrt(spacing(1))\n    self.min_theta = min_theta\n    self.max_theta = max_theta\n    self.min_p = 1\n    self.max_p = 2\n    self.min_Lambda = 1e-9\n    self.max_Lambda = 1.\n    self.n_theta = n_theta\n    self.n_p = n_p\n    self.optim_p = optim_p\n    # Psi matrix condition:\n    self.cnd_Psi = 0\n    self.inf_Psi = False\n\n    self.model_optimizer = model_optimizer\n    if self.model_optimizer is None:\n        self.model_optimizer = differential_evolution\n    self.model_fun_evals = model_fun_evals\n    # differential evaluation uses maxiter = 1000\n    # and sets the number of function evaluations to\n    # (maxiter + 1) * popsize * N, which results in\n    # 1000 * 15 * k, because the default popsize is 15 and\n    # N is the number of parameters. This seems to be quite large:\n    # for k=2 these are 30 000 iterations. Therefore we set this value to\n    # 100\n    if self.model_fun_evals is None:\n        self.model_fun_evals = 100\n\n    # Logging information\n    self.log[\"negLnLike\"] = []\n    self.log[\"theta\"] = []\n    self.log[\"p\"] = []\n    self.log[\"Lambda\"] = []\n    # Logger\n    logger.setLevel(self.log_level)\n    logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.__is_any__","title":"<code>__is_any__(x, v)</code>","text":"<p>Check if any element in <code>x</code> is equal to <code>v</code>.</p> <p>This method checks if any element in the input array <code>x</code> is equal to the value <code>v</code>. If <code>x</code> is not an instance of <code>ndarray</code>, it is first converted to a numpy array using the <code>array()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>np.ndarray or array-like</code> <p>The input array to check for the presence of value <code>v</code>.</p> required <code>v</code> <code>scalar</code> <p>The value to check for in the input array <code>x</code>.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if any element in <code>x</code> is equal to <code>v</code>, False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.n_p = 2\n&gt;&gt;&gt;         self.n = 3\n&gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n&gt;&gt;&gt;         self.k = 2\n&gt;&gt;&gt;         self.seed = 1\n</code></pre> <pre><code>&gt;&gt;&gt; instance = MyClass()\n&gt;&gt;&gt; result = instance.__is_any__(x, v)\n&gt;&gt;&gt; print(result)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def __is_any__(self, x: Union[np.ndarray, Any], v: Any) -&gt; bool:\n\"\"\"\n    Check if any element in `x` is equal to `v`.\n\n    This method checks if any element in the input array `x` is equal to the value `v`.\n    If `x` is not an instance of `ndarray`, it is first converted to a numpy array using\n    the `array()` function.\n\n    Args:\n        x (np.ndarray or array-like):\n            The input array to check for the presence of value `v`.\n        v (scalar):\n            The value to check for in the input array `x`.\n\n    Returns:\n        bool:\n            True if any element in `x` is equal to `v`, False otherwise.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.n_p = 2\n        &gt;&gt;&gt;         self.n = 3\n        &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n        &gt;&gt;&gt;         self.k = 2\n        &gt;&gt;&gt;         self.seed = 1\n\n        &gt;&gt;&gt; instance = MyClass()\n        &gt;&gt;&gt; result = instance.__is_any__(x, v)\n        &gt;&gt;&gt; print(result)\n\n    \"\"\"\n    if not isinstance(x, ndarray):\n        x = array([x])\n    return any(x == v)\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.build_Psi","title":"<code>build_Psi()</code>","text":"<p>Constructs a new (n x n) correlation matrix Psi to reflect new data or a change in hyperparameters.</p> <p>This method uses <code>theta</code>, <code>p</code>, and coded <code>X</code> values to construct the correlation matrix as described in [Forr08a, p.57].</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <p>The object instance.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>LinAlgError</code> <p>If building Psi fails.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.n_p = 2\n&gt;&gt;&gt;         self.n = 3\n&gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n&gt;&gt;&gt;         self.k = 2\n&gt;&gt;&gt;         self.seed = 1\n</code></pre> <pre><code>&gt;&gt;&gt; obj = MyClass()\n&gt;&gt;&gt; obj.build_Psi()\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def build_Psi(self) -&gt; None:\n\"\"\"\n    Constructs a new (n x n) correlation matrix Psi to reflect new data\n    or a change in hyperparameters.\n\n    This method uses `theta`, `p`, and coded `X` values to construct the\n    correlation matrix as described in [Forr08a, p.57].\n\n    Args:\n        self: The object instance.\n\n    Returns:\n        None\n\n    Raises:\n        LinAlgError: If building Psi fails.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.n_p = 2\n        &gt;&gt;&gt;         self.n = 3\n        &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n        &gt;&gt;&gt;         self.k = 2\n        &gt;&gt;&gt;         self.seed = 1\n\n        &gt;&gt;&gt; obj = MyClass()\n        &gt;&gt;&gt; obj.build_Psi()\n\n    \"\"\"\n    self.Psi = zeros((self.n, self.n), dtype=float64)\n    theta = power(10.0, self.theta)\n    if self.n_theta == 1:\n        theta = theta * ones(self.k)\n    try:\n        D = zeros((self.n, self.n))\n        if self.ordered_mask.any():\n            X_ordered = self.cod_X[:, self.ordered_mask]\n            D = squareform(\n                pdist(\n                    X_ordered, metric='sqeuclidean', out=None, w=theta[self.ordered_mask]))\n        if self.factor_mask.any():\n            X_factor = self.cod_X[:, self.factor_mask]\n            D = (D + squareform(\n                pdist(X_factor,\n                      metric='hamming',\n                      out=None,\n                      w=theta[self.factor_mask])))\n        self.Psi = exp(-D)\n    except LinAlgError as err:\n        print(f\"Building Psi failed:\\n {self.Psi}. {err=}, {type(err)=}\")\n    if self.noise:\n        self.Psi[diag_indices_from(self.Psi)] += self.Lambda\n    else:\n        self.Psi[diag_indices_from(self.Psi)] += self.eps\n    if (isinf(self.Psi)).any():\n        self.inf_Psi = True\n    self.cnd_Psi = cond(self.Psi)\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.build_U","title":"<code>build_U(scipy=True)</code>","text":"<p>Performs Cholesky factorization of Psi as U as described in [Forr08a, p.57].</p> <p>This method uses either <code>scipy_cholesky</code> or numpy\u2019s <code>cholesky</code> to perform the Cholesky factorization of Psi.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <p>The object instance.</p> required <code>scipy</code> <code>bool</code> <p>If True, use <code>scipy_cholesky</code>. If False, use numpy\u2019s <code>cholesky</code>. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>LinAlgError</code> <p>If Cholesky factorization fails for Psi.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.n_p = 2\n&gt;&gt;&gt;         self.n = 3\n&gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n&gt;&gt;&gt;         self.k = 2\n&gt;&gt;&gt;         self.seed = 1\n</code></pre> <pre><code>&gt;&gt;&gt; obj = MyClass()\n&gt;&gt;&gt; obj.build_U()\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def build_U(self, scipy: bool = True) -&gt; None:\n\"\"\"\n    Performs Cholesky factorization of Psi as U as described in [Forr08a, p.57].\n\n    This method uses either `scipy_cholesky` or numpy's `cholesky` to perform the Cholesky factorization of Psi.\n\n    Args:\n        self: The object instance.\n        scipy (bool): If True, use `scipy_cholesky`. If False, use numpy's `cholesky`. Defaults to True.\n\n    Returns:\n        None\n\n    Raises:\n        LinAlgError: If Cholesky factorization fails for Psi.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.n_p = 2\n        &gt;&gt;&gt;         self.n = 3\n        &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n        &gt;&gt;&gt;         self.k = 2\n        &gt;&gt;&gt;         self.seed = 1\n\n        &gt;&gt;&gt; obj = MyClass()\n        &gt;&gt;&gt; obj.build_U()\n    \"\"\"\n    try:\n        self.U = scipy_cholesky(self.Psi, lower=True) if scipy else cholesky(self.Psi)\n        self.U = self.U.T\n    except LinAlgError as err:\n        print(f\"build_U() Cholesky failed for Psi:\\n {self.Psi}. {err=}, {type(err)=}\")\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.build_psi_vec","title":"<code>build_psi_vec(cod_x)</code>","text":"<p>Build the psi vector. Needed by <code>predict_cod</code>, <code>predict_err_coded</code>, <code>regression_predict_coded</code>. Modifies <code>self.psi</code>.</p> <p>Parameters:</p> Name Type Description Default <code>cod_x</code> <code>ndarray</code> <p>point to calculate psi</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; from numpy import array\n&gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n&gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n&gt;&gt;&gt; k = Kriging(X, y)\n&gt;&gt;&gt; cod_x = array([0.3, 0.3])\n&gt;&gt;&gt; build_psi_vec(cod_x)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def build_psi_vec(self, cod_x: ndarray) -&gt; None:\n\"\"\"\n    Build the psi vector. Needed by `predict_cod`, `predict_err_coded`,\n    `regression_predict_coded`. Modifies `self.psi`.\n\n    Args:\n        cod_x (ndarray): point to calculate psi\n\n    Returns:\n        None\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; from numpy import array\n        &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n        &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n        &gt;&gt;&gt; k = Kriging(X, y)\n        &gt;&gt;&gt; cod_x = array([0.3, 0.3])\n        &gt;&gt;&gt; build_psi_vec(cod_x)\n\n    \"\"\"\n    self.psi = zeros((self.n))\n    # theta = self.theta  # TODO:\n    theta = power(10.0, self.theta)\n    if self.n_theta == 1:\n        theta = theta * ones(self.k)\n    try:\n        D = zeros((self.n))\n        if self.ordered_mask.any():\n            X_ordered = self.cod_X[:, self.ordered_mask]\n            x_ordered = cod_x[self.ordered_mask]\n            D = cdist(x_ordered.reshape(-1, sum(self.ordered_mask)),\n                      X_ordered.reshape(-1, sum(self.ordered_mask)),\n                      metric='sqeuclidean',\n                      out=None,\n                      w=theta[self.ordered_mask])\n        if self.factor_mask.any():\n            X_factor = self.cod_X[:, self.factor_mask]\n            x_factor = cod_x[self.factor_mask]\n            D = (D + cdist(x_factor.reshape(-1, sum(self.factor_mask)),\n                           X_factor.reshape(-1, sum(self.factor_mask)),\n                           metric='hamming',\n                           out=None,\n                           w=theta[self.factor_mask]))\n        self.psi = exp(-D).T\n    except LinAlgError as err:\n        print(f\"Building psi failed:\\n {self.psi}. {err=}, {type(err)=}\")\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.calculate_mean_MSE","title":"<code>calculate_mean_MSE(n_samples=200, points=None)</code>","text":"<p>Calculates the mean MSE metric of the model by evaluating MSE at a number of points.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>Number of points to sample the mean squared error at.</p> <code>200</code> <code>points</code> <code>np.ndarray</code> <p>An array of points to sample the model at.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mean_MSE</code> <code>float</code> <p>The mean value of MSE.</p> <code>std_MSE</code> <code>float</code> <p>The standard deviation of the MSE points.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; from numpy import array\n&gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n&gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n&gt;&gt;&gt; k = Kriging(X, y)\n&gt;&gt;&gt; n_samples = 200\n&gt;&gt;&gt; mean_MSE, std_MSE = k.calculate_mean_MSE(n_samples)\n&gt;&gt;&gt; print(f\"Mean MSE: {mean_MSE}, Standard deviation of MSE: {std_MSE}\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def calculate_mean_MSE(self, n_samples: int = 200, points: Optional[np.ndarray] = None) -&gt; Tuple[float, float]:\n\"\"\"\n    Calculates the mean MSE metric of the model by evaluating MSE at a number of points.\n\n    Args:\n        n_samples (int): Number of points to sample the mean squared error at.\n        Ignored if the points argument is specified.\n        points (np.ndarray): An array of points to sample the model at.\n\n    Returns:\n        mean_MSE (float): The mean value of MSE.\n        std_MSE (float): The standard deviation of the MSE points.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; from numpy import array\n        &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n        &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n        &gt;&gt;&gt; k = Kriging(X, y)\n        &gt;&gt;&gt; n_samples = 200\n        &gt;&gt;&gt; mean_MSE, std_MSE = k.calculate_mean_MSE(n_samples)\n        &gt;&gt;&gt; print(f\"Mean MSE: {mean_MSE}, Standard deviation of MSE: {std_MSE}\")\n\n    \"\"\"\n    if points is None:\n        points = self.gen.lhd(n_samples)\n    values = [self.predict(cod_X=point, nat=True, return_val=\"s\") for point in points]\n    return mean(values), std(values)\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.cod_to_nat_x","title":"<code>cod_to_nat_x(cod_X)</code>","text":"<p>Converts an array representing one point in normalized (coded) units to natural (physical or real world) units.</p> <p>Parameters:</p> Name Type Description Default <code>cod_X</code> <code>np.ndarray</code> <p>An array representing one point (self.k long) in normalized (coded) units.</p> required <p>Returns:</p> Name Type Description <code>X</code> <code>np.ndarray</code> <p>An array of natural (physical or real world) units.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; from numpy import array\n&gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n&gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n&gt;&gt;&gt; k = Kriging(X, y)\n&gt;&gt;&gt; cod_X = array([0.3, 0.3])\n&gt;&gt;&gt; nat_X = k.cod_to_nat_x(cod_X)\n&gt;&gt;&gt; print(f\"Natural units: {nat_X}\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def cod_to_nat_x(self, cod_X: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Converts an array representing one point in normalized (coded) units to natural (physical or real world) units.\n\n    Args:\n        cod_X (np.ndarray): An array representing one point (self.k long) in normalized (coded) units.\n\n    Returns:\n        X (np.ndarray): An array of natural (physical or real world) units.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; from numpy import array\n        &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n        &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n        &gt;&gt;&gt; k = Kriging(X, y)\n        &gt;&gt;&gt; cod_X = array([0.3, 0.3])\n        &gt;&gt;&gt; nat_X = k.cod_to_nat_x(cod_X)\n        &gt;&gt;&gt; print(f\"Natural units: {nat_X}\")\n\n    \"\"\"\n    X = copy.deepcopy(cod_X)\n    if self.cod_type == \"norm\":\n        for i in range(self.k):\n            X[i] = (\n                X[i] * float(self.nat_range_X[i][1] - self.nat_range_X[i][0])\n            ) + self.nat_range_X[i][0]\n        return X\n    elif self.cod_type == \"std\":\n        for i in range(self.k):\n            X[i] = X[i] * self.nat_std_X[i] + self.nat_mean_X[i]\n        return X\n    else:\n        return cod_X\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.cod_to_nat_y","title":"<code>cod_to_nat_y(cod_y)</code>","text":"<p>Converts a normalized array of coded (model) units in the range of [0,1] to an array of observed values in real-world units.</p> <p>Parameters:</p> Name Type Description Default <code>cod_y</code> <code>np.ndarray</code> <p>A normalized array of coded (model) units in the range of [0,1].</p> required <p>Returns:</p> Name Type Description <code>y</code> <code>np.ndarray</code> <p>An array of observed values in real-world units.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; from numpy import array\n&gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n&gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n&gt;&gt;&gt; k = Kriging(X, y)\n&gt;&gt;&gt; cod_y = array([0.5, 0.5])\n&gt;&gt;&gt; nat_y = k.cod_to_nat_y(cod_y)\n&gt;&gt;&gt; print(f\"Real-world units: {nat_y}\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def cod_to_nat_y(self, cod_y: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Converts a normalized array of coded (model) units in the range of [0,1]\n    to an array of observed values in real-world units.\n\n    Args:\n        cod_y (np.ndarray): A normalized array of coded (model) units in the range of [0,1].\n\n    Returns:\n        y (np.ndarray): An array of observed values in real-world units.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; from numpy import array\n        &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n        &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n        &gt;&gt;&gt; k = Kriging(X, y)\n        &gt;&gt;&gt; cod_y = array([0.5, 0.5])\n        &gt;&gt;&gt; nat_y = k.cod_to_nat_y(cod_y)\n        &gt;&gt;&gt; print(f\"Real-world units: {nat_y}\")\n\n    \"\"\"\n    return (\n        cod_y * (self.nat_range_y[1] - self.nat_range_y[0]) + self.nat_range_y[0]\n        if self.cod_type == \"norm\"\n        else cod_y * self.nat_std_y + self.nat_mean_y\n        if self.cod_type == \"std\"\n        else cod_y\n    )\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.exp_imp","title":"<code>exp_imp(y0, s0)</code>","text":"<p>Calculates the expected improvement for a given function value and error in coded units.</p> <p>Parameters:</p> Name Type Description Default <code>y0</code> <code>float</code> <p>The function value in coded units.</p> required <code>s0</code> <code>float</code> <p>The error value.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The expected improvement value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; S = Kriging(name='kriging', seed=124)\n&gt;&gt;&gt; S.cod_y = [0.0, 0.0, 0.0, 0.0, 0.0]\n&gt;&gt;&gt; S.mean_cod_y = [0.0, 0.0, 0.0, 0.0, 0.0]\n&gt;&gt;&gt; S.exp_imp(1.0, 2.0)\n0.0\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def exp_imp(self, y0: float, s0: float) -&gt; float:\n\"\"\"\n    Calculates the expected improvement for a given function value and error in coded units.\n\n    Args:\n        y0 (float): The function value in coded units.\n        s0 (float): The error value.\n\n    Returns:\n        float: The expected improvement value.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; S = Kriging(name='kriging', seed=124)\n        &gt;&gt;&gt; S.cod_y = [0.0, 0.0, 0.0, 0.0, 0.0]\n        &gt;&gt;&gt; S.mean_cod_y = [0.0, 0.0, 0.0, 0.0, 0.0]\n        &gt;&gt;&gt; S.exp_imp(1.0, 2.0)\n        0.0\n\n    \"\"\"\n    # y_min = min(self.cod_y)\n    y_min = min(self.mean_cod_y)\n    if s0 &lt;= 0.0:\n        EI = 0.0\n    elif s0 &gt; 0.0:\n        EI_one = (y_min - y0) * (\n                0.5 + 0.5 * erf((1.0 / sqrt(2.0)) * ((y_min - y0) / s0))\n        )\n        EI_two = (s0 * (1.0 / sqrt(2.0 * pi))) * (\n            exp(-(1.0 / 2.0) * ((y_min - y0) ** 2.0 / s0 ** 2.0))\n        )\n        EI = EI_one + EI_two\n    return EI\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.extract_from_bounds","title":"<code>extract_from_bounds(new_theta_p_Lambda)</code>","text":"<p>Extract <code>theta</code>, <code>p</code>, and <code>Lambda</code> from bounds. The kriging object stores <code>theta</code> as an array,  <code>p</code> as an array, and <code>Lambda</code> as a float.</p> <p>Parameters:</p> Name Type Description Default <code>new_theta_p_Lambda</code> <code>np.ndarray</code> <p>1d-array with theta, p, and Lambda values. Order is important.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n&gt;&gt;&gt; obj = MyClass()\n&gt;&gt;&gt; obj.extract_from_bounds(np.array([1, 2, 3]))\n&gt;&gt;&gt; print(obj.theta)\n[1]\n&gt;&gt;&gt; print(obj.p)\n[2]\n&gt;&gt;&gt; print(obj.Lambda)\n3\n</code></pre> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def extract_from_bounds(self, new_theta_p_Lambda: np.ndarray) -&gt; None:\n\"\"\"\n    Extract `theta`, `p`, and `Lambda` from bounds. The kriging object stores\n    `theta` as an array,  `p` as an array, and `Lambda` as a float.\n\n    Args:\n        new_theta_p_Lambda (np.ndarray):\n            1d-array with theta, p, and Lambda values. Order is important.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n        &gt;&gt;&gt; obj = MyClass()\n        &gt;&gt;&gt; obj.extract_from_bounds(np.array([1, 2, 3]))\n        &gt;&gt;&gt; print(obj.theta)\n        [1]\n        &gt;&gt;&gt; print(obj.p)\n        [2]\n        &gt;&gt;&gt; print(obj.Lambda)\n        3\n\n    Returns:\n        None\n    \"\"\"\n    self.theta = new_theta_p_Lambda[:self.n_theta]\n    if self.optim_p:\n        self.p = new_theta_p_Lambda[self.n_theta:self.n_theta + self.n_p]\n        if self.noise:\n            self.Lambda = new_theta_p_Lambda[self.n_theta + self.n_p]\n    else:\n        if self.noise:\n            self.Lambda = new_theta_p_Lambda[self.n_theta]\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.fit","title":"<code>fit(nat_X, nat_y)</code>","text":"<p>Fits the hyperparameters (<code>theta</code>, <code>p</code>, <code>Lambda</code>) of the Kriging model.</p> <p>The function computes the following internal values: 1. <code>theta</code>, <code>p</code>, and <code>Lambda</code> values via optimization of the function <code>fun_likelihood()</code>. 2. Correlation matrix <code>Psi</code> via <code>rebuildPsi()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>nat_X</code> <code>np.ndarray</code> <p>Sample points.</p> required <code>nat_y</code> <code>np.ndarray</code> <p>Function values.</p> required <p>Returns:</p> Name Type Description <code>object</code> <code>object</code> <p>Fitted estimator.</p> <p>Attributes:</p> Name Type Description <code>theta</code> <code>np.ndarray</code> <p>Kriging theta values. Shape (k,).</p> <code>p</code> <code>np.ndarray</code> <p>Kriging p values. Shape (k,).</p> <code>LnDetPsi</code> <code>np.float64</code> <p>Determinant Psi matrix.</p> <code>Psi</code> <code>np.matrix</code> <p>Correlation matrix Psi. Shape (n,n).</p> <code>psi</code> <code>np.ndarray</code> <p>psi vector. Shape (n,).</p> <code>one</code> <code>np.ndarray</code> <p>vector of ones. Shape (n,).</p> <code>mu</code> <code>np.float64</code> <p>Kriging expected mean value mu.</p> <code>U</code> <code>np.matrix</code> <p>Kriging U matrix, Cholesky decomposition. Shape (n,n).</p> <code>SigmaSqr</code> <code>np.float64</code> <p>Sigma squared value.</p> <code>Lambda</code> <code>float</code> <p>lambda noise value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; nat_X = np.array([[1, 2], [3, 4]])\n&gt;&gt;&gt; nat_y = np.array([1, 2])\n&gt;&gt;&gt; surrogate = Kriging()\n&gt;&gt;&gt; surrogate.fit(nat_X, nat_y)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def fit(self, nat_X: np.ndarray, nat_y: np.ndarray) -&gt; object:\n\"\"\"\n    Fits the hyperparameters (`theta`, `p`, `Lambda`) of the Kriging model.\n\n    The function computes the following internal values:\n    1. `theta`, `p`, and `Lambda` values via optimization of the function `fun_likelihood()`.\n    2. Correlation matrix `Psi` via `rebuildPsi()`.\n\n    Args:\n        nat_X (np.ndarray): Sample points.\n        nat_y (np.ndarray): Function values.\n\n    Returns:\n        object: Fitted estimator.\n\n    Attributes:\n        theta (np.ndarray): Kriging theta values. Shape (k,).\n        p (np.ndarray): Kriging p values. Shape (k,).\n        LnDetPsi (np.float64): Determinant Psi matrix.\n        Psi (np.matrix): Correlation matrix Psi. Shape (n,n).\n        psi (np.ndarray): psi vector. Shape (n,).\n        one (np.ndarray): vector of ones. Shape (n,).\n        mu (np.float64): Kriging expected mean value mu.\n        U (np.matrix): Kriging U matrix, Cholesky decomposition. Shape (n,n).\n        SigmaSqr (np.float64): Sigma squared value.\n        Lambda (float): lambda noise value.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; nat_X = np.array([[1, 2], [3, 4]])\n        &gt;&gt;&gt; nat_y = np.array([1, 2])\n        &gt;&gt;&gt; surrogate = Kriging()\n        &gt;&gt;&gt; surrogate.fit(nat_X, nat_y)\n    \"\"\"\n    self.initialize_variables(nat_X, nat_y)\n    self.set_variable_types()\n    self.nat_to_cod_init()\n    self.set_theta_values()\n    self.initialize_matrices()\n    # build_Psi() and build_U() are called in fun_likelihood\n    self.set_de_bounds()\n    # Finally, set new theta and p values and update the surrogate again\n    # for new_theta_p_Lambda in de_results[\"x\"]:\n    new_theta_p_Lambda = self.optimize_model()\n    self.extract_from_bounds(new_theta_p_Lambda)\n    self.build_Psi()\n    self.build_U()\n    # TODO: check if the following line is necessary!\n    self.likelihood()\n    self.update_log()\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.fun_likelihood","title":"<code>fun_likelihood(new_theta_p_Lambda)</code>","text":"<p>Compute log likelihood for a set of hyperparameters (theta, p, Lambda).</p> <p>This method computes the log likelihood for a set of hyperparameters (theta, p, Lambda) by performing the following steps: 1. Extracts the hyperparameters from the input array using <code>extract_from_bounds()</code>. 2. Checks if any element in <code>10^theta</code> is equal to 0. If so, logs a warning and returns the penalty value (<code>pen_val</code>). 3. Builds the <code>Psi</code> matrix using <code>build_Psi()</code>. 4. Checks if <code>Psi</code> is ill-conditioned or infinite. If so, logs a warning and returns the penalty value (<code>pen_val</code>). 5. Builds the <code>U</code> matrix using <code>build_U()</code>. If an exception occurs, logs an error and returns the penalty value (<code>pen_val</code>). 6. Computes the negative log likelihood using <code>likelihood()</code>. 7. Returns the computed negative log likelihood (<code>negLnLike</code>).</p> <p>Parameters:</p> Name Type Description Default <code>new_theta_p_Lambda</code> <code>np.ndarray</code> <p>An array containing the <code>theta</code>, <code>p</code>, and <code>Lambda</code> values.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The negative log likelihood of the surface at the specified hyperparameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.n_p = 2\n&gt;&gt;&gt;         self.n = 3\n&gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n&gt;&gt;&gt;         self.k = 2\n&gt;&gt;&gt;         self.seed = 1\n&gt;&gt;&gt; instance = MyClass()\n&gt;&gt;&gt; negLnLike = instance.fun_likelihood(new_theta_p_Lambda)\n&gt;&gt;&gt; print(negLnLike)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def fun_likelihood(self, new_theta_p_Lambda: np.ndarray) -&gt; float:\n\"\"\"\n    Compute log likelihood for a set of hyperparameters (theta, p, Lambda).\n\n    This method computes the log likelihood for a set of hyperparameters\n    (theta, p, Lambda) by performing the following steps:\n    1. Extracts the hyperparameters from the input array using `extract_from_bounds()`.\n    2. Checks if any element in `10^theta` is equal to 0. If so, logs a warning and\n    returns the penalty value (`pen_val`).\n    3. Builds the `Psi` matrix using `build_Psi()`.\n    4. Checks if `Psi` is ill-conditioned or infinite. If so, logs a warning and returns\n    the penalty value (`pen_val`).\n    5. Builds the `U` matrix using `build_U()`. If an exception occurs, logs an error and\n    returns the penalty value (`pen_val`).\n    6. Computes the negative log likelihood using `likelihood()`.\n    7. Returns the computed negative log likelihood (`negLnLike`).\n\n    Args:\n        new_theta_p_Lambda (np.ndarray):\n            An array containing the `theta`, `p`, and `Lambda` values.\n\n    Returns:\n        float:\n            The negative log likelihood of the surface at the specified hyperparameters.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.n_p = 2\n        &gt;&gt;&gt;         self.n = 3\n        &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n        &gt;&gt;&gt;         self.k = 2\n        &gt;&gt;&gt;         self.seed = 1\n        &gt;&gt;&gt; instance = MyClass()\n        &gt;&gt;&gt; negLnLike = instance.fun_likelihood(new_theta_p_Lambda)\n        &gt;&gt;&gt; print(negLnLike)\n\n    \"\"\"\n    self.extract_from_bounds(new_theta_p_Lambda)\n    if self.__is_any__(power(10.0, self.theta), 0):\n        logger.warning(\"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to %s\", self.pen_val)\n        return self.pen_val\n    self.build_Psi()\n    if (self.inf_Psi or self.cnd_Psi &gt; 1e9):\n        logger.warning(\"Failure in fun_likelihood: Psi is ill conditioned: %s\", self.cnd_Psi)\n        logger.warning(\"Setting negLnLike to: %s\", self.pen_val)\n        return self.pen_val\n\n    try:\n        self.build_U()\n    except Exception as error:\n        penalty_value = self.pen_val\n        print(\"Error in fun_likelihood(). Call to build_U() failed.\")\n        print(\"error=%s, type(error)=%s\" % (error, type(error)))\n        print(\"Setting negLnLike to %.2f.\" % self.pen_val)\n        return penalty_value\n    self.likelihood()\n    return self.negLnLike\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.initialize_matrices","title":"<code>initialize_matrices()</code>","text":"<p>Initialize the matrices for the class instance.</p> <p>This method initializes several matrices and attributes for the class instance. The <code>p</code> attribute is initialized as a list of ones with length <code>n_p</code>, multiplied by 2.0. The <code>pen_val</code> attribute is initialized as the natural logarithm of the variance of <code>nat_y</code>, multiplied by <code>n</code>, plus 1e4. The <code>negLnLike</code>, <code>LnDetPsi</code>, <code>mu</code>, <code>U</code>, <code>SigmaSqr</code>, and <code>Lambda</code> attributes are all set to None. The <code>gen</code> attribute is initialized using the <code>spacefilling</code> function with arguments <code>k</code> and <code>seed</code>. The <code>Psi</code> attribute is initialized as a zero matrix with shape <code>(n, n)</code> and dtype <code>float64</code>. The <code>psi</code> attribute is initialized as a zero matrix with shape <code>(n, 1)</code>. The <code>one</code> attribute is initialized as a list of ones with length <code>n</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.n_p = 2\n&gt;&gt;&gt;         self.n = 3\n&gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n&gt;&gt;&gt;         self.k = 2\n&gt;&gt;&gt;         self.seed = 1\n&gt;&gt;&gt; instance = MyClass()\n&gt;&gt;&gt; instance.initialize_matrices()\n</code></pre> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def initialize_matrices(self) -&gt; None:\n\"\"\"\n    Initialize the matrices for the class instance.\n\n    This method initializes several matrices and attributes for the class instance.\n    The `p` attribute is initialized as a list of ones with length `n_p`, multiplied by 2.0.\n    The `pen_val` attribute is initialized as the natural logarithm of the\n    variance of `nat_y`, multiplied by `n`, plus 1e4.\n    The `negLnLike`, `LnDetPsi`, `mu`, `U`, `SigmaSqr`, and `Lambda` attributes are all set to None.\n    The `gen` attribute is initialized using the `spacefilling` function with arguments `k` and `seed`.\n    The `Psi` attribute is initialized as a zero matrix with shape `(n, n)` and dtype `float64`.\n    The `psi` attribute is initialized as a zero matrix with shape `(n, 1)`.\n    The `one` attribute is initialized as a list of ones with length `n`.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.n_p = 2\n        &gt;&gt;&gt;         self.n = 3\n        &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n        &gt;&gt;&gt;         self.k = 2\n        &gt;&gt;&gt;         self.seed = 1\n        &gt;&gt;&gt; instance = MyClass()\n        &gt;&gt;&gt; instance.initialize_matrices()\n\n    Returns:\n        None\n    \"\"\"\n    self.p = ones(self.n_p) * 2.0\n    self.pen_val = self.n * log(var(self.nat_y)) + 1e4\n    self.negLnLike = None\n    self.gen = spacefilling(k=self.k, seed=self.seed)\n    self.LnDetPsi = None\n    self.Psi = zeros((self.n, self.n), dtype=float64)\n    self.psi = zeros((self.n, 1))\n    self.one = ones(self.n)\n    self.mu = None\n    self.U = None\n    self.SigmaSqr = None\n    self.Lambda = None\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.initialize_variables","title":"<code>initialize_variables(nat_X, nat_y)</code>","text":"<p>Initialize variables for the class instance.</p> <p>This method takes in the independent and dependent variable data as input and initializes the class instance variables. It creates deep copies of the input data and stores them in the instance variables <code>nat_X</code> and <code>nat_y</code>. It also calculates the number of observations <code>n</code> and the number of independent variables <code>k</code> from the shape of <code>nat_X</code>. Finally, it creates empty arrays with the same shape as <code>nat_X</code> and <code>nat_y</code> and stores them in the instance variables <code>cod_X</code> and <code>cod_y</code>.</p> <p>Parameters:</p> Name Type Description Default <code>nat_X</code> <code>np.ndarray</code> <p>The independent variable data.</p> required <code>nat_y</code> <code>np.ndarray</code> <p>The dependent variable data.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; surrogate = Kriging()\n&gt;&gt;&gt; nat_X = np.array([[1, 2], [3, 4]])\n&gt;&gt;&gt; nat_y = np.array([1, 2])\n&gt;&gt;&gt; surrogate.initialize_variables(nat_X, nat_y)\n&gt;&gt;&gt; surrogate.nat_X\narray([[1, 2],\n         [3, 4]])\n&gt;&gt;&gt; surrogate.nat_y\narray([1, 2])\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def initialize_variables(self, nat_X: np.ndarray, nat_y: np.ndarray) -&gt; None:\n\"\"\"\n    Initialize variables for the class instance.\n\n    This method takes in the independent and dependent variable data as input\n    and initializes the class instance variables.\n    It creates deep copies of the input data and stores them in the\n    instance variables `nat_X` and `nat_y`.\n    It also calculates the number of observations `n` and\n    the number of independent variables `k` from the shape of `nat_X`.\n    Finally, it creates empty arrays with the same shape as `nat_X`\n    and `nat_y` and stores them in the instance variables `cod_X` and `cod_y`.\n\n    Args:\n        nat_X (np.ndarray): The independent variable data.\n        nat_y (np.ndarray): The dependent variable data.\n\n    Returns:\n        None\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; surrogate = Kriging()\n        &gt;&gt;&gt; nat_X = np.array([[1, 2], [3, 4]])\n        &gt;&gt;&gt; nat_y = np.array([1, 2])\n        &gt;&gt;&gt; surrogate.initialize_variables(nat_X, nat_y)\n        &gt;&gt;&gt; surrogate.nat_X\n        array([[1, 2],\n                 [3, 4]])\n        &gt;&gt;&gt; surrogate.nat_y\n        array([1, 2])\n\n    \"\"\"\n    self.nat_X = copy.deepcopy(nat_X)\n    self.nat_y = copy.deepcopy(nat_y)\n    self.n = self.nat_X.shape[0]\n    self.k = self.nat_X.shape[1]\n    self.cod_X = np.empty_like(self.nat_X)\n    self.cod_y = np.empty_like(self.nat_y)\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.likelihood","title":"<code>likelihood()</code>","text":"<p>Calculates the negative of the concentrated log-likelihood.</p> <p>This method implements equation (2.32) in [Forr08a] to calculate the negative of the concentrated log-likelihood. It also modifies <code>mu</code>, <code>SigmaSqr</code>, <code>LnDetPsi</code>, and <code>negLnLike</code>.</p> Note <p><code>build_Psi</code> and <code>build_U</code> should be called first.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <p>The object instance.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.n_p = 2\n&gt;&gt;&gt;         self.n = 3\n&gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n&gt;&gt;&gt;         self.k = 2\n&gt;&gt;&gt;         self.seed = 1\n</code></pre> <pre><code>&gt;&gt;&gt; obj = MyClass()\n&gt;&gt;&gt; obj.build_Psi()\n&gt;&gt;&gt; obj.build_U()\n&gt;&gt;&gt; obj.likelihood()\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def likelihood(self) -&gt; None:\n\"\"\"\n    Calculates the negative of the concentrated log-likelihood.\n\n    This method implements equation (2.32) in [Forr08a] to calculate\n    the negative of the concentrated log-likelihood. It also modifies `mu`,\n    `SigmaSqr`, `LnDetPsi`, and `negLnLike`.\n\n    Note:\n        `build_Psi` and `build_U` should be called first.\n\n    Args:\n        self: The object instance.\n\n    Returns:\n        None\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.n_p = 2\n        &gt;&gt;&gt;         self.n = 3\n        &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n        &gt;&gt;&gt;         self.k = 2\n        &gt;&gt;&gt;         self.seed = 1\n\n        &gt;&gt;&gt; obj = MyClass()\n        &gt;&gt;&gt; obj.build_Psi()\n        &gt;&gt;&gt; obj.build_U()\n        &gt;&gt;&gt; obj.likelihood()\n    \"\"\"\n    # (2.20) in [Forr08a]:\n    U_T_inv_one = solve(self.U.T, self.one)\n    U_T_inv_cod_y = solve(self.U.T, self.cod_y)\n    mu = self.one.T.dot(solve(self.U, U_T_inv_cod_y)) / self.one.T.dot(solve(self.U, U_T_inv_one))\n    self.mu = mu\n    # (2.31) in [Forr08a]\n    cod_y_minus_mu = self.cod_y - self.one.dot(self.mu)\n    self.SigmaSqr = cod_y_minus_mu.T.dot(solve(self.U, solve(self.U.T, cod_y_minus_mu))) / self.n\n    # (2.32) in [Forr08a]\n    self.LnDetPsi = 2.0 * sum(log(abs(diag(self.U))))\n    self.negLnLike = -1.0 * (-(self.n / 2.0) * log(self.SigmaSqr) - 0.5 * self.LnDetPsi)\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.nat_to_cod_init","title":"<code>nat_to_cod_init()</code>","text":"<p>Determines max and min of each dimension and normalizes that axis to a range of [0,1]. Called when 1) surrogate is initialized and 2) new points arrive, i.e., suggested by the surrogate as infill points. This method calls <code>nat_to_cod_x</code> and <code>nat_to_cod_y</code> and updates the ranges <code>nat_range_X</code> and <code>nat_range_y</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; kriging = Kriging()\n&gt;&gt;&gt; kriging.nat_to_cod_init()\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def nat_to_cod_init(self) -&gt; None:\n\"\"\"\n    Determines max and min of each dimension and normalizes that axis to a range of [0,1].\n    Called when 1) surrogate is initialized and 2) new points arrive, i.e.,\n    suggested by the surrogate as infill points.\n    This method calls `nat_to_cod_x` and `nat_to_cod_y` and updates the ranges `nat_range_X` and `nat_range_y`.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; kriging = Kriging()\n        &gt;&gt;&gt; kriging.nat_to_cod_init()\n    \"\"\"\n    self.nat_range_X = []\n    self.nat_range_y = []\n    for i in range(self.k):\n        self.nat_range_X.append([min(self.nat_X[:, i]), max(self.nat_X[:, i])])\n    self.nat_range_y.append(min(self.nat_y))\n    self.nat_range_y.append(max(self.nat_y))\n    self.nat_mean_X = mean(self.nat_X, axis=0)\n    self.nat_std_X = std(self.nat_X, axis=0)\n    self.nat_mean_y = mean(self.nat_y)\n    self.nat_std_y = std(self.nat_y)\n    Z = aggregate_mean_var(X=self.nat_X, y=self.nat_y)\n    mu = Z[1]\n    self.mean_cod_y = empty_like(mu)\n\n    for i in range(self.n):\n        self.cod_X[i] = self.nat_to_cod_x(self.nat_X[i])\n    for i in range(self.n):\n        self.cod_y[i] = self.nat_to_cod_y(self.nat_y[i])\n    for i in range(mu.shape[0]):\n        self.mean_cod_y[i] = self.nat_to_cod_y(mu[i])\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.nat_to_cod_x","title":"<code>nat_to_cod_x(nat_X)</code>","text":"<p>Normalizes one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated.</p> <p>Parameters:</p> Name Type Description Default <code>nat_X</code> <code>np.ndarray</code> <p>An array representing one point (self.k long) in natural (physical or real world) units.</p> required <p>Returns:</p> Name Type Description <code>X</code> <code>np.ndarray</code> <p>An array of coded values in the range of [0,1] for each dimension.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; from numpy import array\n&gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n&gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n&gt;&gt;&gt; k = Kriging(X, y)\n&gt;&gt;&gt; nat_X = array([5.0, 5.0])\n&gt;&gt;&gt; cod_X = k.nat_to_cod_x(nat_X)\n&gt;&gt;&gt; print(f\"Coded values: {cod_X}\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def nat_to_cod_x(self, nat_X: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Normalizes one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated.\n\n    Args:\n        nat_X (np.ndarray): An array representing one point (self.k long) in natural (physical or real world) units.\n\n    Returns:\n        X (np.ndarray): An array of coded values in the range of [0,1] for each dimension.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; from numpy import array\n        &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n        &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n        &gt;&gt;&gt; k = Kriging(X, y)\n        &gt;&gt;&gt; nat_X = array([5.0, 5.0])\n        &gt;&gt;&gt; cod_X = k.nat_to_cod_x(nat_X)\n        &gt;&gt;&gt; print(f\"Coded values: {cod_X}\")\n\n    \"\"\"\n    X = copy.deepcopy(nat_X)\n    if self.cod_type == \"norm\":\n        for i in range(self.k):\n            # TODO: Check Implementation of range correction if range == 0:\n            # rangex &lt;- xmax - xmin\n            # rangey &lt;- ymax - ymin\n            # xmin[rangex == 0] &lt;- xmin[rangex == 0] - 0.5\n            # xmax[rangex == 0] &lt;- xmax[rangex == 0] + 0.5\n            # rangex[rangex == 0] &lt;- 1\n            # logger.debug(f\"self.nat_range_X[{i}]:\\n {self.nat_range_X[i]}\")\n            # logger.debug(f\"X[{i}]:\\n {X[i]}\")\n            rangex = float(self.nat_range_X[i][1] - self.nat_range_X[i][0])\n            if rangex == 0:\n                self.nat_range_X[i][0] = self.nat_range_X[i][0] - 0.5\n                self.nat_range_X[i][1] = self.nat_range_X[i][1] + 0.5\n            X[i] = (X[i] - self.nat_range_X[i][0]) / float(\n                self.nat_range_X[i][1] - self.nat_range_X[i][0]\n            )\n        return X\n    elif self.cod_type == \"std\":\n        for i in range(self.k):\n            X[i] = (X[i] - self.nat_mean_X[i]) / self.nat_std_X[i]\n        return X\n    else:\n        return nat_X\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.nat_to_cod_y","title":"<code>nat_to_cod_y(nat_y)</code>","text":"<p>Normalizes natural y values to [0,1].</p> <p>Parameters:</p> Name Type Description Default <code>nat_y</code> <code>np.ndarray</code> <p>An array of observed values in natural (real-world) units.</p> required <p>Returns:</p> Name Type Description <code>y</code> <code>np.ndarray</code> <p>A normalized array of coded (model) units in the range of [0,1].</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; kriging = Kriging()\n&gt;&gt;&gt; nat_y = np.array([5.0, 5.0])\n&gt;&gt;&gt; cod_y = kriging.nat_to_cod_y(nat_y)\n&gt;&gt;&gt; print(f\"Coded values: {cod_y}\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def nat_to_cod_y(self, nat_y: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Normalizes natural y values to [0,1].\n\n    Args:\n        nat_y (np.ndarray): An array of observed values in natural (real-world) units.\n\n    Returns:\n        y (np.ndarray): A normalized array of coded (model) units in the range of [0,1].\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; kriging = Kriging()\n        &gt;&gt;&gt; nat_y = np.array([5.0, 5.0])\n        &gt;&gt;&gt; cod_y = kriging.nat_to_cod_y(nat_y)\n        &gt;&gt;&gt; print(f\"Coded values: {cod_y}\")\n    \"\"\"\n    return (\n        (nat_y - self.nat_range_y[0]) / (self.nat_range_y[1] - self.nat_range_y[0])\n        if self.use_cod_y and self.cod_type == \"norm\"\n        else (nat_y - self.nat_mean_y) / self.nat_std_y\n        if self.use_cod_y and self.cod_type == \"std\"\n        else nat_y\n    )\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.optimize_model","title":"<code>optimize_model()</code>","text":"<p>Optimize the model using the specified model_optimizer.</p> <p>This method uses the specified model_optimizer to optimize the likelihood function (<code>fun_likelihood</code>) with respect to the model parameters. The optimization is performed within the bounds specified by the attribute <code>de_bounds</code>. The result of the optimization is returned as a list or tuple of optimized parameter values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n&gt;&gt;&gt; obj = MyClass()\n&gt;&gt;&gt; result = obj.optimize_model()\n&gt;&gt;&gt; print(result)\n[optimized_theta, optimized_p, optimized_Lambda]\n</code></pre> <p>Returns:</p> Type Description <code>Union[List[float], Tuple[float]]</code> <p>result[\u201cx\u201d] (Union[List[float], Tuple[float]]): A list or tuple of optimized parameter values.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def optimize_model(self) -&gt; Union[List[float], Tuple[float]]:\n\"\"\"\n    Optimize the model using the specified model_optimizer.\n\n    This method uses the specified model_optimizer to optimize the\n    likelihood function (`fun_likelihood`) with respect to the model parameters.\n    The optimization is performed within the bounds specified by the attribute\n    `de_bounds`.\n    The result of the optimization is returned as a list or tuple of optimized parameter values.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n        &gt;&gt;&gt; obj = MyClass()\n        &gt;&gt;&gt; result = obj.optimize_model()\n        &gt;&gt;&gt; print(result)\n        [optimized_theta, optimized_p, optimized_Lambda]\n\n    Returns:\n        result[\"x\"] (Union[List[float], Tuple[float]]):\n            A list or tuple of optimized parameter values.\n    \"\"\"\n    if self.model_optimizer.__name__ == 'dual_annealing':\n        result = self.model_optimizer(func=self.fun_likelihood,\n                                      bounds=self.de_bounds)\n    elif self.model_optimizer.__name__ == 'differential_evolution':\n        result = self.model_optimizer(func=self.fun_likelihood,\n                                      bounds=self.de_bounds,\n                                      maxiter=self.model_fun_evals,\n                                      seed=self.seed)\n    elif self.model_optimizer.__name__ == 'direct':\n        result = self.model_optimizer(func=self.fun_likelihood,\n                                      bounds=self.de_bounds,\n                                      # maxfun=self.model_fun_evals,\n                                      eps=1e-2)\n    elif self.model_optimizer.__name__ == 'shgo':\n        result = self.model_optimizer(func=self.fun_likelihood,\n                                      bounds=self.de_bounds)\n    elif self.model_optimizer.__name__ == 'basinhopping':\n        result = self.model_optimizer(func=self.fun_likelihood,\n                                      x0=mean(self.de_bounds, axis=1))\n    else:\n        result = self.model_optimizer(func=self.fun_likelihood, bounds=self.de_bounds)\n    return result[\"x\"]\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.plot","title":"<code>plot(show=True)</code>","text":"<p>This function plots 1D and 2D surrogates.</p> <p>Parameters:</p> Name Type Description Default <code>show</code> <code>bool</code> <p>If <code>True</code>, the plots are displayed.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.n_p = 2\n&gt;&gt;&gt;         self.n = 3\n&gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n&gt;&gt;&gt;         self.k = 2\n&gt;&gt;&gt;         self.seed = 1\n</code></pre> <pre><code>&gt;&gt;&gt; plot(show=True)\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def plot(self, show: Optional[bool] = True) -&gt; None:\n\"\"\"\n    This function plots 1D and 2D surrogates.\n\n    Args:\n        show (bool): If `True`, the plots are displayed.\n        If `False`, `plt.show()` should be called outside this function.\n\n    Returns:\n        None\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.n_p = 2\n        &gt;&gt;&gt;         self.n = 3\n        &gt;&gt;&gt;         self.nat_y = np.array([1, 2, 3])\n        &gt;&gt;&gt;         self.k = 2\n        &gt;&gt;&gt;         self.seed = 1\n\n        &gt;&gt;&gt; plot(show=True)\n    \"\"\"\n    if self.k == 1:\n        # TODO: Improve plot (add conf. interval etc.)\n        fig = pylab.figure(figsize=(9, 6))\n        # t1 = array(arange(0.0, 1.0, 0.01))\n        # y1 = array([self.predict(array([x]), return_val=\"y\") for x in t1])\n        # plt.figure()\n        # plt.plot(t1, y1, \"k\")\n        # if show:\n        #     plt.show()\n        #\n        n_grid = 100\n        x = linspace(\n            self.nat_range_X[0][0], self.nat_range_X[0][1], num=n_grid\n        )\n        y = self.predict(x)\n        plt.figure()\n        plt.plot(x, y, \"k\")\n        if show:\n            plt.show()\n\n    if self.k == 2:\n        fig = pylab.figure(figsize=(9, 6))\n        n_grid = 100\n        x = linspace(\n            self.nat_range_X[0][0], self.nat_range_X[0][1], num=n_grid\n        )\n        y = linspace(\n            self.nat_range_X[1][0], self.nat_range_X[1][1], num=n_grid\n        )\n        X, Y = meshgrid(x, y)\n        # Predict based on the optimized results\n        zz = array(\n            [self.predict(array([x, y]), return_val=\"all\") for x, y in zip(ravel(X), ravel(Y))]\n        )\n        zs = zz[:, 0, :]\n        zse = zz[:, 1, :]\n        Z = zs.reshape(X.shape)\n        Ze = zse.reshape(X.shape)\n\n        if self.cod_type == \"norm\":\n            nat_point_X = (\n                                  self.cod_X[:, 0] * (self.nat_range_X[0][1] - self.nat_range_X[0][0])\n                          ) + self.nat_range_X[0][0]\n            nat_point_Y = (\n                                  self.cod_X[:, 1] * (self.nat_range_X[1][1] - self.nat_range_X[1][0])\n                          ) + self.nat_range_X[1][0]\n        elif self.cod_type == \"std\":\n            nat_point_X = self.cod_X[:, 0] * self.nat_std_X[0] + self.nat_mean_X[0]\n            nat_point_Y = self.cod_X[:, 1] * self.nat_std_X[1] + self.nat_mean_X[1]\n        else:\n            nat_point_X = self.cod_X[:, 0]\n            nat_point_Y = self.cod_X[:, 1]\n        contour_levels = 30\n        ax = fig.add_subplot(224)\n        # plot predicted values:\n        pylab.contourf(X, Y, Ze, contour_levels, cmap=\"jet\")\n        pylab.title(\"Error\")\n        pylab.colorbar()\n        # plot observed points:\n        pylab.plot(nat_point_X, nat_point_Y, \"ow\")\n        #\n        ax = fig.add_subplot(223)\n        # plot predicted values:\n        plt.contourf(X, Y, Z, contour_levels, zorder=1, cmap=\"jet\")\n        plt.title(\"Surrogate\")\n        # plot observed points:\n        pylab.plot(nat_point_X, nat_point_Y, \"ow\", zorder=3)\n        pylab.colorbar()\n        #\n        ax = fig.add_subplot(221, projection=\"3d\")\n        ax.plot_surface(X, Y, Z, rstride=3, cstride=3, alpha=0.9, cmap=\"jet\")\n        #\n        ax = fig.add_subplot(222, projection=\"3d\")\n        ax.plot_surface(X, Y, Ze, rstride=3, cstride=3, alpha=0.9, cmap=\"jet\")\n        #\n        pylab.show()\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.predict","title":"<code>predict(nat_X, nat=True, return_val='y')</code>","text":"<p>This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X.</p> <p>Parameters:</p> Name Type Description Default <code>nat_X</code> <code>ndarray</code> <p>Design variable to evaluate in natural units.</p> required <code>nat</code> <code>bool</code> <p>argument <code>nat_X</code> is in natural range. Default: <code>True</code>. If set to <code>False</code>, <code>nat_X</code> will not be normalized (which might be useful if already normalized y values are used).</p> <code>True</code> <code>return_val</code> <code>str</code> <p>whether <code>y</code>, <code>s</code>, neg. <code>ei</code> (negative expected improvement),</p> <code>'y'</code> <p>Returns:</p> Name Type Description <code>float</code> <code>Union[float, Tuple[float, float, float]]</code> <p>The predicted value in natural units if return_val is \u201cy\u201d.</p> <code>float</code> <code>Union[float, Tuple[float, float, float]]</code> <p>predicted error if return_val is \u201cs\u201d.</p> <code>float</code> <code>Union[float, Tuple[float, float, float]]</code> <p>expected improvement if return_val is \u201cei\u201d.</p> <code>Union[float, Tuple[float, float, float]]</code> <p>Tuple[float, float, float]: The predicted value in natural units, predicted error</p> <code>Union[float, Tuple[float, float, float]]</code> <p>and expected improvement if return_val is \u201call\u201d.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; from numpy import array\n&gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n&gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n&gt;&gt;&gt; k = Kriging(X, y)\n&gt;&gt;&gt; k.predict(array([[0.3, 0.3]]))\narray([0.09])\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def predict(self, nat_X: ndarray, nat: bool = True, return_val: str = \"y\") -&gt; Union[float,\n                                                                                    Tuple[float,\n                                                                                          float,\n                                                                                          float]]:\n\"\"\"\n    This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X.\n\n    Args:\n        nat_X (ndarray): Design variable to evaluate in natural units.\n        nat (bool): argument `nat_X` is in natural range. Default: `True`.\n            If set to `False`, `nat_X` will not be normalized (which might be useful\n            if already normalized y values are used).\n        return_val (str): whether `y`, `s`, neg. `ei` (negative expected improvement),\n        or all three values are returned.\n            Default is (for compatibility with sklearn) \"y\". To return `s`, select \"s\",\n            to return neg. `ei`, select \"ei\".\n            To return the tuple `(y, s, ei)`, select \"all\".\n\n    Returns:\n        float: The predicted value in natural units if return_val is \"y\".\n        float: predicted error if return_val is \"s\".\n        float: expected improvement if return_val is \"ei\".\n        Tuple[float, float, float]: The predicted value in natural units, predicted error\n        and expected improvement if return_val is \"all\".\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; from numpy import array\n        &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n        &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n        &gt;&gt;&gt; k = Kriging(X, y)\n        &gt;&gt;&gt; k.predict(array([[0.3, 0.3]]))\n        array([0.09])\n\n    \"\"\"\n    # Check for the shape and the type of the Input\n    if isinstance(nat_X, ndarray):\n        try:\n            X = nat_X.reshape(-1, self.nat_X.shape[1])\n            X = repair_non_numeric(X, self.var_type)\n        except Exception:\n            raise TypeError(\"13.1: Input to predict was not convertible to the size of X\")\n    else:\n        raise TypeError(f\"type of the given input is an {type(nat_X)} instead of an ndarray\")\n    n = X.shape[0]\n    y = empty(n, dtype=float)\n    s = empty(n, dtype=float)\n    ei = empty(n, dtype=float)\n    for i in range(n):\n        if nat:\n            x = self.nat_to_cod_x(X[i, :])\n        else:\n            x = X[i, :]\n        y[i], s[i], ei[i] = self.predict_coded(x)\n    if return_val == \"y\":\n        return y\n    elif return_val == \"s\":\n        return s\n    elif return_val == \"ei\":\n        return -1.0 * ei\n    else:\n        return y, s, -1.0 * ei\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.predict_coded","title":"<code>predict_coded(cod_x)</code>","text":"<p>Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a]. The error is returned as well.</p> <p>Parameters:</p> Name Type Description Default <code>cod_x</code> <code>np.ndarray</code> <p>Point in coded units to make prediction at.</p> required <p>Returns:</p> Name Type Description <code>f</code> <code>float</code> <p>Predicted value in coded units.</p> <code>SSqr</code> <code>float</code> <p>Predicted error.</p> <code>EI</code> <code>float</code> <p>Expected improvement.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; from numpy import array\n&gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n&gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n&gt;&gt;&gt; k = Kriging(X, y)\n&gt;&gt;&gt; cod_x = array([0.3, 0.3])\n&gt;&gt;&gt; k.predict_coded(cod_x)\n(0.09, 0.0, 0.0)\n</code></pre> Note <p><code>self.mu</code> and <code>self.SigmaSqr</code> are computed in <code>likelihood</code>, not here. See also [Forr08a, p.60].</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def predict_coded(self, cod_x: np.ndarray) -&gt; Tuple[float, float, float]:\n\"\"\"\n    Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a].\n    The error is returned as well.\n\n    Args:\n        cod_x (np.ndarray): Point in coded units to make prediction at.\n\n    Returns:\n        f (float): Predicted value in coded units.\n        SSqr (float): Predicted error.\n        EI (float): Expected improvement.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; from numpy import array\n        &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n        &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n        &gt;&gt;&gt; k = Kriging(X, y)\n        &gt;&gt;&gt; cod_x = array([0.3, 0.3])\n        &gt;&gt;&gt; k.predict_coded(cod_x)\n        (0.09, 0.0, 0.0)\n\n    Note:\n        `self.mu` and `self.SigmaSqr` are computed in `likelihood`, not here.\n        See also [Forr08a, p.60].\n    \"\"\"\n    self.build_psi_vec(cod_x)\n    U_T_inv = solve(self.U.T, self.cod_y - self.one.dot(self.mu))\n    f = self.mu + self.psi.T.dot(solve(self.U, U_T_inv))\n    if self.noise:\n        Lambda = self.Lambda\n    else:\n        Lambda = 0.0\n    # Error in [Forr08a, p.87]:\n    SSqr = self.SigmaSqr * (1 + Lambda - self.psi.T.dot(solve(self.U, solve(self.U.T, self.psi))))\n    SSqr = power(abs(SSqr[0]), 0.5)[0]\n    EI = self.exp_imp(y0=f[0], s0=SSqr)\n    return f[0], SSqr, EI\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.set_de_bounds","title":"<code>set_de_bounds()</code>","text":"<p>Determine search bounds for model_optimizer, e.g., differential evolution.</p> <p>This method sets the attribute <code>de_bounds</code> of the object to a list of lists, where each inner list represents the lower and upper bounds for a parameter being optimized. The number of inner lists is determined by the number of parameters being optimized (<code>n_theta</code> and <code>n_p</code>), as well as whether noise is being considered (<code>noise</code>).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n&gt;&gt;&gt; obj = MyClass()\n&gt;&gt;&gt; obj.set_de_bounds()\n&gt;&gt;&gt; print(obj.de_bounds)\n[[min_theta, max_theta], [min_theta, max_theta], ..., [min_p, max_p], [min_Lambda, max_Lambda]]\n</code></pre> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def set_de_bounds(self) -&gt; None:\n\"\"\"\n    Determine search bounds for model_optimizer, e.g., differential evolution.\n\n    This method sets the attribute `de_bounds` of the object to a list of lists,\n    where each inner list represents the lower and upper bounds for a parameter\n    being optimized. The number of inner lists is determined by the number of\n    parameters being optimized (`n_theta` and `n_p`), as well as whether noise is\n    being considered (`noise`).\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n        &gt;&gt;&gt; obj = MyClass()\n        &gt;&gt;&gt; obj.set_de_bounds()\n        &gt;&gt;&gt; print(obj.de_bounds)\n        [[min_theta, max_theta], [min_theta, max_theta], ..., [min_p, max_p], [min_Lambda, max_Lambda]]\n\n    Returns:\n        None\n    \"\"\"\n    de_bounds = [[self.min_theta, self.max_theta] for _ in range(self.n_theta)]\n    if self.optim_p:\n        de_bounds += [[self.min_p, self.max_p] for _ in range(self.n_p)]\n        if self.noise:\n            de_bounds.append([self.min_Lambda, self.max_Lambda])\n    else:\n        if self.noise:\n            de_bounds.append([self.min_Lambda, self.max_Lambda])\n    self.de_bounds = de_bounds\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.set_theta_values","title":"<code>set_theta_values()</code>","text":"<p>Set the theta values for the class instance.</p> <p>This method sets the theta values for the class instance based on the <code>n_theta</code> and <code>k</code> attributes. If <code>n_theta</code> is greater than <code>k</code>, <code>n_theta</code> is set to <code>k</code> and a warning is logged. The method then initializes the <code>theta</code> attribute as a list of zeros with length <code>n_theta</code>. The <code>x0_theta</code> attribute is also initialized as a list of ones with length <code>n_theta</code>, multiplied by <code>n / (100 * k)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.n_theta = 3\n&gt;&gt;&gt;         self.k = 2\n&gt;&gt;&gt; instance = MyClass()\n&gt;&gt;&gt; instance.set_theta_values()\n</code></pre> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def set_theta_values(self) -&gt; None:\n\"\"\"\n    Set the theta values for the class instance.\n\n    This method sets the theta values for the class instance based\n    on the `n_theta` and `k` attributes. If `n_theta` is greater than\n    `k`, `n_theta` is set to `k` and a warning is logged.\n    The method then initializes the `theta` attribute as a list\n    of zeros with length `n_theta`.\n    The `x0_theta` attribute is also initialized as a list of ones\n    with length `n_theta`, multiplied by `n / (100 * k)`.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.n_theta = 3\n        &gt;&gt;&gt;         self.k = 2\n        &gt;&gt;&gt; instance = MyClass()\n        &gt;&gt;&gt; instance.set_theta_values()\n\n    Returns:\n        None\n    \"\"\"\n    if self.n_theta &gt; self.k:\n        self.n_theta = self.k\n        logger.warning(\"More theta values than dimensions. `n_theta` set to `k`.\")\n    self.theta: List[float] = zeros(self.n_theta)\n    # TODO: Currently not used:\n    self.x0_theta: List[float] = ones((self.n_theta,)) * self.n / (100 * self.k)\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.set_variable_types","title":"<code>set_variable_types()</code>","text":"<p>Set the variable types for the class instance.</p> <p>This method sets the variable types for the class instance based on the <code>var_type</code> attribute. If the length of <code>var_type</code> is less than <code>k</code>, all variable types are forced to \u2018num\u2019 and a warning is logged. The method then creates masks for each variable type (\u2018num\u2019, \u2018factor\u2019, \u2018int\u2019, \u2018float\u2019) using numpy arrays.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; class MyClass(Kriging):\n&gt;&gt;&gt;     def __init__(self):\n&gt;&gt;&gt;         super().__init__()\n&gt;&gt;&gt;         self.var_type = [\"num\", \"factor\"]\n&gt;&gt;&gt; instance = MyClass()\n&gt;&gt;&gt; instance.set_variable_types()\n&gt;&gt;&gt; instance.num_mask\narray([ True, False])\n</code></pre> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def set_variable_types(self) -&gt; None:\n\"\"\"\n    Set the variable types for the class instance.\n\n    This method sets the variable types for the class instance based\n    on the `var_type` attribute. If the length of `var_type` is less\n    than `k`, all variable types are forced to 'num' and a warning is logged.\n    The method then creates masks for each variable\n    type ('num', 'factor', 'int', 'float') using numpy arrays.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; class MyClass(Kriging):\n        &gt;&gt;&gt;     def __init__(self):\n        &gt;&gt;&gt;         super().__init__()\n        &gt;&gt;&gt;         self.var_type = [\"num\", \"factor\"]\n        &gt;&gt;&gt; instance = MyClass()\n        &gt;&gt;&gt; instance.set_variable_types()\n        &gt;&gt;&gt; instance.num_mask\n        array([ True, False])\n\n    Returns:\n        None\n    \"\"\"\n    # assume all variable types are \"num\" if \"num\" is\n    # specified once:\n    if len(self.var_type) &lt; self.k:\n        self.var_type = self.var_type * self.k\n        logger.warning(\"Warning: All variable types forced to 'num'.\")\n    self.num_mask = np.array(list(map(lambda x: x == \"num\", self.var_type)))\n    self.factor_mask = np.array(list(map(lambda x: x == \"factor\", self.var_type)))\n    self.int_mask = np.array(list(map(lambda x: x == \"int\", self.var_type)))\n    self.ordered_mask = np.array(list(map(lambda x: x == \"int\" or x == \"num\" or x == \"float\", self.var_type)))\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.update_log","title":"<code>update_log()</code>","text":"<p>Update the log with the current values of negLnLike, theta, p, and Lambda.</p> <p>This method appends the current values of negLnLike, theta, p (if optim_p is True), and Lambda (if noise is True) to their respective lists in the log dictionary. It also updates the log_length attribute with the current length of the negLnLike list in the log.</p> <p>If spot_writer is not None, this method also writes the current values of negLnLike, theta, p (if optim_p is True), and Lambda (if noise is True) to the spot_writer object.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n&gt;&gt;&gt; obj = MyClass()\n&gt;&gt;&gt; obj.update_log()\n&gt;&gt;&gt; print(obj.log)\n{'negLnLike': [0.5], 'theta': [0.1], 'p': [0.2], 'Lambda': [0.3]}\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def update_log(self) -&gt; None:\n\"\"\"\n    Update the log with the current values of negLnLike, theta, p, and Lambda.\n\n    This method appends the current values of negLnLike, theta, p (if optim_p is True),\n    and Lambda (if noise is True)\n    to their respective lists in the log dictionary.\n    It also updates the log_length attribute with the current length\n    of the negLnLike list in the log.\n\n    If spot_writer is not None, this method also writes the current values of\n    negLnLike, theta, p (if optim_p is True),\n    and Lambda (if noise is True) to the spot_writer object.\n\n    Returns:\n        None\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; MyClass = Kriging(name='kriging', seed=124)\n        &gt;&gt;&gt; obj = MyClass()\n        &gt;&gt;&gt; obj.update_log()\n        &gt;&gt;&gt; print(obj.log)\n        {'negLnLike': [0.5], 'theta': [0.1], 'p': [0.2], 'Lambda': [0.3]}\n    \"\"\"\n    self.log[\"negLnLike\"] = append(self.log[\"negLnLike\"], self.negLnLike)\n    self.log[\"theta\"] = append(self.log[\"theta\"], self.theta)\n    if self.optim_p:\n        self.log[\"p\"] = append(self.log[\"p\"], self.p)\n    if self.noise:\n        self.log[\"Lambda\"] = append(self.log[\"Lambda\"], self.Lambda)\n    # get the length of the log\n    self.log_length = len(self.log[\"negLnLike\"])\n    if self.spot_writer is not None:\n        writer = self.spot_writer\n        negLnLike = self.negLnLike.copy()\n        writer.add_scalar(\"spot_negLnLike\", negLnLike, self.counter+self.log_length)\n        # add the self.n_theta theta values to the writer with one key \"theta\",\n        # i.e, the same key for all theta values\n        theta = self.theta.copy()\n        writer.add_scalars(\"spot_theta\", {f\"theta_{i}\": theta[i] for i in range(self.n_theta)},\n                           self.counter+self.log_length)\n        if self.noise:\n            Lambda = self.Lambda.copy()\n            writer.add_scalar(\"spot_Lambda\", Lambda, self.counter+self.log_length)\n        if self.optim_p:\n            p = self.p.copy()\n            writer.add_scalars(\"spot_p\", {f\"p_{i}\": p[i] for i in range(self.n_p)}, self.counter+self.log_length)\n        writer.flush()\n</code></pre>"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.weighted_exp_imp","title":"<code>weighted_exp_imp(cod_x, w)</code>","text":"<p>Weighted expected improvement.</p> <p>Parameters:</p> Name Type Description Default <code>cod_x</code> <code>np.ndarray</code> <p>A coded design vector.</p> required <code>w</code> <code>float</code> <p>Weight.</p> required <p>Returns:</p> Name Type Description <code>EI</code> <code>float</code> <p>Weighted expected improvement.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.build.kriging import Kriging\n&gt;&gt;&gt; from numpy import array\n&gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n&gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n&gt;&gt;&gt; k = Kriging(X, y)\n&gt;&gt;&gt; cod_x = array([0.3, 0.3])\n&gt;&gt;&gt; w = 0.5\n&gt;&gt;&gt; k.weighted_exp_imp(cod_x, w)\n0.0\n</code></pre> References <p>[Sobester et al. 2005].</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/kriging.py</code> <pre><code>def weighted_exp_imp(self, cod_x: np.ndarray, w: float) -&gt; float:\n\"\"\"\n    Weighted expected improvement.\n\n    Args:\n        cod_x (np.ndarray): A coded design vector.\n        w (float): Weight.\n\n    Returns:\n        EI (float): Weighted expected improvement.\n\n    Examples:\n\n        &gt;&gt;&gt; from spotPython.build.kriging import Kriging\n        &gt;&gt;&gt; from numpy import array\n        &gt;&gt;&gt; X = array([[0.0, 0.0], [0.1, 0.1], [0.2, 0.2]])\n        &gt;&gt;&gt; y = array([0.0, 0.01, 0.04])\n        &gt;&gt;&gt; k = Kriging(X, y)\n        &gt;&gt;&gt; cod_x = array([0.3, 0.3])\n        &gt;&gt;&gt; w = 0.5\n        &gt;&gt;&gt; k.weighted_exp_imp(cod_x, w)\n        0.0\n\n    References:\n\n        [Sobester et al. 2005].\n    \"\"\"\n    y0, s0 = self.predict_coded(cod_x)\n    y_min = min(self.cod_y)\n    if s0 &lt;= 0.0:\n        EI = 0.0\n    else:\n        y_min_y0 = y_min - y0\n        EI_one = w * (\n                y_min_y0\n                * (0.5 + 0.5 * erf((1.0 / sqrt(2.0)) * (y_min_y0 / s0)))\n        )\n        EI_two = (\n                (1.0 - w)\n                * (s0 * (1.0 / sqrt(2.0 * pi)))\n                * (exp(-(1.0 / 2.0) * ((y_min_y0) ** 2.0 / s0 ** 2.0)))\n        )\n        EI = EI_one + EI_two\n    return EI\n</code></pre>"},{"location":"reference/spotPython/build/surrogates/","title":"surrogates","text":""},{"location":"reference/spotPython/build/surrogates/#spotPython.build.surrogates.surrogates","title":"<code>surrogates</code>","text":"<p>Super class for all surrogate model classes (e.g., Kriging)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/build/surrogates.py</code> <pre><code>class surrogates:\n\"\"\"\n    Super class for all surrogate model classes (e.g., Kriging)\n    \"\"\"\n    def __init__(self, name=\"\", seed=123, verbosity=0):\n        self.name = name\n        self.seed = seed\n        self.rng = default_rng(self.seed)\n        self.log = {}\n        self.verbosity = verbosity\n</code></pre>"},{"location":"reference/spotPython/data/","title":"data","text":"<p>Datasets.</p> <p>This module contains a collection of datasets for multiple tasks: classification, regression, etc. The data corresponds to popular datasets and are conveniently wrapped to easily iterate over the data in a stream fashion. All datasets have fixed size.</p>"},{"location":"reference/spotPython/data/base/","title":"base","text":""},{"location":"reference/spotPython/data/base/#spotPython.data.base.Config","title":"<code>Config</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>Base class for all configurations.</p> <p>All configurations inherit from this class, be they stored in a file or generated on the fly.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>class Config(abc.ABC):\n\"\"\"Base class for all configurations.\n\n    All configurations inherit from this class, be they stored in a file or generated on the fly.\n    \"\"\"\n\n    def __init__(\n        self,\n    ):\n        pass\n\n    @property\n    def desc(self):\n\"\"\"Return the description from the docstring.\"\"\"\n        desc = re.split(pattern=r\"\\w+\\n\\s{4}\\-{3,}\", string=self.__doc__, maxsplit=0)[0]\n        return inspect.cleandoc(desc)\n\n    @property\n    def _repr_content(self):\n\"\"\"The items that are displayed in the __repr__ method.\n\n        This property can be overridden in order to modify the output of the __repr__ method.\n\n        \"\"\"\n\n        content = {}\n        content[\"Name\"] = self.__class__.__name__\n        return content\n</code></pre>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.Config.desc","title":"<code>desc</code>  <code>property</code>","text":"<p>Return the description from the docstring.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.Dataset","title":"<code>Dataset</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>Base class for all datasets.</p> <p>All datasets inherit from this class, be they stored in a file or generated on the fly.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.Dataset--parameters","title":"Parameters","text":"<p>task     Type of task the dataset is meant for. Should be one of:     - \u201cRegression\u201d     - \u201cBinary classification\u201d     - \u201cMulti-class classification\u201d     - \u201cMulti-output binary classification\u201d     - \u201cMulti-output regression\u201d n_features     Number of features in the dataset. n_samples     Number of samples in the dataset. n_classes     Number of classes in the dataset, only applies to classification datasets. n_outputs     Number of outputs the target is made of, only applies to multi-output datasets. sparse     Whether the dataset is sparse or not.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>class Dataset(abc.ABC):\n\"\"\"Base class for all datasets.\n\n    All datasets inherit from this class, be they stored in a file or generated on the fly.\n\n    Parameters\n    ----------\n    task\n        Type of task the dataset is meant for. Should be one of:\n        - \"Regression\"\n        - \"Binary classification\"\n        - \"Multi-class classification\"\n        - \"Multi-output binary classification\"\n        - \"Multi-output regression\"\n    n_features\n        Number of features in the dataset.\n    n_samples\n        Number of samples in the dataset.\n    n_classes\n        Number of classes in the dataset, only applies to classification datasets.\n    n_outputs\n        Number of outputs the target is made of, only applies to multi-output datasets.\n    sparse\n        Whether the dataset is sparse or not.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        task,\n        n_features,\n        n_samples=None,\n        n_classes=None,\n        n_outputs=None,\n        sparse=False,\n    ):\n        self.task = task\n        self.n_features = n_features\n        self.n_samples = n_samples\n        self.n_outputs = n_outputs\n        self.n_classes = n_classes\n        self.sparse = sparse\n\n    @abc.abstractmethod\n    def __iter__(self):\n        raise NotImplementedError\n\n    def take(self, k: int):\n\"\"\"Iterate over the k samples.\"\"\"\n        return itertools.islice(self, k)\n\n    @property\n    def desc(self):\n\"\"\"Return the description from the docstring.\"\"\"\n        desc = re.split(pattern=r\"\\w+\\n\\s{4}\\-{3,}\", string=self.__doc__, maxsplit=0)[0]\n        return inspect.cleandoc(desc)\n\n    @property\n    def _repr_content(self):\n\"\"\"The items that are displayed in the __repr__ method.\n\n        This property can be overridden in order to modify the output of the __repr__ method.\n\n        \"\"\"\n\n        content = {}\n        content[\"Name\"] = self.__class__.__name__\n        content[\"Task\"] = self.task\n        if isinstance(self, SyntheticDataset) and self.n_samples is None:\n            content[\"Samples\"] = \"\u221e\"\n        elif self.n_samples:\n            content[\"Samples\"] = f\"{self.n_samples:,}\"\n        if self.n_features:\n            content[\"Features\"] = f\"{self.n_features:,}\"\n        if self.n_outputs:\n            content[\"Outputs\"] = f\"{self.n_outputs:,}\"\n        if self.n_classes:\n            content[\"Classes\"] = f\"{self.n_classes:,}\"\n        content[\"Sparse\"] = str(self.sparse)\n\n        return content\n\n    def __repr__(self):\n        l_len = max(map(len, self._repr_content.keys()))\n        r_len = max(map(len, self._repr_content.values()))\n\n        out = f\"{self.desc}\\n\\n\" + \"\\n\".join(\n            k.rjust(l_len) + \"  \" + v.ljust(r_len) for k, v in self._repr_content.items()\n        )\n\n        if \"Parameters\\n    ----------\" in self.__doc__:\n            params = re.split(\n                r\"\\w+\\n\\s{4}\\-{3,}\",\n                re.split(\"Parameters\\n    ----------\", self.__doc__)[1],\n            )[0].rstrip()\n            out += f\"\\n\\nParameters\\n----------{params}\"\n\n        return out\n</code></pre>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.Dataset.desc","title":"<code>desc</code>  <code>property</code>","text":"<p>Return the description from the docstring.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.Dataset.take","title":"<code>take(k)</code>","text":"<p>Iterate over the k samples.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>def take(self, k: int):\n\"\"\"Iterate over the k samples.\"\"\"\n    return itertools.islice(self, k)\n</code></pre>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.FileConfig","title":"<code>FileConfig</code>","text":"<p>         Bases: <code>Config</code></p> <p>Base class for configurations that are stored in a local file.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.FileConfig--parameters","title":"Parameters","text":"<p>filename     The file\u2019s name. directory     The directory where the file is contained. Defaults to the location of the <code>datasets</code>     module. desc     Extra config parameters to pass as keyword arguments.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>class FileConfig(Config):\n\"\"\"Base class for configurations that are stored in a local file.\n\n    Parameters\n    ----------\n    filename\n        The file's name.\n    directory\n        The directory where the file is contained. Defaults to the location of the `datasets`\n        module.\n    desc\n        Extra config parameters to pass as keyword arguments.\n\n    \"\"\"\n\n    def __init__(self, filename, directory=None, **desc):\n        super().__init__(**desc)\n        self.filename = filename\n        self.directory = directory\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    @property\n    def _repr_content(self):\n        content = super()._repr_content\n        content[\"Path\"] = str(self.path)\n        return content\n</code></pre>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.FileDataset","title":"<code>FileDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> <p>Base class for datasets that are stored in a local file.</p> <p>Small datasets that are part of the spotRiver package inherit from this class.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.FileDataset--parameters","title":"Parameters","text":"<p>filename     The file\u2019s name. directory     The directory where the file is contained. Defaults to the location of the <code>datasets</code>     module. desc     Extra dataset parameters to pass as keyword arguments.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>class FileDataset(Dataset):\n\"\"\"Base class for datasets that are stored in a local file.\n\n    Small datasets that are part of the spotRiver package inherit from this class.\n\n    Parameters\n    ----------\n    filename\n        The file's name.\n    directory\n        The directory where the file is contained. Defaults to the location of the `datasets`\n        module.\n    desc\n        Extra dataset parameters to pass as keyword arguments.\n\n    \"\"\"\n\n    def __init__(self, filename, directory=None, **desc):\n        super().__init__(**desc)\n        self.filename = filename\n        self.directory = directory\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    @property\n    def _repr_content(self):\n        content = super()._repr_content\n        content[\"Path\"] = str(self.path)\n        return content\n</code></pre>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.GenericFileDataset","title":"<code>GenericFileDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> <p>Base class for datasets that are stored in a local file.</p> <p>Small datasets that are part of the spotRiver package inherit from this class.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.GenericFileDataset--parameters","title":"Parameters","text":"<p>filename     The file\u2019s name. directory     The directory where the file is contained. Defaults to the location of the <code>datasets</code>     module. desc     Extra dataset parameters to pass as keyword arguments.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>class GenericFileDataset(Dataset):\n\"\"\"Base class for datasets that are stored in a local file.\n\n    Small datasets that are part of the spotRiver package inherit from this class.\n\n    Parameters\n    ----------\n    filename\n        The file's name.\n    directory\n        The directory where the file is contained. Defaults to the location of the `datasets`\n        module.\n    desc\n        Extra dataset parameters to pass as keyword arguments.\n\n    \"\"\"\n\n    def __init__(self, filename, target, converters, parse_dates, directory=None, **desc):\n        super().__init__(**desc)\n        self.filename = filename\n        self.directory = directory\n        self.target = target\n        self.converters = converters\n        self.parse_dates = parse_dates\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    @property\n    def _repr_content(self):\n        content = super()._repr_content\n        content[\"Path\"] = str(self.path)\n        return content\n</code></pre>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.RemoteDataset","title":"<code>RemoteDataset</code>","text":"<p>         Bases: <code>FileDataset</code></p> <p>Base class for datasets that are stored in a remote file.</p> <p>Medium and large datasets that are not part of the river package inherit from this class.</p> <p>The filename doesn\u2019t have to be provided if unpack is False. Indeed in the latter case the filename will be inferred from the URL.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.RemoteDataset--parameters","title":"Parameters","text":"<p>url     The URL the dataset is located at. size     The expected download size. unpack     Whether to unpack the download or not. filename     An optional name to given to the file if the file is unpacked. desc     Extra dataset parameters to pass as keyword arguments.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>class RemoteDataset(FileDataset):\n\"\"\"Base class for datasets that are stored in a remote file.\n\n    Medium and large datasets that are not part of the river package inherit from this class.\n\n    The filename doesn't have to be provided if unpack is False. Indeed in the latter case the\n    filename will be inferred from the URL.\n\n    Parameters\n    ----------\n    url\n        The URL the dataset is located at.\n    size\n        The expected download size.\n    unpack\n        Whether to unpack the download or not.\n    filename\n        An optional name to given to the file if the file is unpacked.\n    desc\n        Extra dataset parameters to pass as keyword arguments.\n\n    \"\"\"\n\n    def __init__(self, url, size, unpack=True, filename=None, **desc):\n        if filename is None:\n            filename = path.basename(url)\n\n        super().__init__(filename=filename, **desc)\n        self.url = url\n        self.size = size\n        self.unpack = unpack\n\n    @property\n    def path(self):\n        return pathlib.Path(get_data_home(), self.__class__.__name__, self.filename)\n\n    def download(self, force=False, verbose=True):\n        if not force and self.is_downloaded:\n            return\n\n        # Determine where to download the archive\n        directory = self.path.parent\n        directory.mkdir(parents=True, exist_ok=True)\n        archive_path = directory.joinpath(path.basename(self.url))\n\n        with request.urlopen(self.url) as r:\n            # Notify the user\n            if verbose:\n                meta = r.info()\n                try:\n                    n_bytes = int(meta[\"Content-Length\"])\n                    msg = f\"Downloading {self.url} ({n_bytes})\"\n                except KeyError:\n                    msg = f\"Downloading {self.url}\"\n                print(msg)\n\n            # Now dump the contents of the requests\n            with open(archive_path, \"wb\") as f:\n                shutil.copyfileobj(r, f)\n\n        if not self.unpack:\n            return\n\n        if verbose:\n            print(f\"Uncompressing into {directory}\")\n\n        if archive_path.suffix.endswith(\"zip\"):\n            with zipfile.ZipFile(archive_path, \"r\") as zf:\n                zf.extractall(directory)\n\n        elif archive_path.suffix.endswith((\"gz\", \"tar\")):\n            mode = \"r:\" if archive_path.suffix.endswith(\"tar\") else \"r:gz\"\n            tar = tarfile.open(archive_path, mode)\n            tar.extractall(directory)\n            tar.close()\n\n        else:\n            raise RuntimeError(f\"Unhandled extension type: {archive_path.suffix}\")\n\n        # Delete the archive file now that it has been uncompressed\n        archive_path.unlink()\n\n    @abc.abstractmethod\n    def _iter(self):\n        pass\n\n    @property\n    def is_downloaded(self):\n\"\"\"Indicate whether or the data has been correctly downloaded.\"\"\"\n        if self.path.exists():\n            if self.path.is_file():\n                return self.path.stat().st_size == self.size\n            return sum(f.stat().st_size for f in self.path.glob(\"**/*\") if f.is_file())\n\n        return False\n\n    def __iter__(self):\n        if not self.is_downloaded:\n            self.download(verbose=True)\n        if not self.is_downloaded:\n            raise RuntimeError(\"Something went wrong during the download\")\n        yield from self._iter()\n\n    @property\n    def _repr_content(self):\n        content = super()._repr_content\n        content[\"URL\"] = self.url\n        content[\"Size\"] = self.size\n        content[\"Downloaded\"] = str(self.is_downloaded)\n        return content\n</code></pre>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.RemoteDataset.is_downloaded","title":"<code>is_downloaded</code>  <code>property</code>","text":"<p>Indicate whether or the data has been correctly downloaded.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.SyntheticDataset","title":"<code>SyntheticDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> <p>A synthetic dataset.</p>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.SyntheticDataset--parameters","title":"Parameters","text":"<p>task     Type of task the dataset is meant for. Should be one of:     - \u201cRegression\u201d     - \u201cBinary classification\u201d     - \u201cMulti-class classification\u201d     - \u201cMulti-output binary classification\u201d     - \u201cMulti-output regression\u201d n_features     Number of features in the dataset. n_samples     Number of samples in the dataset. n_classes     Number of classes in the dataset, only applies to classification datasets. n_outputs     Number of outputs the target is made of, only applies to multi-output datasets. sparse     Whether the dataset is sparse or not.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>class SyntheticDataset(Dataset):\n\"\"\"A synthetic dataset.\n\n    Parameters\n    ----------\n    task\n        Type of task the dataset is meant for. Should be one of:\n        - \"Regression\"\n        - \"Binary classification\"\n        - \"Multi-class classification\"\n        - \"Multi-output binary classification\"\n        - \"Multi-output regression\"\n    n_features\n        Number of features in the dataset.\n    n_samples\n        Number of samples in the dataset.\n    n_classes\n        Number of classes in the dataset, only applies to classification datasets.\n    n_outputs\n        Number of outputs the target is made of, only applies to multi-output datasets.\n    sparse\n        Whether the dataset is sparse or not.\n\n    \"\"\"\n\n    def __repr__(self):\n        l_len_prop = max(map(len, self._repr_content.keys()))\n        r_len_prop = max(map(len, self._repr_content.values()))\n        params = self._get_params()\n        l_len_config = max(map(len, params.keys()))\n        r_len_config = max(map(len, map(str, params.values())))\n\n        out = (\n            \"Synthetic data generator\\n\\n\"\n            + \"\\n\".join(k.rjust(l_len_prop) + \"  \" + v.ljust(r_len_prop) for k, v in self._repr_content.items())\n            + \"\\n\\nConfiguration\\n-------------\\n\"\n            + \"\\n\".join(k.rjust(l_len_config) + \"  \" + str(v).ljust(r_len_config) for k, v in params.items())\n        )\n\n        return out\n\n    def _get_params(self) -&gt; typing.Dict[str, typing.Any]:\n\"\"\"Return the parameters that were used during initialization.\"\"\"\n        return {\n            name: getattr(self, name)\n            for name, param in inspect.signature(self.__init__).parameters.items()  # type: ignore\n            if param.kind != param.VAR_KEYWORD\n        }\n</code></pre>"},{"location":"reference/spotPython/data/base/#spotPython.data.base.get_data_home","title":"<code>get_data_home(data_home=None)</code>","text":"<p>Return the location where remote datasets are to be stored.     By default the data directory is set to a folder named \u2018spotriver_data\u2019 in the     user home folder. Alternatively, it can be set by the \u2018SPOTRIVER_DATA\u2019 environment     variable or programmatically by giving an explicit folder path. The \u2018~\u2019     symbol is expanded to the user home folder.     If the folder does not already exist, it is automatically created.</p> <p>Parameters:</p> Name Type Description Default <code>data_home</code> <code>str</code> <p>The path to spotriver data directory. If <code>None</code>, the default path is <code>~/spotriver_data</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>data_home</code> <code>str</code> <code>str</code> <p>The path to the spotriver data directory.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/base.py</code> <pre><code>def get_data_home(data_home=None) -&gt; str:\n\"\"\"Return the location where remote datasets are to be stored.\n        By default the data directory is set to a folder named 'spotriver_data' in the\n        user home folder. Alternatively, it can be set by the 'SPOTRIVER_DATA' environment\n        variable or programmatically by giving an explicit folder path. The '~'\n        symbol is expanded to the user home folder.\n        If the folder does not already exist, it is automatically created.\n\n    Args:\n        data_home (str):\n            The path to spotriver data directory. If `None`, the default path\n            is `~/spotriver_data`.\n\n    Returns:\n        data_home (str):\n        The path to the spotriver data directory.\n    \"\"\"\n    if data_home is None:\n        data_home = environ.get(\"SPOTRIVER_DATA\", Path.home() / \"spotriver_data\")\n    # Ensure data_home is a Path() object pointing to an absolute path\n    data_home = Path(data_home).absolute()\n    # Create data directory if it does not exists.\n    data_home.mkdir(parents=True, exist_ok=True)\n    return data_home\n</code></pre>"},{"location":"reference/spotPython/data/light_hyper_dict/","title":"light_hyper_dict","text":""},{"location":"reference/spotPython/data/light_hyper_dict/#spotPython.data.light_hyper_dict.LightHyperDict","title":"<code>LightHyperDict</code>","text":"<p>         Bases: <code>base.FileConfig</code></p> <p>Lightning hyperparameter dictionary.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/light_hyper_dict.py</code> <pre><code>class LightHyperDict(base.FileConfig):\n\"\"\"Lightning hyperparameter dictionary.\"\"\"\n\n    def __init__(self):\n        super().__init__(\n            filename=\"light_hyper_dict.json\",\n        )\n\n    def load(self):\n        with open(self.path, \"r\") as f:\n            d = json.load(f)\n        return d\n</code></pre>"},{"location":"reference/spotPython/data/sklearn_hyper_dict/","title":"sklearn_hyper_dict","text":""},{"location":"reference/spotPython/data/sklearn_hyper_dict/#spotPython.data.sklearn_hyper_dict.SklearnHyperDict","title":"<code>SklearnHyperDict</code>","text":"<p>         Bases: <code>base.FileConfig</code></p> <p>River hyperparameter dictionary.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/sklearn_hyper_dict.py</code> <pre><code>class SklearnHyperDict(base.FileConfig):\n\"\"\"River hyperparameter dictionary.\"\"\"\n\n    def __init__(self):\n        super().__init__(\n            filename=\"sklearn_hyper_dict.json\",\n        )\n\n    def load(self):\n        with open(self.path, \"r\") as f:\n            d = json.load(f)\n        return d\n</code></pre>"},{"location":"reference/spotPython/data/torch_hyper_dict/","title":"torch_hyper_dict","text":""},{"location":"reference/spotPython/data/torch_hyper_dict/#spotPython.data.torch_hyper_dict.TorchHyperDict","title":"<code>TorchHyperDict</code>","text":"<p>         Bases: <code>base.FileConfig</code></p> <p>Torch hyperparameter dictionary.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/torch_hyper_dict.py</code> <pre><code>class TorchHyperDict(base.FileConfig):\n\"\"\"Torch hyperparameter dictionary.\"\"\"\n\n    def __init__(self):\n        super().__init__(\n            filename=\"torch_hyper_dict.json\",\n        )\n\n    def load(self):\n        with open(self.path, \"r\") as f:\n            d = json.load(f)\n        return d\n</code></pre>"},{"location":"reference/spotPython/data/torchdata/","title":"torchdata","text":""},{"location":"reference/spotPython/data/vbdp/","title":"vbdp","text":""},{"location":"reference/spotPython/data/vbdp/#spotPython.data.vbdp.affinity_propagation_features","title":"<code>affinity_propagation_features(X)</code>","text":"<p>Clusters the features of a dataframe using Affinity Propagation</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>pd.DataFrame</code> <p>dataframe with features</p> required <p>Returns:</p> Name Type Description <code>X</code> <code>pd.DataFrame</code> <p>dataframe with new features</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({\"a\": [True, False, True], \"b\": [True, True, False], \"c\": [False, False, True]})\n&gt;&gt;&gt; df\n    a      b      c\n0  True   True   False\n1  False  True   False\n2  True   False  True\n&gt;&gt;&gt; affinity_propagation_features(df)\n    a      b      c  cluster\n0  True   True   False       0\n1  False  True   False       1\n2  True   False  True        2\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/vbdp.py</code> <pre><code>def affinity_propagation_features(X):\n\"\"\"Clusters the features of a dataframe using Affinity Propagation\n\n    Args:\n        X (pd.DataFrame): dataframe with features\n    Returns:\n        X (pd.DataFrame): dataframe with new features\n    Examples:\n        &gt;&gt;&gt; df = pd.DataFrame({\"a\": [True, False, True], \"b\": [True, True, False], \"c\": [False, False, True]})\n        &gt;&gt;&gt; df\n            a      b      c\n        0  True   True   False\n        1  False  True   False\n        2  True   False  True\n        &gt;&gt;&gt; affinity_propagation_features(df)\n            a      b      c  cluster\n        0  True   True   False       0\n        1  False  True   False       1\n        2  True   False  True        2\n    \"\"\"\n    from sklearn.cluster import AffinityPropagation\n    from sklearn.metrics.pairwise import manhattan_distances\n\n    D = manhattan_distances(X)\n    af = AffinityPropagation(random_state=0, affinity=\"precomputed\").fit(D)\n    cluster_centers_indices = af.cluster_centers_indices_\n    n_clusters_ = len(cluster_centers_indices)\n    print(\"Estimated number of clusters: %d\" % n_clusters_)\n    X[\"cluster\"] = af.labels_\n    return X\n</code></pre>"},{"location":"reference/spotPython/data/vbdp/#spotPython.data.vbdp.cluster_features","title":"<code>cluster_features(X)</code>","text":"<p>Clusters the features of a dataframe based on similarity</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>pd.DataFrame</code> <p>dataframe with features</p> required <p>Returns:</p> Name Type Description <code>X</code> <code>pd.DataFrame</code> <p>dataframe with new features</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({\"a\": [True, False, True], \"b\": [True, True, False], \"c\": [False, False, True]})\n&gt;&gt;&gt; df\n    a      b      c\n0  True   True  False\n1 False   True  False\n2  True  False   True\n&gt;&gt;&gt; cluster_features(df)\n    a      b      c  cluster\n0  True   True  False       0\n1 False   True  False       1\n2  True  False   True        2\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/data/vbdp.py</code> <pre><code>def cluster_features(X):\n\"\"\"Clusters the features of a dataframe based on similarity\n\n    Args:\n        X (pd.DataFrame): dataframe with features\n    Returns:\n        X (pd.DataFrame): dataframe with new features\n    Examples:\n        &gt;&gt;&gt; df = pd.DataFrame({\"a\": [True, False, True], \"b\": [True, True, False], \"c\": [False, False, True]})\n        &gt;&gt;&gt; df\n            a      b      c\n        0  True   True  False\n        1 False   True  False\n        2  True  False   True\n        &gt;&gt;&gt; cluster_features(df)\n            a      b      c  cluster\n        0  True   True  False       0\n        1 False   True  False       1\n        2  True  False   True        2\n    \"\"\"\n    c_0 = X.columns[X.columns.str.contains(\"pain\")]\n    c_1 = X.columns[X.columns.str.contains(\"inflammation\")]\n    c_2 = X.columns[X.columns.str.contains(\"bleed\")]\n    c_3 = X.columns[X.columns.str.contains(\"skin\")]\n    X[\"c_0\"] = X[c_0].sum(axis=1)\n    X[\"c_1\"] = X[c_1].sum(axis=1)\n    X[\"c_2\"] = X[c_2].sum(axis=1)\n    X[\"c_3\"] = X[c_3].sum(axis=1)\n    return X\n</code></pre>"},{"location":"reference/spotPython/design/designs/","title":"designs","text":""},{"location":"reference/spotPython/design/designs/#spotPython.design.designs.designs","title":"<code>designs</code>","text":"<p>Super class for all design classes (factorial and spacefilling)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/design/designs.py</code> <pre><code>class designs:\n\"\"\"\n    Super class for all design classes (factorial and spacefilling)\n    \"\"\"\n\n    def __init__(self, k=2, seed=123):\n        self.designs = []\n        self.k = k\n        self.seed = seed\n        self.rng = default_rng(self.seed)\n\n    def get_dim(self):\n\"\"\"Return design dimension.\"\"\"\n        print(self.k)\n</code></pre>"},{"location":"reference/spotPython/design/designs/#spotPython.design.designs.designs.get_dim","title":"<code>get_dim()</code>","text":"<p>Return design dimension.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/design/designs.py</code> <pre><code>def get_dim(self):\n\"\"\"Return design dimension.\"\"\"\n    print(self.k)\n</code></pre>"},{"location":"reference/spotPython/design/factorial/","title":"factorial","text":""},{"location":"reference/spotPython/design/factorial/#spotPython.design.factorial.factorial","title":"<code>factorial</code>","text":"<p>         Bases: <code>designs</code></p> <p>Super class for factorial designs.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/design/factorial.py</code> <pre><code>class factorial(designs):\n\"\"\"\n    Super class for factorial designs.\n    \"\"\"\n\n    def __init__(self, k=2, seed=123):\n        super().__init__(k, seed)\n\n    def full_factorial(self, p):\n        i = (slice(0, 1, p * 1j),) * self.k\n        return mgrid[i].reshape(self.k, p**self.k).T\n</code></pre>"},{"location":"reference/spotPython/design/spacefilling/","title":"spacefilling","text":""},{"location":"reference/spotPython/design/spacefilling/#spotPython.design.spacefilling.spacefilling","title":"<code>spacefilling</code>","text":"<p>         Bases: <code>designs</code></p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/design/spacefilling.py</code> <pre><code>class spacefilling(designs):\n    def __init__(self, k=2, seed=123):\n\"\"\"\n        Spacefilling design class\n\n        Args:\n            k (int, optional): number of design variables (dimensions). Defaults to 2.\n            seed (int, optional): random seed. Defaults to 123.\n        \"\"\"\n        self.k = k\n        self.seed = seed\n        super().__init__(k, seed)\n        self.sampler = LatinHypercube(d=self.k, seed=self.seed)\n\n    def scipy_lhd(\n        self,\n        n: int,\n        repeats: int = 1,\n        lower: Optional[Union[int, float]] = None,\n        upper: Optional[Union[int, float]] = None,\n    ) -&gt; ndarray:\n\"\"\"\n        Latin hypercube sampling based on scipy.\n\n        Args:\n            n (int): number of samples\n            repeats (int): number of repeats (replicates)\n            lower (int, optional): lower bound. Defaults to 0.\n            upper (int, optional): upper bound. Defaults to 1.\n\n        Returns:\n            (numpy.ndarray): Latin hypercube design.\n        Examples:\n            &gt;&gt;&gt; from spotPython.design.spacefilling import spacefilling\n                import numpy as np\n                lhd = spacefilling(k=2, seed=123)\n                lhd.scipy_lhd(n=5, repeats=2, lower=np.array([0,0]), upper=np.array([1,1]))\n                array([[0.66352963, 0.5892358 ],\n                [0.66352963, 0.5892358 ],\n                [0.55592803, 0.96312564],\n                [0.55592803, 0.96312564],\n                [0.16481882, 0.0375811 ],\n                [0.16481882, 0.0375811 ],\n                [0.215331  , 0.34468512],\n                [0.215331  , 0.34468512],\n                [0.83604909, 0.62202146],\n                [0.83604909, 0.62202146]])\n        \"\"\"\n        if lower is None:\n            lower = zeros(self.k)\n        if upper is None:\n            upper = ones(self.k)\n        sample = self.sampler.random(n=n)\n        des = scale(sample, lower, upper)\n        return repeat(des, repeats, axis=0)\n</code></pre>"},{"location":"reference/spotPython/design/spacefilling/#spotPython.design.spacefilling.spacefilling.__init__","title":"<code>__init__(k=2, seed=123)</code>","text":"<p>Spacefilling design class</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>number of design variables (dimensions). Defaults to 2.</p> <code>2</code> <code>seed</code> <code>int</code> <p>random seed. Defaults to 123.</p> <code>123</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/design/spacefilling.py</code> <pre><code>def __init__(self, k=2, seed=123):\n\"\"\"\n    Spacefilling design class\n\n    Args:\n        k (int, optional): number of design variables (dimensions). Defaults to 2.\n        seed (int, optional): random seed. Defaults to 123.\n    \"\"\"\n    self.k = k\n    self.seed = seed\n    super().__init__(k, seed)\n    self.sampler = LatinHypercube(d=self.k, seed=self.seed)\n</code></pre>"},{"location":"reference/spotPython/design/spacefilling/#spotPython.design.spacefilling.spacefilling.scipy_lhd","title":"<code>scipy_lhd(n, repeats=1, lower=None, upper=None)</code>","text":"<p>Latin hypercube sampling based on scipy.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>number of samples</p> required <code>repeats</code> <code>int</code> <p>number of repeats (replicates)</p> <code>1</code> <code>lower</code> <code>int</code> <p>lower bound. Defaults to 0.</p> <code>None</code> <code>upper</code> <code>int</code> <p>upper bound. Defaults to 1.</p> <code>None</code> <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Latin hypercube design.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.design.spacefilling import spacefilling\n    import numpy as np\n    lhd = spacefilling(k=2, seed=123)\n    lhd.scipy_lhd(n=5, repeats=2, lower=np.array([0,0]), upper=np.array([1,1]))\n    array([[0.66352963, 0.5892358 ],\n    [0.66352963, 0.5892358 ],\n    [0.55592803, 0.96312564],\n    [0.55592803, 0.96312564],\n    [0.16481882, 0.0375811 ],\n    [0.16481882, 0.0375811 ],\n    [0.215331  , 0.34468512],\n    [0.215331  , 0.34468512],\n    [0.83604909, 0.62202146],\n    [0.83604909, 0.62202146]])\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/design/spacefilling.py</code> <pre><code>def scipy_lhd(\n    self,\n    n: int,\n    repeats: int = 1,\n    lower: Optional[Union[int, float]] = None,\n    upper: Optional[Union[int, float]] = None,\n) -&gt; ndarray:\n\"\"\"\n    Latin hypercube sampling based on scipy.\n\n    Args:\n        n (int): number of samples\n        repeats (int): number of repeats (replicates)\n        lower (int, optional): lower bound. Defaults to 0.\n        upper (int, optional): upper bound. Defaults to 1.\n\n    Returns:\n        (numpy.ndarray): Latin hypercube design.\n    Examples:\n        &gt;&gt;&gt; from spotPython.design.spacefilling import spacefilling\n            import numpy as np\n            lhd = spacefilling(k=2, seed=123)\n            lhd.scipy_lhd(n=5, repeats=2, lower=np.array([0,0]), upper=np.array([1,1]))\n            array([[0.66352963, 0.5892358 ],\n            [0.66352963, 0.5892358 ],\n            [0.55592803, 0.96312564],\n            [0.55592803, 0.96312564],\n            [0.16481882, 0.0375811 ],\n            [0.16481882, 0.0375811 ],\n            [0.215331  , 0.34468512],\n            [0.215331  , 0.34468512],\n            [0.83604909, 0.62202146],\n            [0.83604909, 0.62202146]])\n    \"\"\"\n    if lower is None:\n        lower = zeros(self.k)\n    if upper is None:\n        upper = ones(self.k)\n    sample = self.sampler.random(n=n)\n    des = scale(sample, lower, upper)\n    return repeat(des, repeats, axis=0)\n</code></pre>"},{"location":"reference/spotPython/fun/hyperlight/","title":"hyperlight","text":""},{"location":"reference/spotPython/fun/hyperlight/#spotPython.fun.hyperlight.HyperLight","title":"<code>HyperLight</code>","text":"<p>Hyperparameter Tuning for Lightning 2.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>seed. See Numpy Random Sampling</p> <code>126</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/hyperlight.py</code> <pre><code>class HyperLight:\n\"\"\"\n    Hyperparameter Tuning for Lightning 2.\n\n    Args:\n        seed (int): seed.\n            See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n\n    \"\"\"\n\n    def __init__(self, seed=126, log_level=50):\n        self.seed = seed\n        self.rng = default_rng(seed=self.seed)\n        self.fun_control = {\n            \"seed\": None,\n            \"data\": None,\n            \"step\": 10_000,\n            \"horizon\": None,\n            \"grace_period\": None,\n            \"metric_river\": None,\n            \"metric_sklearn\": None,\n            \"weights\": array([1, 0, 0]),\n            \"weight_coeff\": 0.0,\n            \"log_level\": log_level,\n            \"var_name\": [],\n            \"var_type\": [],\n        }\n        self.log_level = self.fun_control[\"log_level\"]\n        logger.setLevel(self.log_level)\n        logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n\n    def check_X_shape(self, X):\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != len(self.fun_control[\"var_name\"]):\n            raise Exception\n\n    def fun(self, X, fun_control=None):\n        z_res = np.array([], dtype=float)\n        self.fun_control.update(fun_control)\n        self.check_X_shape(X)\n        var_dict = assign_values(X, self.fun_control[\"var_name\"])\n        # type information and transformations are considered in generate_one_config_from_var_dict:\n        for config in generate_one_config_from_var_dict(var_dict, self.fun_control):\n            print(f\"\\nconfig: {config}\")\n            # extract parameters like epochs, batch_size, lr, etc. from config\n            # config_id = generate_config_id(config)\n            try:\n                df_eval = train_model(config, self.fun_control)\n            except Exception as err:\n                print(f\"Error in fun(). Call to train_model failed. {err=}, {type(err)=}\")\n                print(\"Setting df_eval to np.nan\")\n                df_eval = np.nan\n            z_val = fun_control[\"weights\"] * df_eval\n            z_res = np.append(z_res, z_val)\n        return z_res\n</code></pre>"},{"location":"reference/spotPython/fun/hypersklearn/","title":"hypersklearn","text":""},{"location":"reference/spotPython/fun/hypersklearn/#spotPython.fun.hypersklearn.HyperSklearn","title":"<code>HyperSklearn</code>","text":"<p>Hyperparameter Tuning for Sklearn.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>seed. See Numpy Random Sampling</p> <code>126</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/hypersklearn.py</code> <pre><code>class HyperSklearn:\n\"\"\"\n    Hyperparameter Tuning for Sklearn.\n\n    Args:\n        seed (int): seed.\n            See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n\n    \"\"\"\n\n    def __init__(self, seed=126, log_level=50):\n        self.seed = seed\n        self.rng = default_rng(seed=self.seed)\n        self.fun_control = {\n            \"seed\": None,\n            \"data\": None,\n            \"step\": 10_000,\n            \"horizon\": None,\n            \"grace_period\": None,\n            \"metric_river\": None,\n            \"metric_sklearn\": mean_absolute_error,\n            \"weights\": array([1, 0, 0]),\n            \"weight_coeff\": 0.0,\n            \"log_level\": log_level,\n            \"var_name\": [],\n            \"var_type\": [],\n            \"prep_model\": None,\n            \"predict_proba\": False,\n        }\n        self.log_level = self.fun_control[\"log_level\"]\n        logger.setLevel(self.log_level)\n        logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n\n    def check_X_shape(self, X):\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != len(self.fun_control[\"var_name\"]):\n            raise Exception\n\n    def get_sklearn_df_eval_preds(self, model):\n        try:\n            df_eval, df_preds = self.evaluate_model(model, self.fun_control)\n        except Exception as err:\n            print(f\"Error in get_sklearn_df_eval_preds(). Call to evaluate_model failed. {err=}, {type(err)=}\")\n            print(\"Setting df_eval and df.preds to np.nan\")\n            df_eval = np.nan\n            df_preds = np.nan\n        return df_eval, df_preds\n\n    def fun_sklearn(self, X, fun_control=None):\n        z_res = np.array([], dtype=float)\n        self.fun_control.update(fun_control)\n        self.check_X_shape(X)\n        var_dict = assign_values(X, self.fun_control[\"var_name\"])\n        for config in generate_one_config_from_var_dict(var_dict, self.fun_control):\n            # config_id = generate_config_id(config)\n            if self.fun_control[\"prep_model\"] is not None:\n                model = make_pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**config))\n            else:\n                model = self.fun_control[\"core_model\"](**config)\n            try:\n                eval_type = fun_control[\"eval\"]\n                if eval_type == \"eval_oob_score\":\n                    df_eval, _ = evaluate_model_oob(model, self.fun_control)\n                elif eval_type == \"train_cv\":\n                    df_eval, _ = evaluate_cv(model, self.fun_control)\n                else:  # eval_type == \"train_hold_out\":\n                    df_eval, _ = evaluate_hold_out(model, self.fun_control)\n            except Exception as err:\n                print(f\"Error in fun_sklearn(). Call to evaluate_model failed. {err=}, {type(err)=}\")\n                print(\"Setting df_eval to np.nan\")\n                df_eval = np.nan\n            z_res = np.append(z_res, fun_control[\"weights\"] * df_eval)\n        return z_res\n</code></pre>"},{"location":"reference/spotPython/fun/hypertorch/","title":"hypertorch","text":""},{"location":"reference/spotPython/fun/hypertorch/#spotPython.fun.hypertorch.HyperTorch","title":"<code>HyperTorch</code>","text":"<p>Hyperparameter Tuning for Torch.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>seed. See Numpy Random Sampling</p> <code>126</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/hypertorch.py</code> <pre><code>class HyperTorch:\n\"\"\"\n    Hyperparameter Tuning for Torch.\n\n    Args:\n        seed (int): seed.\n            See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n\n    \"\"\"\n\n    def __init__(self, seed=126, log_level=50):\n        self.seed = seed\n        self.rng = default_rng(seed=self.seed)\n        self.fun_control = {\n            \"seed\": None,\n            \"data\": None,\n            \"step\": 10_000,\n            \"horizon\": None,\n            \"grace_period\": None,\n            \"metric_river\": None,\n            \"metric_sklearn\": None,\n            \"weights\": array([1, 0, 0]),\n            \"weight_coeff\": 0.0,\n            \"log_level\": log_level,\n            \"var_name\": [],\n            \"var_type\": [],\n        }\n        self.log_level = self.fun_control[\"log_level\"]\n        logger.setLevel(self.log_level)\n        logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n\n    def check_X_shape(self, X):\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != len(self.fun_control[\"var_name\"]):\n            raise Exception\n\n    def fun_torch(self, X, fun_control=None):\n        z_res = np.array([], dtype=float)\n        self.fun_control.update(fun_control)\n        self.check_X_shape(X)\n        var_dict = assign_values(X, self.fun_control[\"var_name\"])\n        # type information and transformations are considered in generate_one_config_from_var_dict:\n        for config in generate_one_config_from_var_dict(var_dict, self.fun_control):\n            print(f\"\\nconfig: {config}\")\n            config_id = generate_config_id(config)\n            if self.fun_control[\"prep_model\"] is not None:\n                model = make_pipeline(self.fun_control[\"prep_model\"], self.fun_control[\"core_model\"](**config))\n            else:\n                model = self.fun_control[\"core_model\"](**config)\n            try:\n                if self.fun_control[\"eval\"] == \"train_cv\":\n                    df_eval, _ = evaluate_cv(\n                        model,\n                        dataset=fun_control[\"train\"],\n                        shuffle=self.fun_control[\"shuffle\"],\n                        device=self.fun_control[\"device\"],\n                        show_batch_interval=self.fun_control[\"show_batch_interval\"],\n                        task=self.fun_control[\"task\"],\n                        writer=self.fun_control[\"spot_writer\"],\n                        writerId=config_id,\n                    )\n                elif self.fun_control[\"eval\"] == \"test_cv\":\n                    df_eval, _ = evaluate_cv(\n                        model,\n                        dataset=fun_control[\"test\"],\n                        shuffle=self.fun_control[\"shuffle\"],\n                        device=self.fun_control[\"device\"],\n                        show_batch_interval=self.fun_control[\"show_batch_interval\"],\n                        task=self.fun_control[\"task\"],\n                        writer=self.fun_control[\"spot_writer\"],\n                        writerId=config_id,\n                    )\n                elif self.fun_control[\"eval\"] == \"test_hold_out\":\n                    df_eval, _ = evaluate_hold_out(\n                        model,\n                        train_dataset=fun_control[\"train\"],\n                        shuffle=self.fun_control[\"shuffle\"],\n                        loss_function=self.fun_control[\"loss_function\"],\n                        metric=self.fun_control[\"metric_torch\"],\n                        test_dataset=fun_control[\"test\"],\n                        device=self.fun_control[\"device\"],\n                        show_batch_interval=self.fun_control[\"show_batch_interval\"],\n                        path=self.fun_control[\"path\"],\n                        task=self.fun_control[\"task\"],\n                        writer=self.fun_control[\"spot_writer\"],\n                        writerId=config_id,\n                    )\n                else:  # eval == \"train_hold_out\"\n                    df_eval, _ = evaluate_hold_out(\n                        model,\n                        train_dataset=fun_control[\"train\"],\n                        shuffle=self.fun_control[\"shuffle\"],\n                        loss_function=self.fun_control[\"loss_function\"],\n                        metric=self.fun_control[\"metric_torch\"],\n                        device=self.fun_control[\"device\"],\n                        show_batch_interval=self.fun_control[\"show_batch_interval\"],\n                        path=self.fun_control[\"path\"],\n                        task=self.fun_control[\"task\"],\n                        writer=self.fun_control[\"spot_writer\"],\n                        writerId=config_id,\n                    )\n            except Exception as err:\n                print(f\"Error in fun_torch(). Call to evaluate_model failed. {err=}, {type(err)=}\")\n                print(\"Setting df_eval to np.nan\")\n                df_eval = np.nan\n            z_val = fun_control[\"weights\"] * df_eval\n            if self.fun_control[\"spot_writer\"] is not None:\n                writer = self.fun_control[\"spot_writer\"]\n                writer.add_hparams(config, {\"fun_torch: loss\": z_val})\n                writer.flush()\n            z_res = np.append(z_res, z_val)\n        return z_res\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/","title":"objectivefunctions","text":""},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical","title":"<code>analytical</code>","text":"<p>Analytical test functions.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>float</code> <p>offset</p> <code>0.0</code> <code>hz</code> <code>float</code> <p>hz</p> <code>0</code> <code>seed</code> <code>int</code> <p>seed. See Numpy Random Sampling</p> <code>126</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>class analytical:\n\"\"\"\n    Analytical test functions.\n\n    Args:\n        offset (float): offset\n        hz (float): hz\n        seed (int): seed.\n            See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start)\n\n    \"\"\"\n\n    def __init__(self, offset=0.0, hz=0, seed=126):\n        self.offset = offset\n        self.hz = hz\n        self.seed = seed\n        self.rng = default_rng(seed=self.seed)\n        self.fun_control = {\"sigma\": 0, \"seed\": None, \"sel_var\": None}\n\n    def add_noise(self, y):\n        # Use own rng:\n        if self.fun_control[\"seed\"] is not None:\n            rng = default_rng(seed=self.fun_control[\"seed\"])\n        # Use class rng:\n        else:\n            rng = self.rng\n        noise_y = np.array([], dtype=float)\n        for y_i in y:\n            noise_y = np.append(\n                noise_y,\n                y_i + rng.normal(loc=0, scale=self.fun_control[\"sigma\"], size=1),\n            )\n        return noise_y\n\n    def fun_branin_factor(self, X, fun_control=None):\n\"\"\"\n        This function calculates the Branin function with an additional factor based on the value of x3.\n        :param X: A 2D numpy array with shape (n, 3) where n is the number of samples.\n        :param fun_control: A dictionary containing control parameters for the function.\n            If None, self.fun_control is used.\n        :return: A 1D numpy array with shape (n,) containing the calculated values.\n        \"\"\"\n        if fun_control is None:\n            fun_control = self.fun_control\n        if len(X.shape) == 1:\n            X = np.array([X])\n        if X.shape[1] != 3:\n            raise Exception(\"X must have shape (n, 3)\")\n        x1 = X[:, 0]\n        x2 = X[:, 1]\n        x3 = X[:, 2]\n        a = 1\n        b = 5.1 / (4 * np.pi**2)\n        c = 5 / np.pi\n        r = 6\n        s = 10\n        t = 1 / (8 * np.pi)\n        y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s\n        for j in range(X.shape[0]):\n            if x3[j] == 1:\n                y[j] = y[j] + 10\n            elif x3[j] == 2:\n                y[j] = y[j] - 10\n        if self.fun_control[\"sigma\"] &gt; 0:\n            return self.add_noise(y)\n        else:\n            return y\n\n    def fun_linear(self, X, fun_control=None):\n\"\"\"Linear function.\n\n        Args:\n            X (array): input\n\n        Returns:\n            (float): objective function value.\n        \"\"\"\n        if fun_control is not None:\n            self.fun_control = fun_control\n        try:\n            X.shape[1]\n        except ValueError as err:\n            print(\"error message:\", err)\n            X = np.array(X)\n\n        if len(X.shape) &lt; 2:\n            X = np.array([X])\n        y = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            y = np.append(y, np.sum(X[i]))\n        if self.fun_control[\"sigma\"] &gt; 0:\n            return self.add_noise(y)\n        else:\n            return y\n\n    def fun_sphere(self, X, fun_control=None):\n\"\"\"Sphere function.\n\n        Args:\n            X (array): input\n            fun_control (dict): dict with entries `seed` and `sigma`.\n\n        Returns:\n            (float): function values\n        \"\"\"\n        if fun_control is not None:\n            self.fun_control = fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array(X)\n\n        if len(X.shape) &lt; 2:\n            X = np.array([X])\n        offset = np.ones(X.shape[1]) * self.offset\n        y = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            y = np.append(y, np.sum((X[i] - offset) ** 2))\n        # TODO: move to a separate function:\n        if self.fun_control[\"sigma\"] &gt; 0:\n            # Use own rng:\n            if self.fun_control[\"seed\"] is not None:\n                rng = default_rng(seed=fun_control[\"seed\"])\n            # Use class rng:\n            else:\n                rng = self.rng\n            noise_y = np.array([], dtype=float)\n            for y_i in y:\n                noise_y = np.append(noise_y, y_i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n            return noise_y\n        else:\n            return y\n\n    def fun_cubed(self, X, fun_control=None):\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array(X)\n\n        if len(X.shape) &lt; 2:\n            X = np.array([X])\n        offset = np.ones(X.shape[1]) * self.offset\n        y = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            y = np.append(y, np.sum((X[i] - offset) ** 3))\n        # TODO: move to a separate function:\n        if fun_control[\"sigma\"] &gt; 0:\n            # Use own rng:\n            if fun_control[\"seed\"] is not None:\n                rng = default_rng(seed=fun_control[\"seed\"])\n            # Use class rng:\n            else:\n                rng = self.rng\n            noise_y = np.array([], dtype=float)\n            for i in y:\n                # noise_y = np.append(\n                #     noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1)\n                noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n            return noise_y\n        else:\n            return y\n\n    def fun_forrester(self, X, fun_control=None):\n\"\"\"\n        Function used by [Forr08a, p.83].\n        f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1].\n        Starts with three sample points at x=0, x=0.5, and x=1.\n\n        Args:\n            X (flooat): input values (1-dim)\n\n        Returns:\n            (float): function value\n        \"\"\"\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array(X)\n\n        if len(X.shape) &lt; 2:\n            X = np.array([X])\n        y = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            y = np.append(y, (6.0 * X[i] - 2) ** 2 * np.sin(12 * X[i] - 4))\n        # TODO: move to a separate function:\n        if fun_control[\"sigma\"] &gt; 0:\n            # Use own rng:\n            if fun_control[\"seed\"] is not None:\n                rng = default_rng(seed=fun_control[\"seed\"])\n            # Use class rng:\n            else:\n                rng = self.rng\n            noise_y = np.array([], dtype=float)\n            for i in y:\n                # noise_y = np.append(\n                #     noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1)\n                noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n            return noise_y\n        else:\n            return y\n\n    def fun_branin(self, X, fun_control=None):\n\"\"\"Branin function.\n\n        The 2-dim Branin function is\n        y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s,\n        where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2),\n        c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi).\n\n        It has three global minima:\n        f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475).\n\n        Input Domain:\n        This function is usually evaluated on the square  x1 in  [-5, 10] x x2 in [0, 15].\n\n        Args:\n            X (array): input value\n            fun_control (dict): dict with entries `seed` and `sigma`.\n\n        Returns:\n            (float): function value\n\n        \"\"\"\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != 2:\n            raise Exception\n        x1 = X[:, 0]\n        x2 = X[:, 1]\n        a = 1\n        b = 5.1 / (4 * np.pi**2)\n        c = 5 / np.pi\n        r = 6\n        s = 10\n        t = 1 / (8 * np.pi)\n        y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s\n        # TODO: move to a separate function:\n        if fun_control[\"sigma\"] &gt; 0:\n            # Use own rng:\n            if fun_control[\"seed\"] is not None:\n                rng = default_rng(seed=fun_control[\"seed\"])\n            # Use class rng:\n            else:\n                rng = self.rng\n            noise_y = np.array([], dtype=float)\n            for i in y:\n                # noise_y = np.append(\n                #     noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1)\n                noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n            return noise_y\n        else:\n            return y\n\n    def fun_branin_modified(self, X, fun_control=None):\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n\n        if X.shape[1] != 2:\n            raise Exception\n        x = X[:, 0]\n        y = X[:, 1]\n        X1 = 15 * x - 5\n        X2 = 15 * y\n        a = 1\n        b = 5.1 / (4 * np.pi**2)\n        c = 5 / np.pi\n        d = 6\n        e = 10\n        ff = 1 / (8 * np.pi)\n        y = (a * (X2 - b * X1**2 + c * X1 - d) ** 2 + e * (1 - ff) * np.cos(X1) + e) + 5 * x\n        # TODO: move to a separate function:\n        if fun_control[\"sigma\"] &gt; 0:\n            # Use own rng:\n            if fun_control[\"seed\"] is not None:\n                rng = default_rng(seed=fun_control[\"seed\"])\n            # Use class rng:\n            else:\n                rng = self.rng\n            noise_y = np.array([], dtype=float)\n            for i in y:\n                noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n            return noise_y\n        else:\n            return y\n\n    def branin_noise(self, X):\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n\n        if X.shape[1] != 2:\n            raise Exception\n        x = X[:, 0]\n        y = X[:, 1]\n        X1 = 15 * x - 5\n        X2 = 15 * y\n        a = 1\n        b = 5.1 / (4 * np.pi**2)\n        c = 5 / np.pi\n        d = 6\n        e = 10\n        ff = 1 / (8 * np.pi)\n        noiseFree = (a * (X2 - b * X1**2 + c * X1 - d) ** 2 + e * (1 - ff) * np.cos(X1) + e) + 5 * x\n        noise_y = []\n        for i in noiseFree:\n            noise_y.append(i + np.random.standard_normal() * 15)\n        return np.array(noise_y)\n\n    def fun_sin_cos(self, X, fun_control=None):\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != 2:\n            raise Exception\n        x0 = X[:, 0]\n        x1 = X[:, 1]\n        y = 2.0 * np.sin(x0 + self.hz) + 0.5 * np.cos(x1 + self.hz)\n        # TODO: move to a separate function:\n        if fun_control[\"sigma\"] &gt; 0:\n            # Use own rng:\n            if fun_control[\"seed\"] is not None:\n                rng = default_rng(seed=fun_control[\"seed\"])\n            # Use class rng:\n            else:\n                rng = self.rng\n            noise_y = np.array([], dtype=float)\n            for i in y:\n                noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n            return noise_y\n        else:\n            return y\n\n    # def fun_forrester_2(self, X):\n    #     \"\"\"\n    #     Function used by [Forr08a, p.83].\n    #     f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1].\n    #     Starts with three sample points at x=0, x=0.5, and x=1.\n\n    #     Args:\n    #         X (flooat): input values (1-dim)\n\n    #     Returns:\n    #         float: function value\n    #     \"\"\"\n    #     try:\n    #         X.shape[1]\n    #     except ValueError:\n    #         X = np.array(X)\n\n    #     if len(X.shape) &lt; 2:\n    #         X = np.array([X])\n    #     # y = X[:, 1]\n    #     y = (6.0 * X - 2) ** 2 * np.sin(12 * X - 4)\n    #     if self.sigma != 0:\n    #         noise_y = np.array([], dtype=float)\n    #         for i in y:\n    #             noise_y = np.append(\n    #                 noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1)\n    #             )\n    #         return noise_y\n    #     else:\n    #         return y\n\n    def fun_runge(self, X, fun_control=None):\n\"\"\"\n        Runge function.\n        Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2\n        Dim: k &gt;= 1\n        Interval: -5 &lt;= x &lt;= 5\n\n        Args:\n            X (numpy.array):\n            input\n            fun_control (dictionary, optional):\n            control parameters. Defaults to None.\n\n        Returns:\n            (float) :\n            function value\n        \"\"\"\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array(X)\n\n        if len(X.shape) &lt; 2:\n            X = np.array([X])\n        offset = np.ones(X.shape[1]) * self.offset\n        y = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            y = np.append(y, (1 / (1 + np.sum((X[i] - offset) ** 2))))\n        # TODO: move to a separate function:\n        if fun_control[\"sigma\"] &gt; 0:\n            # Use own rng:\n            if fun_control[\"seed\"] is not None:\n                rng = default_rng(seed=fun_control[\"seed\"])\n            # Use class rng:\n            else:\n                rng = self.rng\n            noise_y = np.array([], dtype=float)\n            for i in y:\n                noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n            return noise_y\n        else:\n            return y\n\n    def fun_wingwt(self, X, fun_control=None):\n\"\"\"\n        Wing weight function. Example from Forrester et al. to understand the weight\n        of an unpainted light aircraft wing as a function of nine design and operational parameters:\n        W = 0.036 S_W**0.758 * Wfw**0.0035 ( A / (cos**2 Lambda))**0.6 *\n            q**0.006  * lambda**0.04 * ( (100 Rtc)/(cos Lambda) ))**-0.3*\n            (Nz Wdg)**0.49\n\n        | Symbol    | Parameter                              | Baseline | Minimum | Maximum |\n        |-----------|----------------------------------------|----------|---------|---------|\n        | $S_W$     | Wing area ($ft^2$)                     | 174      | 150     | 200     |\n        | $W_{fw}$  | Weight of fuel in wing (lb)            | 252      | 220     | 300     |\n        | $A$       | Aspect ratio                          | 7.52     | 6       | 10      |\n        | $Lambda$ | Quarter-chord sweep (deg)              | 0        | -10     | 10      |\n        | $q$       | Dynamic pressure at cruise ($lb/ft^2$) | 34       | 16      | 45      |\n        | $lambda$ | Taper ratio                            | 0.672    | 0.5     | 1       |\n        | $R_{tc}$  | Aerofoil thickness to chord ratio      | 0.12     | 0.08    | 0.18    |\n        | $N_z$     | Ultimate load factor                   | 3.8      | 2.5     | 6       |\n        | $W_{dg}$  | Flight design gross weight (lb)         | 2000     | 1700    | 2500    |\n        | $W_p$     | paint weight (lb/ft^2)                   | 0.064 |   0.025  | 0.08    |\n\n        Args:\n            X (numpy.array):\n                10-dim input vector\n            fun_control (dictionary, optional):\n                control parameters. Defaults to None.\n\n        Returns:\n            (float) :\n            function value\n        \"\"\"\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array(X)\n        #\n        W_res = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            Sw = X[i, 0] * (200 - 150) + 150\n            Wfw = X[i, 1] * (300 - 220) + 220\n            A = X[i, 2] * (10 - 6) + 6\n            L = (X[i, 3] * (10 - (-10)) - 10) * np.pi / 180\n            q = X[i, 4] * (45 - 16) + 16\n            la = X[i, 5] * (1 - 0.5) + 0.5\n            Rtc = X[i, 6] * (0.18 - 0.08) + 0.08\n            Nz = X[i, 7] * (6 - 2.5) + 2.5\n            Wdg = X[i, 8] * (2500 - 1700) + 1700\n            Wp = X[i, 9] * (0.08 - 0.025) + 0.025\n            # calculation on natural scale\n            W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A / np.cos(L) ** 2) ** 0.6 * q**0.006\n            W = W * la**0.04 * (100 * Rtc / np.cos(L)) ** (-0.3) * (Nz * Wdg) ** (0.49) + Sw * Wp\n            W_res = np.append(W_res, W)\n        return W_res\n\n    def fun_xsin(self, X, fun_control=None):\n\"\"\"\n        Args:\n            X (float): input values (1-dim)\n\n        Returns:\n            (float): function value\n        \"\"\"\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array(X)\n\n        if len(X.shape) &lt; 2:\n            X = np.array([X])\n        y = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            y = np.append(y, X[i] * np.sin(1.0 / X[i]))\n        # TODO: move to a separate function:\n        if fun_control[\"sigma\"] &gt; 0:\n            # Use own rng:\n            if fun_control[\"seed\"] is not None:\n                rng = default_rng(seed=fun_control[\"seed\"])\n            # Use class rng:\n            else:\n                rng = self.rng\n            noise_y = np.array([], dtype=float)\n            for i in y:\n                # noise_y = np.append(\n                #     noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1)\n                noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n            return noise_y\n        else:\n            return y\n\n    def fun_rosen(self, X, fun_control=None):\n        if fun_control is None:\n            fun_control = self.fun_control\n        try:\n            X.shape[1]\n        except ValueError:\n            X = np.array([X])\n        if X.shape[1] != 2:\n            raise Exception\n        x0 = X[:, 0]\n        x1 = X[:, 1]\n        b = 10\n        y = (x0 - 1) ** 2 + b * (x1 - x0**2) ** 2\n        if self.fun_control[\"sigma\"] &gt; 0:\n            return self.add_noise(y)\n        else:\n            return y\n\n    def fun_random_error(self, X, fun_control=None):\n\"\"\"Return errors for testing spot stability.\n\n        Args:\n            X (array): input\n\n        Returns:\n            (float): objective function value.\n        \"\"\"\n        if fun_control is not None:\n            self.fun_control = fun_control\n        try:\n            X.shape[1]\n        except ValueError as err:\n            print(\"error message:\", err)\n            X = np.array(X)\n        if len(X.shape) &lt; 2:\n            X = np.array([X])\n        y = np.array([], dtype=float)\n        for i in range(X.shape[0]):\n            # provoke error:\n            if random() &lt; 0.1:\n                y = np.append(y, np.nan)\n            else:\n                y = np.append(y, np.sum(X[i]))\n        if self.fun_control[\"sigma\"] &gt; 0:\n            return self.add_noise(y)\n        else:\n            print(y)\n            return y\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_branin","title":"<code>fun_branin(X, fun_control=None)</code>","text":"<p>Branin function.</p> <p>The 2-dim Branin function is y = a * (x2 - b * x12 + c * x1 - r)  2 + s * (1 - t) * np.cos(x1) + s, where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4pi2), c = 5 / pi, r = 6, s = 10 and t = 1 / (8pi).</p> <p>It has three global minima: f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475).</p> <p>Input Domain: This function is usually evaluated on the square  x1 in  [-5, 10] x x2 in [0, 15].</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>input value</p> required <code>fun_control</code> <code>dict</code> <p>dict with entries <code>seed</code> and <code>sigma</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>function value</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_branin(self, X, fun_control=None):\n\"\"\"Branin function.\n\n    The 2-dim Branin function is\n    y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s,\n    where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2),\n    c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi).\n\n    It has three global minima:\n    f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475).\n\n    Input Domain:\n    This function is usually evaluated on the square  x1 in  [-5, 10] x x2 in [0, 15].\n\n    Args:\n        X (array): input value\n        fun_control (dict): dict with entries `seed` and `sigma`.\n\n    Returns:\n        (float): function value\n\n    \"\"\"\n    if fun_control is None:\n        fun_control = self.fun_control\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array([X])\n    if X.shape[1] != 2:\n        raise Exception\n    x1 = X[:, 0]\n    x2 = X[:, 1]\n    a = 1\n    b = 5.1 / (4 * np.pi**2)\n    c = 5 / np.pi\n    r = 6\n    s = 10\n    t = 1 / (8 * np.pi)\n    y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s\n    # TODO: move to a separate function:\n    if fun_control[\"sigma\"] &gt; 0:\n        # Use own rng:\n        if fun_control[\"seed\"] is not None:\n            rng = default_rng(seed=fun_control[\"seed\"])\n        # Use class rng:\n        else:\n            rng = self.rng\n        noise_y = np.array([], dtype=float)\n        for i in y:\n            # noise_y = np.append(\n            #     noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1)\n            noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n        return noise_y\n    else:\n        return y\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_branin_factor","title":"<code>fun_branin_factor(X, fun_control=None)</code>","text":"<p>This function calculates the Branin function with an additional factor based on the value of x3. :param X: A 2D numpy array with shape (n, 3) where n is the number of samples. :param fun_control: A dictionary containing control parameters for the function.     If None, self.fun_control is used. :return: A 1D numpy array with shape (n,) containing the calculated values.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_branin_factor(self, X, fun_control=None):\n\"\"\"\n    This function calculates the Branin function with an additional factor based on the value of x3.\n    :param X: A 2D numpy array with shape (n, 3) where n is the number of samples.\n    :param fun_control: A dictionary containing control parameters for the function.\n        If None, self.fun_control is used.\n    :return: A 1D numpy array with shape (n,) containing the calculated values.\n    \"\"\"\n    if fun_control is None:\n        fun_control = self.fun_control\n    if len(X.shape) == 1:\n        X = np.array([X])\n    if X.shape[1] != 3:\n        raise Exception(\"X must have shape (n, 3)\")\n    x1 = X[:, 0]\n    x2 = X[:, 1]\n    x3 = X[:, 2]\n    a = 1\n    b = 5.1 / (4 * np.pi**2)\n    c = 5 / np.pi\n    r = 6\n    s = 10\n    t = 1 / (8 * np.pi)\n    y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s\n    for j in range(X.shape[0]):\n        if x3[j] == 1:\n            y[j] = y[j] + 10\n        elif x3[j] == 2:\n            y[j] = y[j] - 10\n    if self.fun_control[\"sigma\"] &gt; 0:\n        return self.add_noise(y)\n    else:\n        return y\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_forrester","title":"<code>fun_forrester(X, fun_control=None)</code>","text":"<p>Function used by [Forr08a, p.83]. f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. Starts with three sample points at x=0, x=0.5, and x=1.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>flooat</code> <p>input values (1-dim)</p> required <p>Returns:</p> Type Description <code>float</code> <p>function value</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_forrester(self, X, fun_control=None):\n\"\"\"\n    Function used by [Forr08a, p.83].\n    f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1].\n    Starts with three sample points at x=0, x=0.5, and x=1.\n\n    Args:\n        X (flooat): input values (1-dim)\n\n    Returns:\n        (float): function value\n    \"\"\"\n    if fun_control is None:\n        fun_control = self.fun_control\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array(X)\n\n    if len(X.shape) &lt; 2:\n        X = np.array([X])\n    y = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        y = np.append(y, (6.0 * X[i] - 2) ** 2 * np.sin(12 * X[i] - 4))\n    # TODO: move to a separate function:\n    if fun_control[\"sigma\"] &gt; 0:\n        # Use own rng:\n        if fun_control[\"seed\"] is not None:\n            rng = default_rng(seed=fun_control[\"seed\"])\n        # Use class rng:\n        else:\n            rng = self.rng\n        noise_y = np.array([], dtype=float)\n        for i in y:\n            # noise_y = np.append(\n            #     noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1)\n            noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n        return noise_y\n    else:\n        return y\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_linear","title":"<code>fun_linear(X, fun_control=None)</code>","text":"<p>Linear function.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>input</p> required <p>Returns:</p> Type Description <code>float</code> <p>objective function value.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_linear(self, X, fun_control=None):\n\"\"\"Linear function.\n\n    Args:\n        X (array): input\n\n    Returns:\n        (float): objective function value.\n    \"\"\"\n    if fun_control is not None:\n        self.fun_control = fun_control\n    try:\n        X.shape[1]\n    except ValueError as err:\n        print(\"error message:\", err)\n        X = np.array(X)\n\n    if len(X.shape) &lt; 2:\n        X = np.array([X])\n    y = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        y = np.append(y, np.sum(X[i]))\n    if self.fun_control[\"sigma\"] &gt; 0:\n        return self.add_noise(y)\n    else:\n        return y\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_random_error","title":"<code>fun_random_error(X, fun_control=None)</code>","text":"<p>Return errors for testing spot stability.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>input</p> required <p>Returns:</p> Type Description <code>float</code> <p>objective function value.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_random_error(self, X, fun_control=None):\n\"\"\"Return errors for testing spot stability.\n\n    Args:\n        X (array): input\n\n    Returns:\n        (float): objective function value.\n    \"\"\"\n    if fun_control is not None:\n        self.fun_control = fun_control\n    try:\n        X.shape[1]\n    except ValueError as err:\n        print(\"error message:\", err)\n        X = np.array(X)\n    if len(X.shape) &lt; 2:\n        X = np.array([X])\n    y = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        # provoke error:\n        if random() &lt; 0.1:\n            y = np.append(y, np.nan)\n        else:\n            y = np.append(y, np.sum(X[i]))\n    if self.fun_control[\"sigma\"] &gt; 0:\n        return self.add_noise(y)\n    else:\n        print(y)\n        return y\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_runge","title":"<code>fun_runge(X, fun_control=None)</code>","text":"<p>Runge function. Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2 Dim: k &gt;= 1 Interval: -5 &lt;= x &lt;= 5</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>numpy.array</code> required <code>fun_control</code> <code>dictionary</code> <code>None</code> <p>Returns:</p> Type Description <p>(float) :</p> <p>function value</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_runge(self, X, fun_control=None):\n\"\"\"\n    Runge function.\n    Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2\n    Dim: k &gt;= 1\n    Interval: -5 &lt;= x &lt;= 5\n\n    Args:\n        X (numpy.array):\n        input\n        fun_control (dictionary, optional):\n        control parameters. Defaults to None.\n\n    Returns:\n        (float) :\n        function value\n    \"\"\"\n    if fun_control is None:\n        fun_control = self.fun_control\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array(X)\n\n    if len(X.shape) &lt; 2:\n        X = np.array([X])\n    offset = np.ones(X.shape[1]) * self.offset\n    y = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        y = np.append(y, (1 / (1 + np.sum((X[i] - offset) ** 2))))\n    # TODO: move to a separate function:\n    if fun_control[\"sigma\"] &gt; 0:\n        # Use own rng:\n        if fun_control[\"seed\"] is not None:\n            rng = default_rng(seed=fun_control[\"seed\"])\n        # Use class rng:\n        else:\n            rng = self.rng\n        noise_y = np.array([], dtype=float)\n        for i in y:\n            noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n        return noise_y\n    else:\n        return y\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_sphere","title":"<code>fun_sphere(X, fun_control=None)</code>","text":"<p>Sphere function.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>input</p> required <code>fun_control</code> <code>dict</code> <p>dict with entries <code>seed</code> and <code>sigma</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>function values</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_sphere(self, X, fun_control=None):\n\"\"\"Sphere function.\n\n    Args:\n        X (array): input\n        fun_control (dict): dict with entries `seed` and `sigma`.\n\n    Returns:\n        (float): function values\n    \"\"\"\n    if fun_control is not None:\n        self.fun_control = fun_control\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array(X)\n\n    if len(X.shape) &lt; 2:\n        X = np.array([X])\n    offset = np.ones(X.shape[1]) * self.offset\n    y = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        y = np.append(y, np.sum((X[i] - offset) ** 2))\n    # TODO: move to a separate function:\n    if self.fun_control[\"sigma\"] &gt; 0:\n        # Use own rng:\n        if self.fun_control[\"seed\"] is not None:\n            rng = default_rng(seed=fun_control[\"seed\"])\n        # Use class rng:\n        else:\n            rng = self.rng\n        noise_y = np.array([], dtype=float)\n        for y_i in y:\n            noise_y = np.append(noise_y, y_i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n        return noise_y\n    else:\n        return y\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_wingwt","title":"<code>fun_wingwt(X, fun_control=None)</code>","text":"<p>Wing weight function. Example from Forrester et al. to understand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters: W = 0.036 S_W0.758 * Wfw0.0035 ( A / (cos2 Lambda))0.6 *     q0.006  * lambda0.04 * ( (100 Rtc)/(cos Lambda) ))-0.3*     (Nz Wdg)0.49</p> Symbol Parameter Baseline Minimum Maximum $S_W$ Wing area ($ft^2$) 174 150 200 $W_{fw}$ Weight of fuel in wing (lb) 252 220 300 $A$ Aspect ratio 7.52 6 10 $Lambda$ Quarter-chord sweep (deg) 0 -10 10 $q$ Dynamic pressure at cruise ($lb/ft^2$) 34 16 45 $lambda$ Taper ratio 0.672 0.5 1 $R_{tc}$ Aerofoil thickness to chord ratio 0.12 0.08 0.18 $N_z$ Ultimate load factor 3.8 2.5 6 $W_{dg}$ Flight design gross weight (lb) 2000 1700 2500 $W_p$ paint weight (lb/ft^2) 0.064 0.025 0.08 <p>Parameters:</p> Name Type Description Default <code>X</code> <code>numpy.array</code> <p>10-dim input vector</p> required <code>fun_control</code> <code>dictionary</code> <p>control parameters. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>(float) :</p> <p>function value</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_wingwt(self, X, fun_control=None):\n\"\"\"\n    Wing weight function. Example from Forrester et al. to understand the weight\n    of an unpainted light aircraft wing as a function of nine design and operational parameters:\n    W = 0.036 S_W**0.758 * Wfw**0.0035 ( A / (cos**2 Lambda))**0.6 *\n        q**0.006  * lambda**0.04 * ( (100 Rtc)/(cos Lambda) ))**-0.3*\n        (Nz Wdg)**0.49\n\n    | Symbol    | Parameter                              | Baseline | Minimum | Maximum |\n    |-----------|----------------------------------------|----------|---------|---------|\n    | $S_W$     | Wing area ($ft^2$)                     | 174      | 150     | 200     |\n    | $W_{fw}$  | Weight of fuel in wing (lb)            | 252      | 220     | 300     |\n    | $A$       | Aspect ratio                          | 7.52     | 6       | 10      |\n    | $Lambda$ | Quarter-chord sweep (deg)              | 0        | -10     | 10      |\n    | $q$       | Dynamic pressure at cruise ($lb/ft^2$) | 34       | 16      | 45      |\n    | $lambda$ | Taper ratio                            | 0.672    | 0.5     | 1       |\n    | $R_{tc}$  | Aerofoil thickness to chord ratio      | 0.12     | 0.08    | 0.18    |\n    | $N_z$     | Ultimate load factor                   | 3.8      | 2.5     | 6       |\n    | $W_{dg}$  | Flight design gross weight (lb)         | 2000     | 1700    | 2500    |\n    | $W_p$     | paint weight (lb/ft^2)                   | 0.064 |   0.025  | 0.08    |\n\n    Args:\n        X (numpy.array):\n            10-dim input vector\n        fun_control (dictionary, optional):\n            control parameters. Defaults to None.\n\n    Returns:\n        (float) :\n        function value\n    \"\"\"\n    if fun_control is None:\n        fun_control = self.fun_control\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array(X)\n    #\n    W_res = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        Sw = X[i, 0] * (200 - 150) + 150\n        Wfw = X[i, 1] * (300 - 220) + 220\n        A = X[i, 2] * (10 - 6) + 6\n        L = (X[i, 3] * (10 - (-10)) - 10) * np.pi / 180\n        q = X[i, 4] * (45 - 16) + 16\n        la = X[i, 5] * (1 - 0.5) + 0.5\n        Rtc = X[i, 6] * (0.18 - 0.08) + 0.08\n        Nz = X[i, 7] * (6 - 2.5) + 2.5\n        Wdg = X[i, 8] * (2500 - 1700) + 1700\n        Wp = X[i, 9] * (0.08 - 0.025) + 0.025\n        # calculation on natural scale\n        W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A / np.cos(L) ** 2) ** 0.6 * q**0.006\n        W = W * la**0.04 * (100 * Rtc / np.cos(L)) ** (-0.3) * (Nz * Wdg) ** (0.49) + Sw * Wp\n        W_res = np.append(W_res, W)\n    return W_res\n</code></pre>"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_xsin","title":"<code>fun_xsin(X, fun_control=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>X</code> <code>float</code> <p>input values (1-dim)</p> required <p>Returns:</p> Type Description <code>float</code> <p>function value</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/fun/objectivefunctions.py</code> <pre><code>def fun_xsin(self, X, fun_control=None):\n\"\"\"\n    Args:\n        X (float): input values (1-dim)\n\n    Returns:\n        (float): function value\n    \"\"\"\n    if fun_control is None:\n        fun_control = self.fun_control\n    try:\n        X.shape[1]\n    except ValueError:\n        X = np.array(X)\n\n    if len(X.shape) &lt; 2:\n        X = np.array([X])\n    y = np.array([], dtype=float)\n    for i in range(X.shape[0]):\n        y = np.append(y, X[i] * np.sin(1.0 / X[i]))\n    # TODO: move to a separate function:\n    if fun_control[\"sigma\"] &gt; 0:\n        # Use own rng:\n        if fun_control[\"seed\"] is not None:\n            rng = default_rng(seed=fun_control[\"seed\"])\n        # Use class rng:\n        else:\n            rng = self.rng\n        noise_y = np.array([], dtype=float)\n        for i in y:\n            # noise_y = np.append(\n            #     noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1)\n            noise_y = np.append(noise_y, i + rng.normal(loc=0, scale=fun_control[\"sigma\"], size=1))\n        return noise_y\n    else:\n        return y\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/categorical/","title":"categorical","text":""},{"location":"reference/spotPython/hyperparameters/categorical/#spotPython.hyperparameters.categorical.add_missing_elements","title":"<code>add_missing_elements(a, b)</code>","text":"<p>Add missing elements from list a to list b.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>list</code> <p>List of elements to check.</p> required <code>b</code> <code>list</code> <p>List of elements to add to.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>List of elements with missing elements from list a added.</p> Example <p>a = [1, 4]     b = [1, 2]     add_missing_elements(a, b)     [1, 2, 4]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/categorical.py</code> <pre><code>def add_missing_elements(a: list, b: list) -&gt; list:\n\"\"\"Add missing elements from list a to list b.\n    Arguments:\n        a (list): List of elements to check.\n        b (list): List of elements to add to.\n\n    Returns:\n        list: List of elements with missing elements from list a added.\n\n    Example:\n        &gt;&gt;&gt; a = [1, 4]\n            b = [1, 2]\n            add_missing_elements(a, b)\n            [1, 2, 4]\n    \"\"\"\n    for element in a:\n        if element not in b:\n            b.append(element)\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/categorical/#spotPython.hyperparameters.categorical.find_closest_key","title":"<code>find_closest_key(integer_value, encoding_dict)</code>","text":"<p>Given an integer value and an encoding dictionary that maps keys to binary values, this function finds the key in the dictionary whose binary value is closest to the binary representation of the integer value.</p> <p>Parameters:</p> Name Type Description Default <code>integer_value</code> <code>int</code> <p>The integer value to find the closest key for.</p> required <code>encoding_dict</code> <code>dict</code> <p>The encoding dictionary that maps keys to binary values.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The key in the encoding dictionary whose binary value is</p> <code>str</code> <p>closest to the binary representation of the integer value.</p> Example <p>encoding_dict = {\u2018A\u2019: [1, 0, 0], \u2018B\u2019: [0, 1, 0], \u2018C\u2019: [0, 0, 1]}     find_closest_key(6, encoding_dict)     \u2018B\u2019</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/categorical.py</code> <pre><code>def find_closest_key(integer_value: int, encoding_dict: dict) -&gt; str:\n\"\"\"\n    Given an integer value and an encoding dictionary that maps keys to binary values,\n    this function finds the key in the dictionary whose binary value is closest to the binary\n    representation of the integer value.\n\n    Arguments:\n        integer_value (int): The integer value to find the closest key for.\n        encoding_dict (dict): The encoding dictionary that maps keys to binary values.\n    Returns:\n        str: The key in the encoding dictionary whose binary value is\n        closest to the binary representation of the integer value.\n    Example:\n        &gt;&gt;&gt; encoding_dict = {'A': [1, 0, 0], 'B': [0, 1, 0], 'C': [0, 0, 1]}\n            find_closest_key(6, encoding_dict)\n            'B'\n    \"\"\"\n    binary_value = [int(x) for x in format(integer_value, f\"0{len(list(encoding_dict.values())[0])}b\")]\n    min_distance = float(\"inf\")\n    closest_key = None\n    for key, encoded_value in encoding_dict.items():\n        distance = sum([x != y for x, y in zip(binary_value, encoded_value)])\n        if distance &lt; min_distance:\n            min_distance = distance\n            closest_key = key\n    return closest_key\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/categorical/#spotPython.hyperparameters.categorical.get_one_hot","title":"<code>get_one_hot(alg, hyper_param, d=None, filename='data.json')</code>","text":"<p>Get one hot encoded values for a hyper parameter of an algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>alg</code> <code>str</code> <p>Name of the algorithm.</p> required <code>hyper_param</code> <code>str</code> <p>Name of the hyper parameter.</p> required <code>d</code> <code>dict</code> <p>Dictionary of algorithms and their hyperparameters.</p> <code>None</code> <code>filename</code> <code>str</code> <p>Name of the file containing the dictionary.</p> <code>'data.json'</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary of hyper parameter values and their one hot encoded values.</p> Example <p>alg = \u201cHoeffdingAdaptiveTreeClassifier\u201d     hyper_param = \u201csplit_criterion\u201d     d = {         \u201cHoeffdingAdaptiveTreeClassifier\u201d: {             \u201csplit_criterion\u201d: [\u201cgini\u201d, \u201cinfo_gain\u201d, \u201chellinger\u201d],             \u201cleaf_prediction\u201d: [\u201cmc\u201d, \u201cnb\u201d, \u201cnba\u201d],             \u201cbootstrap_sampling\u201d: [\u201c0\u201d, \u201c1\u201d]             },             \u201cHoeffdingTreeClassifier\u201d: {                 \u201csplit_criterion\u201d: [\u201cgini\u201d, \u201cinfo_gain\u201d, \u201chellinger\u201d],                 \u201cleaf_prediction\u201d: [\u201cmc\u201d, \u201cnb\u201d, \u201cnba\u201d],                 \u201cbinary_split\u201d: [\u201c0\u201d, \u201c1\u201d],                 \u201cstop_mem_management\u201d: [\u201c0\u201d, \u201c1\u201d]             }         }     get_one_hot(alg, hyper_param, d)     {\u2018gini\u2019: [1, 0, 0], \u2018info_gain\u2019: [0, 1, 0], \u2018hellinger\u2019: [0, 0, 1]}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/categorical.py</code> <pre><code>def get_one_hot(alg: str, hyper_param: str, d: dict = None, filename: str = \"data.json\") -&gt; dict:\n\"\"\"Get one hot encoded values for a hyper parameter of an algorithm.\n    Arguments:\n        alg (str): Name of the algorithm.\n        hyper_param (str): Name of the hyper parameter.\n        d (dict): Dictionary of algorithms and their hyperparameters.\n        filename (str): Name of the file containing the dictionary.\n    Returns:\n        dict: Dictionary of hyper parameter values and their one hot encoded values.\n    Example:\n        &gt;&gt;&gt; alg = \"HoeffdingAdaptiveTreeClassifier\"\n            hyper_param = \"split_criterion\"\n            d = {\n                \"HoeffdingAdaptiveTreeClassifier\": {\n                    \"split_criterion\": [\"gini\", \"info_gain\", \"hellinger\"],\n                    \"leaf_prediction\": [\"mc\", \"nb\", \"nba\"],\n                    \"bootstrap_sampling\": [\"0\", \"1\"]\n                    },\n                    \"HoeffdingTreeClassifier\": {\n                        \"split_criterion\": [\"gini\", \"info_gain\", \"hellinger\"],\n                        \"leaf_prediction\": [\"mc\", \"nb\", \"nba\"],\n                        \"binary_split\": [\"0\", \"1\"],\n                        \"stop_mem_management\": [\"0\", \"1\"]\n                    }\n                }\n            get_one_hot(alg, hyper_param, d)\n            {'gini': [1, 0, 0], 'info_gain': [0, 1, 0], 'hellinger': [0, 0, 1]}\n    \"\"\"\n    if d is None:\n        with open(filename, \"r\") as f:\n            d = json.load(f)\n    values = d[alg][hyper_param]\n    one_hot_encoded_values = one_hot_encode(values)\n    return one_hot_encoded_values\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/categorical/#spotPython.hyperparameters.categorical.one_hot_encode","title":"<code>one_hot_encode(strings)</code>","text":"<p>One hot encode a list of strings.</p> <p>Parameters:</p> Name Type Description Default <code>strings</code> <code>list</code> <p>List of strings to encode.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary of strings and their one hot encoded values.</p> Example <p>one_hot_encode([\u2018a\u2019, \u2018b\u2019, \u2018c\u2019]) {\u2018a\u2019: [1, 0, 0], \u2018b\u2019: [0, 1, 0], \u2018c\u2019: [0, 0, 1]}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/categorical.py</code> <pre><code>def one_hot_encode(strings) -&gt; dict:\n\"\"\"One hot encode a list of strings.\n    Arguments:\n        strings (list): List of strings to encode.\n    Returns:\n        dict: Dictionary of strings and their one hot encoded values.\n    Example:\n        &gt;&gt;&gt; one_hot_encode(['a', 'b', 'c'])\n        {'a': [1, 0, 0], 'b': [0, 1, 0], 'c': [0, 0, 1]}\n    \"\"\"\n    n = len(strings)\n    encoding_dict = {}\n    for i, string in enumerate(strings):\n        one_hot_encoded_value = [0] * n\n        one_hot_encoded_value[i] = 1\n        encoding_dict[string] = one_hot_encoded_value\n    return encoding_dict\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/categorical/#spotPython.hyperparameters.categorical.sum_encoded_values","title":"<code>sum_encoded_values(strings, encoding_dict)</code>","text":"<p>Sum the encoded values of a list of strings.</p> <p>Parameters:</p> Name Type Description Default <code>strings</code> <code>list</code> <p>List of strings to encode.</p> required <code>encoding_dict</code> <code>dict</code> <p>Dictionary of strings and their one hot encoded values.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Decimal value of the sum of the encoded values.</p> Example <p>encoding_dict = {\u2018a\u2019: [1, 0, 0], \u2018b\u2019: [0, 1, 0], \u2018c\u2019: [0, 0, 1]}     sum_encoded_values([\u2018a\u2019, \u2018b\u2019, \u2018c\u2019], encoding_dict)     7     sum_encoded_values([\u2018a\u2019, \u2018c\u2019], encoding_dict)     5</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/categorical.py</code> <pre><code>def sum_encoded_values(strings, encoding_dict) -&gt; int:\n\"\"\"Sum the encoded values of a list of strings.\n\n    Args:\n        strings (list): List of strings to encode.\n        encoding_dict (dict): Dictionary of strings and their one hot encoded values.\n\n    Returns:\n        int: Decimal value of the sum of the encoded values.\n\n    Example:\n        &gt;&gt;&gt; encoding_dict = {'a': [1, 0, 0], 'b': [0, 1, 0], 'c': [0, 0, 1]}\n            sum_encoded_values(['a', 'b', 'c'], encoding_dict)\n            7\n            sum_encoded_values(['a', 'c'], encoding_dict)\n            5\n    \"\"\"\n    result = [0] * len(list(encoding_dict.values())[0])\n    for string in strings:\n        encoded_value = encoding_dict.get(string)\n        if encoded_value:\n            result = [sum(x) for x in zip(result, encoded_value)]\n    decimal_result = 0\n    for i, value in enumerate(result[::-1]):\n        decimal_result += value * (2**i)\n    return decimal_result\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/optimizer/","title":"optimizer","text":""},{"location":"reference/spotPython/hyperparameters/values/","title":"values","text":""},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.add_core_model_to_fun_control","title":"<code>add_core_model_to_fun_control(core_model, fun_control, hyper_dict, filename=None)</code>","text":"<p>Add the core model to the function control dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>core_model</code> <code>class</code> <p>The core model.</p> required <code>fun_control</code> <code>dict</code> <p>The function control dictionary.</p> required <code>hyper_dict</code> <code>dict</code> <p>The hyper parameter dictionary.</p> required <code>filename</code> <code>str</code> <p>The name of the json file that contains the hyper parameter dictionary.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>The function control dictionary.</p> Example <p>from river.tree import HoeffdingAdaptiveTreeRegressor     from spotRiver.data.river_hyper_dict import RiverHyperDict     fun_control = {}     add_core_model_to_fun_control(core_model=HoeffdingAdaptiveTreeRegressor,         fun_control=func_control,         hyper_dict=RiverHyperDict,         filename=None)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def add_core_model_to_fun_control(core_model, fun_control, hyper_dict, filename=None) -&gt; dict:\n\"\"\"Add the core model to the function control dictionary.\n    Args:\n        core_model (class): The core model.\n        fun_control (dict): The function control dictionary.\n        hyper_dict (dict): The hyper parameter dictionary.\n        filename (str): The name of the json file that contains the hyper parameter dictionary.\n        Optional. Default is None.\n    Returns:\n        (dict): The function control dictionary.\n    Example:\n        &gt;&gt;&gt; from river.tree import HoeffdingAdaptiveTreeRegressor\n            from spotRiver.data.river_hyper_dict import RiverHyperDict\n            fun_control = {}\n            add_core_model_to_fun_control(core_model=HoeffdingAdaptiveTreeRegressor,\n                fun_control=func_control,\n                hyper_dict=RiverHyperDict,\n                filename=None)\n    \"\"\"\n    fun_control.update({\"core_model\": core_model})\n    if filename is None:\n        new_hyper_dict = hyper_dict().load()\n    else:\n        with open(filename, \"r\") as f:\n            new_hyper_dict = json.load(f)\n    hyper_dict().load()\n    fun_control.update({\"core_model_hyper_dict\": new_hyper_dict[core_model.__name__]})\n    var_type = get_var_type(fun_control)\n    var_name = get_var_name(fun_control)\n    fun_control.update({\"var_type\": var_type, \"var_name\": var_name})\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.assign_values","title":"<code>assign_values(X, var_list)</code>","text":"<p>This function takes an np.array X and a list of variable names as input arguments and returns a dictionary where the keys are the variable names and the values are assigned from X.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>np.array</code> <p>A 2D numpy array where each column represents a variable.</p> required <code>var_list</code> <code>list</code> <p>A list of strings representing variable names.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary where keys are variable names and values are assigned from X.</p> Example <p>import numpy as np X = np.array([[1, 2], [3, 4], [5, 6]]) var_list = [\u2018a\u2019, \u2018b\u2019] result = assign_values(X, var_list) print(result) {\u2018a\u2019: array([1, 3, 5]), \u2018b\u2019: array([2, 4, 6])}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def assign_values(X: np.array, var_list: list) -&gt; dict:\n\"\"\"\n    This function takes an np.array X and a list of variable names as input arguments\n    and returns a dictionary where the keys are the variable names and the values are assigned from X.\n\n    Parameters:\n        X (np.array): A 2D numpy array where each column represents a variable.\n        var_list (list): A list of strings representing variable names.\n\n    Returns:\n        dict: A dictionary where keys are variable names and values are assigned from X.\n\n    Example:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; var_list = ['a', 'b']\n        &gt;&gt;&gt; result = assign_values(X, var_list)\n        &gt;&gt;&gt; print(result)\n        {'a': array([1, 3, 5]), 'b': array([2, 4, 6])}\n    \"\"\"\n    result = {}\n    for i, var_name in enumerate(var_list):\n        result[var_name] = X[:, i]\n    return result\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.convert_keys","title":"<code>convert_keys(d, var_type)</code>","text":"<p>Convert values in a dictionary to integers based on a list of variable types.</p> <p>This function takes a dictionary <code>d</code> and a list of variable types <code>var_type</code> as arguments. For each key in the dictionary, if the corresponding entry in <code>var_type</code> is not equal to <code>\"num\"</code>, the value associated with that key is converted to an integer.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>The input dictionary.</p> required <code>var_type</code> <code>list</code> <p>A list of variable types. If the entry is not <code>\"num\"</code> the corresponding</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>The modified dictionary with values converted to integers based on <code>var_type</code>.</p> Example <p>d = {\u2018a\u2019: \u20181.1\u2019, \u2018b\u2019: \u20182\u2019, \u2018c\u2019: \u20183.1\u2019} var_type = [\u201cint\u201d, \u201cnum\u201d, \u201cint\u201d] convert_keys(d, var_type) {\u2018a\u2019: 1, \u2018b\u2019: \u20182\u2019, \u2018c\u2019: 3}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def convert_keys(d: dict, var_type: list):\n\"\"\"\n    Convert values in a dictionary to integers based on a list of variable types.\n\n    This function takes a dictionary `d` and a list of variable types `var_type` as arguments.\n    For each key in the dictionary,\n    if the corresponding entry in `var_type` is not equal to `\"num\"`,\n    the value associated with that key is converted to an integer.\n\n    Args:\n        d (dict): The input dictionary.\n        var_type (list): A list of variable types. If the entry is not `\"num\"` the corresponding\n        value will be converted to the type `\"int\"`.\n\n    Returns:\n        dict: The modified dictionary with values converted to integers based on `var_type`.\n\n    Example:\n        &gt;&gt;&gt; d = {'a': '1.1', 'b': '2', 'c': '3.1'}\n        &gt;&gt;&gt; var_type = [\"int\", \"num\", \"int\"]\n        &gt;&gt;&gt; convert_keys(d, var_type)\n        {'a': 1, 'b': '2', 'c': 3}\n    \"\"\"\n    keys = list(d.keys())\n    for i in range(len(keys)):\n        if var_type[i] not in [\"num\", \"float\"]:\n            d[keys[i]] = int(d[keys[i]])\n    return d\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.generate_one_config_from_var_dict","title":"<code>generate_one_config_from_var_dict(var_dict, fun_control)</code>","text":"<p>Generate one configuration from a dictionary of variables (as a generator). This function takes a dictionary of variables as input arguments and returns a dictionary with the values from the arrays in the dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>var_dict</code> <code>dict</code> <p>A dictionary where keys are variable names and values are numpy arrays.</p> required <code>fun_control</code> <code>dict</code> <p>A dictionary which (at least) has an entry with the following key: - \u201cvar_type\u201d: A list of variable types. If the entry is not \u201cnum\u201d the corresponding value will be converted to the type \u201cint\u201d.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary with the values from the arrays in the dictionary.</p> Example <p>import numpy as np var_dict = {\u2018a\u2019: np.array([1, 3, 5]), \u2018b\u2019: np.array([2, 4, 6])} fun_control = {\u201cvar_type\u201d: [\u201cint\u201d, \u201cnum\u201d]} generate_one_config_from_var_dict(var_dict, fun_control) {\u2018a\u2019: 1, \u2018b\u2019: 2}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def generate_one_config_from_var_dict(var_dict, fun_control) -&gt; dict:\n\"\"\"Generate one configuration from a dictionary of variables (as a generator).\n    This function takes a dictionary of variables as input arguments and returns a dictionary\n    with the values from the arrays in the dictionary.\n    Args:\n        var_dict (dict): A dictionary where keys are variable names and values are numpy arrays.\n        fun_control (dict): A dictionary which (at least) has an entry with the following key:\n            - \"var_type\": A list of variable types. If the entry is not \"num\" the corresponding\n            value will be converted to the type \"int\".\n    Returns:\n        dict: A dictionary with the values from the arrays in the dictionary.\n    Example:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; var_dict = {'a': np.array([1, 3, 5]), 'b': np.array([2, 4, 6])}\n        &gt;&gt;&gt; fun_control = {\"var_type\": [\"int\", \"num\"]}\n        &gt;&gt;&gt; generate_one_config_from_var_dict(var_dict, fun_control)\n        {'a': 1, 'b': 2}\n    \"\"\"\n    for values in iterate_dict_values(var_dict):\n        values = convert_keys(values, fun_control[\"var_type\"])\n        values = get_dict_with_levels_and_types(fun_control=fun_control, v=values)\n        values = transform_hyper_parameter_values(fun_control=fun_control, hyper_parameter_values=values)\n        yield values\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.get_bound_values","title":"<code>get_bound_values(fun_control, bound, as_list=False)</code>","text":"<p>Generate a list from a dictionary. It takes the values from the keys \u201cbound\u201d in the fun_control[]\u201dcore_model_hyper_dict\u201d] dictionary and returns a list of the values in the same order as the keys in the dictionary. For example if the dictionary is {\u201ca\u201d: {\u201cupper\u201d: 1}, \u201cb\u201d: {\u201cupper\u201d: 2}} the list is [1, 2] if bound=\u201dupper\u201d.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>dictionary with upper values</p> required <code>bound</code> <code>str</code> <p>either \u201cupper\u201d or \u201clower\u201d</p> required <p>Returns:</p> Type Description <code>list</code> <p>list with lower or upper values</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def get_bound_values(fun_control: dict, bound: str, as_list=False) -&gt; list or np.array:\n\"\"\"Generate a list from a dictionary.\n    It takes the values from the keys \"bound\" in the\n    fun_control[]\"core_model_hyper_dict\"] dictionary and\n    returns a list of the values in the same order as the keys in the\n    dictionary.\n    For example if the dictionary is\n    {\"a\": {\"upper\": 1}, \"b\": {\"upper\": 2}}\n    the list is [1, 2] if bound=\"upper\".\n    Args:\n        fun_control (dict): dictionary with upper values\n        bound (str): either \"upper\" or \"lower\"\n    Returns:\n        (list): list with lower or upper values\n    \"\"\"\n    # Throw value error if bound is not upper or lower:\n    if bound not in [\"upper\", \"lower\"]:\n        raise ValueError(\"bound must be either 'upper' or 'lower'\")\n    d = fun_control[\"core_model_hyper_dict\"]\n    b = []\n    for key, value in d.items():\n        b.append(value[bound])\n    if as_list:\n        return b\n    else:\n        return np.array(b)\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.get_default_values","title":"<code>get_default_values(fun_control)</code>","text":"<p>Get the values from the \u201cdefault\u201d keys from the dictionary fun_control as a dict. If the key of the value has as \u201ctype\u201d the value \u201cint\u201d or \u201cfloat\u201d, convert the value to the corresponding type.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>dictionary with levels and types</p> required <p>Returns:</p> Name Type Description <code>new_dict</code> <code>dict</code> <p>dictionary with default values</p> Example <p>d = {\u201ccore_model_hyper_dict\u201d:{         \u201cleaf_prediction\u201d: {             \u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d],             \u201ctype\u201d: \u201cfactor\u201d,             \u201cdefault\u201d: \u201cmean\u201d,             \u201ccore_model_parameter_type\u201d: \u201cstr\u201d},         \u201cleaf_model\u201d: {             \u201clevels\u201d: [\u201clinear_model.LinearRegression\u201d, \u201clinear_model.PARegressor\u201d, \u201clinear_model.Perceptron\u201d],             \u201ctype\u201d: \u201cfactor\u201d,             \u201cdefault\u201d: \u201cLinearRegression\u201d,             \u201ccore_model_parameter_type\u201d: \u201cinstance\u201d},         \u201csplitter\u201d: {             \u201clevels\u201d: [\u201cEBSTSplitter\u201d, \u201cTEBSTSplitter\u201d, \u201cQOSplitter\u201d],             \u201ctype\u201d: \u201cfactor\u201d,             \u201cdefault\u201d: \u201cEBSTSplitter\u201d,             \u201ccore_model_parameter_type\u201d: \u201cinstance()\u201d},         \u201cbinary_split\u201d: {             \u201clevels\u201d: [0, 1],             \u201ctype\u201d: \u201cfactor\u201d,             \u201cdefault\u201d: 0,             \u201ccore_model_parameter_type\u201d: \u201cbool\u201d},         \u201cstop_mem_management\u201d: {             \u201clevels\u201d: [0, 1],             \u201ctype\u201d: \u201cfactor\u201d,             \u201cdefault\u201d: 0,             \u201ccore_model_parameter_type\u201d: \u201cbool\u201d}}} get_default_values_from_dict(d) {\u2018leaf_prediction\u2019: \u2018mean\u2019, \u2018leaf_model\u2019: \u2018linear_model.LinearRegression\u2019, \u2018splitter\u2019: \u2018EBSTSplitter\u2019, \u2018binary_split\u2019: 0, \u2018stop_mem_management\u2019: 0}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def get_default_values(fun_control) -&gt; dict:\n\"\"\"Get the values from the \"default\" keys from the dictionary fun_control as a dict.\n    If the key of the value has as \"type\" the value \"int\" or \"float\", convert the value to the corresponding type.\n    Args:\n        fun_control (dict): dictionary with levels and types\n    Returns:\n        new_dict (dict): dictionary with default values\n    Example:\n        &gt;&gt;&gt; d = {\"core_model_hyper_dict\":{\n                \"leaf_prediction\": {\n                    \"levels\": [\"mean\", \"model\", \"adaptive\"],\n                    \"type\": \"factor\",\n                    \"default\": \"mean\",\n                    \"core_model_parameter_type\": \"str\"},\n                \"leaf_model\": {\n                    \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n                    \"type\": \"factor\",\n                    \"default\": \"LinearRegression\",\n                    \"core_model_parameter_type\": \"instance\"},\n                \"splitter\": {\n                    \"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n                    \"type\": \"factor\",\n                    \"default\": \"EBSTSplitter\",\n                    \"core_model_parameter_type\": \"instance()\"},\n                \"binary_split\": {\n                    \"levels\": [0, 1],\n                    \"type\": \"factor\",\n                    \"default\": 0,\n                    \"core_model_parameter_type\": \"bool\"},\n                \"stop_mem_management\": {\n                    \"levels\": [0, 1],\n                    \"type\": \"factor\",\n                    \"default\": 0,\n                    \"core_model_parameter_type\": \"bool\"}}}\n        get_default_values_from_dict(d)\n        {'leaf_prediction': 'mean',\n        'leaf_model': 'linear_model.LinearRegression',\n        'splitter': 'EBSTSplitter',\n        'binary_split': 0,\n        'stop_mem_management': 0}\n    \"\"\"\n    d = fun_control[\"core_model_hyper_dict\"]\n    new_dict = {}\n    for key, value in d.items():\n        if value[\"type\"] == \"int\":\n            new_dict[key] = int(value[\"default\"])\n        elif value[\"type\"] == \"float\":\n            new_dict[key] = float(value[\"default\"])\n        else:\n            new_dict[key] = value[\"default\"]\n    return new_dict\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.get_dict_with_levels_and_types","title":"<code>get_dict_with_levels_and_types(fun_control, v)</code>","text":"<p>Get dictionary with levels and types. The function maps the numerical output of the hyperparameter optimization to the corresponding levels of the hyperparameter needed by the core model, i.e., the tuned algorithm. The function takes the dictionaries fun_control and v and returns a new dictionary with the same keys as v but with the values of the levels of the keys from fun_control. If the key value in the dictionary is 0, it takes the first value from the list, if it is 1, it takes the second and so on. If a key is not in fun_control, it takes the key from v. If the core_model_parameter_type value is instance, it returns the class of the value from the module via getattr(\u201cclass\u201d, value). For example, if fun_control = {\u201cHoeffdingTreeRegressor\u201d:{     \u201cleaf_prediction\u201d: {         \u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cmean\u201d,         \u201ccore_model_parameter_type\u201d: \u201cstr\u201d},     \u201cleaf_model\u201d: {         \u201clevels\u201d: [\u201clinear_model.LinearRegression\u201d, \u201clinear_model.PARegressor\u201d, \u201clinear_model.Perceptron\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cLinearRegression\u201d,         \u201ccore_model_parameter_type\u201d: \u201cinstance\u201d},         \u201csplitter\u201d: {\u201clevels\u201d: [\u201cEBSTSplitter\u201d, \u201cTEBSTSplitter\u201d, \u201cQOSplitter\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cEBSTSplitter\u201d, \u201ccore_model_parameter_type\u201d: \u201cinstance()\u201d},     \u201cbinary_split\u201d: {         \u201clevels\u201d: [0, 1],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: 0,         \u201ccore_model_parameter_type\u201d: \u201cbool\u201d},     \u201cstop_mem_management\u201d: {         \u201clevels\u201d: [0, 1],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: 0,         \u201ccore_model_parameter_type\u201d: \u201cbool\u201d}}}     and     v = {\u2018grace_period\u2019: 200,         \u2018max_depth\u2019: 10,         \u2018delta\u2019: 1e-07,         \u2018tau\u2019: 0.05,         \u2018leaf_prediction\u2019: 0,         \u2018leaf_model\u2019: 0,         \u2018model_selector_decay\u2019: 0.95,         \u2018splitter\u2019: 1,         \u2018min_samples_split\u2019: 9,         \u2018binary_split\u2019: 0,         \u2018max_size\u2019: 500.0}     then the function returns     {\u2018grace_period\u2019: 200,     \u2018max_depth\u2019: 10,     \u2018delta\u2019: 1e-07,     \u2018tau\u2019: 0.05,     \u2018leaf_prediction\u2019: \u2018mean\u2019,     \u2018leaf_model\u2019: linear_model.LinearRegression,     \u2018model_selector_decay\u2019: 0.95,     \u2018splitter\u2019: \u2018TEBSTSplitter\u2019,     \u2018min_samples_split\u2019: 9,     \u2018binary_split\u2019: 0,     \u2018max_size\u2019: 500.0}.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>dictionary with levels and types</p> required <code>v</code> <code>dict</code> <p>dictionary with values</p> required <p>Returns:</p> Name Type Description <code>new_dict</code> <code>dict</code> <p>dictionary with levels and types</p> Example <p>fun_control = {\u201cHoeffdingTreeRegressor\u201d:{         \u201cleaf_prediction\u201d: {\u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d],                             \u201ctype\u201d: \u201cfactor\u201d,                             \u201cdefault\u201d: \u201cmean\u201d,                             \u201ccore_model_parameter_type\u201d: \u201cstr\u201d}}}     v = {\u201cleaf_prediction\u201d: 0}     get_dict_with_levels_and_types(fun_control, v)     {\u201cleaf_prediction\u201d: \u201cmean\u201d}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def get_dict_with_levels_and_types(fun_control, v) -&gt; dict:\n\"\"\"Get dictionary with levels and types.\n    The function maps the numerical output of the hyperparameter optimization to the corresponding levels\n    of the hyperparameter needed by the core model, i.e., the tuned algorithm.\n    The function takes the dictionaries fun_control and v and returns a new dictionary with the same keys as v\n    but with the values of the levels of the keys from fun_control.\n    If the key value in the dictionary is 0, it takes the first value from the list,\n    if it is 1, it takes the second and so on.\n    If a key is not in fun_control, it takes the key from v.\n    If the core_model_parameter_type value is instance, it returns the class of the value from the module\n    via getattr(\"class\", value).\n    For example,\n    if fun_control = {\"HoeffdingTreeRegressor\":{\n        \"leaf_prediction\": {\n            \"levels\": [\"mean\", \"model\", \"adaptive\"],\n            \"type\": \"factor\",\n            \"default\": \"mean\",\n            \"core_model_parameter_type\": \"str\"},\n        \"leaf_model\": {\n            \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n            \"type\": \"factor\",\n            \"default\": \"LinearRegression\",\n            \"core_model_parameter_type\": \"instance\"},\n            \"splitter\": {\"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n            \"type\": \"factor\",\n            \"default\": \"EBSTSplitter\", \"core_model_parameter_type\": \"instance()\"},\n        \"binary_split\": {\n            \"levels\": [0, 1],\n            \"type\": \"factor\",\n            \"default\": 0,\n            \"core_model_parameter_type\": \"bool\"},\n        \"stop_mem_management\": {\n            \"levels\": [0, 1],\n            \"type\": \"factor\",\n            \"default\": 0,\n            \"core_model_parameter_type\": \"bool\"}}}\n        and\n        v = {'grace_period': 200,\n            'max_depth': 10,\n            'delta': 1e-07,\n            'tau': 0.05,\n            'leaf_prediction': 0,\n            'leaf_model': 0,\n            'model_selector_decay': 0.95,\n            'splitter': 1,\n            'min_samples_split': 9,\n            'binary_split': 0,\n            'max_size': 500.0}\n        then the function returns\n        {'grace_period': 200,\n        'max_depth': 10,\n        'delta': 1e-07,\n        'tau': 0.05,\n        'leaf_prediction': 'mean',\n        'leaf_model': linear_model.LinearRegression,\n        'model_selector_decay': 0.95,\n        'splitter': 'TEBSTSplitter',\n        'min_samples_split': 9,\n        'binary_split': 0,\n        'max_size': 500.0}.\n\n    Args:\n        fun_control (dict): dictionary with levels and types\n        v (dict): dictionary with values\n\n    Returns:\n        new_dict (dict): dictionary with levels and types\n\n    Example:\n        &gt;&gt;&gt; fun_control = {\"HoeffdingTreeRegressor\":{\n                \"leaf_prediction\": {\"levels\": [\"mean\", \"model\", \"adaptive\"],\n                                    \"type\": \"factor\",\n                                    \"default\": \"mean\",\n                                    \"core_model_parameter_type\": \"str\"}}}\n            v = {\"leaf_prediction\": 0}\n            get_dict_with_levels_and_types(fun_control, v)\n            {\"leaf_prediction\": \"mean\"}\n    \"\"\"\n    d = fun_control[\"core_model_hyper_dict\"]\n    new_dict = {}\n    for key, value in v.items():\n        if key in d and d[key][\"type\"] == \"factor\":\n            if d[key][\"core_model_parameter_type\"] == \"instance\":\n                if \"class_name\" in d[key]:\n                    mdl = d[key][\"class_name\"]\n                c = d[key][\"levels\"][value]\n                new_dict[key] = class_for_name(mdl, c)\n            elif d[key][\"core_model_parameter_type\"] == \"instance()\":\n                mdl = d[key][\"class_name\"]\n                c = d[key][\"levels\"][value]\n                k = class_for_name(mdl, c)\n                new_dict[key] = k()\n            else:\n                new_dict[key] = d[key][\"levels\"][value]\n        else:\n            new_dict[key] = v[key]\n    return new_dict\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.get_transform","title":"<code>get_transform(fun_control)</code>","text":"<p>Get the transformations of the values from the dictionary fun_control as a list.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>dictionary with levels and types</p> required <p>Returns:</p> Type Description <code>list</code> <p>list with transformations</p> Example <p>d = {\u201ccore_model_hyper_dict\u201d:{     \u201cleaf_prediction\u201d: {         \u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cmean\u201d,         \u201ctransform\u201d: \u201cNone\u201d,         \u201ccore_model_parameter_type\u201d: \u201cstr\u201d},     \u201cleaf_model\u201d: {         \u201clevels\u201d: [\u201clinear_model.LinearRegression\u201d, \u201clinear_model.PARegressor\u201d, \u201clinear_model.Perceptron\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cLinearRegression\u201d,         \u201ctransform\u201d: \u201cNone\u201d,         \u201ccore_model_parameter_type\u201d: \u201cinstance\u201d},     \u201csplitter\u201d: {         \u201clevels\u201d: [\u201cEBSTSplitter\u201d, \u201cTEBSTSplitter\u201d, \u201cQOSplitter\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cEBSTSplitter\u201d,         \u201ctransform\u201d: \u201cNone\u201d,         \u201ccore_model_parameter_type\u201d: \u201cinstance()\u201d},     \u201cbinary_split\u201d: {         \u201clevels\u201d: [0, 1],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: 0,         \u201ctransform\u201d: \u201cNone\u201d,         \u201ccore_model_parameter_type\u201d: \u201cbool\u201d},     \u201cstop_mem_management\u201d: {                                                         \u201clevels\u201d: [0, 1],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: 0,         \u201ctransform\u201d: \u201cNone\u201d,         \u201ccore_model_parameter_type\u201d: \u201cbool\u201d}}}</p> <p>get_transform(d) [\u2018None\u2019, \u2018None\u2019, \u2018None\u2019, \u2018None\u2019, \u2018None\u2019]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def get_transform(fun_control) -&gt; list:\n\"\"\"Get the transformations of the values from the dictionary fun_control as a list.\n    Args:\n        fun_control (dict): dictionary with levels and types\n    Returns:\n        (list): list with transformations\n    Example:\n        &gt;&gt;&gt; d = {\"core_model_hyper_dict\":{\n            \"leaf_prediction\": {\n                \"levels\": [\"mean\", \"model\", \"adaptive\"],\n                \"type\": \"factor\",\n                \"default\": \"mean\",\n                \"transform\": \"None\",\n                \"core_model_parameter_type\": \"str\"},\n            \"leaf_model\": {\n                \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n                \"type\": \"factor\",\n                \"default\": \"LinearRegression\",\n                \"transform\": \"None\",\n                \"core_model_parameter_type\": \"instance\"},\n            \"splitter\": {\n                \"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n                \"type\": \"factor\",\n                \"default\": \"EBSTSplitter\",\n                \"transform\": \"None\",\n                \"core_model_parameter_type\": \"instance()\"},\n            \"binary_split\": {\n                \"levels\": [0, 1],\n                \"type\": \"factor\",\n                \"default\": 0,\n                \"transform\": \"None\",\n                \"core_model_parameter_type\": \"bool\"},\n            \"stop_mem_management\": {                                                         \"levels\": [0, 1],\n                \"type\": \"factor\",\n                \"default\": 0,\n                \"transform\": \"None\",\n                \"core_model_parameter_type\": \"bool\"}}}\n\n        get_transform(d)\n        ['None', 'None', 'None', 'None', 'None']\n    \"\"\"\n    return list(\n        fun_control[\"core_model_hyper_dict\"][key][\"transform\"] for key in fun_control[\"core_model_hyper_dict\"].keys()\n    )\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.get_values_from_dict","title":"<code>get_values_from_dict(dictionary)</code>","text":"<p>Get the values from a dictionary as an array. Generate an np.array that contains the values of the keys of a dictionary in the same order as the keys of the dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>dict</code> <p>dictionary with values</p> required <p>Returns:</p> Type Description <code>np.array</code> <p>array with values</p> Example <p>d = {\u201ca\u201d: 1, \u201cb\u201d: 2, \u201cc\u201d: 3} get_values_from_dict(d) array([1, 2, 3])</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def get_values_from_dict(dictionary) -&gt; np.array:\n\"\"\"Get the values from a dictionary as an array.\n    Generate an np.array that contains the values of the keys of a dictionary\n    in the same order as the keys of the dictionary.\n    Args:\n        dictionary (dict): dictionary with values\n    Returns:\n        (np.array): array with values\n    Example:\n        &gt;&gt;&gt; d = {\"a\": 1, \"b\": 2, \"c\": 3}\n        &gt;&gt;&gt; get_values_from_dict(d)\n        array([1, 2, 3])\n    \"\"\"\n    return np.array(list(dictionary.values()))\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.get_var_name","title":"<code>get_var_name(fun_control)</code>","text":"<p>Get the names of the values from the dictionary fun_control as a list.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>dictionary with names</p> required <p>Returns:</p> Type Description <code>list</code> <p>list with names</p> Example <p>d = {\u201ccore_model_hyper_dict\u201d:{     \u201cleaf_prediction\u201d: {         \u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cmean\u201d,         \u201ccore_model_parameter_type\u201d: \u201cstr\u201d},     \u201cleaf_model\u201d: {         \u201clevels\u201d: [\u201clinear_model.LinearRegression\u201d, \u201clinear_model.PARegressor\u201d, \u201clinear_model.Perceptron\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cLinearRegression\u201d,         \u201ccore_model_parameter_type\u201d: \u201cinstance\u201d},     \u201csplitter\u201d: {         \u201clevels\u201d: [\u201cEBSTSplitter\u201d, \u201cTEBSTSplitter\u201d, \u201cQOSplitter\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cEBSTSplitter\u201d,         \u201ccore_model_parameter_type\u201d: \u201cinstance()\u201d},     \u201cbinary_split\u201d: {         \u201clevels\u201d: [0, 1],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: 0,         \u201ccore_model_parameter_type\u201d: \u201cbool\u201d},     \u201cstop_mem_management\u201d: {                                                         \u201clevels\u201d: [0, 1],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: 0,         \u201ccore_model_parameter_type\u201d: \u201cbool\u201d}}}</p> <p>get_var_name(d) [\u2018leaf_prediction\u2019, \u2018leaf_model\u2019, \u2018splitter\u2019, \u2018binary_split\u2019, \u2018stop_mem_management\u2019]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def get_var_name(fun_control) -&gt; list:\n\"\"\"Get the names of the values from the dictionary fun_control as a list.\n    Args:\n        fun_control (dict): dictionary with names\n    Returns:\n        (list): list with names\n    Example:\n        &gt;&gt;&gt; d = {\"core_model_hyper_dict\":{\n            \"leaf_prediction\": {\n                \"levels\": [\"mean\", \"model\", \"adaptive\"],\n                \"type\": \"factor\",\n                \"default\": \"mean\",\n                \"core_model_parameter_type\": \"str\"},\n            \"leaf_model\": {\n                \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n                \"type\": \"factor\",\n                \"default\": \"LinearRegression\",\n                \"core_model_parameter_type\": \"instance\"},\n            \"splitter\": {\n                \"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n                \"type\": \"factor\",\n                \"default\": \"EBSTSplitter\",\n                \"core_model_parameter_type\": \"instance()\"},\n            \"binary_split\": {\n                \"levels\": [0, 1],\n                \"type\": \"factor\",\n                \"default\": 0,\n                \"core_model_parameter_type\": \"bool\"},\n            \"stop_mem_management\": {                                                         \"levels\": [0, 1],\n                \"type\": \"factor\",\n                \"default\": 0,\n                \"core_model_parameter_type\": \"bool\"}}}\n\n        get_var_name(d)\n        ['leaf_prediction', 'leaf_model', 'splitter', 'binary_split', 'stop_mem_management']\n    \"\"\"\n    return list(fun_control[\"core_model_hyper_dict\"].keys())\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.get_var_type","title":"<code>get_var_type(fun_control)</code>","text":"<p>Get the types of the values from the dictionary fun_control as a list.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>dictionary with levels and types</p> required <p>Returns:</p> Type Description <code>list</code> <p>list with types</p> Example <p>d = {\u201ccore_model_hyper_dict\u201d:{     \u201cleaf_prediction\u201d: {         \u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cmean\u201d,         \u201ccore_model_parameter_type\u201d: \u201cstr\u201d},     \u201cleaf_model\u201d: {         \u201clevels\u201d: [\u201clinear_model.LinearRegression\u201d, \u201clinear_model.PARegressor\u201d, \u201clinear_model.Perceptron\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cLinearRegression\u201d,         \u201ccore_model_parameter_type\u201d: \u201cinstance\u201d},     \u201csplitter\u201d: {         \u201clevels\u201d: [\u201cEBSTSplitter\u201d, \u201cTEBSTSplitter\u201d, \u201cQOSplitter\u201d],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: \u201cEBSTSplitter\u201d,         \u201ccore_model_parameter_type\u201d: \u201cinstance()\u201d},     \u201cbinary_split\u201d: {         \u201clevels\u201d: [0, 1],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: 0,         \u201ccore_model_parameter_type\u201d: \u201cbool\u201d},     \u201cstop_mem_management\u201d: {                                                         \u201clevels\u201d: [0, 1],         \u201ctype\u201d: \u201cfactor\u201d,         \u201cdefault\u201d: 0,         \u201ccore_model_parameter_type\u201d: \u201cbool\u201d}}}</p> <p>get_var_type(d) [\u2018factor\u2019, \u2018factor\u2019, \u2018factor\u2019, \u2018factor\u2019, \u2018factor\u2019]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def get_var_type(fun_control) -&gt; list:\n\"\"\"Get the types of the values from the dictionary fun_control as a list.\n    Args:\n        fun_control (dict): dictionary with levels and types\n    Returns:\n        (list): list with types\n    Example:\n        &gt;&gt;&gt; d = {\"core_model_hyper_dict\":{\n            \"leaf_prediction\": {\n                \"levels\": [\"mean\", \"model\", \"adaptive\"],\n                \"type\": \"factor\",\n                \"default\": \"mean\",\n                \"core_model_parameter_type\": \"str\"},\n            \"leaf_model\": {\n                \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n                \"type\": \"factor\",\n                \"default\": \"LinearRegression\",\n                \"core_model_parameter_type\": \"instance\"},\n            \"splitter\": {\n                \"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n                \"type\": \"factor\",\n                \"default\": \"EBSTSplitter\",\n                \"core_model_parameter_type\": \"instance()\"},\n            \"binary_split\": {\n                \"levels\": [0, 1],\n                \"type\": \"factor\",\n                \"default\": 0,\n                \"core_model_parameter_type\": \"bool\"},\n            \"stop_mem_management\": {                                                         \"levels\": [0, 1],\n                \"type\": \"factor\",\n                \"default\": 0,\n                \"core_model_parameter_type\": \"bool\"}}}\n\n        get_var_type(d)\n        ['factor', 'factor', 'factor', 'factor', 'factor']\n    \"\"\"\n    return list(\n        fun_control[\"core_model_hyper_dict\"][key][\"type\"] for key in fun_control[\"core_model_hyper_dict\"].keys()\n    )\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.iterate_dict_values","title":"<code>iterate_dict_values(var_dict)</code>","text":"<p>This function takes a dictionary of variables as input arguments and returns an iterator that yields the values from the arrays in the dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>var_dict</code> <code>dict</code> <p>A dictionary where keys are variable names and values are numpy arrays.</p> required <p>Returns:</p> Name Type Description <code>iterator</code> <p>An iterator that yields the values from the arrays in the dictionary.</p> Example <p>import numpy as np var_dict = {\u2018a\u2019: np.array([1, 3, 5]), \u2018b\u2019: np.array([2, 4, 6])} for values in iterate_dict_values(var_dict): \u2026     print(values) {\u2018a\u2019: 1, \u2018b\u2019: 2} {\u2018a\u2019: 3, \u2018b\u2019: 4} {\u2018a\u2019: 5, \u2018b\u2019: 6}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def iterate_dict_values(var_dict: dict):\n\"\"\"\n    This function takes a dictionary of variables as input arguments and returns an iterator that\n    yields the values from the arrays in the dictionary.\n\n    Parameters:\n        var_dict (dict): A dictionary where keys are variable names and values are numpy arrays.\n\n    Returns:\n        iterator: An iterator that yields the values from the arrays in the dictionary.\n\n    Example:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; var_dict = {'a': np.array([1, 3, 5]), 'b': np.array([2, 4, 6])}\n        &gt;&gt;&gt; for values in iterate_dict_values(var_dict):\n        ...     print(values)\n        {'a': 1, 'b': 2}\n        {'a': 3, 'b': 4}\n        {'a': 5, 'b': 6}\n    \"\"\"\n    n = len(next(iter(var_dict.values())))\n    for i in range(n):\n        yield {key: value[i] for key, value in var_dict.items()}\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.modify_hyper_parameter_bounds","title":"<code>modify_hyper_parameter_bounds(fun_control, hyperparameter, bounds)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>fun_control dictionary</p> required <code>hyperparameter</code> <code>str</code> <p>hyperparameter name</p> required <code>bounds</code> <code>list</code> <p>list of two bound values. The first value represents the lower bound and the second value represents the upper bound.</p> required <p>Returns:</p> Name Type Description <code>fun_control</code> <code>dict</code> <p>updated fun_control</p> Example <p>fun_control = {}     core_model  = HoeffdingTreeRegressor     fun_control.update({\u201ccore_model\u201d: core_model})     fun_control.update({\u201ccore_model_hyper_dict\u201d: river_hyper_dict[core_model.name]})     bounds = [3, 11]     fun_control = modify_hyper_parameter_levels(fun_control, \u201cmin_samples_split\u201d, bounds)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def modify_hyper_parameter_bounds(fun_control, hyperparameter, bounds) -&gt; dict:\n\"\"\"\n\n    Args:\n        fun_control (dict): fun_control dictionary\n        hyperparameter (str): hyperparameter name\n        bounds (list): list of two bound values. The first value represents the lower bound\n            and the second value represents the upper bound.\n\n    Returns:\n        fun_control (dict): updated fun_control\n    Example:\n        &gt;&gt;&gt; fun_control = {}\n            core_model  = HoeffdingTreeRegressor\n            fun_control.update({\"core_model\": core_model})\n            fun_control.update({\"core_model_hyper_dict\": river_hyper_dict[core_model.__name__]})\n            bounds = [3, 11]\n            fun_control = modify_hyper_parameter_levels(fun_control, \"min_samples_split\", bounds)\n    \"\"\"\n    fun_control[\"core_model_hyper_dict\"][hyperparameter].update({\"lower\": bounds[0]})\n    fun_control[\"core_model_hyper_dict\"][hyperparameter].update({\"upper\": bounds[1]})\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.modify_hyper_parameter_levels","title":"<code>modify_hyper_parameter_levels(fun_control, hyperparameter, levels)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>fun_control dictionary</p> required <code>hyperparameter</code> <code>str</code> <p>hyperparameter name</p> required <code>levels</code> <code>list</code> <p>list of levels</p> required <p>Returns:</p> Name Type Description <code>fun_control</code> <code>dict</code> <p>updated fun_control</p> Example <p>fun_control = {}     core_model  = HoeffdingTreeRegressor     fun_control.update({\u201ccore_model\u201d: core_model})     fun_control.update({\u201ccore_model_hyper_dict\u201d: river_hyper_dict[core_model.name]})     levels = [\u201cmean\u201d, \u201cmodel\u201d]     fun_control = modify_hyper_parameter_levels(fun_control, \u201cleaf_prediction\u201d, levels)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def modify_hyper_parameter_levels(fun_control, hyperparameter, levels) -&gt; dict:\n\"\"\"\n\n    Args:\n        fun_control (dict): fun_control dictionary\n        hyperparameter (str): hyperparameter name\n        levels (list): list of levels\n\n    Returns:\n        fun_control (dict): updated fun_control\n    Example:\n        &gt;&gt;&gt; fun_control = {}\n            core_model  = HoeffdingTreeRegressor\n            fun_control.update({\"core_model\": core_model})\n            fun_control.update({\"core_model_hyper_dict\": river_hyper_dict[core_model.__name__]})\n            levels = [\"mean\", \"model\"]\n            fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_prediction\", levels)\n    \"\"\"\n    fun_control[\"core_model_hyper_dict\"][hyperparameter].update({\"levels\": levels})\n    fun_control[\"core_model_hyper_dict\"][hyperparameter].update({\"lower\": 0})\n    fun_control[\"core_model_hyper_dict\"][hyperparameter].update({\"upper\": len(levels) - 1})\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.replace_levels_with_positions","title":"<code>replace_levels_with_positions(hyper_dict, hyper_dict_values)</code>","text":"<p>Replace the levels with the position in the levels list. The function that takes two dictionaries. The first contains as hyperparameters as keys. If the hyperparameter has the key \u201clevels\u201d, then the value of the corresponding hyperparameter in the second dictionary is replaced by the position of the value in the list of levels. The function returns a dictionary with the same keys as the second dictionary. For example, if the second dictionary is {\u201ca\u201d: 1, \u201cb\u201d: \u201cmodel1\u201d, \u201cc\u201d: 3} and the first dictionary is {     \u201ca\u201d: {\u201ctype\u201d: \u201cint\u201d},     \u201cb\u201d: {\u201clevels\u201d: [\u201cmodel4\u201d, \u201cmodel5\u201d, \u201cmodel1\u201d]},     \u201cd\u201d: {\u201ctype\u201d: \u201cfloat\u201d}}, then the function should return {\u201ca\u201d: 1, \u201cb\u201d: 2, \u201cc\u201d: 3}.</p> <p>Parameters:</p> Name Type Description Default <code>hyper_dict</code> <code>dict</code> <p>dictionary with levels</p> required <code>hyper_dict_values</code> <code>dict</code> <p>dictionary with values</p> required <p>Returns:</p> Type Description <code>dict</code> <p>dictionary with values</p> Example <p>hyper_dict = {\u201cleaf_prediction\u201d: { \u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d], \u201ctype\u201d: \u201cfactor\u201d, \u201cdefault\u201d: \u201cmean\u201d, \u201ccore_model_parameter_type\u201d: \u201cstr\u201d}, \u201cleaf_model\u201d: {     \u201clevels\u201d: [\u201clinear_model.LinearRegression\u201d, \u201clinear_model.PARegressor\u201d, \u201clinear_model.Perceptron\u201d],     \u201ctype\u201d: \u201cfactor\u201d,     \u201cdefault\u201d: \u201cLinearRegression\u201d,     \u201ccore_model_parameter_type\u201d: \u201cinstance\u201d}, \u201csplitter\u201d: {     \u201clevels\u201d: [\u201cEBSTSplitter\u201d, \u201cTEBSTSplitter\u201d, \u201cQOSplitter\u201d],     \u201ctype\u201d: \u201cfactor\u201d,     \u201cdefault\u201d: \u201cEBSTSplitter\u201d,     \u201ccore_model_parameter_type\u201d: \u201cinstance()\u201d}, \u201cbinary_split\u201d: {     \u201clevels\u201d: [0, 1],     \u201ctype\u201d: \u201cfactor\u201d,     \u201cdefault\u201d: 0,     \u201ccore_model_parameter_type\u201d: \u201cbool\u201d}, \u201cstop_mem_management\u201d: {     \u201clevels\u201d: [0, 1],     \u201ctype\u201d: \u201cfactor\u201d,     \u201cdefault\u201d: 0,     \u201ccore_model_parameter_type\u201d: \u201cbool\u201d}} hyper_dict_values = {\u201cleaf_prediction\u201d: \u201cmean\u201d, \u201cleaf_model\u201d: \u201clinear_model.LinearRegression\u201d, \u201csplitter\u201d: \u201cEBSTSplitter\u201d, \u201cbinary_split\u201d: 0, \u201cstop_mem_management\u201d: 0} replace_levels_with_position(hyper_dict, hyper_dict_values) {\u2018leaf_prediction\u2019: 0, \u2018leaf_model\u2019: 0, \u2018splitter\u2019: 0, \u2018binary_split\u2019: 0, \u2018stop_mem_management\u2019: 0}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def replace_levels_with_positions(hyper_dict, hyper_dict_values) -&gt; dict:\n\"\"\"Replace the levels with the position in the levels list.\n    The function that takes two dictionaries.\n    The first contains as hyperparameters as keys.\n    If the hyperparameter has the key \"levels\",\n    then the value of the corresponding hyperparameter in the second dictionary is\n    replaced by the position of the value in the list of levels.\n    The function returns a dictionary with the same keys as the second dictionary.\n    For example, if the second dictionary is {\"a\": 1, \"b\": \"model1\", \"c\": 3}\n    and the first dictionary is {\n        \"a\": {\"type\": \"int\"},\n        \"b\": {\"levels\": [\"model4\", \"model5\", \"model1\"]},\n        \"d\": {\"type\": \"float\"}},\n    then the function should return {\"a\": 1, \"b\": 2, \"c\": 3}.\n    Args:\n        hyper_dict (dict): dictionary with levels\n        hyper_dict_values (dict): dictionary with values\n    Returns:\n        (dict): dictionary with values\n    Example:\n        &gt;&gt;&gt; hyper_dict = {\"leaf_prediction\": {\n        \"levels\": [\"mean\", \"model\", \"adaptive\"],\n        \"type\": \"factor\",\n        \"default\": \"mean\",\n        \"core_model_parameter_type\": \"str\"},\n        \"leaf_model\": {\n            \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n            \"type\": \"factor\",\n            \"default\": \"LinearRegression\",\n            \"core_model_parameter_type\": \"instance\"},\n        \"splitter\": {\n            \"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n            \"type\": \"factor\",\n            \"default\": \"EBSTSplitter\",\n            \"core_model_parameter_type\": \"instance()\"},\n        \"binary_split\": {\n            \"levels\": [0, 1],\n            \"type\": \"factor\",\n            \"default\": 0,\n            \"core_model_parameter_type\": \"bool\"},\n        \"stop_mem_management\": {\n            \"levels\": [0, 1],\n            \"type\": \"factor\",\n            \"default\": 0,\n            \"core_model_parameter_type\": \"bool\"}}\n        &gt;&gt;&gt; hyper_dict_values = {\"leaf_prediction\": \"mean\",\n        \"leaf_model\": \"linear_model.LinearRegression\",\n        \"splitter\": \"EBSTSplitter\",\n        \"binary_split\": 0,\n        \"stop_mem_management\": 0}\n        &gt;&gt;&gt; replace_levels_with_position(hyper_dict, hyper_dict_values)\n        {'leaf_prediction': 0,\n        'leaf_model': 0,\n        'splitter': 0,\n        'binary_split': 0,\n        'stop_mem_management': 0}\n    \"\"\"\n    hyper_dict_values_new = copy.deepcopy(hyper_dict_values)\n    for key, value in hyper_dict_values.items():\n        if key in hyper_dict.keys():\n            if \"levels\" in hyper_dict[key].keys():\n                hyper_dict_values_new[key] = hyper_dict[key][\"levels\"].index(value)\n    return hyper_dict_values_new\n</code></pre>"},{"location":"reference/spotPython/hyperparameters/values/#spotPython.hyperparameters.values.return_conf_list_from_var_dict","title":"<code>return_conf_list_from_var_dict(var_dict, fun_control)</code>","text":"<p>This function takes a dictionary of variables and a dictionary of function control. It performs similar steps as generate_one_config_from_var_dict() but returns a list of dictionaries of hyper parameter values.</p> <p>Parameters:</p> Name Type Description Default <code>var_dict</code> <code>dict</code> <p>A dictionary of variables.</p> required <code>fun_control</code> <code>dict</code> <p>A dictionary of function control.</p> required <p>Returns:</p> Type Description <code>list</code> <p>list A list of dictionaries of hyper parameter values. Transformations are applied to the values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n    var_dict = {'a': np.array([1]),\n                'b': np.array([2])}\n    fun_control = {'var_type': ['int', 'int']}\n    return_conf_list_from_var_dict(var_dict, fun_control)\n    var_dict = {'a': np.array([1, 3, 5]), 'b': np.array([2, 4, 6])}\n    fun_control = {'var_type': ['int', 'int']}\n    return_conf_list_from_var_dict(var_dict, fun_control)\n    {'a': [1, 3, 5], 'b': [2, 4, 6]}\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/hyperparameters/values.py</code> <pre><code>def return_conf_list_from_var_dict(var_dict: dict, fun_control: dict) -&gt; list:\n\"\"\"This function takes a dictionary of variables and a dictionary of function control.\n    It performs similar steps as generate_one_config_from_var_dict()\n    but returns a list of dictionaries of hyper parameter values.\n    Args:\n        var_dict (dict): A dictionary of variables.\n        fun_control (dict): A dictionary of function control.\n    Returns:\n        list A list of dictionaries of hyper parameter values. Transformations are applied to the values.\n    Examples:\n        &gt;&gt;&gt; import numpy as np\n            var_dict = {'a': np.array([1]),\n                        'b': np.array([2])}\n            fun_control = {'var_type': ['int', 'int']}\n            return_conf_list_from_var_dict(var_dict, fun_control)\n            var_dict = {'a': np.array([1, 3, 5]), 'b': np.array([2, 4, 6])}\n            fun_control = {'var_type': ['int', 'int']}\n            return_conf_list_from_var_dict(var_dict, fun_control)\n            {'a': [1, 3, 5], 'b': [2, 4, 6]}\n\n    \"\"\"\n    conf_list = []\n    for values in generate_one_config_from_var_dict(var_dict, fun_control):\n        conf_list.append(values)\n    return conf_list\n</code></pre>"},{"location":"reference/spotPython/light/crossvalidationdatamodule/","title":"crossvalidationdatamodule","text":""},{"location":"reference/spotPython/light/csvdatamodule/","title":"csvdatamodule","text":""},{"location":"reference/spotPython/light/csvdataset/","title":"csvdataset","text":""},{"location":"reference/spotPython/light/litmodel/","title":"litmodel","text":""},{"location":"reference/spotPython/light/mnistdatamodule/","title":"mnistdatamodule","text":""},{"location":"reference/spotPython/light/netlightbase/","title":"netlightbase","text":""},{"location":"reference/spotPython/light/traintest/","title":"traintest","text":""},{"location":"reference/spotPython/light/utils/","title":"utils","text":""},{"location":"reference/spotPython/plot/contour/","title":"contour","text":""},{"location":"reference/spotPython/plot/contour/#spotPython.plot.contour.simple_contour","title":"<code>simple_contour(fun, min_x=-1, max_x=1, min_y=-1, max_y=1, min_z=None, max_z=None, n_samples=100, n_levels=30)</code>","text":"<p>Simple contour plot</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <code>_type_</code> <p>description</p> required <code>min_x</code> <code>int</code> <p>description. Defaults to -1.</p> <code>-1</code> <code>max_x</code> <code>int</code> <p>description. Defaults to 1.</p> <code>1</code> <code>min_y</code> <code>int</code> <p>description. Defaults to -1.</p> <code>-1</code> <code>max_y</code> <code>int</code> <p>description. Defaults to 1.</p> <code>1</code> <code>min_z</code> <code>int</code> <p>description. Defaults to 0.</p> <code>None</code> <code>max_z</code> <code>int</code> <p>description. Defaults to 1.</p> <code>None</code> <code>n_samples</code> <code>int</code> <p>description. Defaults to 100.</p> <code>100</code> <code>n_levels</code> <code>int</code> <p>description. Defaults to 5.</p> <code>30</code> Example <p>import matplotlib.pyplot as plt import numpy as np from spotPython.fun.objectivefunctions import analytical fun = analytical().fun_branin simple_contour(fun=fun, n_levels=30, min_x=-5, max_x=10, min_y=0, max_y=15)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/plot/contour.py</code> <pre><code>def simple_contour(\n    fun,\n    min_x=-1,\n    max_x=1,\n    min_y=-1,\n    max_y=1,\n    min_z=None,\n    max_z=None,\n    n_samples=100,\n    n_levels=30,\n):\n\"\"\"\n    Simple contour plot\n\n    Args:\n        fun (_type_): _description_\n        min_x (int, optional): _description_. Defaults to -1.\n        max_x (int, optional): _description_. Defaults to 1.\n        min_y (int, optional): _description_. Defaults to -1.\n        max_y (int, optional): _description_. Defaults to 1.\n        min_z (int, optional): _description_. Defaults to 0.\n        max_z (int, optional): _description_. Defaults to 1.\n        n_samples (int, optional): _description_. Defaults to 100.\n        n_levels (int, optional): _description_. Defaults to 5.\n\n    Example:\n        &gt;&gt;&gt; import matplotlib.pyplot as plt\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from spotPython.fun.objectivefunctions import analytical\n        &gt;&gt;&gt; fun = analytical().fun_branin\n        &gt;&gt;&gt; simple_contour(fun=fun, n_levels=30, min_x=-5, max_x=10, min_y=0, max_y=15)\n\n    \"\"\"\n    XX, YY = np.meshgrid(np.linspace(min_x, max_x, n_samples), np.linspace(min_y, max_y, n_samples))\n    zz = np.array([fun(np.array([xi, yi]).reshape(-1, 2)) for xi, yi in zip(np.ravel(XX), np.ravel(YY))]).reshape(\n        n_samples, n_samples\n    )\n    fig, ax = plt.subplots(figsize=(5, 2.7), layout=\"constrained\")\n    if min_z is None:\n        min_z = np.min(zz)\n    if max_z is None:\n        max_z = np.max(zz)\n    plt.contourf(\n        XX,\n        YY,\n        zz,\n        levels=np.linspace(min_z, max_z, n_levels),\n        zorder=1,\n        cmap=\"jet\",\n        vmin=min_z,\n        vmax=max_z,\n    )\n    plt.colorbar()\n</code></pre>"},{"location":"reference/spotPython/plot/validation/","title":"validation","text":""},{"location":"reference/spotPython/plot/validation/#spotPython.plot.validation.plot_confusion_matrix","title":"<code>plot_confusion_matrix(model, fun_control, target_names=None, title=None)</code>","text":"<p>Plotting a confusion matrix</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/plot/validation.py</code> <pre><code>def plot_confusion_matrix(model, fun_control, target_names=None, title=None):\n\"\"\"\n    Plotting a confusion matrix\n    \"\"\"\n    X_train, y_train = get_Xy_from_df(fun_control[\"train\"], fun_control[\"target_column\"])\n    X_test, y_test = get_Xy_from_df(fun_control[\"test\"], fun_control[\"target_column\"])\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)\n    if target_names is not None:\n        ax.xaxis.set_ticklabels(target_names)\n        ax.yaxis.set_ticklabels(target_names)\n    if title is not None:\n        _ = ax.set_title(title)\n</code></pre>"},{"location":"reference/spotPython/plot/validation/#spotPython.plot.validation.plot_cv_predictions","title":"<code>plot_cv_predictions(model, fun_control)</code>","text":"<p>Regression: Plotting Cross-Validated Predictions. Uses :func:<code>~sklearn.model_selection.cross_val_predict</code> together with :class:<code>~sklearn.metrics.PredictionErrorDisplay</code> to visualize prediction errors. It is based on the example from the scikit-learn documentation: https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_predict.html#sphx-glr-download-auto-examples-model-selection-plot-cv-predict-py</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>sklearn model. The model to be used for cross-validation.</p> required <code>fun_control</code> <p>dict. The dictionary containing the data and the target column.</p> required <p>Returns:</p> Type Description <p>None.</p> Example <p>from sklearn.datasets import load_diabetes from sklearn.linear_model import LinearRegression X, y = load_diabetes(return_X_y=True) lr = LinearRegression() plot_cv_predictions(lr, fun_control)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/plot/validation.py</code> <pre><code>def plot_cv_predictions(model, fun_control):\n\"\"\"\n    Regression: Plotting Cross-Validated Predictions.\n    Uses\n    :func:`~sklearn.model_selection.cross_val_predict` together with\n    :class:`~sklearn.metrics.PredictionErrorDisplay` to visualize prediction\n    errors. It is based on the example from the scikit-learn documentation:\n    https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_predict.html#sphx-glr-download-auto-examples-model-selection-plot-cv-predict-py\n\n    Parameters:\n        model: sklearn model. The model to be used for cross-validation.\n        fun_control: dict. The dictionary containing the data and the target column.\n    Returns:\n        None.\n    Example:\n        &gt;&gt;&gt; from sklearn.datasets import load_diabetes\n        &gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n        &gt;&gt;&gt; X, y = load_diabetes(return_X_y=True)\n        &gt;&gt;&gt; lr = LinearRegression()\n        &gt;&gt;&gt; plot_cv_predictions(lr, fun_control)\n    \"\"\"\n    X_test, y_test = get_Xy_from_df(fun_control[\"test\"], fun_control[\"target_column\"])\n    # cross_val_predict returns an array of the same size of y\n    # where each entry is a prediction obtained by cross validation.\n    y_pred = cross_val_predict(model, X_test, y_test, cv=10)\n    fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n    PredictionErrorDisplay.from_predictions(\n        y_test,\n        y_pred=y_pred,\n        kind=\"actual_vs_predicted\",\n        subsample=100,\n        ax=axs[0],\n        random_state=0,\n    )\n    axs[0].set_title(\"Actual vs. Predicted values\")\n    PredictionErrorDisplay.from_predictions(\n        y_test,\n        y_pred=y_pred,\n        kind=\"residual_vs_predicted\",\n        subsample=100,\n        ax=axs[1],\n        random_state=0,\n    )\n    axs[1].set_title(\"Residuals vs. Predicted Values\")\n    fig.suptitle(\"Plotting cross-validated predictions\")\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"reference/spotPython/plot/validation/#spotPython.plot.validation.plot_roc","title":"<code>plot_roc(model_list, fun_control, alpha=0.8, model_names=None)</code>","text":"<p>================================ ROC Curve with Visualization API ================================ Scikit-learn defines a simple API for creating visualizations for machine learning. The key features of this API is to allow for quick plotting and visual adjustments without recalculation. In this example, we will demonstrate how to use the visualization API by comparing ROC curves.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/plot/validation.py</code> <pre><code>def plot_roc(model_list, fun_control, alpha=0.8, model_names=None):\n\"\"\"\n    ================================\n    ROC Curve with Visualization API\n    ================================\n    Scikit-learn defines a simple API for creating visualizations for machine\n    learning. The key features of this API is to allow for quick plotting and\n    visual adjustments without recalculation. In this example, we will demonstrate\n    how to use the visualization API by comparing ROC curves.\n    \"\"\"\n    X_train, y_train = get_Xy_from_df(fun_control[\"train\"], fun_control[\"target_column\"])\n    X_test, y_test = get_Xy_from_df(fun_control[\"test\"], fun_control[\"target_column\"])\n    ax = plt.gca()\n    for i, model in enumerate(model_list):\n        model.fit(X_train, y_train)\n        if model_names is not None:\n            model_name = model_names[i]\n        else:\n            model_name = None\n        y_pred = model.predict(X_test)\n        RocCurveDisplay.from_predictions(y_test, y_pred, ax=ax, alpha=alpha, name=model_name)\n    plt.show()\n</code></pre>"},{"location":"reference/spotPython/sklearn/traintest/","title":"traintest","text":""},{"location":"reference/spotPython/sklearn/traintest/#spotPython.sklearn.traintest.evaluate_model_oob","title":"<code>evaluate_model_oob(model, fun_control)</code>","text":"<p>Out-of-bag evaluation (Only for RandomForestClassifier). If fun_control[\u201ceval\u201d] == \u201ceval_oob_score\u201d.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/sklearn/traintest.py</code> <pre><code>def evaluate_model_oob(model, fun_control):\n\"\"\"Out-of-bag evaluation (Only for RandomForestClassifier).\n    If fun_control[\"eval\"] == \"eval_oob_score\".\n    \"\"\"\n    try:\n        X, y = get_Xy_from_df(fun_control[\"train\"], fun_control[\"target_column\"])\n        model.fit(X, y)\n        df_preds = model.oob_decision_function_\n        df_eval = fun_control[\"metric_sklearn\"](y, df_preds, **fun_control[\"metric_params\"])\n    except Exception as err:\n        print(f\"Error in fun_sklearn(). Call to evaluate_model_oob failed. {err=}, {type(err)=}\")\n        df_eval = np.nan\n        df_eval = np.nan\n    return df_eval, df_preds\n</code></pre>"},{"location":"reference/spotPython/spot/spot/","title":"spot","text":""},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot","title":"<code>Spot</code>","text":"<p>Spot base class to handle the following tasks in a uniform manner:</p> <ul> <li>Getting and setting parameters. This is done via the <code>Spot</code> initialization.</li> <li>Running surrogate based hyperparameter optimization. After the class is initialized, hyperparameter tuning runs can be performed via the <code>run</code> method.</li> <li>Displaying information. The <code>plot</code> method can be used for visualizing results. The <code>print</code> methods summarizes information about the tuning run.</li> </ul> <p>The <code>Spot</code> class is built in a modular manner. It combines the following three components:</p> <pre><code>1. Design\n2. Surrogate\n3. Optimizer\n</code></pre> <p>For each of the three components different implementations can be selected and combined. Internal components are selected as default. These can be replaced by components from other packages, e.g., scikit-learn or scikit-optimize.</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <code>Callable</code> <p>objective function</p> required <code>lower</code> <code>np.array</code> <p>lower bound</p> required <code>upper</code> <code>np.array</code> <p>upper bound</p> required <code>fun_evals</code> <code>int</code> <p>number of function evaluations</p> <code>15</code> <code>fun_repeats</code> <code>int</code> <p>number of repeats (replicates).</p> <code>1</code> <code>max_time</code> <code>int</code> <p>maximum time (in minutes)</p> <code>inf</code> <code>noise</code> <code>bool</code> <p>deterministic or noisy objective function</p> <code>False</code> <code>tolerance_x</code> <code>float</code> <p>tolerance for new x solutions. Minimum distance of new solutions, generated by <code>suggest_new_X</code>, to already existing solutions. If zero (which is the default), every new solution is accepted.</p> <code>0</code> <code>ocba_delta</code> <code>int</code> <p>OCBA increment (only used if <code>noise==True</code>)</p> <code>0</code> <code>var_type</code> <code>List[str]</code> <p>list of type information, can be either \u201cnum\u201d or \u201cfactor\u201d</p> <code>['num']</code> <code>var_name</code> <code>List[str]</code> <p>list of variable names, e.g., [\u201cx1\u201d, \u201cx2\u201d]</p> <code>None</code> <code>infill_criterion</code> <code>str</code> <p>Can be <code>\"y\"</code>, <code>\"s\"</code>, <code>\"ei\"</code> (negative expected improvement), or <code>\"all\"</code>.</p> <code>'y'</code> <code>n_points</code> <code>int</code> <p>number of infill points</p> <code>1</code> <code>seed</code> <code>int</code> <p>initial seed</p> <code>123</code> <code>log_level</code> <code>int</code> <p>log level with the following settings: <code>NOTSET</code> (<code>0</code>), <code>DEBUG</code> (<code>10</code>: Detailed information, typically of interest only when diagnosing problems.), <code>INFO</code> (<code>20</code>: Confirmation that things are working as expected.), <code>WARNING</code> (<code>30</code>: An indication that something unexpected happened, or indicative of some problem in the near     future (e.g. \u2018disk space low\u2019). The software is still working as expected.), <code>ERROR</code> (<code>40</code>: Due to a more serious problem, the software has not been able to perform some function.), and <code>CRITICAL</code> (<code>50</code>: A serious error, indicating that the program itself may be unable to continue running.)</p> <code>50</code> <code>show_models</code> <code>bool</code> <p>Plot model. Currently only 1-dim functions are supported.</p> <code>False</code> <code>show_progress</code> <code>bool</code> <p>Show progress bar.</p> <code>True</code> <code>design</code> <code>object</code> <p>experimental design.</p> <code>None</code> <code>design_control</code> <code>Dict[str, Union[int, float]]</code> <p>experimental design information stored as a dictionary with the following entries: \u201cinit_size\u201d: <code>10</code>, \u201crepeats\u201d: <code>1</code>.</p> <code>{}</code> <code>surrogate</code> <code>object</code> <p>surrogate model. If <code>None</code>, spotPython\u2019s <code>kriging</code> is used.</p> <code>None</code> <code>surrogate_control</code> <code>Dict[str, Union[int, float]]</code> <p>surrogate model information stored as a dictionary with the following entries: \u201cmodel_optimizer\u201d: <code>differential_evolution</code>, \u201cmodel_fun_evals\u201d: <code>None</code>, \u201cmin_theta\u201d: <code>-3.</code>,  \u201cmax_theta\u201d: <code>3.</code>, \u201cn_theta\u201d: <code>1</code>, \u201cn_p\u201d: <code>1</code>, \u201coptim_p\u201d: <code>False</code>, \u201ccod_type\u201d: <code>\"norm\"</code>, \u201cvar_type\u201d: <code>self.var_type</code>, \u201cuse_cod_y\u201d: <code>False</code>.</p> <code>{}</code> <code>optimizer</code> <code>object</code> <p>optimizer. If <code>None</code>, <code>scipy.optimize</code>\u2018s <code>differential_evolution</code> is used.</p> <code>None</code> <code>optimizer_control</code> <code>Dict[str, Union[int, float]]</code> <p>information about the optimizer stored as a dictionary with the following entries: \u201cmax_iter\u201d: <code>1000</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p> Note <p>Description in the source code refers to [bart21i]: Bartz-Beielstein, T., and Zaefferer, M. Hyperparameter tuning approaches. In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, E. Bartz, T. Bartz-Beielstein, M. Zaefferer, and O. Mersmann, Eds. Springer, 2022, ch. 4, pp. 67\u2013114.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from math import inf\n&gt;&gt;&gt; from spotpy.spot_setup import Spot\n&gt;&gt;&gt; def objective_function(x):\n&gt;&gt;&gt;     return x[0]**2 + x[1]**2\n&gt;&gt;&gt; lower = np.array([0, 0])\n&gt;&gt;&gt; upper = np.array([10, 10])\n&gt;&gt;&gt; spot = Spot(fun=objective_function,\n&gt;&gt;&gt;             lower=lower,\n&gt;&gt;&gt;             upper=upper,\n&gt;&gt;&gt;             fun_evals=100,\n&gt;&gt;&gt;             fun_repeats=1,\n&gt;&gt;&gt;             max_time=inf,\n&gt;&gt;&gt;             noise=False,\n&gt;&gt;&gt;             tolerance_x=0,\n&gt;&gt;&gt;             ocba_delta=0,\n&gt;&gt;&gt;             var_type=[\"num\", \"num\"],\n&gt;&gt;&gt;             var_name=[\"x1\", \"x2\"],\n&gt;&gt;&gt;             infill_criterion=\"ei\",\n&gt;&gt;&gt;             n_points=10,\n&gt;&gt;&gt;             seed=123,\n&gt;&gt;&gt;             log_level=20,\n&gt;&gt;&gt;             show_models=False,\n&gt;&gt;&gt;             show_progress=True,\n&gt;&gt;&gt;             design=None,\n&gt;&gt;&gt;             design_control={\"init_size\": 10, \"repeats\": 1},\n&gt;&gt;&gt;             surrogate=None,\n&gt;&gt;&gt;             surrogate_control={\"model_optimizer\": \"differential_evolution\",\n&gt;&gt;&gt;                                \"model_fun_evals\": None,\n&gt;&gt;&gt;                                \"min_theta\": -3.,\n&gt;&gt;&gt;                                \"max_theta\": 3.,\n&gt;&gt;&gt;                                \"n_theta\": 1,\n&gt;&gt;&gt;                                \"n_p\": 1,\n&gt;&gt;&gt;                                \"optim_p\": False,\n&gt;&gt;&gt;                                \"cod_type\": \"norm\",\n&gt;&gt;&gt;                                \"var_type\": [\"num\", \"num\"],\n&gt;&gt;&gt;                                \"use_cod_y\": False},\n&gt;&gt;&gt;             optimizer_control={\"max_iter\": 1000})\n&gt;&gt;&gt; spot.run()\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>class Spot:\n\"\"\"\n    Spot base class to handle the following tasks in a uniform manner:\n\n    * Getting and setting parameters. This is done via the `Spot` initialization.\n    * Running surrogate based hyperparameter optimization. After the class is initialized, hyperparameter tuning\n    runs can be performed via the `run` method.\n    * Displaying information. The `plot` method can be used for visualizing results. The `print` methods summarizes\n    information about the tuning run.\n\n    The `Spot` class is built in a modular manner. It combines the following three components:\n\n        1. Design\n        2. Surrogate\n        3. Optimizer\n\n    For each of the three components different implementations can be selected and combined.\n    Internal components are selected as default.\n    These can be replaced by components from other packages, e.g., scikit-learn or scikit-optimize.\n\n    Args:\n        fun (Callable): objective function\n        lower (np.array): lower bound\n        upper (np.array): upper bound\n        fun_evals (int):\n            number of function evaluations\n        fun_repeats (int):\n            number of repeats (replicates).\n        max_time (int):\n            maximum time (in minutes)\n        noise (bool):\n            deterministic or noisy objective function\n        tolerance_x (float):\n            tolerance for new x solutions. Minimum distance of new solutions,\n            generated by `suggest_new_X`, to already existing solutions.\n            If zero (which is the default), every new solution is accepted.\n        ocba_delta (int):\n            OCBA increment (only used if `noise==True`)\n        var_type (List[str]):\n            list of type information, can be either \"num\" or \"factor\"\n        var_name (List[str]):\n            list of variable names, e.g., [\"x1\", \"x2\"]\n        infill_criterion (str):\n            Can be `\"y\"`, `\"s\"`, `\"ei\"` (negative expected improvement), or `\"all\"`.\n        n_points (int):\n            number of infill points\n        seed (int):\n            initial seed\n        log_level (int):\n            log level with the following settings:\n            `NOTSET` (`0`),\n            `DEBUG` (`10`: Detailed information, typically of interest only when diagnosing problems.),\n            `INFO` (`20`: Confirmation that things are working as expected.),\n            `WARNING` (`30`: An indication that something unexpected happened, or indicative of some problem in the near\n                future (e.g. \u2018disk space low\u2019). The software is still working as expected.),\n            `ERROR` (`40`: Due to a more serious problem, the software has not been able to perform some function.), and\n            `CRITICAL` (`50`: A serious error, indicating that the program itself may be unable to continue running.)\n        show_models (bool):\n            Plot model. Currently only 1-dim functions are supported.\n        show_progress (bool):\n            Show progress bar.\n        design (object):\n            experimental design.\n        design_control (Dict[str, Union[int, float]]):\n            experimental design information stored as a dictionary with the following entries:\n            \"init_size\": `10`, \"repeats\": `1`.\n        surrogate (object):\n            surrogate model. If `None`, spotPython's `kriging` is used.\n        surrogate_control (Dict[str, Union[int, float]]):\n            surrogate model information stored as a dictionary with the following entries:\n            \"model_optimizer\": `differential_evolution`,\n            \"model_fun_evals\": `None`,\n            \"min_theta\": `-3.`,  \"max_theta\": `3.`,\n            \"n_theta\": `1`,\n            \"n_p\": `1`,\n            \"optim_p\": `False`,\n            \"cod_type\": `\"norm\"`,\n            \"var_type\": `self.var_type`,\n            \"use_cod_y\": `False`.\n        optimizer (object):\n            optimizer. If `None`, `scipy.optimize`'s `differential_evolution` is used.\n        optimizer_control (Dict[str, Union[int, float]]):\n            information about the optimizer stored as a dictionary with the following entries:\n            \"max_iter\": `1000`.\n\n    Returns:\n        None\n\n    Note:\n        Description in the source code refers to [bart21i]:\n        Bartz-Beielstein, T., and Zaefferer, M. Hyperparameter tuning approaches.\n        In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide,\n        E. Bartz, T. Bartz-Beielstein, M. Zaefferer, and O. Mersmann, Eds. Springer, 2022, ch. 4, pp. 67\u2013114.\n\n    Examples:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from math import inf\n        &gt;&gt;&gt; from spotpy.spot_setup import Spot\n        &gt;&gt;&gt; def objective_function(x):\n        &gt;&gt;&gt;     return x[0]**2 + x[1]**2\n        &gt;&gt;&gt; lower = np.array([0, 0])\n        &gt;&gt;&gt; upper = np.array([10, 10])\n        &gt;&gt;&gt; spot = Spot(fun=objective_function,\n        &gt;&gt;&gt;             lower=lower,\n        &gt;&gt;&gt;             upper=upper,\n        &gt;&gt;&gt;             fun_evals=100,\n        &gt;&gt;&gt;             fun_repeats=1,\n        &gt;&gt;&gt;             max_time=inf,\n        &gt;&gt;&gt;             noise=False,\n        &gt;&gt;&gt;             tolerance_x=0,\n        &gt;&gt;&gt;             ocba_delta=0,\n        &gt;&gt;&gt;             var_type=[\"num\", \"num\"],\n        &gt;&gt;&gt;             var_name=[\"x1\", \"x2\"],\n        &gt;&gt;&gt;             infill_criterion=\"ei\",\n        &gt;&gt;&gt;             n_points=10,\n        &gt;&gt;&gt;             seed=123,\n        &gt;&gt;&gt;             log_level=20,\n        &gt;&gt;&gt;             show_models=False,\n        &gt;&gt;&gt;             show_progress=True,\n        &gt;&gt;&gt;             design=None,\n        &gt;&gt;&gt;             design_control={\"init_size\": 10, \"repeats\": 1},\n        &gt;&gt;&gt;             surrogate=None,\n        &gt;&gt;&gt;             surrogate_control={\"model_optimizer\": \"differential_evolution\",\n        &gt;&gt;&gt;                                \"model_fun_evals\": None,\n        &gt;&gt;&gt;                                \"min_theta\": -3.,\n        &gt;&gt;&gt;                                \"max_theta\": 3.,\n        &gt;&gt;&gt;                                \"n_theta\": 1,\n        &gt;&gt;&gt;                                \"n_p\": 1,\n        &gt;&gt;&gt;                                \"optim_p\": False,\n        &gt;&gt;&gt;                                \"cod_type\": \"norm\",\n        &gt;&gt;&gt;                                \"var_type\": [\"num\", \"num\"],\n        &gt;&gt;&gt;                                \"use_cod_y\": False},\n        &gt;&gt;&gt;             optimizer_control={\"max_iter\": 1000})\n        &gt;&gt;&gt; spot.run()\n    \"\"\"\n\n    def __str__(self):\n        return self.__class__.__name__\n\n    def __init__(\n        self,\n        fun: Callable,\n        lower: np.array,\n        upper: np.array,\n        fun_evals: int = 15,\n        fun_repeats: int = 1,\n        fun_control: Dict[str, Union[int, float]] = {},\n        max_time: int = inf,\n        noise: bool = False,\n        tolerance_x: float = 0,\n        var_type: List[str] = [\"num\"],\n        var_name: List[str] = None,\n        all_var_name: List[str] = None,\n        infill_criterion: str = \"y\",\n        n_points: int = 1,\n        ocba_delta: int = 0,\n        seed: int = 123,\n        log_level: int = 50,\n        show_models: bool = False,\n        show_progress: bool = True,\n        design: object = None,\n        design_control: Dict[str, Union[int, float]] = {},\n        surrogate: object = None,\n        surrogate_control: Dict[str, Union[int, float]] = {},\n        optimizer: object = None,\n        optimizer_control: Dict[str, Union[int, float]] = {},\n    ):\n        # use x0, x1, ... as default variable names:\n        if var_name is None:\n            var_name = [\"x\" + str(i) for i in range(len(lower))]\n        # small value:\n        self.eps = sqrt(spacing(1))\n        self.fun = fun\n        self.lower = lower\n        self.upper = upper\n        self.var_type = var_type\n        self.var_name = var_name\n        self.all_var_name = all_var_name\n        # Reduce dim based on lower == upper logic:\n        # modifies lower, upper, and var_type\n        self.to_red_dim()\n        self.k = self.lower.size\n        self.fun_evals = fun_evals\n        self.fun_repeats = fun_repeats\n        self.max_time = max_time\n        self.noise = noise\n        self.tolerance_x = tolerance_x\n        self.ocba_delta = ocba_delta\n        self.log_level = log_level\n        self.show_models = show_models\n        self.show_progress = show_progress\n        # Random number generator:\n        self.seed = seed\n        self.rng = default_rng(self.seed)\n        # Force numeric type as default in every dim:\n        # assume all variable types are \"num\" if \"num\" is\n        # specified once:\n        if len(self.var_type) &lt; self.k:\n            self.var_type = self.var_type * self.k\n            logger.warning(\"Warning: All variable types forced to 'num'.\")\n        self.infill_criterion = infill_criterion\n        # Bounds\n        de_bounds = []\n        for j in range(self.k):\n            de_bounds.append([self.lower[j], self.upper[j]])\n        self.de_bounds = de_bounds\n        # Infill points:\n        self.n_points = n_points\n        # Objective function related information:\n        self.fun_control = {\"sigma\": 0, \"seed\": None}\n        self.fun_control.update(fun_control)\n        # Design related information:\n        self.design = design\n        if design is None:\n            self.design = spacefilling(k=self.k, seed=self.seed)\n        self.design_control = {\"init_size\": 10, \"repeats\": 1}\n        self.design_control.update(design_control)\n        # Surrogate related information:\n        self.surrogate = surrogate\n        self.surrogate_control = {\n            \"noise\": self.noise,\n            \"model_optimizer\": differential_evolution,\n            \"model_fun_evals\": None,\n            \"min_theta\": -3.0,\n            \"max_theta\": 3.0,\n            \"n_theta\": 1,\n            \"n_p\": 1,\n            \"optim_p\": False,\n            \"cod_type\": \"norm\",\n            \"var_type\": self.var_type,\n            \"seed\": 124,\n            \"use_cod_y\": False,\n        }\n        # Logging information:\n        self.counter = 0\n        self.min_y = None\n        self.min_X = None\n        self.min_mean_X = None\n        self.min_mean_y = None\n        self.mean_X = None\n        self.mean_y = None\n        self.var_y = None\n        logger.setLevel(self.log_level)\n        logger.info(f\"Starting the logger at level {self.log_level} for module {__name__}:\")\n\n        # if the key \"spot_writer\" is not in the dictionary fun_control,\n        # set self.spot_writer to None else to the value of the key \"spot_writer\"\n        self.spot_writer = fun_control.get(\"spot_writer\", None)\n        self.surrogate_control.update(surrogate_control)\n        # If no surrogate model is specified, use the internal\n        # spotPython kriging surrogate:\n        if self.surrogate is None:\n            # Call kriging with surrogate_control parameters:\n            self.surrogate = Kriging(\n                name=\"kriging\",\n                noise=self.surrogate_control[\"noise\"],\n                model_optimizer=self.surrogate_control[\"model_optimizer\"],\n                model_fun_evals=self.surrogate_control[\"model_fun_evals\"],\n                seed=self.surrogate_control[\"seed\"],\n                log_level=self.log_level,\n                min_theta=self.surrogate_control[\"min_theta\"],\n                max_theta=self.surrogate_control[\"max_theta\"],\n                n_theta=self.surrogate_control[\"n_theta\"],\n                n_p=self.surrogate_control[\"n_p\"],\n                optim_p=self.surrogate_control[\"optim_p\"],\n                cod_type=self.surrogate_control[\"cod_type\"],\n                var_type=self.surrogate_control[\"var_type\"],\n                use_cod_y=self.surrogate_control[\"use_cod_y\"],\n                spot_writer=self.spot_writer,\n                counter=self.design_control[\"init_size\"] * self.design_control[\"repeats\"] - 1,\n            )\n        # Optimizer related information:\n        self.optimizer = optimizer\n        self.optimizer_control = {\"max_iter\": 1000, \"seed\": 125}\n        self.optimizer_control.update(optimizer_control)\n        if self.optimizer is None:\n            self.optimizer = optimize.differential_evolution\n\n    def to_red_dim(self):\n        self.all_lower = self.lower\n        self.all_upper = self.upper\n        self.ident = (self.upper - self.lower) == 0\n        self.lower = self.lower[~self.ident]\n        self.upper = self.upper[~self.ident]\n        self.red_dim = self.ident.any()\n        self.all_var_type = self.var_type\n        self.var_type = [x for x, y in zip(self.all_var_type, self.ident) if not y]\n        if self.var_name is not None:\n            self.all_var_name = self.var_name\n            self.var_name = [x for x, y in zip(self.all_var_name, self.ident) if not y]\n\n    def to_all_dim(self, X0):\n        n = X0.shape[0]\n        k = len(self.ident)\n        X = np.zeros((n, k))\n        j = 0\n        for i in range(k):\n            if self.ident[i]:\n                X[:, i] = self.all_lower[i]\n                j += 1\n            else:\n                X[:, i] = X0[:, i - j]\n        return X\n\n    def to_all_dim_if_needed(self, X):\n        if self.red_dim:\n            return self.to_all_dim(X)\n        else:\n            return X\n\n    def get_X_ocba(self):\n        if self.noise and self.ocba_delta &gt; 0:\n            return get_ocba_X(self.mean_X, self.mean_y, self.var_y, self.ocba_delta)\n        else:\n            return None\n\n    def get_new_X0(self):\n        X0 = self.suggest_new_X()\n        X0 = repair_non_numeric(X0, self.var_type)\n        # (S-16) Duplicate Handling:\n        # Condition: select only X= that have min distance\n        # to existing solutions\n        X0, X0_ind = selectNew(A=X0, X=self.X, tolerance=self.tolerance_x)\n        logger.debug(\"XO values are new: %s %s\", X0_ind, X0)\n        # 1. There are X0 that fullfil the condition.\n        # Note: The number of new X0 can be smaller than self.n_points!\n        if X0.shape[0] &gt; 0:\n            return repeat(X0, self.fun_repeats, axis=0)\n        # 2. No X0 found. Then generate self.n_points new solutions:\n        else:\n            self.design = spacefilling(k=self.k, seed=self.seed + self.counter)\n            X0 = self.generate_design(\n                size=self.n_points, repeats=self.design_control[\"repeats\"], lower=self.lower, upper=self.upper\n            )\n            X0 = repair_non_numeric(X0, self.var_type)\n            logger.warning(\"No new XO found on surrogate. Generate new solution %s\", X0)\n            return X0\n\n    def append_X_ocba(self, X_ocba, X0):\n        if self.noise and self.ocba_delta &gt; 0:\n            return append(X_ocba, X0, axis=0)\n        else:\n            return X0\n\n    def run(self, X_start=None):\n        self.initialize_design(X_start)\n        # New: self.update_stats() moved here:\n        # self.update_stats()\n        # (S-5) Calling the spotLoop Function\n        # and\n        # (S-9) Termination Criteria, Conditions:\n        timeout_start = time.time()\n        while self.should_continue(timeout_start):\n            self.update_design()\n            # (S-10): Subset Selection for the Surrogate:\n            # Not implemented yet.\n            # Update stats\n            self.update_stats()\n            # Update writer:\n            self.update_writer()\n            # (S-11) Surrogate Fit:\n            self.fit_surrogate()\n            # progress bar:\n            self.show_progress_if_needed(timeout_start)\n        if self.spot_writer is not None:\n            writer = self.spot_writer\n            writer.close()\n        return self\n\n    def initialize_design(self, X_start=None):\n        # (S-2) Initial Design:\n        X0 = self.generate_design(\n            size=self.design_control[\"init_size\"],\n            repeats=self.design_control[\"repeats\"],\n            lower=self.lower,\n            upper=self.upper,\n        )\n        if X_start is not None:\n            try:\n                X0 = append(X_start, X0, axis=0)\n            except ValueError:\n                logger.warning(\"X_start has wrong shape. Ignoring it.\")\n        X0 = repair_non_numeric(X0, self.var_type)\n        self.X = X0\n        # (S-3): Eval initial design:\n        X_all = self.to_all_dim_if_needed(X0)\n        self.y = self.fun(X=X_all, fun_control=self.fun_control)\n        # TODO: Error if only nan values are returned\n        logger.debug(\"New y value: %s\", self.y)\n        #\n        self.counter = self.y.size\n        if self.spot_writer is not None:\n            writer = self.spot_writer\n            # range goes to init_size -1 because the last value is added by update_stats(),\n            # which always adds the last value.\n            # Changed in 0.5.9:\n            for j in range(len(self.y)):\n                X_j = self.X[j].copy()\n                y_j = self.y[j].copy()\n                config = {self.var_name[i]: X_j[i] for i in range(self.k)}\n                writer.add_hparams(config, {\"spot_y\": y_j})\n                writer.flush()\n        #\n        self.X, self.y = remove_nan(self.X, self.y)\n        # self.update_stats() moved to run()!\n        # changed in 0.5.9:\n        self.update_stats()\n        # (S-4): Imputation:\n        # Not implemented yet.\n        # (S-11) Surrogate Fit:\n        self.fit_surrogate()\n\n    def should_continue(self, timeout_start):\n        return (self.counter &lt; self.fun_evals) and (time.time() &lt; timeout_start + self.max_time * 60)\n\n    def update_design(self):\n        # OCBA (only if noise)\n        X_ocba = self.get_X_ocba()\n        # (S-15) Compile Surrogate Results:\n        X0 = self.get_new_X0()\n        # (S-18): Evaluating New Solutions:\n        X0 = self.append_X_ocba(X_ocba, X0)\n        X_all = self.to_all_dim_if_needed(X0)\n        y0 = self.fun(X=X_all, fun_control=self.fun_control)\n        X0, y0 = remove_nan(X0, y0)\n        # Append New Solutions:\n        self.X = np.append(self.X, X0, axis=0)\n        self.y = np.append(self.y, y0)\n\n    def fit_surrogate(self):\n        self.surrogate.fit(self.X, self.y)\n        if self.show_models:\n            self.plot_model()\n\n    def show_progress_if_needed(self, timeout_start):\n        if not self.show_progress:\n            return\n        if isfinite(self.fun_evals):\n            progress_bar(progress=self.counter / self.fun_evals, y=self.min_y)\n        else:\n            progress_bar(progress=(time.time() - timeout_start) / (self.max_time * 60), y=self.min_y)\n\n    def generate_design(self, size, repeats, lower, upper):\n        return self.design.scipy_lhd(n=size, repeats=repeats, lower=lower, upper=upper)\n\n    def update_stats(self):\n\"\"\"\n        Update the following stats: 1. `min_y` 2. `min_X` 3. `counter`\n        If `noise` is `True`, additionally the following stats are computed: 1. `mean_X`\n        2. `mean_y` 3. `min_mean_y` 4. `min_mean_X`.\n\n        \"\"\"\n        self.min_y = min(self.y)\n        self.min_X = self.X[argmin(self.y)]\n        self.counter = self.y.size\n        # Update aggregated x and y values (if noise):\n        if self.noise:\n            Z = aggregate_mean_var(X=self.X, y=self.y)\n            self.mean_X = Z[0]\n            self.mean_y = Z[1]\n            self.var_y = Z[2]\n            # X value of the best mean y value so far:\n            self.min_mean_X = self.mean_X[argmin(self.mean_y)]\n            # variance of the best mean y value so far:\n            self.min_var_y = self.var_y[argmin(self.mean_y)]\n            # best mean y value so far:\n            self.min_mean_y = self.mean_y[argmin(self.mean_y)]\n\n    def update_writer(self):\n        if self.spot_writer is not None:\n            writer = self.spot_writer\n            # get the last y value:\n            y_last = self.y[-1].copy()\n            if self.noise is False:\n                y_min = self.min_y.copy()\n                X_min = self.min_X.copy()\n                # y_min: best y value so far\n                # y_last: last y value, can be worse than y_min\n                writer.add_scalars(\"spot_y\", {\"min\": y_min, \"last\": y_last}, self.counter)\n                # X_min: X value of the best y value so far\n                writer.add_scalars(\"spot_X\", {f\"X_{i}\": X_min[i] for i in range(self.k)}, self.counter)\n            else:\n                # get the last n y values:\n                y_last_n = self.y[-self.fun_repeats :].copy()\n                # y_min_mean: best mean y value so far\n                y_min_mean = self.min_mean_y.copy()\n                # X_min_mean: X value of the best mean y value so far\n                X_min_mean = self.min_mean_X.copy()\n                # y_min_var: variance of the min y value so far\n                y_min_var = self.min_var_y.copy()\n                writer.add_scalar(\"spot_y_min_var\", y_min_var, self.counter)\n                # y_min_mean: best mean y value so far (see above)\n                writer.add_scalar(\"spot_y\", y_min_mean, self.counter)\n                # last n y values (noisy):\n                writer.add_scalars(\n                    \"spot_y\", {f\"y_last_n{i}\": y_last_n[i] for i in range(self.fun_repeats)}, self.counter\n                )\n                # X_min_mean: X value of the best mean y value so far (see above)\n                writer.add_scalars(\n                    \"spot_X_noise\", {f\"X_min_mean{i}\": X_min_mean[i] for i in range(self.k)}, self.counter\n                )\n            # get last value of self.X and convert to dict. take the values from self.var_name as keys:\n            X_last = self.X[-1].copy()\n            config = {self.var_name[i]: X_last[i] for i in range(self.k)}\n            # hyperparameters X and value y of the last configuration:\n            writer.add_hparams(config, {\"spot_y\": y_last})\n            writer.flush()\n\n    def suggest_new_X_old(self):\n\"\"\"\n        Compute `n_points` new infill points in natural units.\n        The optimizer searches in the ranges from `lower_j` to `upper_j`.\n        The method `infill()` is used as the objective function.\n\n        Returns:\n            (numpy.ndarray): `n_points` infill points in natural units, each of dim k\n\n        Note:\n            This is step (S-14a) in [bart21i].\n        \"\"\"\n        # (S-14a) Optimization on the surrogate:\n        new_X = np.zeros([self.n_points, self.k], dtype=float)\n\n        optimizer_name = self.optimizer.__name__\n        for i in range(self.n_points):\n            if optimizer_name == \"dual_annealing\":\n                result = self.optimizer(func=self.infill, bounds=self.de_bounds)\n            elif optimizer_name == \"differential_evolution\":\n                result = self.optimizer(\n                    func=self.infill,\n                    bounds=self.de_bounds,\n                    maxiter=self.optimizer_control[\"max_iter\"],\n                    seed=self.optimizer_control[\"seed\"],\n                    # popsize=10,\n                    # updating=\"deferred\"\n                )\n            elif optimizer_name == \"direct\":\n                result = self.optimizer(func=self.infill, bounds=self.de_bounds, eps=1e-2)\n            elif optimizer_name == \"shgo\":\n                result = self.optimizer(func=self.infill, bounds=self.de_bounds)\n            elif optimizer_name == \"basinhopping\":\n                result = self.optimizer(func=self.infill, x0=self.min_X)\n            else:\n                result = self.optimizer(func=self.infill, bounds=self.de_bounds)\n            new_X[i][:] = result.x\n        return new_X\n\n    def suggest_new_X(self):\n\"\"\"\n        Compute `n_points` new infill points in natural units.\n        The optimizer searches in the ranges from `lower_j` to `upper_j`.\n        The method `infill()` is used as the objective function.\n\n        Returns:\n            (numpy.ndarray): `n_points` infill points in natural units, each of dim k\n\n        Note:\n            This is step (S-14a) in [bart21i].\n        \"\"\"\n        # (S-14a) Optimization on the surrogate:\n        new_X = np.zeros([self.n_points, self.k], dtype=float)\n\n        optimizer_name = self.optimizer.__name__\n\n        optimizers = {\n            \"dual_annealing\": lambda: self.optimizer(func=self.infill, bounds=self.de_bounds),\n            \"differential_evolution\": lambda: self.optimizer(\n                func=self.infill,\n                bounds=self.de_bounds,\n                maxiter=self.optimizer_control[\"max_iter\"],\n                seed=self.optimizer_control[\"seed\"],\n            ),\n            \"direct\": lambda: self.optimizer(func=self.infill, bounds=self.de_bounds, eps=1e-2),\n            \"shgo\": lambda: self.optimizer(func=self.infill, bounds=self.de_bounds),\n            \"basinhopping\": lambda: self.optimizer(func=self.infill, x0=self.min_X),\n            \"default\": lambda: self.optimizer(func=self.infill, bounds=self.de_bounds),\n        }\n\n        for i in range(self.n_points):\n            result = optimizers.get(optimizer_name, optimizers[\"default\"])()\n            new_X[i][:] = result.x\n        return new_X\n\n    def infill(self, x):\n\"\"\"\n        Infill (acquisition) function. Evaluates one point on the surrogate via `surrogate.predict(x.reshape(1,-1))`,\n        if `sklearn` surrogates are used or `surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion)`\n        if the internal surrogate `kriging` is selected.\n        This method is passed to the optimizer in `suggest_new_X`, i.e., the optimizer is called via\n        `self.optimizer(func=self.infill)`.\n\n        Args:\n            x (array): point in natural units with shape `(1, dim)`.\n\n        Returns:\n            (numpy.ndarray): value based on infill criterion, e.g., `\"ei\"`. Shape `(1,)`.\n                The objective function value `y` that is used as a base value for the\n                infill criterion is calculated in natural units.\n\n        Note:\n            This is step (S-12) in [bart21i].\n        \"\"\"\n        # Reshape x to have shape (1, -1) because the predict method expects a 2D array\n        x_reshaped = x.reshape(1, -1)\n        if isinstance(self.surrogate, Kriging):\n            return self.surrogate.predict(x_reshaped, return_val=self.infill_criterion)\n        else:\n            return self.surrogate.predict(x_reshaped)\n\n    def plot_progress(\n        self, show=True, log_x=False, log_y=False, filename=\"plot.png\", style=[\"ko\", \"k\", \"ro-\"], dpi=300\n    ) -&gt; None:\n\"\"\"Plot the progress of the hyperparameter tuning (optimization).\n        Args:\n            show (bool): Show the plot.\n            log_x (bool): Use logarithmic scale for x-axis.\n            log_y (bool): Use logarithmic scale for y-axis.\n            filename (str): Filename to save the plot.\n            style (list): Style of the plot. Default: ['k', 'ro-'], i.e., the initial points are plotted as a black line\n            and the subsequent points as red dots connected by a line.\n        Returns:\n            None\n        \"\"\"\n        fig = pylab.figure(figsize=(9, 6))\n        s_y = pd.Series(self.y)\n        s_c = s_y.cummin()\n        n_init = self.design_control[\"init_size\"] * self.design_control[\"repeats\"]\n        ax = fig.add_subplot(211)\n        ax.plot(\n            range(1, n_init + 1),\n            s_y[:n_init],\n            style[0],\n            range(1, n_init + 2),\n            [s_c[:n_init].min()] * (n_init + 1),\n            style[1],\n            range(n_init + 1, len(s_c) + 1),\n            s_c[n_init:],\n            style[2],\n        )\n        if log_x:\n            ax.set_xscale(\"log\")\n        if log_y:\n            ax.set_yscale(\"log\")\n        if filename is not None:\n            pylab.savefig(filename, dpi=dpi, bbox_inches=\"tight\")\n        if show:\n            pylab.show()\n\n    def plot_model(self, y_min=None, y_max=None):\n\"\"\"\n        Plot the model fit for 1-dim objective functions.\n\n        Args:\n            y_min (float, optional): y range, lower bound.\n            y_max (float, optional): y range, upper bound.\n        \"\"\"\n        if self.k == 1:\n            X_test = np.linspace(self.lower[0], self.upper[0], 100)\n            y_test = self.fun(X=X_test.reshape(-1, 1), fun_control=self.fun_control)\n            if isinstance(self.surrogate, Kriging):\n                y_hat = self.surrogate.predict(X_test[:, np.newaxis], return_val=\"y\")\n            else:\n                y_hat = self.surrogate.predict(X_test[:, np.newaxis])\n            plt.plot(X_test, y_hat, label=\"Model\")\n            plt.plot(X_test, y_test, label=\"True function\")\n            plt.scatter(self.X, self.y, edgecolor=\"b\", s=20, label=\"Samples\")\n            plt.scatter(self.X[-1], self.y[-1], edgecolor=\"r\", s=30, label=\"Last Sample\")\n            if self.noise:\n                plt.scatter(self.min_mean_X, self.min_mean_y, edgecolor=\"g\", s=30, label=\"Best Sample (mean)\")\n            else:\n                plt.scatter(self.min_X, self.min_y, edgecolor=\"g\", s=30, label=\"Best Sample\")\n            plt.xlabel(\"x\")\n            plt.ylabel(\"y\")\n            plt.xlim((self.lower[0], self.upper[0]))\n            if y_min is None:\n                y_min = min(min(self.y), min(y_test))\n            if y_max is None:\n                y_max = max(max(self.y), max(y_test))\n            plt.ylim((y_min, y_max))\n            plt.legend(loc=\"best\")\n            # plt.title(self.surrogate.__class__.__name__ + \". \" + str(self.counter) + \": \" + str(self.min_y))\n            if self.noise:\n                plt.title(\n                    str(self.counter)\n                    + \". y (noise): \"\n                    + str(np.round(self.min_y, 6))\n                    + \" y mean: \"\n                    + str(np.round(self.min_mean_y, 6))\n                )\n            else:\n                plt.title(str(self.counter) + \". y: \" + str(np.round(self.min_y, 6)))\n            plt.show()\n\n    def print_results(self, print_screen=True) -&gt; list[str]:\n\"\"\"Print results from the run:\n            1. min y\n            2. min X\n            If `noise == True`, additionally the following values are printed:\n            3. min mean y\n            4. min mean X\n        Args:\n            print_screen (bool, optional): print results to screen\n        Returns:\n            output (list): list of results\n        \"\"\"\n        output = []\n        if print_screen:\n            print(f\"min y: {self.min_y}\")\n        res = self.to_all_dim(self.min_X.reshape(1, -1))\n        for i in range(res.shape[1]):\n            var_name = \"x\" + str(i) if self.all_var_name is None else self.all_var_name[i]\n            if print_screen:\n                print(var_name + \":\", res[0][i])\n            output.append([var_name, res[0][i]])\n        if self.noise:\n            res = self.to_all_dim(self.min_mean_X.reshape(1, -1))\n            if print_screen:\n                print(f\"min mean y: {self.min_mean_y}\")\n            for i in range(res.shape[1]):\n                var_name = \"x\" + str(i) if self.all_var_name is None else self.all_var_name[i]\n                if print_screen:\n                    print(var_name + \":\", res[0][i])\n                output.append([var_name, res[0][i]])\n        return output\n\n    def chg(self, x, y, z0, i, j):\n\"\"\"\n        Change the values of elements at indices `i` and `j` in the array `z0` to `x` and `y`, respectively.\n\n        Args:\n            x (int or float): The new value for the element at index `i`.\n            y (int or float): The new value for the element at index `j`.\n            z0 (list or numpy.ndarray): The array to be modified.\n            i (int): The index of the element to be changed to `x`.\n            j (int): The index of the element to be changed to `y`.\n\n        Returns:\n            list or numpy.ndarray: The modified array.\n\n        Example:\n            &gt;&gt;&gt; z0 = [1, 2, 3]\n            &gt;&gt;&gt; chg(4, 5, z0, 0, 2)\n            [4, 2, 5]\n        \"\"\"\n        z0[i] = x\n        z0[j] = y\n        return z0\n\n    def plot_contour(\n        self, i=0, j=1, min_z=None, max_z=None, show=True, filename=None, n_grid=25, contour_levels=10, dpi=200\n    ) -&gt; None:\n\"\"\"Plot the contour of any dimension.\n        Args:\n            i (int): the first dimension\n            j (int): the second dimension\n            min_z (float): the minimum value of z\n            max_z (float): the maximum value of z\n            show (bool): show the plot\n            filename (str): save the plot to a file\n            n_grid (int): number of grid points\n            contour_levels (int): number of contour levels\n        Returns:\n            None\n        \"\"\"\n        fig = pylab.figure(figsize=(9, 6))\n        # lower and upper\n        x = np.linspace(self.lower[i], self.upper[i], num=n_grid)\n        y = np.linspace(self.lower[j], self.upper[j], num=n_grid)\n        X, Y = meshgrid(x, y)\n        # Predict based on the optimized results\n        z0 = np.mean(np.array([self.lower, self.upper]), axis=0)\n        zz = array([self.surrogate.predict(array([self.chg(x, y, z0, i, j)])) for x, y in zip(ravel(X), ravel(Y))])\n        zs = zz[:, 0]\n        Z = zs.reshape(X.shape)\n        if min_z is None:\n            min_z = np.min(Z)\n        if max_z is None:\n            max_z = np.max(Z)\n        ax = fig.add_subplot(221)\n        # plot predicted values:\n        plt.contourf(X, Y, Z, contour_levels, zorder=1, cmap=\"jet\", vmin=min_z, vmax=max_z)\n        if self.var_name is None:\n            plt.xlabel(\"x\" + str(i))\n            plt.ylabel(\"x\" + str(j))\n        else:\n            plt.xlabel(\"x\" + str(i) + \": \" + self.var_name[i])\n            plt.ylabel(\"x\" + str(j) + \": \" + self.var_name[j])\n        plt.title(\"Surrogate\")\n        pylab.colorbar()\n        ax = fig.add_subplot(222, projection=\"3d\")\n        ax.plot_surface(X, Y, Z, rstride=3, cstride=3, alpha=0.9, cmap=\"jet\", vmin=min_z, vmax=max_z)\n        if self.var_name is None:\n            plt.xlabel(\"x\" + str(i))\n            plt.ylabel(\"x\" + str(j))\n        else:\n            plt.xlabel(\"x\" + str(i) + \": \" + self.var_name[i])\n            plt.ylabel(\"x\" + str(j) + \": \" + self.var_name[j])\n        if filename:\n            pylab.savefig(filename, bbox_inches=\"tight\", dpi=dpi, pad_inches=0),\n        if show:\n            pylab.show()\n\n    def plot_important_hyperparameter_contour(self, threshold=0.025, filename=None):\n        impo = self.print_importance(threshold=threshold, print_screen=True)\n        var_plots = [i for i, x in enumerate(impo) if x[1] &gt; threshold]\n        min_z = min(self.y)\n        max_z = max(self.y)\n        for i in var_plots:\n            for j in var_plots:\n                if j &gt; i:\n                    if filename is not None:\n                        filename_full = filename + \"_contour_\" + str(i) + \"_\" + str(j) + \".png\"\n                    else:\n                        filename_full = None\n                    self.plot_contour(i=i, j=j, min_z=min_z, max_z=max_z, filename=filename_full)\n\n    def get_importance(self) -&gt; list:\n\"\"\"Get importance of each variable and return the results as a list.\n        Returns:\n            output (list): list of results\n        \"\"\"\n        if self.surrogate.n_theta &gt; 1 and self.var_name is not None:\n            output = [0] * len(self.all_var_name)\n            theta = np.power(10, self.surrogate.theta)\n            imp = 100 * theta / np.max(theta)\n            ind = find_indices(A=self.var_name, B=self.all_var_name)\n            j = 0\n            for i in ind:\n                output[i] = imp[j]\n                j = j + 1\n            return output\n        else:\n            print(\"Importance requires more than one theta values (n_theta&gt;1).\")\n\n    def print_importance(self, threshold=0.1, print_screen=True) -&gt; list:\n\"\"\"Print importance of each variable and return the results as a list.\n        Args:\n            threshold (float): threshold for printing\n            print_screen (boolean): if `True`, values are also printed on the screen. Default is `True`.\n        Returns:\n            output (list): list of results\n        \"\"\"\n        output = []\n        if self.surrogate.n_theta &gt; 1:\n            theta = np.power(10, self.surrogate.theta)\n            imp = 100 * theta / np.max(theta)\n            # imp = imp[imp &gt;= threshold]\n            if self.var_name is None:\n                for i in range(len(imp)):\n                    if imp[i] &gt;= threshold:\n                        if print_screen:\n                            print(\"x\", i, \": \", imp[i])\n                        output.append(\"x\" + str(i) + \": \" + str(imp[i]))\n            else:\n                var_name = [self.var_name[i] for i in range(len(imp))]\n                for i in range(len(imp)):\n                    if imp[i] &gt;= threshold:\n                        if print_screen:\n                            print(var_name[i] + \": \", imp[i])\n                    output.append([var_name[i], imp[i]])\n        else:\n            print(\"Importance requires more than one theta values (n_theta&gt;1).\")\n        return output\n\n    def plot_importance(self, threshold=0.1, filename=None, dpi=300) -&gt; None:\n\"\"\"Plot the importance of each variable.\n        Args:\n            threshold (float):  The threshold of the importance.\n            filename (str): The filename of the plot.\n        Returns:\n            None\n        \"\"\"\n        if self.surrogate.n_theta &gt; 1:\n            theta = np.power(10, self.surrogate.theta)\n            imp = 100 * theta / np.max(theta)\n            idx = np.where(imp &gt; threshold)[0]\n            if self.var_name is None:\n                plt.bar(range(len(imp[idx])), imp[idx])\n                plt.xticks(range(len(imp[idx])), [\"x\" + str(i) for i in idx])\n            else:\n                var_name = [self.var_name[i] for i in idx]\n                plt.bar(range(len(imp[idx])), imp[idx])\n                plt.xticks(range(len(imp[idx])), var_name)\n            if filename is not None:\n                plt.savefig(filename, bbox_inches=\"tight\", dpi=dpi)\n            plt.show()\n\n    def parallel_plot(self):\n        X = self.X\n        y = self.y\n        df = pd.DataFrame(np.concatenate((X, y.reshape(-1, 1)), axis=1), columns=self.var_name + [\"y\"])\n\n        fig = go.Figure(\n            data=go.Parcoords(\n                line=dict(color=df[\"y\"], colorscale=\"Jet\", showscale=True, cmin=min(df[\"y\"]), cmax=max(df[\"y\"])),\n                dimensions=list(\n                    [\n                        dict(range=[min(df.iloc[:, i]), max(df.iloc[:, i])], label=df.columns[i], values=df.iloc[:, i])\n                        for i in range(len(df.columns) - 1)\n                    ]\n                ),\n            )\n        )\n        fig.show()\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.chg","title":"<code>chg(x, y, z0, i, j)</code>","text":"<p>Change the values of elements at indices <code>i</code> and <code>j</code> in the array <code>z0</code> to <code>x</code> and <code>y</code>, respectively.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int or float</code> <p>The new value for the element at index <code>i</code>.</p> required <code>y</code> <code>int or float</code> <p>The new value for the element at index <code>j</code>.</p> required <code>z0</code> <code>list or numpy.ndarray</code> <p>The array to be modified.</p> required <code>i</code> <code>int</code> <p>The index of the element to be changed to <code>x</code>.</p> required <code>j</code> <code>int</code> <p>The index of the element to be changed to <code>y</code>.</p> required <p>Returns:</p> Type Description <p>list or numpy.ndarray: The modified array.</p> Example <p>z0 = [1, 2, 3] chg(4, 5, z0, 0, 2) [4, 2, 5]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def chg(self, x, y, z0, i, j):\n\"\"\"\n    Change the values of elements at indices `i` and `j` in the array `z0` to `x` and `y`, respectively.\n\n    Args:\n        x (int or float): The new value for the element at index `i`.\n        y (int or float): The new value for the element at index `j`.\n        z0 (list or numpy.ndarray): The array to be modified.\n        i (int): The index of the element to be changed to `x`.\n        j (int): The index of the element to be changed to `y`.\n\n    Returns:\n        list or numpy.ndarray: The modified array.\n\n    Example:\n        &gt;&gt;&gt; z0 = [1, 2, 3]\n        &gt;&gt;&gt; chg(4, 5, z0, 0, 2)\n        [4, 2, 5]\n    \"\"\"\n    z0[i] = x\n    z0[j] = y\n    return z0\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.get_importance","title":"<code>get_importance()</code>","text":"<p>Get importance of each variable and return the results as a list.</p> <p>Returns:</p> Name Type Description <code>output</code> <code>list</code> <p>list of results</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def get_importance(self) -&gt; list:\n\"\"\"Get importance of each variable and return the results as a list.\n    Returns:\n        output (list): list of results\n    \"\"\"\n    if self.surrogate.n_theta &gt; 1 and self.var_name is not None:\n        output = [0] * len(self.all_var_name)\n        theta = np.power(10, self.surrogate.theta)\n        imp = 100 * theta / np.max(theta)\n        ind = find_indices(A=self.var_name, B=self.all_var_name)\n        j = 0\n        for i in ind:\n            output[i] = imp[j]\n            j = j + 1\n        return output\n    else:\n        print(\"Importance requires more than one theta values (n_theta&gt;1).\")\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.infill","title":"<code>infill(x)</code>","text":"<p>Infill (acquisition) function. Evaluates one point on the surrogate via <code>surrogate.predict(x.reshape(1,-1))</code>, if <code>sklearn</code> surrogates are used or <code>surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion)</code> if the internal surrogate <code>kriging</code> is selected. This method is passed to the optimizer in <code>suggest_new_X</code>, i.e., the optimizer is called via <code>self.optimizer(func=self.infill)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array</code> <p>point in natural units with shape <code>(1, dim)</code>.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>value based on infill criterion, e.g., <code>\"ei\"</code>. Shape <code>(1,)</code>. The objective function value <code>y</code> that is used as a base value for the infill criterion is calculated in natural units.</p> Note <p>This is step (S-12) in [bart21i].</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def infill(self, x):\n\"\"\"\n    Infill (acquisition) function. Evaluates one point on the surrogate via `surrogate.predict(x.reshape(1,-1))`,\n    if `sklearn` surrogates are used or `surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion)`\n    if the internal surrogate `kriging` is selected.\n    This method is passed to the optimizer in `suggest_new_X`, i.e., the optimizer is called via\n    `self.optimizer(func=self.infill)`.\n\n    Args:\n        x (array): point in natural units with shape `(1, dim)`.\n\n    Returns:\n        (numpy.ndarray): value based on infill criterion, e.g., `\"ei\"`. Shape `(1,)`.\n            The objective function value `y` that is used as a base value for the\n            infill criterion is calculated in natural units.\n\n    Note:\n        This is step (S-12) in [bart21i].\n    \"\"\"\n    # Reshape x to have shape (1, -1) because the predict method expects a 2D array\n    x_reshaped = x.reshape(1, -1)\n    if isinstance(self.surrogate, Kriging):\n        return self.surrogate.predict(x_reshaped, return_val=self.infill_criterion)\n    else:\n        return self.surrogate.predict(x_reshaped)\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.plot_contour","title":"<code>plot_contour(i=0, j=1, min_z=None, max_z=None, show=True, filename=None, n_grid=25, contour_levels=10, dpi=200)</code>","text":"<p>Plot the contour of any dimension.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>the first dimension</p> <code>0</code> <code>j</code> <code>int</code> <p>the second dimension</p> <code>1</code> <code>min_z</code> <code>float</code> <p>the minimum value of z</p> <code>None</code> <code>max_z</code> <code>float</code> <p>the maximum value of z</p> <code>None</code> <code>show</code> <code>bool</code> <p>show the plot</p> <code>True</code> <code>filename</code> <code>str</code> <p>save the plot to a file</p> <code>None</code> <code>n_grid</code> <code>int</code> <p>number of grid points</p> <code>25</code> <code>contour_levels</code> <code>int</code> <p>number of contour levels</p> <code>10</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def plot_contour(\n    self, i=0, j=1, min_z=None, max_z=None, show=True, filename=None, n_grid=25, contour_levels=10, dpi=200\n) -&gt; None:\n\"\"\"Plot the contour of any dimension.\n    Args:\n        i (int): the first dimension\n        j (int): the second dimension\n        min_z (float): the minimum value of z\n        max_z (float): the maximum value of z\n        show (bool): show the plot\n        filename (str): save the plot to a file\n        n_grid (int): number of grid points\n        contour_levels (int): number of contour levels\n    Returns:\n        None\n    \"\"\"\n    fig = pylab.figure(figsize=(9, 6))\n    # lower and upper\n    x = np.linspace(self.lower[i], self.upper[i], num=n_grid)\n    y = np.linspace(self.lower[j], self.upper[j], num=n_grid)\n    X, Y = meshgrid(x, y)\n    # Predict based on the optimized results\n    z0 = np.mean(np.array([self.lower, self.upper]), axis=0)\n    zz = array([self.surrogate.predict(array([self.chg(x, y, z0, i, j)])) for x, y in zip(ravel(X), ravel(Y))])\n    zs = zz[:, 0]\n    Z = zs.reshape(X.shape)\n    if min_z is None:\n        min_z = np.min(Z)\n    if max_z is None:\n        max_z = np.max(Z)\n    ax = fig.add_subplot(221)\n    # plot predicted values:\n    plt.contourf(X, Y, Z, contour_levels, zorder=1, cmap=\"jet\", vmin=min_z, vmax=max_z)\n    if self.var_name is None:\n        plt.xlabel(\"x\" + str(i))\n        plt.ylabel(\"x\" + str(j))\n    else:\n        plt.xlabel(\"x\" + str(i) + \": \" + self.var_name[i])\n        plt.ylabel(\"x\" + str(j) + \": \" + self.var_name[j])\n    plt.title(\"Surrogate\")\n    pylab.colorbar()\n    ax = fig.add_subplot(222, projection=\"3d\")\n    ax.plot_surface(X, Y, Z, rstride=3, cstride=3, alpha=0.9, cmap=\"jet\", vmin=min_z, vmax=max_z)\n    if self.var_name is None:\n        plt.xlabel(\"x\" + str(i))\n        plt.ylabel(\"x\" + str(j))\n    else:\n        plt.xlabel(\"x\" + str(i) + \": \" + self.var_name[i])\n        plt.ylabel(\"x\" + str(j) + \": \" + self.var_name[j])\n    if filename:\n        pylab.savefig(filename, bbox_inches=\"tight\", dpi=dpi, pad_inches=0),\n    if show:\n        pylab.show()\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.plot_importance","title":"<code>plot_importance(threshold=0.1, filename=None, dpi=300)</code>","text":"<p>Plot the importance of each variable.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>The threshold of the importance.</p> <code>0.1</code> <code>filename</code> <code>str</code> <p>The filename of the plot.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def plot_importance(self, threshold=0.1, filename=None, dpi=300) -&gt; None:\n\"\"\"Plot the importance of each variable.\n    Args:\n        threshold (float):  The threshold of the importance.\n        filename (str): The filename of the plot.\n    Returns:\n        None\n    \"\"\"\n    if self.surrogate.n_theta &gt; 1:\n        theta = np.power(10, self.surrogate.theta)\n        imp = 100 * theta / np.max(theta)\n        idx = np.where(imp &gt; threshold)[0]\n        if self.var_name is None:\n            plt.bar(range(len(imp[idx])), imp[idx])\n            plt.xticks(range(len(imp[idx])), [\"x\" + str(i) for i in idx])\n        else:\n            var_name = [self.var_name[i] for i in idx]\n            plt.bar(range(len(imp[idx])), imp[idx])\n            plt.xticks(range(len(imp[idx])), var_name)\n        if filename is not None:\n            plt.savefig(filename, bbox_inches=\"tight\", dpi=dpi)\n        plt.show()\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.plot_model","title":"<code>plot_model(y_min=None, y_max=None)</code>","text":"<p>Plot the model fit for 1-dim objective functions.</p> <p>Parameters:</p> Name Type Description Default <code>y_min</code> <code>float</code> <p>y range, lower bound.</p> <code>None</code> <code>y_max</code> <code>float</code> <p>y range, upper bound.</p> <code>None</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def plot_model(self, y_min=None, y_max=None):\n\"\"\"\n    Plot the model fit for 1-dim objective functions.\n\n    Args:\n        y_min (float, optional): y range, lower bound.\n        y_max (float, optional): y range, upper bound.\n    \"\"\"\n    if self.k == 1:\n        X_test = np.linspace(self.lower[0], self.upper[0], 100)\n        y_test = self.fun(X=X_test.reshape(-1, 1), fun_control=self.fun_control)\n        if isinstance(self.surrogate, Kriging):\n            y_hat = self.surrogate.predict(X_test[:, np.newaxis], return_val=\"y\")\n        else:\n            y_hat = self.surrogate.predict(X_test[:, np.newaxis])\n        plt.plot(X_test, y_hat, label=\"Model\")\n        plt.plot(X_test, y_test, label=\"True function\")\n        plt.scatter(self.X, self.y, edgecolor=\"b\", s=20, label=\"Samples\")\n        plt.scatter(self.X[-1], self.y[-1], edgecolor=\"r\", s=30, label=\"Last Sample\")\n        if self.noise:\n            plt.scatter(self.min_mean_X, self.min_mean_y, edgecolor=\"g\", s=30, label=\"Best Sample (mean)\")\n        else:\n            plt.scatter(self.min_X, self.min_y, edgecolor=\"g\", s=30, label=\"Best Sample\")\n        plt.xlabel(\"x\")\n        plt.ylabel(\"y\")\n        plt.xlim((self.lower[0], self.upper[0]))\n        if y_min is None:\n            y_min = min(min(self.y), min(y_test))\n        if y_max is None:\n            y_max = max(max(self.y), max(y_test))\n        plt.ylim((y_min, y_max))\n        plt.legend(loc=\"best\")\n        # plt.title(self.surrogate.__class__.__name__ + \". \" + str(self.counter) + \": \" + str(self.min_y))\n        if self.noise:\n            plt.title(\n                str(self.counter)\n                + \". y (noise): \"\n                + str(np.round(self.min_y, 6))\n                + \" y mean: \"\n                + str(np.round(self.min_mean_y, 6))\n            )\n        else:\n            plt.title(str(self.counter) + \". y: \" + str(np.round(self.min_y, 6)))\n        plt.show()\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.plot_progress","title":"<code>plot_progress(show=True, log_x=False, log_y=False, filename='plot.png', style=['ko', 'k', 'ro-'], dpi=300)</code>","text":"<p>Plot the progress of the hyperparameter tuning (optimization).</p> <p>Parameters:</p> Name Type Description Default <code>show</code> <code>bool</code> <p>Show the plot.</p> <code>True</code> <code>log_x</code> <code>bool</code> <p>Use logarithmic scale for x-axis.</p> <code>False</code> <code>log_y</code> <code>bool</code> <p>Use logarithmic scale for y-axis.</p> <code>False</code> <code>filename</code> <code>str</code> <p>Filename to save the plot.</p> <code>'plot.png'</code> <code>style</code> <code>list</code> <p>Style of the plot. Default: [\u2018k\u2019, \u2018ro-\u2018], i.e., the initial points are plotted as a black line</p> <code>['ko', 'k', 'ro-']</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def plot_progress(\n    self, show=True, log_x=False, log_y=False, filename=\"plot.png\", style=[\"ko\", \"k\", \"ro-\"], dpi=300\n) -&gt; None:\n\"\"\"Plot the progress of the hyperparameter tuning (optimization).\n    Args:\n        show (bool): Show the plot.\n        log_x (bool): Use logarithmic scale for x-axis.\n        log_y (bool): Use logarithmic scale for y-axis.\n        filename (str): Filename to save the plot.\n        style (list): Style of the plot. Default: ['k', 'ro-'], i.e., the initial points are plotted as a black line\n        and the subsequent points as red dots connected by a line.\n    Returns:\n        None\n    \"\"\"\n    fig = pylab.figure(figsize=(9, 6))\n    s_y = pd.Series(self.y)\n    s_c = s_y.cummin()\n    n_init = self.design_control[\"init_size\"] * self.design_control[\"repeats\"]\n    ax = fig.add_subplot(211)\n    ax.plot(\n        range(1, n_init + 1),\n        s_y[:n_init],\n        style[0],\n        range(1, n_init + 2),\n        [s_c[:n_init].min()] * (n_init + 1),\n        style[1],\n        range(n_init + 1, len(s_c) + 1),\n        s_c[n_init:],\n        style[2],\n    )\n    if log_x:\n        ax.set_xscale(\"log\")\n    if log_y:\n        ax.set_yscale(\"log\")\n    if filename is not None:\n        pylab.savefig(filename, dpi=dpi, bbox_inches=\"tight\")\n    if show:\n        pylab.show()\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.print_importance","title":"<code>print_importance(threshold=0.1, print_screen=True)</code>","text":"<p>Print importance of each variable and return the results as a list.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>threshold for printing</p> <code>0.1</code> <code>print_screen</code> <code>boolean</code> <p>if <code>True</code>, values are also printed on the screen. Default is <code>True</code>.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>output</code> <code>list</code> <p>list of results</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def print_importance(self, threshold=0.1, print_screen=True) -&gt; list:\n\"\"\"Print importance of each variable and return the results as a list.\n    Args:\n        threshold (float): threshold for printing\n        print_screen (boolean): if `True`, values are also printed on the screen. Default is `True`.\n    Returns:\n        output (list): list of results\n    \"\"\"\n    output = []\n    if self.surrogate.n_theta &gt; 1:\n        theta = np.power(10, self.surrogate.theta)\n        imp = 100 * theta / np.max(theta)\n        # imp = imp[imp &gt;= threshold]\n        if self.var_name is None:\n            for i in range(len(imp)):\n                if imp[i] &gt;= threshold:\n                    if print_screen:\n                        print(\"x\", i, \": \", imp[i])\n                    output.append(\"x\" + str(i) + \": \" + str(imp[i]))\n        else:\n            var_name = [self.var_name[i] for i in range(len(imp))]\n            for i in range(len(imp)):\n                if imp[i] &gt;= threshold:\n                    if print_screen:\n                        print(var_name[i] + \": \", imp[i])\n                output.append([var_name[i], imp[i]])\n    else:\n        print(\"Importance requires more than one theta values (n_theta&gt;1).\")\n    return output\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.print_results","title":"<code>print_results(print_screen=True)</code>","text":"Print results from the run <ol> <li>min y</li> <li>min X If <code>noise == True</code>, additionally the following values are printed:</li> <li>min mean y</li> <li>min mean X</li> </ol> <p>Parameters:</p> Name Type Description Default <code>print_screen</code> <code>bool</code> <p>print results to screen</p> <code>True</code> <p>Returns:</p> Name Type Description <code>output</code> <code>list</code> <p>list of results</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def print_results(self, print_screen=True) -&gt; list[str]:\n\"\"\"Print results from the run:\n        1. min y\n        2. min X\n        If `noise == True`, additionally the following values are printed:\n        3. min mean y\n        4. min mean X\n    Args:\n        print_screen (bool, optional): print results to screen\n    Returns:\n        output (list): list of results\n    \"\"\"\n    output = []\n    if print_screen:\n        print(f\"min y: {self.min_y}\")\n    res = self.to_all_dim(self.min_X.reshape(1, -1))\n    for i in range(res.shape[1]):\n        var_name = \"x\" + str(i) if self.all_var_name is None else self.all_var_name[i]\n        if print_screen:\n            print(var_name + \":\", res[0][i])\n        output.append([var_name, res[0][i]])\n    if self.noise:\n        res = self.to_all_dim(self.min_mean_X.reshape(1, -1))\n        if print_screen:\n            print(f\"min mean y: {self.min_mean_y}\")\n        for i in range(res.shape[1]):\n            var_name = \"x\" + str(i) if self.all_var_name is None else self.all_var_name[i]\n            if print_screen:\n                print(var_name + \":\", res[0][i])\n            output.append([var_name, res[0][i]])\n    return output\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.suggest_new_X","title":"<code>suggest_new_X()</code>","text":"<p>Compute <code>n_points</code> new infill points in natural units. The optimizer searches in the ranges from <code>lower_j</code> to <code>upper_j</code>. The method <code>infill()</code> is used as the objective function.</p> <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p><code>n_points</code> infill points in natural units, each of dim k</p> Note <p>This is step (S-14a) in [bart21i].</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def suggest_new_X(self):\n\"\"\"\n    Compute `n_points` new infill points in natural units.\n    The optimizer searches in the ranges from `lower_j` to `upper_j`.\n    The method `infill()` is used as the objective function.\n\n    Returns:\n        (numpy.ndarray): `n_points` infill points in natural units, each of dim k\n\n    Note:\n        This is step (S-14a) in [bart21i].\n    \"\"\"\n    # (S-14a) Optimization on the surrogate:\n    new_X = np.zeros([self.n_points, self.k], dtype=float)\n\n    optimizer_name = self.optimizer.__name__\n\n    optimizers = {\n        \"dual_annealing\": lambda: self.optimizer(func=self.infill, bounds=self.de_bounds),\n        \"differential_evolution\": lambda: self.optimizer(\n            func=self.infill,\n            bounds=self.de_bounds,\n            maxiter=self.optimizer_control[\"max_iter\"],\n            seed=self.optimizer_control[\"seed\"],\n        ),\n        \"direct\": lambda: self.optimizer(func=self.infill, bounds=self.de_bounds, eps=1e-2),\n        \"shgo\": lambda: self.optimizer(func=self.infill, bounds=self.de_bounds),\n        \"basinhopping\": lambda: self.optimizer(func=self.infill, x0=self.min_X),\n        \"default\": lambda: self.optimizer(func=self.infill, bounds=self.de_bounds),\n    }\n\n    for i in range(self.n_points):\n        result = optimizers.get(optimizer_name, optimizers[\"default\"])()\n        new_X[i][:] = result.x\n    return new_X\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.suggest_new_X_old","title":"<code>suggest_new_X_old()</code>","text":"<p>Compute <code>n_points</code> new infill points in natural units. The optimizer searches in the ranges from <code>lower_j</code> to <code>upper_j</code>. The method <code>infill()</code> is used as the objective function.</p> <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p><code>n_points</code> infill points in natural units, each of dim k</p> Note <p>This is step (S-14a) in [bart21i].</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def suggest_new_X_old(self):\n\"\"\"\n    Compute `n_points` new infill points in natural units.\n    The optimizer searches in the ranges from `lower_j` to `upper_j`.\n    The method `infill()` is used as the objective function.\n\n    Returns:\n        (numpy.ndarray): `n_points` infill points in natural units, each of dim k\n\n    Note:\n        This is step (S-14a) in [bart21i].\n    \"\"\"\n    # (S-14a) Optimization on the surrogate:\n    new_X = np.zeros([self.n_points, self.k], dtype=float)\n\n    optimizer_name = self.optimizer.__name__\n    for i in range(self.n_points):\n        if optimizer_name == \"dual_annealing\":\n            result = self.optimizer(func=self.infill, bounds=self.de_bounds)\n        elif optimizer_name == \"differential_evolution\":\n            result = self.optimizer(\n                func=self.infill,\n                bounds=self.de_bounds,\n                maxiter=self.optimizer_control[\"max_iter\"],\n                seed=self.optimizer_control[\"seed\"],\n                # popsize=10,\n                # updating=\"deferred\"\n            )\n        elif optimizer_name == \"direct\":\n            result = self.optimizer(func=self.infill, bounds=self.de_bounds, eps=1e-2)\n        elif optimizer_name == \"shgo\":\n            result = self.optimizer(func=self.infill, bounds=self.de_bounds)\n        elif optimizer_name == \"basinhopping\":\n            result = self.optimizer(func=self.infill, x0=self.min_X)\n        else:\n            result = self.optimizer(func=self.infill, bounds=self.de_bounds)\n        new_X[i][:] = result.x\n    return new_X\n</code></pre>"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.update_stats","title":"<code>update_stats()</code>","text":"<p>Update the following stats: 1. <code>min_y</code> 2. <code>min_X</code> 3. <code>counter</code> If <code>noise</code> is <code>True</code>, additionally the following stats are computed: 1. <code>mean_X</code> 2. <code>mean_y</code> 3. <code>min_mean_y</code> 4. <code>min_mean_X</code>.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py</code> <pre><code>def update_stats(self):\n\"\"\"\n    Update the following stats: 1. `min_y` 2. `min_X` 3. `counter`\n    If `noise` is `True`, additionally the following stats are computed: 1. `mean_X`\n    2. `mean_y` 3. `min_mean_y` 4. `min_mean_X`.\n\n    \"\"\"\n    self.min_y = min(self.y)\n    self.min_X = self.X[argmin(self.y)]\n    self.counter = self.y.size\n    # Update aggregated x and y values (if noise):\n    if self.noise:\n        Z = aggregate_mean_var(X=self.X, y=self.y)\n        self.mean_X = Z[0]\n        self.mean_y = Z[1]\n        self.var_y = Z[2]\n        # X value of the best mean y value so far:\n        self.min_mean_X = self.mean_X[argmin(self.mean_y)]\n        # variance of the best mean y value so far:\n        self.min_var_y = self.var_y[argmin(self.mean_y)]\n        # best mean y value so far:\n        self.min_mean_y = self.mean_y[argmin(self.mean_y)]\n</code></pre>"},{"location":"reference/spotPython/torch/activation/","title":"activation","text":""},{"location":"reference/spotPython/torch/dataframedataset/","title":"dataframedataset","text":""},{"location":"reference/spotPython/torch/initialization/","title":"initialization","text":""},{"location":"reference/spotPython/torch/mapk/","title":"mapk","text":""},{"location":"reference/spotPython/torch/mapk/#spotPython.torch.mapk.MAPK","title":"<code>MAPK</code>","text":"<p>         Bases: <code>torchmetrics.Metric</code></p> <p>Mean Average Precision at K (MAPK) metric.</p> <p>This class inherits from the <code>Metric</code> class of the <code>torchmetrics</code> library.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>The number of top predictions to consider when calculating the metric.</p> <code>10</code> <code>dist_sync_on_step</code> <code>bool</code> <p>Whether to synchronize the metric states across processes during the forward pass.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>total</code> <code>torch.Tensor</code> <p>The cumulative sum of the metric scores across all batches.</p> <code>count</code> <code>torch.Tensor</code> <p>The number of batches processed.</p> Example <p>from spotPython.torch.mapk import MAPK import torch mapk = MAPK(k=2) target = torch.tensor([0, 1, 2, 2]) preds = torch.tensor(     [         [0.5, 0.2, 0.2],  # 0 is in top 2         [0.3, 0.4, 0.2],  # 1 is in top 2         [0.2, 0.4, 0.3],  # 2 is in top 2         [0.7, 0.2, 0.1],  # 2 isn\u2019t in top 2     ] ) mapk.update(preds, target) print(mapk.compute()) # tensor(0.6250)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/torch/mapk.py</code> <pre><code>class MAPK(torchmetrics.Metric):\n\"\"\"\n    Mean Average Precision at K (MAPK) metric.\n\n    This class inherits from the `Metric` class of the `torchmetrics` library.\n\n    Args:\n        k (int): The number of top predictions to consider when calculating the metric.\n        dist_sync_on_step (bool): Whether to synchronize the metric states across processes during the forward pass.\n\n    Attributes:\n        total (torch.Tensor): The cumulative sum of the metric scores across all batches.\n        count (torch.Tensor): The number of batches processed.\n\n    Example:\n        from spotPython.torch.mapk import MAPK\n        import torch\n        mapk = MAPK(k=2)\n        target = torch.tensor([0, 1, 2, 2])\n        preds = torch.tensor(\n            [\n                [0.5, 0.2, 0.2],  # 0 is in top 2\n                [0.3, 0.4, 0.2],  # 1 is in top 2\n                [0.2, 0.4, 0.3],  # 2 is in top 2\n                [0.7, 0.2, 0.1],  # 2 isn't in top 2\n            ]\n        )\n        mapk.update(preds, target)\n        print(mapk.compute()) # tensor(0.6250)\n    \"\"\"\n\n    def __init__(self, k=10, dist_sync_on_step=False):\n        super().__init__(dist_sync_on_step=dist_sync_on_step)\n        self.k = k\n        self.add_state(\"total\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n        self.add_state(\"count\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n\n    def update(self, predicted: torch.Tensor, actual: torch.Tensor):\n\"\"\"\n        Update the state variables with a new batch of data.\n\n        Args:\n            predicted (torch.Tensor): A 2D tensor containing the predicted scores for each class.\n            actual (torch.Tensor): A 1D tensor containing the ground truth labels.\n\n\n        Raises:\n            AssertionError: If `actual` is not a 1D tensor or if `predicted` is not a 2D tensor\n            or if `actual` and `predicted` do not have the same number of elements.\n        \"\"\"\n        assert len(actual.shape) == 1, \"actual must be a 1D tensor\"\n        assert len(predicted.shape) == 2, \"predicted must be a 2D tensor\"\n        assert actual.shape[0] == predicted.shape[0], \"actual and predicted must have the same number of elements\"\n\n        # Convert actual to list of lists\n        actual = actual.tolist()\n        actual = [[a] for a in actual]\n\n        # Convert predicted to list of lists of indices sorted by confidence score\n        _, predicted = predicted.topk(k=self.k, dim=1)\n        predicted = predicted.tolist()\n        # Code modified according to: \"Inplace update to inference tensor outside InferenceMode\n        # is not allowed. You can make a clone to get a normal tensor before doing inplace update.\"\n        score = np.mean([self.apk(p, a, self.k) for p, a in zip(predicted, actual)])\n        self.total = self.total + score\n        self.count = self.count + 1\n\n    def compute(self):\n\"\"\"\n        Compute the mean average precision at k.\n\n        Returns:\n            float: The mean average precision at k.\n        \"\"\"\n        return self.total / self.count\n\n    @staticmethod\n    def apk(predicted, actual, k=10):\n\"\"\"\n        Calculate the average precision at k for a single pair of actual and predicted labels.\n\n        Args:\n            predicted (list): A list of predicted labels.\n            actual (list): A list of ground truth labels.\n            k (int): The number of top predictions to consider.\n\n        Returns:\n            float: The average precision at k.\n        \"\"\"\n        if not actual:\n            return 0.0\n\n        if len(predicted) &gt; k:\n            predicted = predicted[:k]\n\n        score = 0.0\n        num_hits = 0.0\n\n        for i, p in enumerate(predicted):\n            if p in actual and p not in predicted[:i]:\n                num_hits += 1.0\n                score += num_hits / (i + 1.0)\n\n        return score / min(len(actual), k)\n</code></pre>"},{"location":"reference/spotPython/torch/mapk/#spotPython.torch.mapk.MAPK.apk","title":"<code>apk(predicted, actual, k=10)</code>  <code>staticmethod</code>","text":"<p>Calculate the average precision at k for a single pair of actual and predicted labels.</p> <p>Parameters:</p> Name Type Description Default <code>predicted</code> <code>list</code> <p>A list of predicted labels.</p> required <code>actual</code> <code>list</code> <p>A list of ground truth labels.</p> required <code>k</code> <code>int</code> <p>The number of top predictions to consider.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>float</code> <p>The average precision at k.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/torch/mapk.py</code> <pre><code>@staticmethod\ndef apk(predicted, actual, k=10):\n\"\"\"\n    Calculate the average precision at k for a single pair of actual and predicted labels.\n\n    Args:\n        predicted (list): A list of predicted labels.\n        actual (list): A list of ground truth labels.\n        k (int): The number of top predictions to consider.\n\n    Returns:\n        float: The average precision at k.\n    \"\"\"\n    if not actual:\n        return 0.0\n\n    if len(predicted) &gt; k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i + 1.0)\n\n    return score / min(len(actual), k)\n</code></pre>"},{"location":"reference/spotPython/torch/mapk/#spotPython.torch.mapk.MAPK.compute","title":"<code>compute()</code>","text":"<p>Compute the mean average precision at k.</p> <p>Returns:</p> Name Type Description <code>float</code> <p>The mean average precision at k.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/torch/mapk.py</code> <pre><code>def compute(self):\n\"\"\"\n    Compute the mean average precision at k.\n\n    Returns:\n        float: The mean average precision at k.\n    \"\"\"\n    return self.total / self.count\n</code></pre>"},{"location":"reference/spotPython/torch/mapk/#spotPython.torch.mapk.MAPK.update","title":"<code>update(predicted, actual)</code>","text":"<p>Update the state variables with a new batch of data.</p> <p>Parameters:</p> Name Type Description Default <code>predicted</code> <code>torch.Tensor</code> <p>A 2D tensor containing the predicted scores for each class.</p> required <code>actual</code> <code>torch.Tensor</code> <p>A 1D tensor containing the ground truth labels.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If <code>actual</code> is not a 1D tensor or if <code>predicted</code> is not a 2D tensor</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/torch/mapk.py</code> <pre><code>def update(self, predicted: torch.Tensor, actual: torch.Tensor):\n\"\"\"\n    Update the state variables with a new batch of data.\n\n    Args:\n        predicted (torch.Tensor): A 2D tensor containing the predicted scores for each class.\n        actual (torch.Tensor): A 1D tensor containing the ground truth labels.\n\n\n    Raises:\n        AssertionError: If `actual` is not a 1D tensor or if `predicted` is not a 2D tensor\n        or if `actual` and `predicted` do not have the same number of elements.\n    \"\"\"\n    assert len(actual.shape) == 1, \"actual must be a 1D tensor\"\n    assert len(predicted.shape) == 2, \"predicted must be a 2D tensor\"\n    assert actual.shape[0] == predicted.shape[0], \"actual and predicted must have the same number of elements\"\n\n    # Convert actual to list of lists\n    actual = actual.tolist()\n    actual = [[a] for a in actual]\n\n    # Convert predicted to list of lists of indices sorted by confidence score\n    _, predicted = predicted.topk(k=self.k, dim=1)\n    predicted = predicted.tolist()\n    # Code modified according to: \"Inplace update to inference tensor outside InferenceMode\n    # is not allowed. You can make a clone to get a normal tensor before doing inplace update.\"\n    score = np.mean([self.apk(p, a, self.k) for p, a in zip(predicted, actual)])\n    self.total = self.total + score\n    self.count = self.count + 1\n</code></pre>"},{"location":"reference/spotPython/torch/netcifar10/","title":"netcifar10","text":""},{"location":"reference/spotPython/torch/netcore/","title":"netcore","text":""},{"location":"reference/spotPython/torch/netfashionMNIST/","title":"netfashionMNIST","text":""},{"location":"reference/spotPython/torch/netregression/","title":"netregression","text":""},{"location":"reference/spotPython/torch/netvbdp/","title":"netvbdp","text":""},{"location":"reference/spotPython/torch/traintest/","title":"traintest","text":""},{"location":"reference/spotPython/utils/aggregate/","title":"aggregate","text":""},{"location":"reference/spotPython/utils/aggregate/#spotPython.utils.aggregate.aggregate_mean_var","title":"<code>aggregate_mean_var(X, y, sort=False)</code>","text":"<p>Aggregate array to mean.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>numpy.ndarray</code> <p>X array, shape <code>(n, k)</code>.</p> required <code>y</code> <code>numpy.ndarray</code> <p>values, shape <code>(n,)</code>.</p> required <code>sort</code> <code>bool</code> <p>Whether to sort the resulting DataFrame by the group keys.</p> <code>False</code> <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>aggregated <code>X</code> values, shape <code>(n-m, k)</code>, if <code>m</code> duplicates in <code>X</code>.</p> <code>numpy.ndarray</code> <p>aggregated (mean per group) <code>y</code> values, shape <code>(1,)</code>, if <code>m</code> duplicates in <code>X</code>.</p> <code>numpy.ndarray</code> <p>aggregated (variance per group) <code>y</code> values, shape <code>(1,)</code>, if <code>m</code> duplicates in <code>X</code>.</p> Example <p>X = np.array([[1, 2], [3, 4], [1, 2]]) y = np.array([1, 2, 3]) X_agg, y_mean, y_var = aggregate_mean_var(X, y) print(X_agg) [[1. 2.]  [3. 4.]] print(y_mean) [2. 2.] print(y_var) [1. 0.]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/aggregate.py</code> <pre><code>def aggregate_mean_var(X, y, sort=False):\n\"\"\"\n    Aggregate array to mean.\n\n    Args:\n        X (numpy.ndarray): X array, shape `(n, k)`.\n        y (numpy.ndarray): values, shape `(n,)`.\n        sort (bool): Whether to sort the resulting DataFrame by the group keys.\n\n    Returns:\n        (numpy.ndarray): aggregated `X` values, shape `(n-m, k)`, if `m` duplicates in `X`.\n        (numpy.ndarray): aggregated (mean per group) `y` values, shape `(1,)`, if `m` duplicates in `X`.\n        (numpy.ndarray): aggregated (variance per group) `y` values, shape `(1,)`, if `m` duplicates in `X`.\n\n    Example:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2]])\n        &gt;&gt;&gt; y = np.array([1, 2, 3])\n        &gt;&gt;&gt; X_agg, y_mean, y_var = aggregate_mean_var(X, y)\n        &gt;&gt;&gt; print(X_agg)\n        [[1. 2.]\n         [3. 4.]]\n        &gt;&gt;&gt; print(y_mean)\n        [2. 2.]\n        &gt;&gt;&gt; print(y_var)\n        [1. 0.]\n    \"\"\"\n    # Create a DataFrame from X and y\n    df = pd.DataFrame(X)\n    df[\"y\"] = y\n\n    # Group by all columns except 'y' and calculate the mean and variance of 'y' for each group\n    grouped = df.groupby(list(df.columns.difference([\"y\"])), as_index=False, sort=sort)\n    df_mean = grouped.mean()\n    df_var = grouped.var()\n\n    # Convert the resulting DataFrames to numpy arrays\n    mean_array = df_mean.to_numpy()\n    var_array = df_var.to_numpy()\n\n    # Split the resulting arrays into separate arrays for X and y\n    X_agg = np.delete(mean_array, -1, 1)\n    y_mean = mean_array[:, -1]\n    y_var = var_array[:, -1]\n\n    return X_agg, y_mean, y_var\n</code></pre>"},{"location":"reference/spotPython/utils/aggregate/#spotPython.utils.aggregate.get_ranks","title":"<code>get_ranks(x)</code>","text":"<p>Returns a numpy array containing ranks of numbers within an input numpy array x:</p> <p>Examples:</p> <p>get_ranks([2, 1]) [1, 0]</p> <p>get_ranks([20, 10, 100]) [1, 0, 2]</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>numpy.ndarray</code> <p>numpy array</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>ranks</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/aggregate.py</code> <pre><code>def get_ranks(x):\n\"\"\"\n    Returns a numpy array containing ranks of numbers within an input numpy array x:\n\n    Examples:\n\n    get_ranks([2, 1])\n    [1, 0]\n\n    get_ranks([20, 10, 100])\n    [1, 0, 2]\n\n    Args:\n        x (numpy.ndarray): numpy array\n\n    Returns:\n        (numpy.ndarray): ranks\n\n    \"\"\"\n    ts = x.argsort()\n    ranks = np.empty_like(ts)\n    ranks[ts] = np.arange(len(x))\n    return ranks\n</code></pre>"},{"location":"reference/spotPython/utils/classes/","title":"classes","text":""},{"location":"reference/spotPython/utils/compare/","title":"compare","text":""},{"location":"reference/spotPython/utils/compare/#spotPython.utils.compare.find_equal_in_lists","title":"<code>find_equal_in_lists(a, b)</code>","text":"<p>Find equal values in two lists.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>list</code> <p>list with a values</p> required <code>b</code> <code>list</code> <p>list with b values</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>List[int]</code> <p>list with 1 if equal, otherwise 0</p> Example <p>a = [1, 2, 3, 4, 5] b = [1, 2, 3, 4, 5] find_equal_in_lists(a, b) [1, 1, 1, 1, 1]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/compare.py</code> <pre><code>def find_equal_in_lists(a: List[int], b: List[int]) -&gt; List[int]:\n\"\"\"Find equal values in two lists.\n\n    Args:\n        a (list): list with a values\n        b (list): list with b values\n\n    Returns:\n        list: list with 1 if equal, otherwise 0\n    Example:\n        &gt;&gt;&gt; a = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; b = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; find_equal_in_lists(a, b)\n        [1, 1, 1, 1, 1]\n    \"\"\"\n    equal = [1 if a[i] == b[i] else 0 for i in range(len(a))]\n    return equal\n    return equal\n</code></pre>"},{"location":"reference/spotPython/utils/compare/#spotPython.utils.compare.selectNew","title":"<code>selectNew(A, X, tolerance=0)</code>","text":"<p>Select rows from A that are not in X.</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>numpy.ndarray</code> <p>A array with new values</p> required <code>X</code> <code>numpy.ndarray</code> <p>X array with known values</p> required <code>tolerance</code> <code>float</code> <p>tolerance value for comparison</p> <code>0</code> <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>array with unknown (new) values</p> <code>numpy.ndarray</code> <p>array with <code>True</code> if value is new, otherwise <code>False</code>.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/compare.py</code> <pre><code>def selectNew(A: np.ndarray, X: np.ndarray, tolerance: float = 0) -&gt; Tuple[np.ndarray, np.ndarray]:\n\"\"\"\n    Select rows from A that are not in X.\n\n    Args:\n        A (numpy.ndarray): A array with new values\n        X (numpy.ndarray): X array with known values\n        tolerance (float): tolerance value for comparison\n\n    Returns:\n        (numpy.ndarray): array with unknown (new) values\n        (numpy.ndarray): array with `True` if value is new, otherwise `False`.\n    \"\"\"\n    B = np.abs(A[:, None] - X)\n    ind = np.any(np.all(B &lt;= tolerance, axis=2), axis=1)\n    return A[~ind], ~ind\n</code></pre>"},{"location":"reference/spotPython/utils/convert/","title":"convert","text":""},{"location":"reference/spotPython/utils/convert/#spotPython.utils.convert.add_logical_columns","title":"<code>add_logical_columns(X, arity=2, operations=['and', 'or', 'xor'])</code>","text":"<p>Combines all features in a dataframe with each other using bitwise operations</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>pd.DataFrame</code> <p>dataframe with features</p> required <code>arity</code> <code>int</code> <p>the number of columns to combine at once</p> <code>2</code> <code>operations</code> <code>list of str</code> <p>the operations to apply. Possible values are \u2018and\u2019, \u2018or\u2019 and \u2018xor\u2019</p> <code>['and', 'or', 'xor']</code> <p>Returns:</p> Name Type Description <code>X</code> <code>pd.DataFrame</code> <p>dataframe with new features</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = pd.DataFrame({\"a\": [True, False, True], \"b\": [True, True, False], \"c\": [False, False, True]})\n&gt;&gt;&gt; add_logical_columns(X)\n    a      b      c  a_and_b  a_and_c  b_and_c  a_or_b  a_or_c  b_or_c  a_xor_b  a_xor_c  b_xor_c\n0  True   True  False     True    False    False    True    True    True    False     True     True\n1 False   True  False    False    False    False    True   False    True     True     True    False\n2  True  False   True    False     True    False    True    True    True     True    False     True\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/convert.py</code> <pre><code>def add_logical_columns(X, arity=2, operations=[\"and\", \"or\", \"xor\"]):\n\"\"\"Combines all features in a dataframe with each other using bitwise operations\n\n    Args:\n        X (pd.DataFrame): dataframe with features\n        arity (int): the number of columns to combine at once\n        operations (list of str): the operations to apply. Possible values are 'and', 'or' and 'xor'\n    Returns:\n        X (pd.DataFrame): dataframe with new features\n    Examples:\n        &gt;&gt;&gt; X = pd.DataFrame({\"a\": [True, False, True], \"b\": [True, True, False], \"c\": [False, False, True]})\n        &gt;&gt;&gt; add_logical_columns(X)\n            a      b      c  a_and_b  a_and_c  b_and_c  a_or_b  a_or_c  b_or_c  a_xor_b  a_xor_c  b_xor_c\n        0  True   True  False     True    False    False    True    True    True    False     True     True\n        1 False   True  False    False    False    False    True   False    True     True     True    False\n        2  True  False   True    False     True    False    True    True    True     True    False     True\n\n    \"\"\"\n    new_cols = []\n    # Iterate over all combinations of columns of the given arity\n    for cols in combinations(X.columns, arity):\n        # Create new columns for the specified operations\n        if \"and\" in operations:\n            and_col = X[list(cols)].apply(lambda x: x.all(), axis=1)\n            new_cols.append(and_col)\n        if \"or\" in operations:\n            or_col = X[list(cols)].apply(lambda x: x.any(), axis=1)\n            new_cols.append(or_col)\n        if \"xor\" in operations:\n            xor_col = X[list(cols)].apply(lambda x: x.sum() % 2 == 1, axis=1)\n            new_cols.append(xor_col)\n    # Join all the new columns at once\n    X = pd.concat([X] + new_cols, axis=1)\n    return X\n</code></pre>"},{"location":"reference/spotPython/utils/convert/#spotPython.utils.convert.class_for_name","title":"<code>class_for_name(module_name, class_name)</code>","text":"<p>Returns a class for a given module and class name.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>The name of the module.</p> required <code>class_name</code> <code>str</code> <p>The name of the class.</p> required <p>Returns:</p> Name Type Description <code>object</code> <code>object</code> <p>The class.</p> Example <p>from spotPython.utils.convert import class_for_name     from scipy.optimize import rosen     bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)]     shgo_class = class_for_name(\u201cscipy.optimize\u201d, \u201cshgo\u201d)     result = shgo_class(rosen, bounds)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/convert.py</code> <pre><code>def class_for_name(module_name, class_name) -&gt; object:\n\"\"\"Returns a class for a given module and class name.\n\n    Parameters:\n        module_name (str): The name of the module.\n        class_name (str): The name of the class.\n\n    Returns:\n        object: The class.\n\n    Example:\n        &gt;&gt;&gt; from spotPython.utils.convert import class_for_name\n            from scipy.optimize import rosen\n            bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)]\n            shgo_class = class_for_name(\"scipy.optimize\", \"shgo\")\n            result = shgo_class(rosen, bounds)\n    \"\"\"\n    m = importlib.import_module(module_name)\n    c = getattr(m, class_name)\n    return c\n</code></pre>"},{"location":"reference/spotPython/utils/convert/#spotPython.utils.convert.get_Xy_from_df","title":"<code>get_Xy_from_df(df, target_column)</code>","text":"<p>Get X and y from a dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>The input dataframe.</p> required <code>target_column</code> <code>str</code> <p>The name of the target column.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>The tuple (X, y).</p> Example <p>from spotPython.utils.convert import get_Xy_from_df import pandas as pd df = pd.DataFrame({\u201ca\u201d: [1, 2, 3], \u201cb\u201d: [4, 5, 6], \u201cc\u201d: [7, 8, 9]}) X, y = get_Xy_from_df(df, \u201cc\u201d)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/convert.py</code> <pre><code>def get_Xy_from_df(df, target_column) -&gt; tuple:\n\"\"\"Get X and y from a dataframe.\n    Parameters:\n        df (pandas.DataFrame): The input dataframe.\n        target_column (str): The name of the target column.\n    Returns:\n        tuple: The tuple (X, y).\n    Example:\n        &gt;&gt;&gt; from spotPython.utils.convert import get_Xy_from_df\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]})\n        &gt;&gt;&gt; X, y = get_Xy_from_df(df, \"c\")\n    \"\"\"\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    return X, y\n</code></pre>"},{"location":"reference/spotPython/utils/convert/#spotPython.utils.convert.series_to_array","title":"<code>series_to_array(series)</code>","text":"<p>Converts a pandas series to a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>pandas.Series</code> <p>The input series.</p> required <p>Returns:</p> Type Description <p>numpy.ndarray: The output array.</p> Example <p>from spotPython.utils.convert import series_to_array import pandas as pd series = pd.Series([1, 2, 3]) series_to_array(series) array([1, 2, 3])</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/convert.py</code> <pre><code>def series_to_array(series):\n\"\"\"Converts a pandas series to a numpy array.\n    Args:\n        series (pandas.Series): The input series.\n    Returns:\n        numpy.ndarray: The output array.\n    Example:\n        &gt;&gt;&gt; from spotPython.utils.convert import series_to_array\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; series = pd.Series([1, 2, 3])\n        &gt;&gt;&gt; series_to_array(series)\n        array([1, 2, 3])\n    \"\"\"\n    if isinstance(series, np.ndarray):\n        return series\n    else:\n        return series.to_numpy()\n</code></pre>"},{"location":"reference/spotPython/utils/device/","title":"device","text":""},{"location":"reference/spotPython/utils/device/#spotPython.utils.device.getDevice","title":"<code>getDevice(device=None)</code>","text":"<p>Get cpu, gpu or mps device for training.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>str</code> <p>Device for training. If None or \u201cauto\u201d the device is selected automatically.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>device</code> <code>str</code> <p>Device for training.</p> <code>Example</code> <p>from spotPython.utils.device import getDevice getDevice() \u2018cuda:0\u2019</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/device.py</code> <pre><code>def getDevice(device=None):\n\"\"\"Get cpu, gpu or mps device for training.\n    Args:\n        device (str): Device for training. If None or \"auto\" the device is selected automatically.\n    Returns:\n        device (str): Device for training.\n        Example:\n            &gt;&gt;&gt; from spotPython.utils.device import getDevice\n            &gt;&gt;&gt; getDevice()\n            'cuda:0'\n    \"\"\"\n    if device is None or device == \"auto\":\n        device = \"cpu\"\n        if torch.cuda.is_available():\n            device = \"cuda:0\"\n        elif torch.backends.mps.is_available():\n            device = \"mps\"\n    return device\n</code></pre>"},{"location":"reference/spotPython/utils/eda/","title":"eda","text":""},{"location":"reference/spotPython/utils/eda/#spotPython.utils.eda.gen_design_table","title":"<code>gen_design_table(fun_control, spot=None, tablefmt='github')</code>","text":"<p>Generates a table with the design variables and their bounds.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>A dictionary with function design variables.</p> required <code>spot</code> <code>object</code> <p>A spot object. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A table with the design variables, their default values, and their bounds. If a spot object is provided, the table will also include the value and the importance of each hyperparameter.</p> <code>str</code> <p>Use the <code>print</code> function to display the table.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/eda.py</code> <pre><code>def gen_design_table(fun_control: dict, spot: object = None, tablefmt=\"github\") -&gt; str:\n\"\"\"Generates a table with the design variables and their bounds.\n    Args:\n        fun_control (dict): A dictionary with function design variables.\n        spot (object): A spot object. Defaults to None.\n    Returns:\n        str: A table with the design variables, their default values, and their bounds.\n            If a spot object is provided,\n            the table will also include the value\n            and the importance of each hyperparameter.\n        Use the `print` function to display the table.\n    \"\"\"\n    default_values = get_default_values(fun_control)\n    defaults = list(default_values.values())\n    if spot is None:\n        tab = tabulate(\n            {\n                \"name\": get_var_name(fun_control),\n                \"type\": get_var_type(fun_control),\n                \"default\": defaults,\n                \"lower\": get_bound_values(fun_control, \"lower\", as_list=True),\n                \"upper\": get_bound_values(fun_control, \"upper\", as_list=True),\n                \"transform\": get_transform(fun_control),\n            },\n            headers=\"keys\",\n            tablefmt=tablefmt,\n        )\n    else:\n        res = spot.print_results(print_screen=False)\n        tuned = [item[1] for item in res]\n        # imp = spot.print_importance(threshold=0.0, print_screen=False)\n        # importance = [item[1] for item in imp]\n        importance = spot.get_importance()\n        stars = get_stars(importance)\n        tab = tabulate(\n            {\n                \"name\": get_var_name(fun_control),\n                \"type\": get_var_type(fun_control),\n                \"default\": defaults,\n                \"lower\": get_bound_values(fun_control, \"lower\", as_list=True),\n                \"upper\": get_bound_values(fun_control, \"upper\", as_list=True),\n                \"tuned\": tuned,\n                \"transform\": get_transform(fun_control),\n                \"importance\": importance,\n                \"stars\": stars,\n            },\n            headers=\"keys\",\n            numalign=\"right\",\n            floatfmt=(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \".2f\"),\n            tablefmt=tablefmt,\n        )\n    return tab\n</code></pre>"},{"location":"reference/spotPython/utils/eda/#spotPython.utils.eda.generate_config_id","title":"<code>generate_config_id(config)</code>","text":"<p>Generates a unique id for a configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>A dictionary with the configuration.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>A unique id for the configuration.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/eda.py</code> <pre><code>def generate_config_id(config):\n\"\"\"Generates a unique id for a configuration.\n    Args:\n        config (dict): A dictionary with the configuration.\n    Returns:\n        str: A unique id for the configuration.\n    \"\"\"\n    config_id = \"\"\n    for key in config:\n        config_id += str(config[key]) + \"_\"\n    return config_id[:-1]\n</code></pre>"},{"location":"reference/spotPython/utils/eda/#spotPython.utils.eda.get_stars","title":"<code>get_stars(input_list)</code>","text":"<p>Converts a list of values to a list of stars, which can be used to     visualize the importance of a variable.</p> <p>Parameters:</p> Name Type Description Default <code>input_list</code> <code>list</code> <p>A list of values.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of strings.</p> Example <p>from spotPython.utils.eda import convert_list get_stars([100, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]) [***, \u2018\u2019, \u2018\u2019, \u2018\u2019, \u2018\u2019, \u2018\u2019, \u2018\u2019, \u2018\u2019, \u2018\u2019]</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/eda.py</code> <pre><code>def get_stars(input_list) -&gt; list:\n\"\"\"Converts a list of values to a list of stars, which can be used to\n        visualize the importance of a variable.\n    Args:\n        input_list (list): A list of values.\n    Returns:\n        list: A list of strings.\n    Example:\n        &gt;&gt;&gt; from spotPython.utils.eda import convert_list\n        &gt;&gt;&gt; get_stars([100, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n        [***, '', '', '', '', '', '', '', '']\n    \"\"\"\n    output_list = []\n    for value in input_list:\n        if value &gt; 95:\n            output_list.append(\"***\")\n        elif value &gt; 50:\n            output_list.append(\"**\")\n        elif value &gt; 1:\n            output_list.append(\"*\")\n        elif value &gt; 0.1:\n            output_list.append(\".\")\n        else:\n            output_list.append(\"\")\n    return output_list\n</code></pre>"},{"location":"reference/spotPython/utils/eda/#spotPython.utils.eda.visualize_activations","title":"<code>visualize_activations(net, device='cpu', color='C0')</code>","text":"<p>Visualizes the activations of a neural network. Code is based on: PyTorch Lightning TUTORIAL 2: ACTIVATION FUNCTIONS, Author: Phillip Lippe, License: CC BY-SA.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>object</code> <p>A neural network.</p> required <code>device</code> <code>str</code> <p>The device to use. Defaults to \u201ccpu\u201d.</p> <code>'cpu'</code> <code>color</code> <code>str</code> <p>The color to use. Defaults to \u201cC0\u201d.</p> <code>'C0'</code> Example <p>from spotPython.hyperparameters.values import get_one_config_from_X X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1)) config = get_one_config_from_X(X, fun_control) model = fun_control\u201ccore_model\u201d visualize_activations(model, device=\u201dcpu\u201d, color=f\u201dC{0}\u201d)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/eda.py</code> <pre><code>def visualize_activations(net, device=\"cpu\", color=\"C0\"):\n\"\"\"Visualizes the activations of a neural network.\n    Code is based on:\n    PyTorch Lightning TUTORIAL 2: ACTIVATION FUNCTIONS,\n    Author: Phillip Lippe,\n    License: CC BY-SA.\n\n    Args:\n        net (object): A neural network.\n        device (str, optional): The device to use. Defaults to \"cpu\".\n        color (str, optional): The color to use. Defaults to \"C0\".\n    Example:\n        &gt;&gt;&gt; from spotPython.hyperparameters.values import get_one_config_from_X\n        &gt;&gt;&gt; X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n        &gt;&gt;&gt; config = get_one_config_from_X(X, fun_control)\n        &gt;&gt;&gt; model = fun_control[\"core_model\"](**config, _L_in=64, _L_out=11)\n        &gt;&gt;&gt; visualize_activations(model, device=\"cpu\", color=f\"C{0}\")\n    \"\"\"\n    activations = {}\n    net.eval()\n    # Create an instance of CSVDataset\n    dataset = CSVDataset(csv_file=\"./data/VBDP/train.csv\", train=True)\n    # Set batch size for DataLoader\n    batch_size = 128\n    # Create DataLoader\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    # for batch in dataloader:\n    #     inputs, targets = batch\n    # small_loader = data.DataLoader(train_set, batch_size=1024)\n    inputs, _ = next(iter(dataloader))\n    with torch.no_grad():\n        layer_index = 0\n        inputs = inputs.to(device)\n        inputs = inputs.view(inputs.size(0), -1)\n        # We need to manually loop through the layers to save all activations\n        for layer_index, layer in enumerate(net.layers[:-1]):\n            inputs = layer(inputs)\n            activations[layer_index] = inputs.view(-1).cpu().numpy()\n\n    # Plotting\n    columns = 4\n    rows = math.ceil(len(activations) / columns)\n    fig, ax = plt.subplots(rows, columns, figsize=(columns * 2.7, rows * 2.5))\n    fig_index = 0\n    for key in activations:\n        key_ax = ax[fig_index // columns][fig_index % columns]\n        sns.histplot(data=activations[key], bins=50, ax=key_ax, color=color, kde=True, stat=\"density\")\n        key_ax.set_title(f\"Layer {key} - {net.layers[key].__class__.__name__}\")\n        fig_index += 1\n    fig.suptitle(f\"Activation distribution for activation function {net.hparams.act_fn}\", fontsize=14)\n    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n    plt.show()\n    plt.close()\n</code></pre>"},{"location":"reference/spotPython/utils/file/","title":"file","text":""},{"location":"reference/spotPython/utils/file/#spotPython.utils.file.get_experiment_name","title":"<code>get_experiment_name(prefix='00')</code>","text":"<p>Returns a unique experiment name with a given prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix for the experiment name. Defaults to \u201c00\u201d.</p> <code>'00'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Unique experiment name.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.utils.file import get_experiment_name\n&gt;&gt;&gt; get_experiment_name(prefix=\"00\")\n00_ubuntu_2021-08-31_14-30-00\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/file.py</code> <pre><code>def get_experiment_name(prefix: str = \"00\") -&gt; str:\n\"\"\"Returns a unique experiment name with a given prefix.\n    Args:\n        prefix (str, optional): Prefix for the experiment name. Defaults to \"00\".\n    Returns:\n        str: Unique experiment name.\n    Examples:\n        &gt;&gt;&gt; from spotPython.utils.file import get_experiment_name\n        &gt;&gt;&gt; get_experiment_name(prefix=\"00\")\n        00_ubuntu_2021-08-31_14-30-00\n    \"\"\"\n    start_time = datetime.now(tzlocal())\n    HOSTNAME = socket.gethostname().split(\".\")[0]\n    experiment_name = prefix + \"_\" + HOSTNAME + \"_\" + str(start_time).split(\".\", 1)[0].replace(\" \", \"_\")\n    experiment_name = experiment_name.replace(\":\", \"-\")\n    return experiment_name\n</code></pre>"},{"location":"reference/spotPython/utils/file/#spotPython.utils.file.get_spot_tensorboard_path","title":"<code>get_spot_tensorboard_path(experiment_name)</code>","text":"<p>Get the path to the spot tensorboard files.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> <p>The name of the experiment.</p> required <p>Returns:</p> Name Type Description <code>spot_tensorboard_path</code> <code>str</code> <p>The path to the folder where the spot tensorboard files are saved.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/file.py</code> <pre><code>def get_spot_tensorboard_path(experiment_name):\n\"\"\"Get the path to the spot tensorboard files.\n    Args:\n        experiment_name (str): The name of the experiment.\n    Returns:\n        spot_tensorboard_path (str): The path to the folder where the spot tensorboard files are saved.\n    \"\"\"\n    spot_tensorboard_path = os.environ.get(\"PATH_TENSORBOARD\", \"runs/spot_logs/\")\n    spot_tensorboard_path = os.path.join(spot_tensorboard_path, experiment_name)\n    return spot_tensorboard_path\n</code></pre>"},{"location":"reference/spotPython/utils/file/#spotPython.utils.file.get_tensorboard_path","title":"<code>get_tensorboard_path(fun_control)</code>","text":"<p>Get the path to the tensorboard files.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>The function control dictionary.</p> required <p>Returns:</p> Name Type Description <code>tensorboard_path</code> <code>str</code> <p>The path to the folder where the tensorboard files are saved.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/file.py</code> <pre><code>def get_tensorboard_path(fun_control):\n\"\"\"Get the path to the tensorboard files.\n    Args:\n        fun_control (dict): The function control dictionary.\n    Returns:\n        tensorboard_path (str): The path to the folder where the tensorboard files are saved.\n    \"\"\"\n    return fun_control[\"TENSORBOARD_PATH\"]\n</code></pre>"},{"location":"reference/spotPython/utils/file/#spotPython.utils.file.load_data","title":"<code>load_data(data_dir='./data')</code>","text":"<p>Loads the CIFAR10 dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>Directory to save the data. Defaults to \u201c./data\u201d.</p> <code>'./data'</code> <p>Returns:</p> Name Type Description <code>trainset</code> <code>torchvision.datasets.CIFAR10</code> <p>Training dataset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.utils.file import load_data\n&gt;&gt;&gt; trainset = load_data(data_dir=\"./data\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/file.py</code> <pre><code>def load_data(data_dir=\"./data\"):\n\"\"\"Loads the CIFAR10 dataset.\n    Args:\n        data_dir (str, optional): Directory to save the data. Defaults to \"./data\".\n    Returns:\n        trainset (torchvision.datasets.CIFAR10): Training dataset.\n    Examples:\n        &gt;&gt;&gt; from spotPython.utils.file import load_data\n        &gt;&gt;&gt; trainset = load_data(data_dir=\"./data\")\n\n    \"\"\"\n    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n    trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n\n    testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n\n    return trainset, testset\n</code></pre>"},{"location":"reference/spotPython/utils/file/#spotPython.utils.file.load_pickle","title":"<code>load_pickle(filename)</code>","text":"<p>Loads a pickle file.     Add .pkl to the filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Name of the pickle file.</p> required <p>Returns:</p> Name Type Description <code>object</code> <p>Loaded object.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.utils.file import load_pickle\n&gt;&gt;&gt; obj = load_pickle(filename=\"obj.pkl\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/file.py</code> <pre><code>def load_pickle(filename: str):\n\"\"\"Loads a pickle file.\n        Add .pkl to the filename.\n    Args:\n        filename (str): Name of the pickle file.\n    Returns:\n        object: Loaded object.\n    Examples:\n        &gt;&gt;&gt; from spotPython.utils.file import load_pickle\n        &gt;&gt;&gt; obj = load_pickle(filename=\"obj.pkl\")\n    \"\"\"\n    filename = filename + \".pkl\"\n    with open(filename, \"rb\") as f:\n        obj = pickle.load(f)\n    return obj\n</code></pre>"},{"location":"reference/spotPython/utils/file/#spotPython.utils.file.save_pickle","title":"<code>save_pickle(obj, filename)</code>","text":"<p>Saves an object as a pickle file.     Add .pkl to the filename.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to be saved.</p> required <code>filename</code> <code>str</code> <p>Name of the pickle file.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spotPython.utils.file import save_pickle\n&gt;&gt;&gt; save_pickle(obj, filename=\"obj.pkl\")\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/file.py</code> <pre><code>def save_pickle(obj, filename: str):\n\"\"\"Saves an object as a pickle file.\n        Add .pkl to the filename.\n    Args:\n        obj (object): Object to be saved.\n        filename (str): Name of the pickle file.\n    Examples:\n        &gt;&gt;&gt; from spotPython.utils.file import save_pickle\n        &gt;&gt;&gt; save_pickle(obj, filename=\"obj.pkl\")\n    \"\"\"\n    filename = filename + \".pkl\"\n    with open(filename, \"wb\") as f:\n        pickle.dump(obj, f)\n</code></pre>"},{"location":"reference/spotPython/utils/init/","title":"init","text":""},{"location":"reference/spotPython/utils/init/#spotPython.utils.init.check_and_create_dir","title":"<code>check_and_create_dir(path)</code>","text":"<p>Check if the path exists and create it if it does not.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the directory.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/init.py</code> <pre><code>def check_and_create_dir(path):\n\"\"\"Check if the path exists and create it if it does not.\n    Args:\n        path (str): Path to the directory.\n    Returns:\n        None\n    \"\"\"\n    if not isinstance(path, str):\n        raise Exception(\"path must be a string\")\n    if not os.path.exists(path):\n        os.makedirs(path)\n</code></pre>"},{"location":"reference/spotPython/utils/init/#spotPython.utils.init.fun_control_init","title":"<code>fun_control_init(task='classification', _L_in=None, _L_out=None, enable_progress_bar=False, spot_tensorboard_path=None, TENSORBOARD_CLEAN=False, num_workers=0, device=None, seed=1234, sigma=0.0)</code>","text":"<p>Initialize fun_control dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>The task to perform. It can be either \u201cclassification\u201d or \u201cregression\u201d.</p> <code>'classification'</code> <code>_L_in</code> <code>int</code> <p>The number of input features.</p> <code>None</code> <code>_L_out</code> <code>int</code> <p>The number of output features.</p> <code>None</code> <code>enable_progress_bar</code> <code>bool</code> <p>Whether to enable the progress bar or not.</p> <code>False</code> <code>spot_tensorboard_path</code> <code>str</code> <p>The path to the folder where the spot tensorboard files are saved.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>The number of workers to use for the data loading.</p> <code>0</code> <code>device</code> <code>str</code> <p>The device to use for the training. It can be either \u201ccpu\u201d, \u201cmps\u201d, or \u201ccuda\u201d.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>fun_control</code> <code>dict</code> <p>A dictionary containing the information about the core model, loss function, metrics,</p> <p>and the hyperparameters.</p> Example <p>fun_control = fun_control_init(_L_in=64, _L_out=11, num_workers=0, device=None) fun_control {\u2018CHECKPOINT_PATH\u2019: \u2018saved_models/\u2019,         \u2018DATASET_PATH\u2019: \u2018data/\u2019,         \u2018RESULTS_PATH\u2019: \u2018results/\u2019,         \u2018TENSORBOARD_PATH\u2019: \u2018runs/\u2019,         \u2018_L_in\u2019: 64,         \u2018_L_out\u2019: 11,         \u2018data\u2019: None,         \u2018data_dir\u2019: \u2018./data\u2019,         \u2018device\u2019: None,         \u2018enable_progress_bar\u2019: False,         \u2018eval\u2019: None,         \u2018k_folds\u2019: None,         \u2018loss_function\u2019: None,         \u2018metric_river\u2019: None,         \u2018metric_sklearn\u2019: None,         \u2018metric_torch\u2019: None,         \u2018metric_params\u2019: {},         \u2018model_dict\u2019: {},         \u2018n_samples\u2019: None,         \u2018num_workers\u2019: 0,         \u2018optimizer\u2019: None,         \u2018path\u2019: None,         \u2018prep_model\u2019: None,         \u2018save_model\u2019: False,         \u2018seed\u2019: 1234,         \u2018show_batch_interval\u2019: 1000000,         \u2018shuffle\u2019: None,         \u2018sigma\u2019: 0.0,         \u2018target_column\u2019: None,         \u2018train\u2019: None,         \u2018test\u2019: None,         \u2018task\u2019: \u2018classification\u2019,         \u2018tensorboard_path\u2019: None,         \u2018weights\u2019: 1.0,         \u2018writer\u2019: None}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/init.py</code> <pre><code>def fun_control_init(\n    task=\"classification\",\n    _L_in=None,\n    _L_out=None,\n    enable_progress_bar=False,\n    spot_tensorboard_path=None,\n    TENSORBOARD_CLEAN=False,\n    num_workers=0,\n    device=None,\n    seed=1234,\n    sigma=0.0,\n):\n\"\"\"Initialize fun_control dictionary.\n    Args:\n        task (str): The task to perform. It can be either \"classification\" or \"regression\".\n        _L_in (int): The number of input features.\n        _L_out (int): The number of output features.\n        enable_progress_bar (bool): Whether to enable the progress bar or not.\n        spot_tensorboard_path (str): The path to the folder where the spot tensorboard files are saved.\n        If None, no spot tensorboard files are saved.\n        num_workers (int): The number of workers to use for the data loading.\n        device (str): The device to use for the training. It can be either \"cpu\", \"mps\", or \"cuda\".\n    Returns:\n        fun_control (dict): A dictionary containing the information about the core model, loss function, metrics,\n        and the hyperparameters.\n    Example:\n        &gt;&gt;&gt; fun_control = fun_control_init(_L_in=64, _L_out=11, num_workers=0, device=None)\n        &gt;&gt;&gt; fun_control\n        &gt;&gt;&gt; {'CHECKPOINT_PATH': 'saved_models/',\n                'DATASET_PATH': 'data/',\n                'RESULTS_PATH': 'results/',\n                'TENSORBOARD_PATH': 'runs/',\n                '_L_in': 64,\n                '_L_out': 11,\n                'data': None,\n                'data_dir': './data',\n                'device': None,\n                'enable_progress_bar': False,\n                'eval': None,\n                'k_folds': None,\n                'loss_function': None,\n                'metric_river': None,\n                'metric_sklearn': None,\n                'metric_torch': None,\n                'metric_params': {},\n                'model_dict': {},\n                'n_samples': None,\n                'num_workers': 0,\n                'optimizer': None,\n                'path': None,\n                'prep_model': None,\n                'save_model': False,\n                'seed': 1234,\n                'show_batch_interval': 1000000,\n                'shuffle': None,\n                'sigma': 0.0,\n                'target_column': None,\n                'train': None,\n                'test': None,\n                'task': 'classification',\n                'tensorboard_path': None,\n                'weights': 1.0,\n                'writer': None}\n    \"\"\"\n    # Setting the seed\n    L.seed_everything(42)\n\n    # Path to the folder where the pretrained models are saved\n    CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/\")\n    os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n    # Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n    DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n    os.makedirs(DATASET_PATH, exist_ok=True)\n    # Path to the folder where the results (plots, csv, etc.) are saved\n    RESULTS_PATH = os.environ.get(\"PATH_RESULTS\", \"results/\")\n    os.makedirs(RESULTS_PATH, exist_ok=True)\n    # Path to the folder where the tensorboard files are saved\n    TENSORBOARD_PATH = os.environ.get(\"PATH_TENSORBOARD\", \"runs/\")\n    if TENSORBOARD_CLEAN:\n        # if the folder \"runs\"  exists, move it to \"runs_Y_M_D_H_M_S\" to avoid overwriting old tensorboard files\n        if os.path.exists(TENSORBOARD_PATH):\n            now = datetime.datetime.now()\n            os.makedirs(\"runs_OLD\", exist_ok=True)\n            # use [:-1] to remove \"/\" from the end of the path\n            TENSORBOARD_PATH_OLD = \"runs_OLD/\" + TENSORBOARD_PATH[:-1] + \"_\" + now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n            os.rename(TENSORBOARD_PATH[:-1], TENSORBOARD_PATH_OLD)\n    os.makedirs(TENSORBOARD_PATH, exist_ok=True)\n    if spot_tensorboard_path is not None:\n        os.makedirs(spot_tensorboard_path, exist_ok=True)\n        spot_writer = SummaryWriter(spot_tensorboard_path)\n    else:\n        spot_writer = None\n\n    if not os.path.exists(\"./figures\"):\n        os.makedirs(\"./figures\")\n\n    fun_control = {\n        \"CHECKPOINT_PATH\": CHECKPOINT_PATH,\n        \"DATASET_PATH\": DATASET_PATH,\n        \"RESULTS_PATH\": RESULTS_PATH,\n        \"TENSORBOARD_PATH\": TENSORBOARD_PATH,\n        \"_L_in\": _L_in,\n        \"_L_out\": _L_out,\n        \"data\": None,\n        \"data_dir\": \"./data\",\n        \"device\": device,\n        \"enable_progress_bar\": enable_progress_bar,\n        \"eval\": None,\n        \"k_folds\": 3,\n        \"loss_function\": None,\n        \"metric_river\": None,\n        \"metric_sklearn\": None,\n        \"metric_torch\": None,\n        \"metric_params\": {},\n        \"model_dict\": {},\n        \"n_samples\": None,\n        \"num_workers\": num_workers,\n        \"optimizer\": None,\n        \"path\": None,\n        \"prep_model\": None,\n        \"save_model\": False,\n        \"seed\": seed,\n        \"show_batch_interval\": 1_000_000,\n        \"shuffle\": None,\n        \"sigma\": sigma,\n        \"target_column\": None,\n        \"train\": None,\n        \"test\": None,\n        \"task\": task,\n        \"spot_tensorboard_path\": spot_tensorboard_path,\n        \"weights\": 1.0,\n        \"spot_writer\": spot_writer,\n    }\n    return fun_control\n</code></pre>"},{"location":"reference/spotPython/utils/metrics/","title":"metrics","text":""},{"location":"reference/spotPython/utils/metrics/#spotPython.utils.metrics.apk","title":"<code>apk(actual, predicted, k=10)</code>","text":"<p>Computes the average precision at k. This function computes the average precision at k between two lists of items. Parameters</p> list <p>A list of elements that are to be predicted (order doesn\u2019t matter)</p> list <p>A list of predicted elements (order does matter)</p> int, optional <p>The maximum number of predicted elements</p>"},{"location":"reference/spotPython/utils/metrics/#spotPython.utils.metrics.apk--returns","title":"Returns","text":"double <p>The average precision at k over the input lists</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/metrics.py</code> <pre><code>def apk(actual, predicted, k=10):\n\"\"\"\n    Computes the average precision at k.\n    This function computes the average precision at k between two lists of\n    items.\n    Parameters\n    ----------\n    actual : list\n             A list of elements that are to be predicted (order doesn't matter)\n    predicted : list\n                A list of predicted elements (order does matter)\n    k : int, optional\n        The maximum number of predicted elements\n    Returns\n    -------\n    score : double\n            The average precision at k over the input lists\n    \"\"\"\n    if len(predicted) &gt; k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i + 1.0)\n\n    if not actual:\n        return 0.0\n\n    return score / min(len(actual), k)\n</code></pre>"},{"location":"reference/spotPython/utils/metrics/#spotPython.utils.metrics.mapk","title":"<code>mapk(actual, predicted, k=10)</code>","text":"<p>Computes the mean average precision at k. This function computes the mean average precision at k between two lists of lists of items. Parameters</p> list <p>A list of lists of elements that are to be predicted (order doesn\u2019t matter in the lists)</p> list <p>A list of lists of predicted elements (order matters in the lists)</p> int, optional <p>The maximum number of predicted elements</p>"},{"location":"reference/spotPython/utils/metrics/#spotPython.utils.metrics.mapk--returns","title":"Returns","text":"double <p>The mean average precision at k over the input lists</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/metrics.py</code> <pre><code>def mapk(actual, predicted, k=10):\n\"\"\"\n    Computes the mean average precision at k.\n    This function computes the mean average precision at k between two lists\n    of lists of items.\n    Parameters\n    ----------\n    actual : list\n             A list of lists of elements that are to be predicted\n             (order doesn't matter in the lists)\n    predicted : list\n                A list of lists of predicted elements\n                (order matters in the lists)\n    k : int, optional\n        The maximum number of predicted elements\n    Returns\n    -------\n    score : double\n            The mean average precision at k over the input lists\n    \"\"\"\n    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n</code></pre>"},{"location":"reference/spotPython/utils/metrics/#spotPython.utils.metrics.mapk_score","title":"<code>mapk_score(y_true, y_pred, k=3)</code>","text":"<p>Wrapper for mapk func using numpy arrays  Args:         y_true (np.array): array of true values         y_pred (np.array): array of predicted values         k (int): number of predictions</p> <p>Returns:</p> Name Type Description <code>score</code> <code>float</code> <p>mean average precision at k</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; y_true = np.array([0, 1, 2, 2])\n&gt;&gt;&gt; y_pred = np.array([[0.5, 0.2, 0.2],  # 0 is in top 2\n         [0.3, 0.4, 0.2],  # 1 is in top 2\n         [0.2, 0.4, 0.3],  # 2 is in top 2\n         [0.7, 0.2, 0.1]]) # 2 isn't in top 2\n&gt;&gt;&gt; mapk_score(y_true, y_pred, k=1)\n0.25\n&gt;&gt;&gt; mapk_score(y_true, y_pred, k=2)\n0.375\n&gt;&gt;&gt; mapk_score(y_true, y_pred, k=3)\n0.4583333333333333\n&gt;&gt;&gt; mapk_score(y_true, y_pred, k=4)\n0.4583333333333333\n</code></pre> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/metrics.py</code> <pre><code>def mapk_score(y_true, y_pred, k=3):\n\"\"\"Wrapper for mapk func using numpy arrays\n     Args:\n            y_true (np.array): array of true values\n            y_pred (np.array): array of predicted values\n            k (int): number of predictions\n    Returns:\n            score (float): mean average precision at k\n    Examples:\n            &gt;&gt;&gt; y_true = np.array([0, 1, 2, 2])\n            &gt;&gt;&gt; y_pred = np.array([[0.5, 0.2, 0.2],  # 0 is in top 2\n                     [0.3, 0.4, 0.2],  # 1 is in top 2\n                     [0.2, 0.4, 0.3],  # 2 is in top 2\n                     [0.7, 0.2, 0.1]]) # 2 isn't in top 2\n            &gt;&gt;&gt; mapk_score(y_true, y_pred, k=1)\n            0.25\n            &gt;&gt;&gt; mapk_score(y_true, y_pred, k=2)\n            0.375\n            &gt;&gt;&gt; mapk_score(y_true, y_pred, k=3)\n            0.4583333333333333\n            &gt;&gt;&gt; mapk_score(y_true, y_pred, k=4)\n            0.4583333333333333\n    \"\"\"\n    y_true = series_to_array(y_true)\n    sorted_prediction_ids = np.argsort(-y_pred, axis=1)\n    top_k_prediction_ids = sorted_prediction_ids[:, :k]\n    score = mapk(y_true.reshape(-1, 1), top_k_prediction_ids, k=k)\n    return score\n</code></pre>"},{"location":"reference/spotPython/utils/metrics/#spotPython.utils.metrics.mapk_scorer","title":"<code>mapk_scorer(estimator, X, y)</code>","text":"<p>Scorer for mean average precision at k. This function computes the mean average precision at k between two lists of lists of items. Parameters</p> sklearn estimator <p>The estimator to be used for prediction.</p> array-like of shape (n_samples, n_features) <p>The input samples.</p> array-like of shape (n_samples,) <p>The target values.</p>"},{"location":"reference/spotPython/utils/metrics/#spotPython.utils.metrics.mapk_scorer--returns","title":"Returns","text":"double <p>The mean average precision at k over the input lists</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/metrics.py</code> <pre><code>def mapk_scorer(estimator, X, y):\n\"\"\"\n    Scorer for mean average precision at k.\n    This function computes the mean average precision at k between two lists\n    of lists of items.\n    Parameters\n    ----------\n    estimator : sklearn estimator\n                The estimator to be used for prediction.\n    X : array-like of shape (n_samples, n_features)\n        The input samples.\n    y : array-like of shape (n_samples,)\n        The target values.\n    Returns\n    -------\n    score : double\n            The mean average precision at k over the input lists\n    \"\"\"\n    y_pred = estimator.predict_proba(X)\n    score = mapk_score(y, y_pred, k=3)\n    return score\n</code></pre>"},{"location":"reference/spotPython/utils/progress/","title":"progress","text":""},{"location":"reference/spotPython/utils/progress/#spotPython.utils.progress.progress_bar","title":"<code>progress_bar(progress, bar_length=10, message='spotPython tuning:', y=None)</code>","text":"<p>Displays or updates a console progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>progress</code> <code>float</code> <p>a float between 0 and 1. Any int will be converted to a float. A value under 0 represents a halt. A value at 1 or bigger represents 100%.</p> required <code>bar_length</code> <code>int</code> <p>length of the progress bar</p> <code>10</code> <code>message</code> <code>str</code> <p>message text to display</p> <code>'spotPython tuning:'</code> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/progress.py</code> <pre><code>def progress_bar(progress: float, bar_length: int = 10, message: str = \"spotPython tuning:\", y=None) -&gt; None:\n\"\"\"\n    Displays or updates a console progress bar.\n\n    Args:\n        progress (float): a float between 0 and 1. Any int will be converted to a float.\n            A value under 0 represents a halt.\n            A value at 1 or bigger represents 100%.\n        bar_length (int): length of the progress bar\n        message (str): message text to display\n    \"\"\"\n    status = \"\"\n    if y is not None:\n        message = f\"{message} {y}\"\n    if progress &lt; 0:\n        progress = 0\n        status = \"Halt...\\r\\n\"\n    elif progress &gt;= 1:\n        progress = 1\n        status = \"Done...\\r\\n\"\n    block = int(round(bar_length * progress))\n    text = f\"{message} [{'#' * block + '-' * (bar_length - block)}] {progress * 100:.2f}% {status}\\r\\n\"\n    stdout.write(text)\n    stdout.flush()\n</code></pre>"},{"location":"reference/spotPython/utils/repair/","title":"repair","text":""},{"location":"reference/spotPython/utils/repair/#spotPython.utils.repair.remove_nan","title":"<code>remove_nan(X, y)</code>","text":"<p>Remove rows from X and y where y contains NaN values.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>numpy.ndarray</code> <p>X array</p> required <code>y</code> <code>numpy.ndarray</code> <p>y array</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray, np.ndarray]</code> <p>Tuple[numpy.ndarray, numpy.ndarray]: X and y arrays with rows containing NaN values in y removed</p> Example <p>X = np.array([[1, 2], [3, 4], [5, 6]]) y = np.array([1, np.nan, 2]) remove_nan(X, y) (array([[1, 2],         [5, 6]]), array([1., 2.]))</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/repair.py</code> <pre><code>def remove_nan(X: np.ndarray, y: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n\"\"\"\n    Remove rows from X and y where y contains NaN values.\n\n    Args:\n        X (numpy.ndarray): X array\n        y (numpy.ndarray): y array\n\n    Returns:\n        Tuple[numpy.ndarray, numpy.ndarray]: X and y arrays with rows containing NaN values in y removed\n\n    Example:\n        &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])\n        &gt;&gt;&gt; y = np.array([1, np.nan, 2])\n        &gt;&gt;&gt; remove_nan(X, y)\n        (array([[1, 2],\n                [5, 6]]), array([1., 2.]))\n    \"\"\"\n    ind = np.isfinite(y)\n    y = y[ind]\n    X = X[ind, :]\n    return X, y\n</code></pre>"},{"location":"reference/spotPython/utils/repair/#spotPython.utils.repair.repair_non_numeric","title":"<code>repair_non_numeric(X, var_type)</code>","text":"<p>Round non-numeric values to integers. This applies to all variables except for \u201cnum\u201d and \u201cfloat\u201d.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>numpy.ndarray</code> <p>X array</p> required <code>var_type</code> <code>list</code> <p>list with type information</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>numpy.ndarray: X array with non-numeric values rounded to integers</p> Example <p>X = np.array([[1.2, 2.3], [3.4, 4.5]]) var_type = [\u201cnum\u201d, \u201cfactor\u201d] repair_non_numeric(X, var_type) array([[1., 2.],        [3., 4.]])</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/repair.py</code> <pre><code>def repair_non_numeric(X: np.ndarray, var_type: List[str]) -&gt; np.ndarray:\n\"\"\"\n    Round non-numeric values to integers.\n    This applies to all variables except for \"num\" and \"float\".\n\n    Args:\n        X (numpy.ndarray): X array\n        var_type (list): list with type information\n\n    Returns:\n        numpy.ndarray: X array with non-numeric values rounded to integers\n\n    Example:\n        &gt;&gt;&gt; X = np.array([[1.2, 2.3], [3.4, 4.5]])\n        &gt;&gt;&gt; var_type = [\"num\", \"factor\"]\n        &gt;&gt;&gt; repair_non_numeric(X, var_type)\n        array([[1., 2.],\n               [3., 4.]])\n    \"\"\"\n    mask = np.isin(var_type, [\"num\", \"float\"], invert=True)\n    X[:, mask] = np.around(X[:, mask])\n    return X\n</code></pre>"},{"location":"reference/spotPython/utils/transform/","title":"transform","text":""},{"location":"reference/spotPython/utils/transform/#spotPython.utils.transform.scale","title":"<code>scale(X, lower, upper)</code>","text":"<p>Sample scaling from unit hypercube to different bounds.</p> <p>Converts a sample from <code>[0, 1)</code> to <code>[a, b)</code>. Note: equal lower and upper bounds are feasible. The following transformation is used:</p> <p><code>(b - a) * X + a</code></p> <p>X (array):     Sample to scale. lower (array):     lower bound of transformed data. upper (array):     upper bounds of transformed data.</p> <p>(array):     Scaled sample.</p> <p>Examples:</p> <p>Transform three samples in the unit hypercube to (lower, upper) bounds:</p> <p>import numpy as np from scipy.stats import qmc from spotPython.utils.transform import scale lower = np.array([6, 0]) upper = np.array([6, 5]) sample = np.array([[0.5 , 0.75],             [0.5 , 0.5],             [0.75, 0.25]]) scale(sample, lower, upper)</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/transform.py</code> <pre><code>def scale(X: np.ndarray, lower: np.ndarray, upper: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Sample scaling from unit hypercube to different bounds.\n\n    Converts a sample from `[0, 1)` to `[a, b)`.\n    Note: equal lower and upper bounds are feasible.\n    The following transformation is used:\n\n    `(b - a) * X + a`\n\n    Args:\n    X (array):\n        Sample to scale.\n    lower (array):\n        lower bound of transformed data.\n    upper (array):\n        upper bounds of transformed data.\n\n    Returns:\n    (array):\n        Scaled sample.\n\n    Examples:\n    Transform three samples in the unit hypercube to (lower, upper) bounds:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from scipy.stats import qmc\n    &gt;&gt;&gt; from spotPython.utils.transform import scale\n    &gt;&gt;&gt; lower = np.array([6, 0])\n    &gt;&gt;&gt; upper = np.array([6, 5])\n    &gt;&gt;&gt; sample = np.array([[0.5 , 0.75],\n    &gt;&gt;&gt;             [0.5 , 0.5],\n    &gt;&gt;&gt;             [0.75, 0.25]])\n    &gt;&gt;&gt; scale(sample, lower, upper)\n\n    \"\"\"\n    # Checking that X is within (0,1) interval\n    if (X.max() &gt; 1.0) or (X.min() &lt; 0.0):\n        raise ValueError(\"Sample is not in unit hypercube\")\n    # Vectorized scaling operation\n    X = (upper - lower) * X + lower\n    # Handling case where lower == upper\n    X[:, lower == upper] = lower[lower == upper]\n    return X\n</code></pre>"},{"location":"reference/spotPython/utils/transform/#spotPython.utils.transform.transform_hyper_parameter_values","title":"<code>transform_hyper_parameter_values(fun_control, hyper_parameter_values)</code>","text":"<p>Transform the values of the hyperparameters according to the transform function specified in fun_control if the hyperparameter is of type \u201cint\u201d, or \u201cfloat\u201d or \u201cnum\u201d. Let fun_control = {\u201ccore_model_hyper_dict\u201d:{ \u201cleaf_prediction\u201d: { \u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d], \u201ctype\u201d: \u201cfactor\u201d, \u201cdefault\u201d: \u201cmean\u201d, \u201ccore_model_parameter_type\u201d: \u201cstr\u201d}, \u201cmax_depth\u201d: { \u201ctype\u201d: \u201cint\u201d, \u201cdefault\u201d: 20, \u201ctransform\u201d: \u201ctransform_power_2\u201d, \u201clower\u201d: 2, \u201cupper\u201d: 20}}} and v = {\u2018max_depth\u2019: 20,\u2019leaf_prediction\u2019: \u2018mean\u2019} and def transform_power_2(x): return 2**x. The function takes fun_control and v as input and returns a dictionary with the same structure as v. The function transforms the values of the hyperparameters according to the transform function specified in fun_control if the hyperparameter is of type \u201cint\u201d, or \u201cfloat\u201d or \u201cnum\u201d.</p> <p>For example, transform_hyper_parameter_values(fun_control, v) returns  {\u2018max_depth\u2019: 1048576, \u2018leaf_prediction\u2019: \u2018mean\u2019}.</p> <p>Parameters:</p> Name Type Description Default <code>fun_control</code> <code>dict</code> <p>A dictionary containing the information about the core model and the hyperparameters.</p> required <code>hyper_parameter_values</code> <code>dict</code> <p>A dictionary containing the values of the hyperparameters.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the values of the hyperparameters.</p> Example <p>import copy     from spotPython.utils.prepare import transform_hyper_parameter_values     fun_control = {     \u201ccore_model_hyper_dict\u201d: {         \u201cleaf_prediction\u201d: {             \u201clevels\u201d: [\u201cmean\u201d, \u201cmodel\u201d, \u201cadaptive\u201d],             \u201ctype\u201d: \u201cfactor\u201d,             \u201cdefault\u201d: \u201cmean\u201d,             \u201ccore_model_parameter_type\u201d: \u201cstr\u201d},         \u201cmax_depth\u201d: {\u201ctype\u201d: \u201cint\u201d,                       \u201cdefault\u201d: 20                       \u201ctransform\u201d: \u201ctransform_power_2\u201d,                       \u201clower\u201d: 2,                       \u201cupper\u201d: 20}}}     hyper_parameter_values = {\u2018max_depth\u2019: 20,                               \u2018leaf_prediction\u2019: \u2018mean\u2019}     transform_hyper_parameter_values(fun_control, hyper_parameter_values)     {\u2018max_depth\u2019: 1048576,      \u2018leaf_prediction\u2019: \u2018mean\u2019}</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/transform.py</code> <pre><code>def transform_hyper_parameter_values(fun_control, hyper_parameter_values):\n\"\"\"\n    Transform the values of the hyperparameters according to the transform function specified in fun_control\n    if the hyperparameter is of type \"int\", or \"float\" or \"num\".\n    Let fun_control = {\"core_model_hyper_dict\":{ \"leaf_prediction\":\n    { \"levels\": [\"mean\", \"model\", \"adaptive\"], \"type\": \"factor\", \"default\": \"mean\", \"core_model_parameter_type\": \"str\"},\n    \"max_depth\": { \"type\": \"int\", \"default\": 20, \"transform\": \"transform_power_2\", \"lower\": 2, \"upper\": 20}}}\n    and v = {'max_depth': 20,'leaf_prediction': 'mean'} and def transform_power_2(x): return 2**x.\n    The function takes fun_control and v as input and returns a dictionary with the same structure as v.\n    The function transforms the values of the hyperparameters according to the transform function\n    specified in fun_control if the hyperparameter is of type \"int\", or \"float\" or \"num\".\n\n    For example, transform_hyper_parameter_values(fun_control, v) returns\n     {'max_depth': 1048576, 'leaf_prediction': 'mean'}.\n    Args:\n        fun_control (dict): A dictionary containing the information about the core model and the hyperparameters.\n        hyper_parameter_values (dict): A dictionary containing the values of the hyperparameters.\n    Returns:\n        dict: A dictionary containing the values of the hyperparameters.\n    Example:\n        &gt;&gt;&gt; import copy\n            from spotPython.utils.prepare import transform_hyper_parameter_values\n            fun_control = {\n            \"core_model_hyper_dict\": {\n                \"leaf_prediction\": {\n                    \"levels\": [\"mean\", \"model\", \"adaptive\"],\n                    \"type\": \"factor\",\n                    \"default\": \"mean\",\n                    \"core_model_parameter_type\": \"str\"},\n                \"max_depth\": {\"type\": \"int\",\n                              \"default\": 20\n                              \"transform\": \"transform_power_2\",\n                              \"lower\": 2,\n                              \"upper\": 20}}}\n            hyper_parameter_values = {'max_depth': 20,\n                                      'leaf_prediction': 'mean'}\n            transform_hyper_parameter_values(fun_control, hyper_parameter_values)\n            {'max_depth': 1048576,\n             'leaf_prediction': 'mean'}\n    \"\"\"\n    hyper_parameter_values = copy.deepcopy(hyper_parameter_values)\n    for key, value in hyper_parameter_values.items():\n        if (\n            fun_control[\"core_model_hyper_dict\"][key][\"type\"] in [\"int\", \"float\", \"num\", \"factor\"]\n            and fun_control[\"core_model_hyper_dict\"][key][\"transform\"] != \"None\"\n        ):\n            hyper_parameter_values[key] = eval(fun_control[\"core_model_hyper_dict\"][key][\"transform\"])(value)\n    return hyper_parameter_values\n</code></pre>"},{"location":"reference/spotPython/utils/transform/#spotPython.utils.transform.transform_none_to_None","title":"<code>transform_none_to_None(x)</code>","text":"<p>Needed for sklearn.linear_model.LogisticRegression</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/transform.py</code> <pre><code>def transform_none_to_None(x):\n\"\"\"Needed for sklearn.linear_model.LogisticRegression\"\"\"\n    if x == \"none\":\n        return None\n    else:\n        return x\n</code></pre>"},{"location":"reference/spotPython/utils/transform/#spotPython.utils.transform.transform_power","title":"<code>transform_power(base, x, as_int=False)</code>","text":"<p>Raises a given base to the power of x.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>int</code> <p>The base to raise to the power of x.</p> required <code>x</code> <code>int</code> <p>The exponent.</p> required <code>as_int</code> <code>bool</code> <p>If True, returns the result as an integer.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The result of raising the base to the power of x.</p> Source code in <code>/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/utils/transform.py</code> <pre><code>def transform_power(base: int, x: int, as_int: bool = False) -&gt; float:\n\"\"\"\n    Raises a given base to the power of x.\n\n    Args:\n        base (int): The base to raise to the power of x.\n        x (int): The exponent.\n        as_int (bool): If True, returns the result as an integer.\n\n    Returns:\n        float: The result of raising the base to the power of x.\n    \"\"\"\n    result = base**x\n    if as_int:\n        result = int(result)\n    return result\n</code></pre>"}]}