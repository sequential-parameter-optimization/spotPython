{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to spotPython For official information see SPOTSeven","title":"Home"},{"location":"#welcome-to-spotpython","text":"For official information see SPOTSeven","title":"Welcome to spotPython"},{"location":"about/","text":"Contact/Privacy Policy Address Prof. Dr. Thomas Bartz-Beielstein TH K\u00f6ln Raum 1.519 Steinm\u00fcllerallee 6 51643 Gummersbach +49 (0)2261 8196 6391 thomas.bartz-beielstein [at] th-koeln.de www.spotseven.de Privacy Policy We are very delighted that you have shown interest in our enterprise. Data protection is of a particularly high priority for the management of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. The use of the Internet pages of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is possible without any indication of personal data; however, if a data subject wants to use special enterprise services via our website, processing of personal data could become necessary. If the processing of personal data is necessary and there is no statutory basis for such processing, we generally obtain consent from the data subject. The processing of personal data, such as the name, address, e-mail address, or telephone number of a data subject shall always be in line with the General Data Protection Regulation (GDPR), and in accordance with the country-specific data protection regulations applicable to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. By means of this data protection declaration, our enterprise would like to inform the general public of the nature, scope, and purpose of the personal data we collect, use and process. Furthermore, data subjects are informed, by means of this data protection declaration, of the rights to which they are entitled. As the controller, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab has implemented numerous technical and organizational measures to ensure the most complete protection of personal data processed through this website. However, Internet-based data transmissions may in principle have security gaps, so absolute protection may not be guaranteed. For this reason, every data subject is free to transfer personal data to us via alternative means, e.g. by telephone. Definitions The data protection declaration of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is based on the terms used by the European legislator for the adoption of the General Data Protection Regulation (GDPR). Our data protection declaration should be legible and understandable for the general public, as well as our customers and business partners. To ensure this, we would like to first explain the terminology used. In this data protection declaration, we use, inter alia, the following terms: a) Personal data Personal data means any information relating to an identified or identifiable natural person (\u201cdata subject\u201d). An identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person. b) Data subject Data subject is any identified or identifiable natural person, whose personal data is processed by the controller responsible for the processing. c) Processing Processing is any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction. d) Restriction of processing Restriction of processing is the marking of stored personal data with the aim of limiting their processing in the future. e) Profiling Profiling means any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person, in particular to analyse or predict aspects concerning that natural person\u2019s performance at work, economic situation, health, personal preferences, interests, reliability, behaviour, location or movements. f) Pseudonymisation Pseudonymisation is the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organisational measures to ensure that the personal data are not attributed to an identified or identifiable natural person. g) Controller or controller responsible for the processing Controller or controller responsible for the processing is the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data; where the purposes and means of such processing are determined by Union or Member State law, the controller or the specific criteria for its nomination may be provided for by Union or Member State law. h) Processor Processor is a natural or legal person, public authority, agency or other body which processes personal data on behalf of the controller. i) Recipient Recipient is a natural or legal person, public authority, agency or another body, to which the personal data are disclosed, whether a third party or not. However, public authorities which may receive personal data in the framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing. j) Third party Third party is a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data. k) Consent Consent of the data subject is any freely given, specific, informed and unambiguous indication of the data subject\u2019s wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her. Name and Address of the controller Controller for the purposes of the General Data Protection Regulation (GDPR), other data protection laws applicable in Member states of the European Union and other provisions related to data protection is: TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab Steinm\u00fcllerallee 1 51643 Gummersbach Deutschland Phone: +49 2261 81966391 Email: thomas.bartz-beielstein@th-koeln.de Website: www.spotseven.de Collection of general data and information The website of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab collects a series of general data and information when a data subject or automated system calls up the website. This general data and information are stored in the server log files. Collected may be (1) the browser types and versions used, (2) the operating system used by the accessing system, (3) the website from which an accessing system reaches our website (so-called referrers), (4) the sub-websites, (5) the date and time of access to the Internet site, (6) an Internet protocol address (IP address), (7) the Internet service provider of the accessing system, and (8) any other similar data and information that may be used in the event of attacks on our information technology systems. When using these general data and information, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab does not draw any conclusions about the data subject. Rather, this information is needed to (1) deliver the content of our website correctly, (2) optimize the content of our website as well as its advertisement, (3) ensure the long-term viability of our information technology systems and website technology, and (4) provide law enforcement authorities with the information necessary for criminal prosecution in case of a cyber-attack. Therefore, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab analyzes anonymously collected data and information statistically, with the aim of increasing the data protection and data security of our enterprise, and to ensure an optimal level of protection for the personal data we process. The anonymous data of the server log files are stored separately from all personal data provided by a data subject. Comments function in the blog on the website The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab offers users the possibility to leave individual comments on individual blog contributions on a blog, which is on the website of the controller. A blog is a web-based, publicly-accessible portal, through which one or more people called bloggers or web-bloggers may post articles or write down thoughts in so-called blogposts. Blogposts may usually be commented by third parties. If a data subject leaves a comment on the blog published on this website, the comments made by the data subject are also stored and published, as well as information on the date of the commentary and on the user\u2019s (pseudonym) chosen by the data subject. In addition, the IP address assigned by the Internet service provider (ISP) to the data subject is also logged. This storage of the IP address takes place for security reasons, and in case the data subject violates the rights of third parties, or posts illegal content through a given comment. The storage of these personal data is, therefore, in the own interest of the data controller, so that he can exculpate in the event of an infringement. This collected personal data will not be passed to third parties, unless such a transfer is required by law or serves the aim of the defense of the data controller. Routine erasure and blocking of personal data The data controller shall process and store the personal data of the data subject only for the period necessary to achieve the purpose of storage, or as far as this is granted by the European legislator or other legislators in laws or regulations to which the controller is subject to. If the storage purpose is not applicable, or if a storage period prescribed by the European legislator or another competent legislator expires, the personal data are routinely blocked or erased in accordance with legal requirements. Rights of the data subject a) Right of confirmation Each data subject shall have the right granted by the European legislator to obtain from the controller the confirmation as to whether or not personal data concerning him or her are being processed. If a data subject wishes to avail himself of this right of confirmation, he or she may, at any time, contact our Data Protection Officer or another employee of the controller. b) Right of access Each data subject shall have the right granted by the European legislator to obtain from the controller free information about his or her personal data stored at any time and a copy of this information. Furthermore, the European directives and regulations grant the data subject access to the following information: the purposes of the processing; the categories of personal data concerned; the recipients or categories of recipients to whom the personal data have been or will be disclosed, in particular recipients in third countries or international organisations; where possible, the envisaged period for which the personal data will be stored, or, if not possible, the criteria used to determine that period; the existence of the right to request from the controller rectification or erasure of personal data, or restriction of processing of personal data concerning the data subject, or to object to such processing; the existence of the right to lodge a complaint with a supervisory authority; where the personal data are not collected from the data subject, any available information as to their source; the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) of the GDPR and, at least in those cases, meaningful information about the logic involved, as well as the significance and envisaged consequences of such processing for the data subject. Furthermore, the data subject shall have a right to obtain information as to whether personal data are transferred to a third country or to an international organisation. Where this is the case, the data subject shall have the right to be informed of the appropriate safeguards relating to the transfer. If a data subject wishes to avail himself of this right of access, he or she may at any time contact our Data Protection Officer or another employee of the controller. c) Right to rectification Each data subject shall have the right granted by the European legislator to obtain from the controller without undue delay the rectification of inaccurate personal data concerning him or her. Taking into account the purposes of the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement. If a data subject wishes to exercise this right to rectification, he or she may, at any time, contact our Data Protection Officer or another employee of the controller. d) Right to erasure (Right to be forgotten) Each data subject shall have the right granted by the European legislator to obtain from the controller the erasure of personal data concerning him or her without undue delay, and the controller shall have the obligation to erase personal data without undue delay where one of the following grounds applies, as long as the processing is not necessary: The personal data are no longer necessary in relation to the purposes for which they were collected or otherwise processed. The data subject withdraws consent to which the processing is based according to point (a) of Article 6(1) of the GDPR, or point (a) of Article 9(2) of the GDPR, and where there is no other legal ground for the processing. The data subject objects to the processing pursuant to Article 21(1) of the GDPR and there are no overriding legitimate grounds for the processing, or the data subject objects to the processing pursuant to Article 21(2) of the GDPR. The personal data have been unlawfully processed. The personal data must be erased for compliance with a legal obligation in Union or Member State law to which the controller is subject. The personal data have been collected in relation to the offer of information society services referred to in Article 8(1) of the GDPR. If one of the aforementioned reasons applies, and a data subject wishes to request the erasure of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee shall promptly ensure that the erasure request is complied with immediately. Where the controller has made personal data public and is obliged pursuant to Article 17(1) to erase the personal data, the controller, taking account of available technology and the cost of implementation, shall take reasonable steps, including technical measures, to inform other controllers processing the personal data that the data subject has requested erasure by such controllers of any links to, or copy or replication of, those personal data, as far as processing is not required. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the necessary measures in individual cases. e) Right of restriction of processing Each data subject shall have the right granted by the European legislator to obtain from the controller restriction of processing where one of the following applies: The accuracy of the personal data is contested by the data subject, for a period enabling the controller to verify the accuracy of the personal data. The processing is unlawful and the data subject opposes the erasure of the personal data and requests instead the restriction of their use instead. The controller no longer needs the personal data for the purposes of the processing, but they are required by the data subject for the establishment, exercise or defence of legal claims. The data subject has objected to processing pursuant to Article 21(1) of the GDPR pending the verification whether the legitimate grounds of the controller override those of the data subject. If one of the aforementioned conditions is met, and a data subject wishes to request the restriction of the processing of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the restriction of the processing. f) Right to data portability Each data subject shall have the right granted by the European legislator, to receive the personal data concerning him or her, which was provided to a controller, in a structured, commonly used and machine-readable format. He or she shall have the right to transmit those data to another controller without hindrance from the controller to which the personal data have been provided, as long as the processing is based on consent pursuant to point (a) of Article 6(1) of the GDPR or point (a) of Article 9(2) of the GDPR, or on a contract pursuant to point (b) of Article 6(1) of the GDPR, and the processing is carried out by automated means, as long as the processing is not necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller. Furthermore, in exercising his or her right to data portability pursuant to Article 20(1) of the GDPR, the data subject shall have the right to have personal data transmitted directly from one controller to another, where technically feasible and when doing so does not adversely affect the rights and freedoms of others. In order to assert the right to data portability, the data subject may at any time contact the Data Protection Officer designated by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. g) Right to object Each data subject shall have the right granted by the European legislator to object, on grounds relating to his or her particular situation, at any time, to processing of personal data concerning him or her, which is based on point (e) or (f) of Article 6(1) of the GDPR. This also applies to profiling based on these provisions. The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall no longer process the personal data in the event of the objection, unless we can demonstrate compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject, or for the establishment, exercise or defence of legal claims. If the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab processes personal data for direct marketing purposes, the data subject shall have the right to object at any time to processing of personal data concerning him or her for such marketing. This applies to profiling to the extent that it is related to such direct marketing. If the data subject objects to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab to the processing for direct marketing purposes, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab will no longer process the personal data for these purposes. In addition, the data subject has the right, on grounds relating to his or her particular situation, to object to processing of personal data concerning him or her by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab for scientific or historical research purposes, or for statistical purposes pursuant to Article 89(1) of the GDPR, unless the processing is necessary for the performance of a task carried out for reasons of public interest. In order to exercise the right to object, the data subject may directly contact the Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. In addition, the data subject is free in the context of the use of information society services, and notwithstanding Directive 2002/58/EC, to use his or her right to object by automated means using technical specifications. h) Automated individual decision-making, including profiling Each data subject shall have the right granted by the European legislator not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects concerning him or her, or similarly significantly affects him or her, as long as the decision (1) is not is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) is not authorised by Union or Member State law to which the controller is subject and which also lays down suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, or (3) is not based on the data subject\u2019s explicit consent. If the decision (1) is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) it is based on the data subject\u2019s explicit consent, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall implement suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, at least the right to obtain human intervention on the part of the controller, to express his or her point of view and contest the decision. If the data subject wishes to exercise the rights concerning automated individual decision-making, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller. i) Right to withdraw data protection consent Each data subject shall have the right granted by the European legislator to withdraw his or her consent to processing of his or her personal data at any time. f the data subject wishes to exercise the right to withdraw the consent, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller. Data protection provisions about the application and use of Facebook On this website, the controller has integrated components of the enterprise Facebook. Facebook is a social network. A social network is a place for social meetings on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Facebook allows social network users to include the creation of private profiles, upload photos, and network through friend requests. The operating company of Facebook is Facebook, Inc., 1 Hacker Way, Menlo Park, CA 94025, United States. If a person lives outside of the United States or Canada, the controller is the Facebook Ireland Ltd., 4 Grand Canal Square, Grand Canal Harbour, Dublin 2, Ireland. With each call-up to one of the individual pages of this Internet website, which is operated by the controller and into which a Facebook component (Facebook plug-ins) was integrated, the web browser on the information technology system of the data subject is automatically prompted to download display of the corresponding Facebook component from Facebook through the Facebook component. An overview of all the Facebook Plug-ins may be accessed under https://developers.facebook.com/docs/plugins/. During the course of this technical procedure, Facebook is made aware of what specific sub-site of our website was visited by the data subject. If the data subject is logged in at the same time on Facebook, Facebook detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-site of our Internet page was visited by the data subject. This information is collected through the Facebook component and associated with the respective Facebook account of the data subject. If the data subject clicks on one of the Facebook buttons integrated into our website, e.g. the \u201cLike\u201d button, or if the data subject submits a comment, then Facebook matches this information with the personal Facebook user account of the data subject and stores the personal data. Facebook always receives, through the Facebook component, information about a visit to our website by the data subject, whenever the data subject is logged in at the same time on Facebook during the time of the call-up to our website. This occurs regardless of whether the data subject clicks on the Facebook component or not. If such a transmission of information to Facebook is not desirable for the data subject, then he or she may prevent this by logging off from their Facebook account before a call-up to our website is made. The data protection guideline published by Facebook, which is available at https://facebook.com/about/privacy/, provides information about the collection, processing and use of personal data by Facebook. In addition, it is explained there what setting options Facebook offers to protect the privacy of the data subject. In addition, different configuration options are made available to allow the elimination of data transmission to Facebook, e.g. the Facebook blocker of the provider Webgraph, which may be obtained under http://webgraph.com/resources/facebookblocker/. These applications may be used by the data subject to eliminate a data transmission to Facebook. Data protection provisions about the application and use of Google+ On this website, the controller has integrated the Google+ button as a component. Google+ is a so-called social network. A social network is a social meeting place on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Google+ allows users of the social network to include the creation of private profiles, upload photos and network through friend requests. The operating company of Google+ is Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES. With each call-up to one of the individual pages of this website, which is operated by the controller and on which a Google+ button has been integrated, the Internet browser on the information technology system of the data subject automatically downloads a display of the corresponding Google+ button of Google through the respective Google+ button component. During the course of this technical procedure, Google is made aware of what specific sub-page of our website was visited by the data subject. More detailed information about Google+ is available under https://developers.google.com/+/. If the data subject is logged in at the same time to Google+, Google recognizes with each call-up to our website by the data subject and for the entire duration of his or her stay on our Internet site, which specific sub-pages of our Internet page were visited by the data subject. This information is collected through the Google+ button and Google matches this with the respective Google+ account associated with the data subject. If the data subject clicks on the Google+ button integrated on our website and thus gives a Google+ 1 recommendation, then Google assigns this information to the personal Google+ user account of the data subject and stores the personal data. Google stores the Google+ 1 recommendation of the data subject, making it publicly available in accordance with the terms and conditions accepted by the data subject in this regard. Subsequently, a Google+ 1 recommendation given by the data subject on this website together with other personal data, such as the Google+ account name used by the data subject and the stored photo, is stored and processed on other Google services, such as search-engine results of the Google search engine, the Google account of the data subject or in other places, e.g. on Internet pages, or in relation to advertisements. Google is also able to link the visit to this website with other personal data stored on Google. Google further records this personal information with the purpose of improving or optimizing the various Google services. Through the Google+ button, Google receives information that the data subject visited our website, if the data subject at the time of the call-up to our website is logged in to Google+. This occurs regardless of whether the data subject clicks or doesn\u2019t click on the Google+ button. If the data subject does not wish to transmit personal data to Google, he or she may prevent such transmission by logging out of his Google+ account before calling up our website. Further information and the data protection provisions of Google may be retrieved under https://www.google.com/intl/en/policies/privacy/. More references from Google about the Google+ 1 button may be obtained under https://developers.google.com/+/web/buttons-policy. Data protection provisions about the application and use of Jetpack for WordPress On this website, the controller has integrated Jetpack. Jetpack is a WordPress plug-in, which provides additional features to the operator of a website based on WordPress. Jetpack allows the Internet site operator, inter alia, an overview of the visitors of the site. By displaying related posts and publications, or the ability to share content on the page, it is also possible to increase visitor numbers. In addition, security features are integrated into Jetpack, so a Jetpack-using site is better protected against brute-force attacks. Jetpack also optimizes and accelerates the loading of images on the website. The operating company of Jetpack Plug-Ins for WordPress is the Automattic Inc., 132 Hawthorne Street, San Francisco, CA 94107, UNITED STATES. The operating enterprise uses the tracking technology created by Quantcast Inc., 201 Third Street, San Francisco, CA 94103, UNITED STATES. Jetpack sets a cookie on the information technology system used by the data subject. The definition of cookies is explained above. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Jetpack component was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to submit data through the Jetpack component for analysis purposes to Automattic. During the course of this technical procedure Automattic receives data that is used to create an overview of website visits. The data obtained in this way serves the analysis of the behaviour of the data subject, which has access to the Internet page of the controller and is analyzed with the aim to optimize the website. The data collected through the Jetpack component is not used to identify the data subject without a prior obtaining of a separate express consent of the data subject. The data comes also to the notice of Quantcast. Quantcast uses the data for the same purposes as Automattic. The data subject can, as stated above, prevent the setting of cookies through our website at any time by means of a corresponding adjustment of the web browser used and thus permanently deny the setting of cookies. Such an adjustment to the Internet browser used would also prevent Automattic/Quantcast from setting a cookie on the information technology system of the data subject. In addition, cookies already in use by Automattic/Quantcast may be deleted at any time via a web browser or other software programs. In addition, the data subject has the possibility of objecting to a collection of data relating to a use of this Internet site that are generated by the Jetpack cookie as well as the processing of these data by Automattic/Quantcast and the chance to preclude any such. For this purpose, the data subject must press the \u2018opt-out\u2019 button under the link https://www.quantcast.com/opt-out/ which sets an opt-out cookie. The opt-out cookie set with this purpose is placed on the information technology system used by the data subject. If the cookies are deleted on the system of the data subject, then the data subject must call up the link again and set a new opt-out cookie. With the setting of the opt-out cookie, however, the possibility exists that the websites of the controller are not fully usable anymore by the data subject. The applicable data protection provisions of Automattic may be accessed under https://automattic.com/privacy/. The applicable data protection provisions of Quantcast can be accessed under https://www.quantcast.com/privacy/. Data protection provisions about the application and use of LinkedIn The controller has integrated components of the LinkedIn Corporation on this website. LinkedIn is a web-based social network that enables users with existing business contacts to connect and to make new business contacts. Over 400 million registered people in more than 200 countries use LinkedIn. Thus, LinkedIn is currently the largest platform for business contacts and one of the most visited websites in the world. The operating company of LinkedIn is LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, UNITED STATES. For privacy matters outside of the UNITED STATES LinkedIn Ireland, Privacy Policy Issues, Wilton Plaza, Wilton Place, Dublin 2, Ireland, is responsible. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a LinkedIn component (LinkedIn plug-in) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to the download of a display of the corresponding LinkedIn component of LinkedIn. Further information about the LinkedIn plug-in may be accessed under https://developer.linkedin.com/plugins. During the course of this technical procedure, LinkedIn gains knowledge of what specific sub-page of our website was visited by the data subject. If the data subject is logged in at the same time on LinkedIn, LinkedIn detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-page of our Internet page was visited by the data subject. This information is collected through the LinkedIn component and associated with the respective LinkedIn account of the data subject. If the data subject clicks on one of the LinkedIn buttons integrated on our website, then LinkedIn assigns this information to the personal LinkedIn user account of the data subject and stores the personal data. LinkedIn receives information via the LinkedIn component that the data subject has visited our website, provided that the data subject is logged in at LinkedIn at the time of the call-up to our website. This occurs regardless of whether the person clicks on the LinkedIn button or not. If such a transmission of information to LinkedIn is not desirable for the data subject, then he or she may prevent this by logging off from their LinkedIn account before a call-up to our website is made. LinkedIn provides under https://www.linkedin.com/psettings/guest-controls the possibility to unsubscribe from e-mail messages, SMS messages and targeted ads, as well as the ability to manage ad settings. LinkedIn also uses affiliates such as Eire, Google Analytics, BlueKai, DoubleClick, Nielsen, Comscore, Eloqua, and Lotame. The setting of such cookies may be denied under https://www.linkedin.com/legal/cookie-policy. The applicable privacy policy for LinkedIn is available under https://www.linkedin.com/legal/privacy-policy. The LinkedIn Cookie Policy is available under https://www.linkedin.com/legal/cookie-policy. Data protection provisions about the application and use of Twitter On this website, the controller has integrated components of Twitter. Twitter is a multilingual, publicly-accessible microblogging service on which users may publish and spread so-called \u2018tweets,\u2019 e.g. short messages, which are limited to 140 characters. These short messages are available for everyone, including those who are not logged on to Twitter. The tweets are also displayed to so-called followers of the respective user. Followers are other Twitter users who follow a user\u2019s tweets. Furthermore, Twitter allows you to address a wide audience via hashtags, links or retweets. The operating company of Twitter is Twitter, Inc., 1355 Market Street, Suite 900, San Francisco, CA 94103, UNITED STATES. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Twitter component (Twitter button) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding Twitter component of Twitter. Further information about the Twitter buttons is available under https://about.twitter.com/de/resources/buttons. During the course of this technical procedure, Twitter gains knowledge of what specific sub-page of our website was visited by the data subject. The purpose of the integration of the Twitter component is a retransmission of the contents of this website to allow our users to introduce this web page to the digital world and increase our visitor numbers. If the data subject is logged in at the same time on Twitter, Twitter detects with every call-up to our website by the data subject and for the entire duration of their stay on our Internet site which specific sub-page of our Internet page was visited by the data subject. This information is collected through the Twitter component and associated with the respective Twitter account of the data subject. If the data subject clicks on one of the Twitter buttons integrated on our website, then Twitter assigns this information to the personal Twitter user account of the data subject and stores the personal data. Twitter receives information via the Twitter component that the data subject has visited our website, provided that the data subject is logged in on Twitter at the time of the call-up to our website. This occurs regardless of whether the person clicks on the Twitter component or not. If such a transmission of information to Twitter is not desirable for the data subject, then he or she may prevent this by logging off from their Twitter account before a call-up to our website is made. The applicable data protection provisions of Twitter may be accessed under https://twitter.com/privacy?lang=en. Data protection provisions about the application and use of YouTube On this website, the controller has integrated components of YouTube. YouTube is an Internet video portal that enables video publishers to set video clips and other users free of charge, which also provides free viewing, review and commenting on them. YouTube allows you to publish all kinds of videos, so you can access both full movies and TV broadcasts, as well as music videos, trailers, and videos made by users via the Internet portal. The operating company of YouTube is YouTube, LLC, 901 Cherry Ave., San Bruno, CA 94066, UNITED STATES. The YouTube, LLC is a subsidiary of Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a YouTube component (YouTube video) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding YouTube component. Further information about YouTube may be obtained under https://www.youtube.com/yt/about/en/. During the course of this technical procedure, YouTube and Google gain knowledge of what specific sub-page of our website was visited by the data subject. If the data subject is logged in on YouTube, YouTube recognizes with each call-up to a sub-page that contains a YouTube video, which specific sub-page of our Internet site was visited by the data subject. This information is collected by YouTube and Google and assigned to the respective YouTube account of the data subject. YouTube and Google will receive information through the YouTube component that the data subject has visited our website, if the data subject at the time of the call to our website is logged in on YouTube; this occurs regardless of whether the person clicks on a YouTube video or not. If such a transmission of this information to YouTube and Google is not desirable for the data subject, the delivery may be prevented if the data subject logs off from their own YouTube account before a call-up to our website is made. YouTube\u2019s data protection provisions, available at https://www.google.com/intl/en/policies/privacy/, provide information about the collection, processing and use of personal data by YouTube and Google. Legal basis for the processing Art. 6(1) lit. a GDPR serves as the legal basis for processing operations for which we obtain consent for a specific processing purpose. If the processing of personal data is necessary for the performance of a contract to which the data subject is party, as is the case, for example, when processing operations are necessary for the supply of goods or to provide any other service, the processing is based on Article 6(1) lit. b GDPR. The same applies to such processing operations which are necessary for carrying out pre-contractual measures, for example in the case of inquiries concerning our products or services. Is our company subject to a legal obligation by which processing of personal data is required, such as for the fulfillment of tax obligations, the processing is based on Art. 6(1) lit. c GDPR. In rare cases, the processing of personal data may be necessary to protect the vital interests of the data subject or of another natural person. This would be the case, for example, if a visitor were injured in our company and his name, age, health insurance data or other vital information would have to be passed on to a doctor, hospital or other third party. Then the processing would be based on Art. 6(1) lit. d GDPR. Finally, processing operations could be based on Article 6(1) lit. f GDPR. This legal basis is used for processing operations which are not covered by any of the abovementioned legal grounds, if processing is necessary for the purposes of the legitimate interests pursued by our company or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data. Such processing operations are particularly permissible because they have been specifically mentioned by the European legislator. He considered that a legitimate interest could be assumed if the data subject is a client of the controller (Recital 47 Sentence 2 GDPR). The legitimate interests pursued by the controller or by a third party Where the processing of personal data is based on Article 6(1) lit. f GDPR our legitimate interest is to carry out our business in favor of the well-being of all our employees and the shareholders. Period for which the personal data will be stored The criteria used to determine the period of storage of personal data is the respective statutory retention period. After expiration of that period, the corresponding data is routinely deleted, as long as it is no longer necessary for the fulfillment of the contract or the initiation of a contract. Provision of personal data as statutory or contractual requirement; Requirement necessary to enter into a contract; Obligation of the data subject to provide the personal data; possible consequences of failure to provide such data We clarify that the provision of personal data is partly required by law (e.g. tax regulations) or can also result from contractual provisions (e.g. information on the contractual partner). Sometimes it may be necessary to conclude a contract that the data subject provides us with personal data, which must subsequently be processed by us. The data subject is, for example, obliged to provide us with personal data when our company signs a contract with him or her. The non-provision of the personal data would have the consequence that the contract with the data subject could not be concluded. Before personal data is provided by the data subject, the data subject must contact our Data Protection Officer. Our Data Protection Officer clarifies to the data subject whether the provision of the personal data is required by law or contract or is necessary for the conclusion of the contract, whether there is an obligation to provide the personal data and the consequences of non-provision of the personal data. Existence of automated decision-making As a responsible company, we do not use automatic decision-making or profiling. This Privacy Policy has been generated by the Privacy Policy Generator of the External Data Protection Officers that was developed in cooperation with RC GmbH, which sells used notebooks and the Media Law Lawyers from WBS-LAW.","title":"About"},{"location":"about/#contactprivacy-policy","text":"","title":"Contact/Privacy Policy"},{"location":"about/#address","text":"Prof. Dr. Thomas Bartz-Beielstein TH K\u00f6ln Raum 1.519 Steinm\u00fcllerallee 6 51643 Gummersbach +49 (0)2261 8196 6391 thomas.bartz-beielstein [at] th-koeln.de www.spotseven.de","title":"Address"},{"location":"about/#privacy-policy","text":"We are very delighted that you have shown interest in our enterprise. Data protection is of a particularly high priority for the management of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. The use of the Internet pages of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is possible without any indication of personal data; however, if a data subject wants to use special enterprise services via our website, processing of personal data could become necessary. If the processing of personal data is necessary and there is no statutory basis for such processing, we generally obtain consent from the data subject. The processing of personal data, such as the name, address, e-mail address, or telephone number of a data subject shall always be in line with the General Data Protection Regulation (GDPR), and in accordance with the country-specific data protection regulations applicable to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab. By means of this data protection declaration, our enterprise would like to inform the general public of the nature, scope, and purpose of the personal data we collect, use and process. Furthermore, data subjects are informed, by means of this data protection declaration, of the rights to which they are entitled. As the controller, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab has implemented numerous technical and organizational measures to ensure the most complete protection of personal data processed through this website. However, Internet-based data transmissions may in principle have security gaps, so absolute protection may not be guaranteed. For this reason, every data subject is free to transfer personal data to us via alternative means, e.g. by telephone. Definitions The data protection declaration of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab is based on the terms used by the European legislator for the adoption of the General Data Protection Regulation (GDPR). Our data protection declaration should be legible and understandable for the general public, as well as our customers and business partners. To ensure this, we would like to first explain the terminology used. In this data protection declaration, we use, inter alia, the following terms: a) Personal data Personal data means any information relating to an identified or identifiable natural person (\u201cdata subject\u201d). An identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person. b) Data subject Data subject is any identified or identifiable natural person, whose personal data is processed by the controller responsible for the processing. c) Processing Processing is any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction. d) Restriction of processing Restriction of processing is the marking of stored personal data with the aim of limiting their processing in the future. e) Profiling Profiling means any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person, in particular to analyse or predict aspects concerning that natural person\u2019s performance at work, economic situation, health, personal preferences, interests, reliability, behaviour, location or movements. f) Pseudonymisation Pseudonymisation is the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organisational measures to ensure that the personal data are not attributed to an identified or identifiable natural person. g) Controller or controller responsible for the processing Controller or controller responsible for the processing is the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data; where the purposes and means of such processing are determined by Union or Member State law, the controller or the specific criteria for its nomination may be provided for by Union or Member State law. h) Processor Processor is a natural or legal person, public authority, agency or other body which processes personal data on behalf of the controller. i) Recipient Recipient is a natural or legal person, public authority, agency or another body, to which the personal data are disclosed, whether a third party or not. However, public authorities which may receive personal data in the framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing. j) Third party Third party is a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data. k) Consent Consent of the data subject is any freely given, specific, informed and unambiguous indication of the data subject\u2019s wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her. Name and Address of the controller Controller for the purposes of the General Data Protection Regulation (GDPR), other data protection laws applicable in Member states of the European Union and other provisions related to data protection is: TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab Steinm\u00fcllerallee 1 51643 Gummersbach Deutschland Phone: +49 2261 81966391 Email: thomas.bartz-beielstein@th-koeln.de Website: www.spotseven.de Collection of general data and information The website of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab collects a series of general data and information when a data subject or automated system calls up the website. This general data and information are stored in the server log files. Collected may be (1) the browser types and versions used, (2) the operating system used by the accessing system, (3) the website from which an accessing system reaches our website (so-called referrers), (4) the sub-websites, (5) the date and time of access to the Internet site, (6) an Internet protocol address (IP address), (7) the Internet service provider of the accessing system, and (8) any other similar data and information that may be used in the event of attacks on our information technology systems. When using these general data and information, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab does not draw any conclusions about the data subject. Rather, this information is needed to (1) deliver the content of our website correctly, (2) optimize the content of our website as well as its advertisement, (3) ensure the long-term viability of our information technology systems and website technology, and (4) provide law enforcement authorities with the information necessary for criminal prosecution in case of a cyber-attack. Therefore, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab analyzes anonymously collected data and information statistically, with the aim of increasing the data protection and data security of our enterprise, and to ensure an optimal level of protection for the personal data we process. The anonymous data of the server log files are stored separately from all personal data provided by a data subject. Comments function in the blog on the website The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab offers users the possibility to leave individual comments on individual blog contributions on a blog, which is on the website of the controller. A blog is a web-based, publicly-accessible portal, through which one or more people called bloggers or web-bloggers may post articles or write down thoughts in so-called blogposts. Blogposts may usually be commented by third parties. If a data subject leaves a comment on the blog published on this website, the comments made by the data subject are also stored and published, as well as information on the date of the commentary and on the user\u2019s (pseudonym) chosen by the data subject. In addition, the IP address assigned by the Internet service provider (ISP) to the data subject is also logged. This storage of the IP address takes place for security reasons, and in case the data subject violates the rights of third parties, or posts illegal content through a given comment. The storage of these personal data is, therefore, in the own interest of the data controller, so that he can exculpate in the event of an infringement. This collected personal data will not be passed to third parties, unless such a transfer is required by law or serves the aim of the defense of the data controller. Routine erasure and blocking of personal data The data controller shall process and store the personal data of the data subject only for the period necessary to achieve the purpose of storage, or as far as this is granted by the European legislator or other legislators in laws or regulations to which the controller is subject to. If the storage purpose is not applicable, or if a storage period prescribed by the European legislator or another competent legislator expires, the personal data are routinely blocked or erased in accordance with legal requirements. Rights of the data subject a) Right of confirmation Each data subject shall have the right granted by the European legislator to obtain from the controller the confirmation as to whether or not personal data concerning him or her are being processed. If a data subject wishes to avail himself of this right of confirmation, he or she may, at any time, contact our Data Protection Officer or another employee of the controller. b) Right of access Each data subject shall have the right granted by the European legislator to obtain from the controller free information about his or her personal data stored at any time and a copy of this information. Furthermore, the European directives and regulations grant the data subject access to the following information: the purposes of the processing; the categories of personal data concerned; the recipients or categories of recipients to whom the personal data have been or will be disclosed, in particular recipients in third countries or international organisations; where possible, the envisaged period for which the personal data will be stored, or, if not possible, the criteria used to determine that period; the existence of the right to request from the controller rectification or erasure of personal data, or restriction of processing of personal data concerning the data subject, or to object to such processing; the existence of the right to lodge a complaint with a supervisory authority; where the personal data are not collected from the data subject, any available information as to their source; the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) of the GDPR and, at least in those cases, meaningful information about the logic involved, as well as the significance and envisaged consequences of such processing for the data subject. Furthermore, the data subject shall have a right to obtain information as to whether personal data are transferred to a third country or to an international organisation. Where this is the case, the data subject shall have the right to be informed of the appropriate safeguards relating to the transfer. If a data subject wishes to avail himself of this right of access, he or she may at any time contact our Data Protection Officer or another employee of the controller. c) Right to rectification Each data subject shall have the right granted by the European legislator to obtain from the controller without undue delay the rectification of inaccurate personal data concerning him or her. Taking into account the purposes of the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement. If a data subject wishes to exercise this right to rectification, he or she may, at any time, contact our Data Protection Officer or another employee of the controller. d) Right to erasure (Right to be forgotten) Each data subject shall have the right granted by the European legislator to obtain from the controller the erasure of personal data concerning him or her without undue delay, and the controller shall have the obligation to erase personal data without undue delay where one of the following grounds applies, as long as the processing is not necessary: The personal data are no longer necessary in relation to the purposes for which they were collected or otherwise processed. The data subject withdraws consent to which the processing is based according to point (a) of Article 6(1) of the GDPR, or point (a) of Article 9(2) of the GDPR, and where there is no other legal ground for the processing. The data subject objects to the processing pursuant to Article 21(1) of the GDPR and there are no overriding legitimate grounds for the processing, or the data subject objects to the processing pursuant to Article 21(2) of the GDPR. The personal data have been unlawfully processed. The personal data must be erased for compliance with a legal obligation in Union or Member State law to which the controller is subject. The personal data have been collected in relation to the offer of information society services referred to in Article 8(1) of the GDPR. If one of the aforementioned reasons applies, and a data subject wishes to request the erasure of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee shall promptly ensure that the erasure request is complied with immediately. Where the controller has made personal data public and is obliged pursuant to Article 17(1) to erase the personal data, the controller, taking account of available technology and the cost of implementation, shall take reasonable steps, including technical measures, to inform other controllers processing the personal data that the data subject has requested erasure by such controllers of any links to, or copy or replication of, those personal data, as far as processing is not required. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the necessary measures in individual cases. e) Right of restriction of processing Each data subject shall have the right granted by the European legislator to obtain from the controller restriction of processing where one of the following applies: The accuracy of the personal data is contested by the data subject, for a period enabling the controller to verify the accuracy of the personal data. The processing is unlawful and the data subject opposes the erasure of the personal data and requests instead the restriction of their use instead. The controller no longer needs the personal data for the purposes of the processing, but they are required by the data subject for the establishment, exercise or defence of legal claims. The data subject has objected to processing pursuant to Article 21(1) of the GDPR pending the verification whether the legitimate grounds of the controller override those of the data subject. If one of the aforementioned conditions is met, and a data subject wishes to request the restriction of the processing of personal data stored by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab, he or she may at any time contact our Data Protection Officer or another employee of the controller. The Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee will arrange the restriction of the processing. f) Right to data portability Each data subject shall have the right granted by the European legislator, to receive the personal data concerning him or her, which was provided to a controller, in a structured, commonly used and machine-readable format. He or she shall have the right to transmit those data to another controller without hindrance from the controller to which the personal data have been provided, as long as the processing is based on consent pursuant to point (a) of Article 6(1) of the GDPR or point (a) of Article 9(2) of the GDPR, or on a contract pursuant to point (b) of Article 6(1) of the GDPR, and the processing is carried out by automated means, as long as the processing is not necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller. Furthermore, in exercising his or her right to data portability pursuant to Article 20(1) of the GDPR, the data subject shall have the right to have personal data transmitted directly from one controller to another, where technically feasible and when doing so does not adversely affect the rights and freedoms of others. In order to assert the right to data portability, the data subject may at any time contact the Data Protection Officer designated by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. g) Right to object Each data subject shall have the right granted by the European legislator to object, on grounds relating to his or her particular situation, at any time, to processing of personal data concerning him or her, which is based on point (e) or (f) of Article 6(1) of the GDPR. This also applies to profiling based on these provisions. The TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall no longer process the personal data in the event of the objection, unless we can demonstrate compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject, or for the establishment, exercise or defence of legal claims. If the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab processes personal data for direct marketing purposes, the data subject shall have the right to object at any time to processing of personal data concerning him or her for such marketing. This applies to profiling to the extent that it is related to such direct marketing. If the data subject objects to the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab to the processing for direct marketing purposes, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab will no longer process the personal data for these purposes. In addition, the data subject has the right, on grounds relating to his or her particular situation, to object to processing of personal data concerning him or her by the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab for scientific or historical research purposes, or for statistical purposes pursuant to Article 89(1) of the GDPR, unless the processing is necessary for the performance of a task carried out for reasons of public interest. In order to exercise the right to object, the data subject may directly contact the Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee. In addition, the data subject is free in the context of the use of information society services, and notwithstanding Directive 2002/58/EC, to use his or her right to object by automated means using technical specifications. h) Automated individual decision-making, including profiling Each data subject shall have the right granted by the European legislator not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects concerning him or her, or similarly significantly affects him or her, as long as the decision (1) is not is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) is not authorised by Union or Member State law to which the controller is subject and which also lays down suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, or (3) is not based on the data subject\u2019s explicit consent. If the decision (1) is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) it is based on the data subject\u2019s explicit consent, the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab shall implement suitable measures to safeguard the data subject\u2019s rights and freedoms and legitimate interests, at least the right to obtain human intervention on the part of the controller, to express his or her point of view and contest the decision. If the data subject wishes to exercise the rights concerning automated individual decision-making, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller. i) Right to withdraw data protection consent Each data subject shall have the right granted by the European legislator to withdraw his or her consent to processing of his or her personal data at any time. f the data subject wishes to exercise the right to withdraw the consent, he or she may at any time directly contact our Data Protection Officer of the TH K\u00f6ln, Fakult\u00e4t Informatik und Ingenieurwissenschaften, SPOTSeven Lab or another employee of the controller. Data protection provisions about the application and use of Facebook On this website, the controller has integrated components of the enterprise Facebook. Facebook is a social network. A social network is a place for social meetings on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Facebook allows social network users to include the creation of private profiles, upload photos, and network through friend requests. The operating company of Facebook is Facebook, Inc., 1 Hacker Way, Menlo Park, CA 94025, United States. If a person lives outside of the United States or Canada, the controller is the Facebook Ireland Ltd., 4 Grand Canal Square, Grand Canal Harbour, Dublin 2, Ireland. With each call-up to one of the individual pages of this Internet website, which is operated by the controller and into which a Facebook component (Facebook plug-ins) was integrated, the web browser on the information technology system of the data subject is automatically prompted to download display of the corresponding Facebook component from Facebook through the Facebook component. An overview of all the Facebook Plug-ins may be accessed under https://developers.facebook.com/docs/plugins/. During the course of this technical procedure, Facebook is made aware of what specific sub-site of our website was visited by the data subject. If the data subject is logged in at the same time on Facebook, Facebook detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-site of our Internet page was visited by the data subject. This information is collected through the Facebook component and associated with the respective Facebook account of the data subject. If the data subject clicks on one of the Facebook buttons integrated into our website, e.g. the \u201cLike\u201d button, or if the data subject submits a comment, then Facebook matches this information with the personal Facebook user account of the data subject and stores the personal data. Facebook always receives, through the Facebook component, information about a visit to our website by the data subject, whenever the data subject is logged in at the same time on Facebook during the time of the call-up to our website. This occurs regardless of whether the data subject clicks on the Facebook component or not. If such a transmission of information to Facebook is not desirable for the data subject, then he or she may prevent this by logging off from their Facebook account before a call-up to our website is made. The data protection guideline published by Facebook, which is available at https://facebook.com/about/privacy/, provides information about the collection, processing and use of personal data by Facebook. In addition, it is explained there what setting options Facebook offers to protect the privacy of the data subject. In addition, different configuration options are made available to allow the elimination of data transmission to Facebook, e.g. the Facebook blocker of the provider Webgraph, which may be obtained under http://webgraph.com/resources/facebookblocker/. These applications may be used by the data subject to eliminate a data transmission to Facebook. Data protection provisions about the application and use of Google+ On this website, the controller has integrated the Google+ button as a component. Google+ is a so-called social network. A social network is a social meeting place on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Google+ allows users of the social network to include the creation of private profiles, upload photos and network through friend requests. The operating company of Google+ is Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES. With each call-up to one of the individual pages of this website, which is operated by the controller and on which a Google+ button has been integrated, the Internet browser on the information technology system of the data subject automatically downloads a display of the corresponding Google+ button of Google through the respective Google+ button component. During the course of this technical procedure, Google is made aware of what specific sub-page of our website was visited by the data subject. More detailed information about Google+ is available under https://developers.google.com/+/. If the data subject is logged in at the same time to Google+, Google recognizes with each call-up to our website by the data subject and for the entire duration of his or her stay on our Internet site, which specific sub-pages of our Internet page were visited by the data subject. This information is collected through the Google+ button and Google matches this with the respective Google+ account associated with the data subject. If the data subject clicks on the Google+ button integrated on our website and thus gives a Google+ 1 recommendation, then Google assigns this information to the personal Google+ user account of the data subject and stores the personal data. Google stores the Google+ 1 recommendation of the data subject, making it publicly available in accordance with the terms and conditions accepted by the data subject in this regard. Subsequently, a Google+ 1 recommendation given by the data subject on this website together with other personal data, such as the Google+ account name used by the data subject and the stored photo, is stored and processed on other Google services, such as search-engine results of the Google search engine, the Google account of the data subject or in other places, e.g. on Internet pages, or in relation to advertisements. Google is also able to link the visit to this website with other personal data stored on Google. Google further records this personal information with the purpose of improving or optimizing the various Google services. Through the Google+ button, Google receives information that the data subject visited our website, if the data subject at the time of the call-up to our website is logged in to Google+. This occurs regardless of whether the data subject clicks or doesn\u2019t click on the Google+ button. If the data subject does not wish to transmit personal data to Google, he or she may prevent such transmission by logging out of his Google+ account before calling up our website. Further information and the data protection provisions of Google may be retrieved under https://www.google.com/intl/en/policies/privacy/. More references from Google about the Google+ 1 button may be obtained under https://developers.google.com/+/web/buttons-policy. Data protection provisions about the application and use of Jetpack for WordPress On this website, the controller has integrated Jetpack. Jetpack is a WordPress plug-in, which provides additional features to the operator of a website based on WordPress. Jetpack allows the Internet site operator, inter alia, an overview of the visitors of the site. By displaying related posts and publications, or the ability to share content on the page, it is also possible to increase visitor numbers. In addition, security features are integrated into Jetpack, so a Jetpack-using site is better protected against brute-force attacks. Jetpack also optimizes and accelerates the loading of images on the website. The operating company of Jetpack Plug-Ins for WordPress is the Automattic Inc., 132 Hawthorne Street, San Francisco, CA 94107, UNITED STATES. The operating enterprise uses the tracking technology created by Quantcast Inc., 201 Third Street, San Francisco, CA 94103, UNITED STATES. Jetpack sets a cookie on the information technology system used by the data subject. The definition of cookies is explained above. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Jetpack component was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to submit data through the Jetpack component for analysis purposes to Automattic. During the course of this technical procedure Automattic receives data that is used to create an overview of website visits. The data obtained in this way serves the analysis of the behaviour of the data subject, which has access to the Internet page of the controller and is analyzed with the aim to optimize the website. The data collected through the Jetpack component is not used to identify the data subject without a prior obtaining of a separate express consent of the data subject. The data comes also to the notice of Quantcast. Quantcast uses the data for the same purposes as Automattic. The data subject can, as stated above, prevent the setting of cookies through our website at any time by means of a corresponding adjustment of the web browser used and thus permanently deny the setting of cookies. Such an adjustment to the Internet browser used would also prevent Automattic/Quantcast from setting a cookie on the information technology system of the data subject. In addition, cookies already in use by Automattic/Quantcast may be deleted at any time via a web browser or other software programs. In addition, the data subject has the possibility of objecting to a collection of data relating to a use of this Internet site that are generated by the Jetpack cookie as well as the processing of these data by Automattic/Quantcast and the chance to preclude any such. For this purpose, the data subject must press the \u2018opt-out\u2019 button under the link https://www.quantcast.com/opt-out/ which sets an opt-out cookie. The opt-out cookie set with this purpose is placed on the information technology system used by the data subject. If the cookies are deleted on the system of the data subject, then the data subject must call up the link again and set a new opt-out cookie. With the setting of the opt-out cookie, however, the possibility exists that the websites of the controller are not fully usable anymore by the data subject. The applicable data protection provisions of Automattic may be accessed under https://automattic.com/privacy/. The applicable data protection provisions of Quantcast can be accessed under https://www.quantcast.com/privacy/. Data protection provisions about the application and use of LinkedIn The controller has integrated components of the LinkedIn Corporation on this website. LinkedIn is a web-based social network that enables users with existing business contacts to connect and to make new business contacts. Over 400 million registered people in more than 200 countries use LinkedIn. Thus, LinkedIn is currently the largest platform for business contacts and one of the most visited websites in the world. The operating company of LinkedIn is LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, UNITED STATES. For privacy matters outside of the UNITED STATES LinkedIn Ireland, Privacy Policy Issues, Wilton Plaza, Wilton Place, Dublin 2, Ireland, is responsible. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a LinkedIn component (LinkedIn plug-in) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to the download of a display of the corresponding LinkedIn component of LinkedIn. Further information about the LinkedIn plug-in may be accessed under https://developer.linkedin.com/plugins. During the course of this technical procedure, LinkedIn gains knowledge of what specific sub-page of our website was visited by the data subject. If the data subject is logged in at the same time on LinkedIn, LinkedIn detects with every call-up to our website by the data subject\u2014and for the entire duration of their stay on our Internet site\u2014which specific sub-page of our Internet page was visited by the data subject. This information is collected through the LinkedIn component and associated with the respective LinkedIn account of the data subject. If the data subject clicks on one of the LinkedIn buttons integrated on our website, then LinkedIn assigns this information to the personal LinkedIn user account of the data subject and stores the personal data. LinkedIn receives information via the LinkedIn component that the data subject has visited our website, provided that the data subject is logged in at LinkedIn at the time of the call-up to our website. This occurs regardless of whether the person clicks on the LinkedIn button or not. If such a transmission of information to LinkedIn is not desirable for the data subject, then he or she may prevent this by logging off from their LinkedIn account before a call-up to our website is made. LinkedIn provides under https://www.linkedin.com/psettings/guest-controls the possibility to unsubscribe from e-mail messages, SMS messages and targeted ads, as well as the ability to manage ad settings. LinkedIn also uses affiliates such as Eire, Google Analytics, BlueKai, DoubleClick, Nielsen, Comscore, Eloqua, and Lotame. The setting of such cookies may be denied under https://www.linkedin.com/legal/cookie-policy. The applicable privacy policy for LinkedIn is available under https://www.linkedin.com/legal/privacy-policy. The LinkedIn Cookie Policy is available under https://www.linkedin.com/legal/cookie-policy. Data protection provisions about the application and use of Twitter On this website, the controller has integrated components of Twitter. Twitter is a multilingual, publicly-accessible microblogging service on which users may publish and spread so-called \u2018tweets,\u2019 e.g. short messages, which are limited to 140 characters. These short messages are available for everyone, including those who are not logged on to Twitter. The tweets are also displayed to so-called followers of the respective user. Followers are other Twitter users who follow a user\u2019s tweets. Furthermore, Twitter allows you to address a wide audience via hashtags, links or retweets. The operating company of Twitter is Twitter, Inc., 1355 Market Street, Suite 900, San Francisco, CA 94103, UNITED STATES. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a Twitter component (Twitter button) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding Twitter component of Twitter. Further information about the Twitter buttons is available under https://about.twitter.com/de/resources/buttons. During the course of this technical procedure, Twitter gains knowledge of what specific sub-page of our website was visited by the data subject. The purpose of the integration of the Twitter component is a retransmission of the contents of this website to allow our users to introduce this web page to the digital world and increase our visitor numbers. If the data subject is logged in at the same time on Twitter, Twitter detects with every call-up to our website by the data subject and for the entire duration of their stay on our Internet site which specific sub-page of our Internet page was visited by the data subject. This information is collected through the Twitter component and associated with the respective Twitter account of the data subject. If the data subject clicks on one of the Twitter buttons integrated on our website, then Twitter assigns this information to the personal Twitter user account of the data subject and stores the personal data. Twitter receives information via the Twitter component that the data subject has visited our website, provided that the data subject is logged in on Twitter at the time of the call-up to our website. This occurs regardless of whether the person clicks on the Twitter component or not. If such a transmission of information to Twitter is not desirable for the data subject, then he or she may prevent this by logging off from their Twitter account before a call-up to our website is made. The applicable data protection provisions of Twitter may be accessed under https://twitter.com/privacy?lang=en. Data protection provisions about the application and use of YouTube On this website, the controller has integrated components of YouTube. YouTube is an Internet video portal that enables video publishers to set video clips and other users free of charge, which also provides free viewing, review and commenting on them. YouTube allows you to publish all kinds of videos, so you can access both full movies and TV broadcasts, as well as music videos, trailers, and videos made by users via the Internet portal. The operating company of YouTube is YouTube, LLC, 901 Cherry Ave., San Bruno, CA 94066, UNITED STATES. The YouTube, LLC is a subsidiary of Google Inc., 1600 Amphitheatre Pkwy, Mountain View, CA 94043-1351, UNITED STATES. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a YouTube component (YouTube video) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding YouTube component. Further information about YouTube may be obtained under https://www.youtube.com/yt/about/en/. During the course of this technical procedure, YouTube and Google gain knowledge of what specific sub-page of our website was visited by the data subject. If the data subject is logged in on YouTube, YouTube recognizes with each call-up to a sub-page that contains a YouTube video, which specific sub-page of our Internet site was visited by the data subject. This information is collected by YouTube and Google and assigned to the respective YouTube account of the data subject. YouTube and Google will receive information through the YouTube component that the data subject has visited our website, if the data subject at the time of the call to our website is logged in on YouTube; this occurs regardless of whether the person clicks on a YouTube video or not. If such a transmission of this information to YouTube and Google is not desirable for the data subject, the delivery may be prevented if the data subject logs off from their own YouTube account before a call-up to our website is made. YouTube\u2019s data protection provisions, available at https://www.google.com/intl/en/policies/privacy/, provide information about the collection, processing and use of personal data by YouTube and Google. Legal basis for the processing Art. 6(1) lit. a GDPR serves as the legal basis for processing operations for which we obtain consent for a specific processing purpose. If the processing of personal data is necessary for the performance of a contract to which the data subject is party, as is the case, for example, when processing operations are necessary for the supply of goods or to provide any other service, the processing is based on Article 6(1) lit. b GDPR. The same applies to such processing operations which are necessary for carrying out pre-contractual measures, for example in the case of inquiries concerning our products or services. Is our company subject to a legal obligation by which processing of personal data is required, such as for the fulfillment of tax obligations, the processing is based on Art. 6(1) lit. c GDPR. In rare cases, the processing of personal data may be necessary to protect the vital interests of the data subject or of another natural person. This would be the case, for example, if a visitor were injured in our company and his name, age, health insurance data or other vital information would have to be passed on to a doctor, hospital or other third party. Then the processing would be based on Art. 6(1) lit. d GDPR. Finally, processing operations could be based on Article 6(1) lit. f GDPR. This legal basis is used for processing operations which are not covered by any of the abovementioned legal grounds, if processing is necessary for the purposes of the legitimate interests pursued by our company or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data. Such processing operations are particularly permissible because they have been specifically mentioned by the European legislator. He considered that a legitimate interest could be assumed if the data subject is a client of the controller (Recital 47 Sentence 2 GDPR). The legitimate interests pursued by the controller or by a third party Where the processing of personal data is based on Article 6(1) lit. f GDPR our legitimate interest is to carry out our business in favor of the well-being of all our employees and the shareholders. Period for which the personal data will be stored The criteria used to determine the period of storage of personal data is the respective statutory retention period. After expiration of that period, the corresponding data is routinely deleted, as long as it is no longer necessary for the fulfillment of the contract or the initiation of a contract. Provision of personal data as statutory or contractual requirement; Requirement necessary to enter into a contract; Obligation of the data subject to provide the personal data; possible consequences of failure to provide such data We clarify that the provision of personal data is partly required by law (e.g. tax regulations) or can also result from contractual provisions (e.g. information on the contractual partner). Sometimes it may be necessary to conclude a contract that the data subject provides us with personal data, which must subsequently be processed by us. The data subject is, for example, obliged to provide us with personal data when our company signs a contract with him or her. The non-provision of the personal data would have the consequence that the contract with the data subject could not be concluded. Before personal data is provided by the data subject, the data subject must contact our Data Protection Officer. Our Data Protection Officer clarifies to the data subject whether the provision of the personal data is required by law or contract or is necessary for the conclusion of the contract, whether there is an obligation to provide the personal data and the consequences of non-provision of the personal data. Existence of automated decision-making As a responsible company, we do not use automatic decision-making or profiling. This Privacy Policy has been generated by the Privacy Policy Generator of the External Data Protection Officers that was developed in cooperation with RC GmbH, which sells used notebooks and the Media Law Lawyers from WBS-LAW.","title":"Privacy Policy"},{"location":"download/","text":"Install spotPython pip install spotPython","title":"Download"},{"location":"download/#install-spotpython","text":"pip install spotPython","title":"Install spotPython"},{"location":"examples/","text":"SPOT Examples Simple spotPython run import numpy as np from spotPython.fun.objectivefunctions import analytical from spotPython.spot import spot import numpy as np from math import inf number of initial points: ni = 7 number of points n = 10 fun = analytical().fun_sphere lower = np.array([-1]) upper = np.array([1]) design_control={\"init_size\": ni} spot_1 = spot.Spot(fun=fun, lower = lower, upper= upper, fun_evals = n, show_progress=True, design_control=design_control,) spot_1.run()","title":"Examples"},{"location":"examples/#spot-examples","text":"","title":"SPOT Examples"},{"location":"examples/#simple-spotpython-run","text":"import numpy as np from spotPython.fun.objectivefunctions import analytical from spotPython.spot import spot import numpy as np from math import inf","title":"Simple spotPython run"},{"location":"examples/#number-of-initial-points","text":"ni = 7","title":"number of initial points:"},{"location":"examples/#number-of-points","text":"n = 10 fun = analytical().fun_sphere lower = np.array([-1]) upper = np.array([1]) design_control={\"init_size\": ni} spot_1 = spot.Spot(fun=fun, lower = lower, upper= upper, fun_evals = n, show_progress=True, design_control=design_control,) spot_1.run()","title":"number of points"},{"location":"reference/SUMMARY/","text":"spotPython _version budget ocba build kriging surrogates design designs factorial spacefilling fun objectivefunctions plot contour spot spot utils aggregate compare progress repair transform","title":"SUMMARY"},{"location":"reference/spotPython/_version/","text":"","title":"_version"},{"location":"reference/spotPython/budget/ocba/","text":"OCBA: Optimal Computing Budget Allocation get_ocba ( means , vars , delta ) Optimal Computer Budget Allocation (OCBA) References Chun-Hung Chen and Loo Hay Lee: Stochastic Simulation Optimization: An Optimal Computer Budget Allocation, pp. 49 and pp. 215 C.S.M Currie and T. Monks: How to choose the best setup for a system. A tutorial for the Simulation Workshop 2021, see: https://colab.research.google.com/github/TomMonks/sim-tools/blob/master/examples/sw21_tutorial.ipynb and https://github.com/TomMonks/sim-tools Examples: From the Chen et al. book (p. 49): mean_y = np.array([1,2,3,4,5]) var_y = np.array([1,1,9,9,4]) get_ocba(mean_y, var_y, 50) [11 9 19 9 2] Args: means (numpy.array): means vars (numpy.array): variances delta (int): incremental budget Returns: (numpy.array): budget recommendations. (n,) numpy.array Source code in spotPython/budget/ocba.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def get_ocba ( means , vars , delta ): \"\"\" Optimal Computer Budget Allocation (OCBA) References: Chun-Hung Chen and Loo Hay Lee: Stochastic Simulation Optimization: An Optimal Computer Budget Allocation, pp. 49 and pp. 215 C.S.M Currie and T. Monks: How to choose the best setup for a system. A tutorial for the Simulation Workshop 2021, see: https://colab.research.google.com/github/TomMonks/sim-tools/blob/master/examples/sw21_tutorial.ipynb and https://github.com/TomMonks/sim-tools Examples: From the Chen et al. book (p. 49): mean_y = np.array([1,2,3,4,5]) var_y = np.array([1,1,9,9,4]) get_ocba(mean_y, var_y, 50) [11 9 19 9 2] Args: means (numpy.array): means vars (numpy.array): variances delta (int): incremental budget Returns: (numpy.array): budget recommendations. `(n,)` numpy.array \"\"\" n_designs = means . shape [ 0 ] allocations = zeros ( n_designs , int32 ) ratios = zeros ( n_designs , float64 ) budget = delta ranks = get_ranks ( means ) best , second_best = argpartition ( ranks , 2 )[: 2 ] ratios [ second_best ] = 1.0 select = [ i for i in range ( n_designs ) if i not in [ best , second_best ]] temp = ( means [ best ] - means [ second_best ]) / ( means [ best ] - means [ select ]) ratios [ select ] = square ( temp ) * ( vars [ select ] / vars [ second_best ]) select = [ i for i in range ( n_designs ) if i not in [ best ]] temp = ( square ( ratios [ select ]) / vars [ select ]) . sum () ratios [ best ] = sqrt ( vars [ best ] * temp ) more_runs = full ( n_designs , True , dtype = bool ) add_budget = zeros ( n_designs , dtype = float ) more_alloc = True while more_alloc : more_alloc = False ratio_s = ( more_runs * ratios ) . sum () add_budget [ more_runs ] = ( budget / ratio_s ) * ratios [ more_runs ] add_budget = around ( add_budget ) . astype ( int ) mask = add_budget < allocations add_budget [ mask ] = allocations [ mask ] more_runs [ mask ] = 0 if mask . sum () > 0 : more_alloc = True if more_alloc : budget = allocations . sum () + delta budget -= ( add_budget * ~ more_runs ) . sum () t_budget = add_budget . sum () add_budget [ best ] += allocations . sum () + delta - t_budget return add_budget - allocations","title":"ocba"},{"location":"reference/spotPython/budget/ocba/#spotPython.budget.ocba.get_ocba","text":"Optimal Computer Budget Allocation (OCBA) References Chun-Hung Chen and Loo Hay Lee: Stochastic Simulation Optimization: An Optimal Computer Budget Allocation, pp. 49 and pp. 215 C.S.M Currie and T. Monks: How to choose the best setup for a system. A tutorial for the Simulation Workshop 2021, see: https://colab.research.google.com/github/TomMonks/sim-tools/blob/master/examples/sw21_tutorial.ipynb and https://github.com/TomMonks/sim-tools Examples: From the Chen et al. book (p. 49): mean_y = np.array([1,2,3,4,5]) var_y = np.array([1,1,9,9,4]) get_ocba(mean_y, var_y, 50) [11 9 19 9 2] Args: means (numpy.array): means vars (numpy.array): variances delta (int): incremental budget Returns: (numpy.array): budget recommendations. (n,) numpy.array Source code in spotPython/budget/ocba.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def get_ocba ( means , vars , delta ): \"\"\" Optimal Computer Budget Allocation (OCBA) References: Chun-Hung Chen and Loo Hay Lee: Stochastic Simulation Optimization: An Optimal Computer Budget Allocation, pp. 49 and pp. 215 C.S.M Currie and T. Monks: How to choose the best setup for a system. A tutorial for the Simulation Workshop 2021, see: https://colab.research.google.com/github/TomMonks/sim-tools/blob/master/examples/sw21_tutorial.ipynb and https://github.com/TomMonks/sim-tools Examples: From the Chen et al. book (p. 49): mean_y = np.array([1,2,3,4,5]) var_y = np.array([1,1,9,9,4]) get_ocba(mean_y, var_y, 50) [11 9 19 9 2] Args: means (numpy.array): means vars (numpy.array): variances delta (int): incremental budget Returns: (numpy.array): budget recommendations. `(n,)` numpy.array \"\"\" n_designs = means . shape [ 0 ] allocations = zeros ( n_designs , int32 ) ratios = zeros ( n_designs , float64 ) budget = delta ranks = get_ranks ( means ) best , second_best = argpartition ( ranks , 2 )[: 2 ] ratios [ second_best ] = 1.0 select = [ i for i in range ( n_designs ) if i not in [ best , second_best ]] temp = ( means [ best ] - means [ second_best ]) / ( means [ best ] - means [ select ]) ratios [ select ] = square ( temp ) * ( vars [ select ] / vars [ second_best ]) select = [ i for i in range ( n_designs ) if i not in [ best ]] temp = ( square ( ratios [ select ]) / vars [ select ]) . sum () ratios [ best ] = sqrt ( vars [ best ] * temp ) more_runs = full ( n_designs , True , dtype = bool ) add_budget = zeros ( n_designs , dtype = float ) more_alloc = True while more_alloc : more_alloc = False ratio_s = ( more_runs * ratios ) . sum () add_budget [ more_runs ] = ( budget / ratio_s ) * ratios [ more_runs ] add_budget = around ( add_budget ) . astype ( int ) mask = add_budget < allocations add_budget [ mask ] = allocations [ mask ] more_runs [ mask ] = 0 if mask . sum () > 0 : more_alloc = True if more_alloc : budget = allocations . sum () + delta budget -= ( add_budget * ~ more_runs ) . sum () t_budget = add_budget . sum () add_budget [ best ] += allocations . sum () + delta - t_budget return add_budget - allocations","title":"get_ocba()"},{"location":"reference/spotPython/build/kriging/","text":"Kriging Bases: surrogates Source code in spotPython/build/kriging.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 class Kriging ( surrogates ): def __init__ ( self , noise = False , cod_type = \"norm\" , var_type = [ \"num\" ], use_cod_y = False , name = \"kriging\" , seed = 124 , model_optimizer = None , model_fun_evals = None , min_theta =- 3 , # TODO max_theta = 2 , # TODO n_theta = 1 , n_p = 1 , optim_p = False , log_level = 50 , ** kwargs ): \"\"\" Kriging surrogate. Args: noise (bool): use regression instead of interpolation kriging. Defaults to \"False\". cod_type (bool): normalize or standardize X and values. Can be None, \"norm\", or \"std\". Defaults to \"norm\". var_type (str): variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor). Defaults to `\"num\"`. use_cod_y (bool): use coded y values (instead of natural one). Defaults to `False`. name (str): Surrogate name. Defaults to `\"kriging\"`. seed (int): Random seed. Defaults to `124`. model_optimizer (object): Optimizer on the surrogate. If `None`, `differential_evolution` is selected. model_fun_evals (int): Number of iterations used by the optimizer on the surrogate. min_theta (float): min log10 theta value. Defaults to `-6.`. max_theta (float): max log10 theta value. Defaults to `3.`. n_theta (int): number of theta values. Defaults to `1`. n_p (int): number of p values. Defaults to `1`. optim_p (bool): Determines whether `p` should be optimized. log_level (int): logging level, e.g., `20` is `\"INFO\"`. Defaults to `50` (`\"CRITICAL\"`). Attributes: nat_range_X (list): List of X natural ranges. nat_range_y (list): List of y nat ranges. noise (bool): noisy objective function. Default: False. If `True`, regression kriging will be used. var_type (str): variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor). num_mask (array): array of bool variables. `True` represent numerical (float) variables. factor_mask (array): array of factor variables. `True` represents factor (unordered) variables. int_mask (array): array of integer variables. `True` represents integers (ordered) variables. ordered_mask (array): array of ordered variables. `True` represents integers or float (ordered) variables. Set of veriables which an order relation, i.e., they are either num (float) or int. name (str): Surrogate name seed (int): Random seed. use_cod_y (bool): Use coded y values. sigma (float): Kriging sigma. gen (method): Design generator, e.g., spotPython.design.spacefilling.spacefilling. min_theta (float): min log10 theta value. Defaults: -6. max_theta (float): max log10 theta value. Defaults: 3. min_p (float): min p value. Default: 1. max_p (float): max p value. Default: 2. Examples: Surrogate of the x*sin(x) function. See: [scikit-learn](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html) >>> from spotPython.build.kriging import Kriging >>> import numpy as np >>> import matplotlib.pyplot as plt >>> rng = np.random.RandomState(1) >>> X = linspace(start=0, stop=10, num=1_000).reshape(-1, 1) >>> y = np.squeeze(X * np.sin(X)) >>> training_indices = rng.choice(arange(y.size), size=6, replace=False) >>> X_train, y_train = X[training_indices], y[training_indices] >>> S = Kriging(name='kriging', seed=124) >>> S.fit(X_train, y_train) >>> mean_prediction, std_prediction = S.predict(X) >>> plt.plot(X, y, label=r\"$f(x)$\", linestyle=\"dotted\") >>> plt.scatter(X_train, y_train, label=\"Observations\") >>> plt.plot(X, mean_prediction, label=\"Mean prediction\") >>> plt.fill_between( X.ravel(), mean_prediction - 1.96 * std_prediction, mean_prediction + 1.96 * std_prediction, alpha=0.5, label=r\"95% confidence interval\", ) >>> plt.legend() >>> plt.xlabel(\"$x$\") >>> plt.ylabel(\"$f(x)$\") >>> _ = plt.title(\"Gaussian process regression on noise-free dataset\") \"\"\" super () . __init__ ( name , seed , log_level ) self . noise = noise self . var_type = var_type self . cod_type = cod_type self . use_cod_y = use_cod_y self . name = name self . seed = seed self . log_level = log_level self . sigma = 0 self . eps = sqrt ( spacing ( 1 )) self . min_theta = min_theta self . max_theta = max_theta self . min_p = 1 self . max_p = 2 self . min_Lambda = 1e-9 self . max_Lambda = 1. self . n_theta = n_theta self . n_p = n_p self . optim_p = optim_p # Psi matrix condition: self . cnd_Psi = 0 self . inf_Psi = False self . model_optimizer = model_optimizer if self . model_optimizer is None : self . model_optimizer = differential_evolution self . model_fun_evals = model_fun_evals # differential evaluation uses maxiter = 1000 # and sets the number of function evaluations to # (maxiter + 1) * popsize * N, which results in # 1000 * 15 * k, because the default popsize is 15 and # N is the number of parameters. This seems to be quite large: # for k=2 these are 30 000 iterations. Therefore we set this value to # 100 if self . model_fun_evals is None : self . model_fun_evals = 100 # Logging information self . log [ \"negLnLike\" ] = [] self . log [ \"theta\" ] = [] self . log [ \"p\" ] = [] self . log [ \"Lambda\" ] = [] # Logger logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) def exp_imp ( self , y0 , s0 ): \"\"\" Returns the expected improvement for y0 and error s0 (in coded units). Args: y0 (float): function value (in coded units) s0 (float): error Returns: (float): The expected improvement value. \"\"\" # y_min = min(self.cod_y) y_min = min ( self . mean_cod_y ) if s0 <= 0.0 : EI = 0.0 elif s0 > 0.0 : EI_one = ( y_min - y0 ) * ( 0.5 + 0.5 * erf (( 1.0 / sqrt ( 2.0 )) * (( y_min - y0 ) / s0 )) ) EI_two = ( s0 * ( 1.0 / sqrt ( 2.0 * pi ))) * ( exp ( - ( 1.0 / 2.0 ) * (( y_min - y0 ) ** 2.0 / s0 ** 2.0 )) ) EI = EI_one + EI_two return EI def set_de_bounds ( self ): \"\"\" Determine search bounds for model_optimizer, e.g., differential evolution. \"\"\" de_bounds = [] for i in range ( self . n_theta ): de_bounds . append ([ self . min_theta , self . max_theta ]) if self . optim_p : for i in range ( self . n_p ): de_bounds . append ([ self . min_p , self . max_p ]) if self . noise : de_bounds . append ([ self . min_Lambda , self . max_Lambda ]) else : if self . noise : de_bounds . append ([ self . min_Lambda , self . max_Lambda ]) self . de_bounds = de_bounds def extract_from_bounds ( self , new_theta_p_Lambda ): \"\"\" Extract `theta`, `p`, and `Lambda` from bounds. The kriging object stores `theta` as an array, `p` as an array, and `Lambda` as a float. Args: new_theta_p_Lambda (numpy.array): 1d-array with theta, p, and Lambda values. Order is important. \"\"\" for i in range ( self . n_theta ): self . theta [ i ] = new_theta_p_Lambda [ i ] if self . optim_p : for i in range ( self . n_p ): self . p [ i ] = new_theta_p_Lambda [ i + self . n_theta ] if self . noise : self . Lambda = new_theta_p_Lambda [ self . n_theta + self . n_p ] else : if self . noise : self . Lambda = new_theta_p_Lambda [ self . n_theta ] def fit ( self , nat_X , nat_y ): \"\"\" The function fits the hyperparameters (`theta`, `p`, `Lambda`) of the Kriging model, i.e., the following internal values are computed: 1. `theta`, `p`, and `Lambda` values via optimization of the function `fun_likelihood()`. 2. Correlation matrix `Psi` via `rebuildPsi()`. Args: nat_X (array): sample points nat_y (array): function values Returns: surrogate (object): Fitted estimator. Attributes: theta (numpy.ndarray): Kriging theta values. Shape (k,). p (numpy.ndarray): Kriging p values. Shape (k,). LnDetPsi (numpy.float64): Determinant Psi matrix. Psi (numpy.matrix): Correlation matrix Psi. Shape (n,n). psi (numpy.ndarray): psi vector. Shape (n,). one (numpy.ndarray): vector of ones. Shape (n,). mu (numpy.float64): Kriging expected mean value mu. U (numpy.matrix): Kriging U matrix, Cholesky decomposition. Shape (n,n). SigmaSqr (numpy.float64): Sigma squared value. Lambda (float): lambda noise value. \"\"\" self . nat_X = copy . deepcopy ( nat_X ) self . nat_y = copy . deepcopy ( nat_y ) self . n = self . nat_X . shape [ 0 ] self . k = self . nat_X . shape [ 1 ] self . cod_X = empty_like ( self . nat_X ) self . cod_y = empty_like ( self . nat_y ) # assume all variable types are \"num\" if \"num\" is # specified once: if len ( self . var_type ) < self . k : self . var_type = self . var_type * self . k logger . warning ( \"Warning: All variable types forced to 'num'.\" ) self . num_mask = array ( list ( map ( lambda x : x == \"num\" , self . var_type ))) self . factor_mask = array ( list ( map ( lambda x : x == \"factor\" , self . var_type ))) self . int_mask = array ( list ( map ( lambda x : x == \"int\" , self . var_type ))) self . ordered_mask = array ( list ( map ( lambda x : x == \"int\" or x == \"num\" , self . var_type ))) self . nat_to_cod_init () if self . n_theta > self . k : self . n_theta = self . k logger . warning ( \"Warning: More theta values than dimensions. `n_theta` set to `k`.\" ) self . theta = zeros ( self . n_theta ) # TODO: Currently not used: self . x0_theta = ones (( self . n_theta ,)) * self . n / ( 100 * self . k ) self . p = ones ( self . n_p ) * 2.0 self . pen_val = self . n * log ( var ( self . nat_y )) + 1e4 self . negLnLike = None self . gen = spacefilling ( k = self . k , seed = self . seed ) # matrix related self . LnDetPsi = None self . Psi = zeros (( self . n , self . n ), dtype = float64 ) self . psi = zeros (( self . n , 1 )) self . one = ones ( self . n ) self . mu = None self . U = None self . SigmaSqr = None self . Lambda = None # build_Psi() and build_U() are called in fun_likelihood self . set_de_bounds () if self . model_optimizer . __name__ == 'dual_annealing' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) elif self . model_optimizer . __name__ == 'differential_evolution' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds , maxiter = self . model_fun_evals , seed = self . seed ) elif self . model_optimizer . __name__ == 'direct' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds , # maxfun=self.model_fun_evals, eps = 1e-2 ) elif self . model_optimizer . __name__ == 'shgo' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) elif self . model_optimizer . __name__ == 'basinhopping' : result = self . model_optimizer ( func = self . fun_likelihood , x0 = mean ( self . de_bounds , axis = 1 )) else : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) # Finally, set new theta and p values and update the surrogate again # for new_theta_p_Lambda in de_results[\"x\"]: new_theta_p_Lambda = result [ \"x\" ] self . extract_from_bounds ( new_theta_p_Lambda ) self . build_Psi () self . build_U () # TODO: check if the following line is necessary! self . likelihood () self . log [ \"negLnLike\" ] = append ( self . log [ \"negLnLike\" ], self . negLnLike ) self . log [ \"theta\" ] = append ( self . log [ \"theta\" ], self . theta ) self . log [ \"p\" ] = append ( self . log [ \"p\" ], self . p ) self . log [ \"Lambda\" ] = append ( self . log [ \"Lambda\" ], self . Lambda ) # TODO: return self def fun_likelihood ( self , new_theta_p_Lambda ): \"\"\" Compute log likelihood for a set of hyperparameters (theta, p, Lambda). Performs the following steps: 1. Build Psi via `build_Psi()` and `build_U()`. 2. Compute negLnLikelihood via `likelihood() 3. If successful, the return `negLnLike` value, otherwise a penalty value (`pen_val`). Args: new_theta_p_Lambda (array): `theta`, `p`, and `Lambda` values stored in an array. Returns: (float): negLnLike, th negative log likelihood of the surface at the hyperparameters specified. \"\"\" self . extract_from_bounds ( new_theta_p_Lambda ) if self . __is_any__ ( power ( 10.0 , self . theta ), 0 ): # print(f\"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to {self.pen_val:.2f}.\") logger . warning ( \"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to %s \" , self . pen_val ) return self . pen_val self . build_Psi () if ( self . inf_Psi or self . cnd_Psi > 1e9 ): # print(f\"\\nFailure in fun_likelihood: Psi is ill conditioned ({self.cnd_Psi}).\") # print(f\"Setting negLnLike to {self.pen_val:.2f}.\") logger . warning ( \"Failure in fun_likelihood: Psi is ill conditioned: %s \" , self . cnd_Psi ) logger . warning ( \"Setting negLnLike to: %s \" , self . pen_val ) return self . pen_val else : try : self . build_U () except Exception as err : f = self . pen_val print ( f \"Error in fun_likelihood(). Call to build_U() failed. { err =} , { type ( err ) =} \" ) print ( f \"Setting negLnLike to { self . pen_val : .2f } .\" ) return f self . likelihood () return self . negLnLike def __is_any__ ( self , x , v ): if not isinstance ( x , ndarray ): x = array ([ x ]) return any ( x == v ) def build_Psi ( self ): \"\"\" New construction (rebuild to reflect new data or a change in hyperparameters) of the (nxn) correlation matrix Psi as described in [Forr08a, p.57]. Note: Method uses `theta`, `p`, and coded `X` values. \"\"\" self . Psi = zeros (( self . n , self . n ), dtype = float64 ) theta = power ( 10.0 , self . theta ) if self . n_theta == 1 : theta = theta * ones ( self . k ) try : D = zeros (( self . n , self . n )) if self . ordered_mask . any (): X_ordered = self . cod_X [:, self . ordered_mask ] D = squareform ( pdist ( X_ordered , metric = 'sqeuclidean' , out = None , w = theta [ self . ordered_mask ])) if self . factor_mask . any (): X_factor = self . cod_X [:, self . factor_mask ] D = ( D + squareform ( pdist ( X_factor , metric = 'hamming' , out = None , w = theta [ self . factor_mask ]))) self . Psi = exp ( - D ) except LinAlgError as err : print ( f \"Building Psi failed: \\n { self . Psi } . { err =} , { type ( err ) =} \" ) if self . noise : self . Psi = self . Psi + multiply ( eye ( self . n ), self . Lambda ) else : self . Psi = self . Psi + multiply ( eye ( self . n ), self . eps ) if ( isinf ( self . Psi )) . any (): self . inf_Psi = True self . cnd_Psi = cond ( self . Psi ) def build_U ( self , scipy = True ): \"\"\" Cholesky factorization of Psi as U as described in [Forr08a, p.57]. Args: scipy (bool): Use `scipy_cholesky`. If `False`, numpy's `cholesky` is used. \"\"\" try : if scipy : self . U = scipy_cholesky ( self . Psi , lower = True ) else : self . U = cholesky ( self . Psi ) self . U = self . U . T except LinAlgError as err : print ( f \"build_U() Cholesky failed for Psi: \\n { self . Psi } . { err =} , { type ( err ) =} \" ) def likelihood ( self ): \"\"\" Calculates the negative of the concentrated log-likelihood. Implementation of (2.32) in [Forr08a]. See also function krigingLikelihood() in spot. Note: `build_Psi` and `build_U` should be called first. Modifies: `mu`, `SigmaSqr`, `LnDetPsi`, and `negLnLike`, concentrated log-likelihood *-1 for minimizing \"\"\" # (2.20) in [Forr08a]: mu = ( self . one . T . dot ( solve ( self . U , solve ( self . U . T , self . cod_y )) ) ) / self . one . T . dot ( solve ( self . U , solve ( self . U . T , self . one ))) self . mu = mu # (2.31) in [Forr08a] self . SigmaSqr = ( ( self . cod_y - self . one . dot ( self . mu )) . T . dot ( solve ( self . U , solve ( self . U . T , ( self . cod_y - self . one . dot ( self . mu ))), ) ) ) / self . n # (2.32) in [Forr08a] self . LnDetPsi = 2.0 * sum ( log ( abs ( diag ( self . U )))) self . negLnLike = - 1.0 * ( - ( self . n / 2.0 ) * log ( self . SigmaSqr ) - 0.5 * self . LnDetPsi ) def plot ( self , show = True ): \"\"\" This function plots 1d and 2d surrogates. Args: show (boolean): If `True`, the plots are displayed. If `False`, `plt.show()` should be called outside this function. \"\"\" if self . k == 1 : # TODO: Improve plot (add conf. interval etc.) fig = pylab . figure ( figsize = ( 9 , 6 )) # t1 = array(arange(0.0, 1.0, 0.01)) # y1 = array([self.predict(array([x]), return_val=\"y\") for x in t1]) # plt.figure() # plt.plot(t1, y1, \"k\") # if show: # plt.show() # n_grid = 100 x = linspace ( self . nat_range_X [ 0 ][ 0 ], self . nat_range_X [ 0 ][ 1 ], num = n_grid ) y = self . predict ( x ) plt . figure () plt . plot ( x , y , \"k\" ) if show : plt . show () if self . k == 2 : fig = pylab . figure ( figsize = ( 9 , 6 )) n_grid = 100 x = linspace ( self . nat_range_X [ 0 ][ 0 ], self . nat_range_X [ 0 ][ 1 ], num = n_grid ) y = linspace ( self . nat_range_X [ 1 ][ 0 ], self . nat_range_X [ 1 ][ 1 ], num = n_grid ) X , Y = meshgrid ( x , y ) # Predict based on the optimized results zz = array ( [ self . predict ( array ([ x , y ]), return_val = \"all\" ) for x , y in zip ( ravel ( X ), ravel ( Y ))] ) zs = zz [:, 0 , :] zse = zz [:, 1 , :] Z = zs . reshape ( X . shape ) Ze = zse . reshape ( X . shape ) if self . cod_type == \"norm\" : nat_point_X = ( self . cod_X [:, 0 ] * ( self . nat_range_X [ 0 ][ 1 ] - self . nat_range_X [ 0 ][ 0 ]) ) + self . nat_range_X [ 0 ][ 0 ] nat_point_Y = ( self . cod_X [:, 1 ] * ( self . nat_range_X [ 1 ][ 1 ] - self . nat_range_X [ 1 ][ 0 ]) ) + self . nat_range_X [ 1 ][ 0 ] elif self . cod_type == \"std\" : nat_point_X = self . cod_X [:, 0 ] * self . nat_std_X [ 0 ] + self . nat_mean_X [ 0 ] nat_point_Y = self . cod_X [:, 1 ] * self . nat_std_X [ 1 ] + self . nat_mean_X [ 1 ] else : nat_point_X = self . cod_X [:, 0 ] nat_point_Y = self . cod_X [:, 1 ] contour_levels = 30 ax = fig . add_subplot ( 224 ) # plot predicted values: pylab . contourf ( X , Y , Ze , contour_levels , cmap = \"jet\" ) pylab . title ( \"Error\" ) pylab . colorbar () # plot observed points: pylab . plot ( nat_point_X , nat_point_Y , \"ow\" ) # ax = fig . add_subplot ( 223 ) # plot predicted values: plt . contourf ( X , Y , Z , contour_levels , zorder = 1 , cmap = \"jet\" ) plt . title ( \"Surrogate\" ) # plot observed points: pylab . plot ( nat_point_X , nat_point_Y , \"ow\" , zorder = 3 ) pylab . colorbar () # ax = fig . add_subplot ( 221 , projection = \"3d\" ) ax . plot_surface ( X , Y , Z , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" ) # ax = fig . add_subplot ( 222 , projection = \"3d\" ) ax . plot_surface ( X , Y , Ze , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" ) # pylab . show () def predict ( self , nat_X , nat = True , return_val = \"y\" ): \"\"\" This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X. Args: nat_X (array): Design variable to evaluate in natural units. nat (bool): argument `nat_X` is in natural range. Default: `True`. If set to `False`, `nat_X` will not be normalized (which might be useful if already normalized y values are used). return_val (string): whether `y`, `s`, neg. `ei` (negative expected improvement), or all three values are returned. Default is (for compatibility with sklearn) \"y\". To return `s`, select \"s\", to return neg. `ei`, select \"ei\". To return the tuple `(y, s, ei)`, select \"all\". Returns: (float): The predicted value in natural units. (float): predicted error (float): expected improvement \"\"\" # Check for the shape and the type of the Input if isinstance ( nat_X , ndarray ): try : X = nat_X . reshape ( - 1 , self . nat_X . shape [ 1 ]) X = repair_non_numeric ( X , self . var_type ) except Exception : raise TypeError ( \"13.1: Input to predict was not convertible to the size of X\" ) else : raise TypeError ( f \"type of the given input is an { type ( nat_X ) } instead of an ndarray\" ) # Iterate through the Input y = array ([], dtype = float ) s = array ([], dtype = float ) ei = array ([], dtype = float ) for i in range ( X . shape [ 0 ]): # logger.debug(f\"13.2: predict() Step 2: x (reshaped nat_X):\\n {x}\") if nat : x = self . nat_to_cod_x ( X [ i , :]) else : x = X [ i , :] y0 , s0 , ei0 = self . predict_coded ( x ) y = append ( y , y0 ) s = append ( s , s0 ) ei = append ( ei , ei0 ) if return_val == \"y\" : return y elif return_val == \"s\" : return s elif return_val == \"ei\" : return - 1.0 * ei else : return y , s , - 1.0 * ei def build_psi_vec ( self , cod_x ): \"\"\" Build the psi vector. Needed by `predict_cod`, `predict_err_coded`, `regression_predict_coded`. Modifies `self.psi`. Args: cod_x (array): point to calculate psi \"\"\" self . psi = zeros (( self . n )) # theta = self.theta # TODO: theta = power ( 10.0 , self . theta ) if self . n_theta == 1 : theta = theta * ones ( self . k ) try : D = zeros (( self . n )) if self . ordered_mask . any (): X_ordered = self . cod_X [:, self . ordered_mask ] x_ordered = cod_x [ self . ordered_mask ] D = cdist ( x_ordered . reshape ( - 1 , sum ( self . ordered_mask )), X_ordered . reshape ( - 1 , sum ( self . ordered_mask )), metric = 'sqeuclidean' , out = None , w = theta [ self . ordered_mask ]) if self . factor_mask . any (): X_factor = self . cod_X [:, self . factor_mask ] x_factor = cod_x [ self . factor_mask ] D = ( D + cdist ( x_factor . reshape ( - 1 , sum ( self . factor_mask )), X_factor . reshape ( - 1 , sum ( self . factor_mask )), metric = 'hamming' , out = None , w = theta [ self . factor_mask ])) self . psi = exp ( - D ) . T except LinAlgError as err : print ( f \"Building psi failed: \\n { self . psi } . { err =} , { type ( err ) =} \" ) def predict_coded ( self , cod_x ): \"\"\" Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a]. The error is returned as well. See also [Forr08a, p.60]. Note: `self.mu` and `self.SigmaSqr` are computed in `likelihood`, not here. Args: cod_x (array): point in coded units to make prediction at Returns: (float): predicted value in coded units. (float): predicted error. \"\"\" self . build_psi_vec ( cod_x ) f = self . mu + self . psi . T . dot ( solve ( self . U , solve ( self . U . T , self . cod_y - self . one . dot ( self . mu ))) ) try : if self . noise : Lambda = self . Lambda else : Lambda = 0.0 # Error in [Forr08a, p.87]: SSqr = self . SigmaSqr * ( 1 + Lambda - self . psi . T . dot ( solve ( self . U , solve ( self . U . T , self . psi )))) except Exception as err : print ( f \"Could not determine SSqr. Wrong or missing Lambda? { err =} , { type ( err ) =} \" ) SSqr = power ( abs ( SSqr [ 0 ]), 0.5 )[ 0 ] EI = self . exp_imp ( y0 = f [ 0 ], s0 = SSqr ) return f [ 0 ], SSqr , EI def weighted_exp_imp ( self , cod_x , w ): \"\"\" Weighted expected improvement. References: [Sobester et al. 2005]. Args: cod_x (array): A coded design vector. w (float): weight Returns: (float): weighted expected improvement. \"\"\" y0 , s0 = self . predict_coded ( cod_x ) y_min = min ( self . cod_y ) if s0 <= 0.0 : EI = 0.0 elif s0 > 0.0 : EI_one = w * ( ( y_min - y0 ) * ( 0.5 + 0.5 * erf (( 1.0 / sqrt ( 2.0 )) * (( y_min - y0 ) / s0 ))) ) EI_two = ( ( 1.0 - w ) * ( s0 * ( 1.0 / sqrt ( 2.0 * pi ))) * ( exp ( - ( 1.0 / 2.0 ) * (( y_min - y0 ) ** 2.0 / s0 ** 2.0 ))) ) EI = EI_one + EI_two return EI def calculate_mean_MSE ( self , n_samples = 200 , points = None ): \"\"\" This function calculates the mean MSE metric of the model by evaluating MSE at a number of points. Args: n_samples (integer): Number of points to sample the mean squared error at. Ignored if the points argument is specified. points (array): an array of points to sample the model at. Returns: (float): the mean value of MSE and the standard deviation of the MSE points \"\"\" if points is None : points = self . gen . lhd ( n_samples ) values = zeros ( len ( points )) for enu , point in enumerate ( points ): s0 = self . predict ( cod_X = point , nat = True , return_val = \"s\" ) values [ enu ] = s0 return mean ( values ), std ( values ) def cod_to_nat_x ( self , cod_X ): \"\"\" Args: cod_X (array): An array representing one point (self.k long) in normalized (coded) units. Returns: (array): An array of natural (physical or real world) units. \"\"\" X = copy . deepcopy ( cod_X ) if self . cod_type == \"norm\" : for i in range ( self . k ): X [ i ] = ( X [ i ] * float ( self . nat_range_X [ i ][ 1 ] - self . nat_range_X [ i ][ 0 ]) ) + self . nat_range_X [ i ][ 0 ] return X elif self . cod_type == \"std\" : for i in range ( self . k ): X [ i ] = X [ i ] * self . nat_std_X [ i ] + self . nat_mean_X [ i ] return X else : return cod_X def cod_to_nat_y ( self , cod_y ): \"\"\" Args: cod_y (array): A normalized array of coded (model) units in the range of [0,1]. Returns: (array): An array of observed values in real-world units. \"\"\" if self . cod_type == \"norm\" : return ( cod_y * ( self . nat_range_y [ 1 ] - self . nat_range_y [ 0 ]) ) + self . nat_range_y [ 0 ] elif self . cod_type == \"std\" : return cod_y * self . nat_std_y + self . nat_mean_y else : return cod_y def nat_to_cod_x ( self , nat_X ): \"\"\" Normalize one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated. Args: nat_X (array): An array representing one points (self.k long) in natural (physical or real world) units. Returns: (array): An array of coded values in the range of [0,1] for each dimension. \"\"\" X = copy . deepcopy ( nat_X ) if self . cod_type == \"norm\" : for i in range ( self . k ): X [ i ] = ( X [ i ] - self . nat_range_X [ i ][ 0 ]) / float ( self . nat_range_X [ i ][ 1 ] - self . nat_range_X [ i ][ 0 ]) # TODO: Implement range correction if range == 0: # rangex <- xmax - xmin # rangey <- ymax - ymin # xmin[rangex == 0] <- xmin[rangex == 0] - 0.5 # xmax[rangex == 0] <- xmax[rangex == 0] + 0.5 # rangex[rangex == 0] <- 1 # logger.debug(f\"self.nat_range_X[{i}]:\\n {self.nat_range_X[i]}\") # logger.debug(f\"X[{i}]:\\n {X[i]}\") return X elif self . cod_type == \"std\" : for i in range ( self . k ): X [ i ] = ( X [ i ] - self . nat_mean_X [ i ]) / self . nat_std_X [ i ] return X else : return nat_X def nat_to_cod_y ( self , nat_y ): \"\"\" Normalize natural y values to [0,1]. Args: nat_y (array): An array of observed values in natural (real-world) units. Returns: (array): A normalized array of coded (model) units in the range of [0,1]. \"\"\" if self . use_cod_y : if self . cod_type == \"norm\" : return ( nat_y - self . nat_range_y [ 0 ]) / ( self . nat_range_y [ 1 ] - self . nat_range_y [ 0 ]) elif self . cod_type == \"std\" : return ( nat_y - self . nat_mean_y ) / self . nat_std_y else : return nat_y else : return nat_y def nat_to_cod_init ( self ): \"\"\" Determine max and min of each dimension and normalize that axis to a range of [0,1]. Called when 1) surrogate is initialized and 2) new points arrive, i.e., suggested by the surrogate as infill points. This method calls `nat_to_cod_x` and `nat_to_cod_y` and updates the ranges `nat_range_X` and `nat_range_y`. \"\"\" self . nat_range_X = [] self . nat_range_y = [] for i in range ( self . k ): self . nat_range_X . append ([ min ( self . nat_X [:, i ]), max ( self . nat_X [:, i ])]) self . nat_range_y . append ( min ( self . nat_y )) self . nat_range_y . append ( max ( self . nat_y )) self . nat_mean_X = mean ( self . nat_X , axis = 0 ) self . nat_std_X = std ( self . nat_X , axis = 0 ) self . nat_mean_y = mean ( self . nat_y ) self . nat_std_y = std ( self . nat_y ) Z = aggregate_mean_var ( X = self . nat_X , y = self . nat_y ) mu = Z [ 1 ] self . mean_cod_y = empty_like ( mu ) for i in range ( self . n ): self . cod_X [ i ] = self . nat_to_cod_x ( self . nat_X [ i ]) for i in range ( self . n ): self . cod_y [ i ] = self . nat_to_cod_y ( self . nat_y [ i ]) for i in range ( mu . shape [ 0 ]): self . mean_cod_y [ i ] = self . nat_to_cod_y ( mu [ i ]) __init__ ( noise = False , cod_type = 'norm' , var_type = [ 'num' ], use_cod_y = False , name = 'kriging' , seed = 124 , model_optimizer = None , model_fun_evals = None , min_theta =- 3 , max_theta = 2 , n_theta = 1 , n_p = 1 , optim_p = False , log_level = 50 , ** kwargs ) Kriging surrogate. Parameters: Name Type Description Default noise bool use regression instead of interpolation kriging. Defaults to \"False\". False cod_type bool normalize or standardize X and values. Can be None, \"norm\", or \"std\". Defaults to \"norm\". 'norm' var_type str variable type. Can be either \"num \" (numerical) of \"factor\" (factor). Defaults to \"num\" . ['num'] use_cod_y bool use coded y values (instead of natural one). Defaults to False . False name str Surrogate name. Defaults to \"kriging\" . 'kriging' seed int Random seed. Defaults to 124 . 124 model_optimizer object Optimizer on the surrogate. If None , differential_evolution is selected. None model_fun_evals int Number of iterations used by the optimizer on the surrogate. None min_theta float min log10 theta value. Defaults to -6. . -3 max_theta float max log10 theta value. Defaults to 3. . 2 n_theta int number of theta values. Defaults to 1 . 1 n_p int number of p values. Defaults to 1 . 1 optim_p bool Determines whether p should be optimized. False log_level int logging level, e.g., 20 is \"INFO\" . Defaults to 50 ( \"CRITICAL\" ). 50 Attributes: Name Type Description nat_range_X list List of X natural ranges. nat_range_y list List of y nat ranges. noise bool noisy objective function. Default: False. If True , regression kriging will be used. var_type str variable type. Can be either \"num \" (numerical) of \"factor\" (factor). num_mask array array of bool variables. True represent numerical (float) variables. factor_mask array array of factor variables. True represents factor (unordered) variables. int_mask array array of integer variables. True represents integers (ordered) variables. ordered_mask array array of ordered variables. True represents integers or float (ordered) variables. Set of veriables which an order relation, i.e., they are either num (float) or int. name str Surrogate name seed int Random seed. use_cod_y bool Use coded y values. sigma float Kriging sigma. gen method Design generator, e.g., spotPython.design.spacefilling.spacefilling. min_theta float min log10 theta value. Defaults: -6. max_theta float max log10 theta value. Defaults: 3. min_p float min p value. Default: 1. max_p float max p value. Default: 2. Examples: Surrogate of the x*sin(x) function. See: scikit-learn >>> from spotPython.build.kriging import Kriging >>> import numpy as np >>> import matplotlib.pyplot as plt >>> rng = np . random . RandomState ( 1 ) >>> X = linspace ( start = 0 , stop = 10 , num = 1_000 ) . reshape ( - 1 , 1 ) >>> y = np . squeeze ( X * np . sin ( X )) >>> training_indices = rng . choice ( arange ( y . size ), size = 6 , replace = False ) >>> X_train , y_train = X [ training_indices ], y [ training_indices ] >>> S = Kriging ( name = 'kriging' , seed = 124 ) >>> S . fit ( X_train , y_train ) >>> mean_prediction , std_prediction = S . predict ( X ) >>> plt . plot ( X , y , label = r \"$f(x)$\" , linestyle = \"dotted\" ) >>> plt . scatter ( X_train , y_train , label = \"Observations\" ) >>> plt . plot ( X , mean_prediction , label = \"Mean prediction\" ) >>> plt . fill_between ( X.ravel(), mean_prediction - 1.96 * std_prediction, mean_prediction + 1.96 * std_prediction, alpha=0.5, label=r\"95% confidence interval\", ) >>> plt . legend () >>> plt . xlabel ( \"$x$\" ) >>> plt . ylabel ( \"$f(x)$\" ) >>> _ = plt . title ( \"Gaussian process regression on noise-free dataset\" ) Source code in spotPython/build/kriging.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 def __init__ ( self , noise = False , cod_type = \"norm\" , var_type = [ \"num\" ], use_cod_y = False , name = \"kriging\" , seed = 124 , model_optimizer = None , model_fun_evals = None , min_theta =- 3 , # TODO max_theta = 2 , # TODO n_theta = 1 , n_p = 1 , optim_p = False , log_level = 50 , ** kwargs ): \"\"\" Kriging surrogate. Args: noise (bool): use regression instead of interpolation kriging. Defaults to \"False\". cod_type (bool): normalize or standardize X and values. Can be None, \"norm\", or \"std\". Defaults to \"norm\". var_type (str): variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor). Defaults to `\"num\"`. use_cod_y (bool): use coded y values (instead of natural one). Defaults to `False`. name (str): Surrogate name. Defaults to `\"kriging\"`. seed (int): Random seed. Defaults to `124`. model_optimizer (object): Optimizer on the surrogate. If `None`, `differential_evolution` is selected. model_fun_evals (int): Number of iterations used by the optimizer on the surrogate. min_theta (float): min log10 theta value. Defaults to `-6.`. max_theta (float): max log10 theta value. Defaults to `3.`. n_theta (int): number of theta values. Defaults to `1`. n_p (int): number of p values. Defaults to `1`. optim_p (bool): Determines whether `p` should be optimized. log_level (int): logging level, e.g., `20` is `\"INFO\"`. Defaults to `50` (`\"CRITICAL\"`). Attributes: nat_range_X (list): List of X natural ranges. nat_range_y (list): List of y nat ranges. noise (bool): noisy objective function. Default: False. If `True`, regression kriging will be used. var_type (str): variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor). num_mask (array): array of bool variables. `True` represent numerical (float) variables. factor_mask (array): array of factor variables. `True` represents factor (unordered) variables. int_mask (array): array of integer variables. `True` represents integers (ordered) variables. ordered_mask (array): array of ordered variables. `True` represents integers or float (ordered) variables. Set of veriables which an order relation, i.e., they are either num (float) or int. name (str): Surrogate name seed (int): Random seed. use_cod_y (bool): Use coded y values. sigma (float): Kriging sigma. gen (method): Design generator, e.g., spotPython.design.spacefilling.spacefilling. min_theta (float): min log10 theta value. Defaults: -6. max_theta (float): max log10 theta value. Defaults: 3. min_p (float): min p value. Default: 1. max_p (float): max p value. Default: 2. Examples: Surrogate of the x*sin(x) function. See: [scikit-learn](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html) >>> from spotPython.build.kriging import Kriging >>> import numpy as np >>> import matplotlib.pyplot as plt >>> rng = np.random.RandomState(1) >>> X = linspace(start=0, stop=10, num=1_000).reshape(-1, 1) >>> y = np.squeeze(X * np.sin(X)) >>> training_indices = rng.choice(arange(y.size), size=6, replace=False) >>> X_train, y_train = X[training_indices], y[training_indices] >>> S = Kriging(name='kriging', seed=124) >>> S.fit(X_train, y_train) >>> mean_prediction, std_prediction = S.predict(X) >>> plt.plot(X, y, label=r\"$f(x)$\", linestyle=\"dotted\") >>> plt.scatter(X_train, y_train, label=\"Observations\") >>> plt.plot(X, mean_prediction, label=\"Mean prediction\") >>> plt.fill_between( X.ravel(), mean_prediction - 1.96 * std_prediction, mean_prediction + 1.96 * std_prediction, alpha=0.5, label=r\"95% confidence interval\", ) >>> plt.legend() >>> plt.xlabel(\"$x$\") >>> plt.ylabel(\"$f(x)$\") >>> _ = plt.title(\"Gaussian process regression on noise-free dataset\") \"\"\" super () . __init__ ( name , seed , log_level ) self . noise = noise self . var_type = var_type self . cod_type = cod_type self . use_cod_y = use_cod_y self . name = name self . seed = seed self . log_level = log_level self . sigma = 0 self . eps = sqrt ( spacing ( 1 )) self . min_theta = min_theta self . max_theta = max_theta self . min_p = 1 self . max_p = 2 self . min_Lambda = 1e-9 self . max_Lambda = 1. self . n_theta = n_theta self . n_p = n_p self . optim_p = optim_p # Psi matrix condition: self . cnd_Psi = 0 self . inf_Psi = False self . model_optimizer = model_optimizer if self . model_optimizer is None : self . model_optimizer = differential_evolution self . model_fun_evals = model_fun_evals # differential evaluation uses maxiter = 1000 # and sets the number of function evaluations to # (maxiter + 1) * popsize * N, which results in # 1000 * 15 * k, because the default popsize is 15 and # N is the number of parameters. This seems to be quite large: # for k=2 these are 30 000 iterations. Therefore we set this value to # 100 if self . model_fun_evals is None : self . model_fun_evals = 100 # Logging information self . log [ \"negLnLike\" ] = [] self . log [ \"theta\" ] = [] self . log [ \"p\" ] = [] self . log [ \"Lambda\" ] = [] # Logger logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) build_Psi () New construction (rebuild to reflect new data or a change in hyperparameters) of the (nxn) correlation matrix Psi as described in [Forr08a, p.57]. Note Method uses theta , p , and coded X values. Source code in spotPython/build/kriging.py 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 def build_Psi ( self ): \"\"\" New construction (rebuild to reflect new data or a change in hyperparameters) of the (nxn) correlation matrix Psi as described in [Forr08a, p.57]. Note: Method uses `theta`, `p`, and coded `X` values. \"\"\" self . Psi = zeros (( self . n , self . n ), dtype = float64 ) theta = power ( 10.0 , self . theta ) if self . n_theta == 1 : theta = theta * ones ( self . k ) try : D = zeros (( self . n , self . n )) if self . ordered_mask . any (): X_ordered = self . cod_X [:, self . ordered_mask ] D = squareform ( pdist ( X_ordered , metric = 'sqeuclidean' , out = None , w = theta [ self . ordered_mask ])) if self . factor_mask . any (): X_factor = self . cod_X [:, self . factor_mask ] D = ( D + squareform ( pdist ( X_factor , metric = 'hamming' , out = None , w = theta [ self . factor_mask ]))) self . Psi = exp ( - D ) except LinAlgError as err : print ( f \"Building Psi failed: \\n { self . Psi } . { err =} , { type ( err ) =} \" ) if self . noise : self . Psi = self . Psi + multiply ( eye ( self . n ), self . Lambda ) else : self . Psi = self . Psi + multiply ( eye ( self . n ), self . eps ) if ( isinf ( self . Psi )) . any (): self . inf_Psi = True self . cnd_Psi = cond ( self . Psi ) build_U ( scipy = True ) Cholesky factorization of Psi as U as described in [Forr08a, p.57]. Parameters: Name Type Description Default scipy bool Use scipy_cholesky . If False , numpy's cholesky is used. True Source code in spotPython/build/kriging.py 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 def build_U ( self , scipy = True ): \"\"\" Cholesky factorization of Psi as U as described in [Forr08a, p.57]. Args: scipy (bool): Use `scipy_cholesky`. If `False`, numpy's `cholesky` is used. \"\"\" try : if scipy : self . U = scipy_cholesky ( self . Psi , lower = True ) else : self . U = cholesky ( self . Psi ) self . U = self . U . T except LinAlgError as err : print ( f \"build_U() Cholesky failed for Psi: \\n { self . Psi } . { err =} , { type ( err ) =} \" ) build_psi_vec ( cod_x ) Build the psi vector. Needed by predict_cod , predict_err_coded , regression_predict_coded . Modifies self.psi . Parameters: Name Type Description Default cod_x array point to calculate psi required Source code in spotPython/build/kriging.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 def build_psi_vec ( self , cod_x ): \"\"\" Build the psi vector. Needed by `predict_cod`, `predict_err_coded`, `regression_predict_coded`. Modifies `self.psi`. Args: cod_x (array): point to calculate psi \"\"\" self . psi = zeros (( self . n )) # theta = self.theta # TODO: theta = power ( 10.0 , self . theta ) if self . n_theta == 1 : theta = theta * ones ( self . k ) try : D = zeros (( self . n )) if self . ordered_mask . any (): X_ordered = self . cod_X [:, self . ordered_mask ] x_ordered = cod_x [ self . ordered_mask ] D = cdist ( x_ordered . reshape ( - 1 , sum ( self . ordered_mask )), X_ordered . reshape ( - 1 , sum ( self . ordered_mask )), metric = 'sqeuclidean' , out = None , w = theta [ self . ordered_mask ]) if self . factor_mask . any (): X_factor = self . cod_X [:, self . factor_mask ] x_factor = cod_x [ self . factor_mask ] D = ( D + cdist ( x_factor . reshape ( - 1 , sum ( self . factor_mask )), X_factor . reshape ( - 1 , sum ( self . factor_mask )), metric = 'hamming' , out = None , w = theta [ self . factor_mask ])) self . psi = exp ( - D ) . T except LinAlgError as err : print ( f \"Building psi failed: \\n { self . psi } . { err =} , { type ( err ) =} \" ) calculate_mean_MSE ( n_samples = 200 , points = None ) This function calculates the mean MSE metric of the model by evaluating MSE at a number of points. Parameters: Name Type Description Default n_samples integer Number of points to sample the mean squared error at. Ignored if the points argument is specified. 200 points array an array of points to sample the model at. None Returns: Type Description float the mean value of MSE and the standard deviation of the MSE points Source code in spotPython/build/kriging.py 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 def calculate_mean_MSE ( self , n_samples = 200 , points = None ): \"\"\" This function calculates the mean MSE metric of the model by evaluating MSE at a number of points. Args: n_samples (integer): Number of points to sample the mean squared error at. Ignored if the points argument is specified. points (array): an array of points to sample the model at. Returns: (float): the mean value of MSE and the standard deviation of the MSE points \"\"\" if points is None : points = self . gen . lhd ( n_samples ) values = zeros ( len ( points )) for enu , point in enumerate ( points ): s0 = self . predict ( cod_X = point , nat = True , return_val = \"s\" ) values [ enu ] = s0 return mean ( values ), std ( values ) cod_to_nat_x ( cod_X ) Parameters: Name Type Description Default cod_X array An array representing one point (self.k long) in normalized (coded) units. required Returns: Type Description array An array of natural (physical or real world) units. Source code in spotPython/build/kriging.py 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 def cod_to_nat_x ( self , cod_X ): \"\"\" Args: cod_X (array): An array representing one point (self.k long) in normalized (coded) units. Returns: (array): An array of natural (physical or real world) units. \"\"\" X = copy . deepcopy ( cod_X ) if self . cod_type == \"norm\" : for i in range ( self . k ): X [ i ] = ( X [ i ] * float ( self . nat_range_X [ i ][ 1 ] - self . nat_range_X [ i ][ 0 ]) ) + self . nat_range_X [ i ][ 0 ] return X elif self . cod_type == \"std\" : for i in range ( self . k ): X [ i ] = X [ i ] * self . nat_std_X [ i ] + self . nat_mean_X [ i ] return X else : return cod_X cod_to_nat_y ( cod_y ) Parameters: Name Type Description Default cod_y array A normalized array of coded (model) units in the range of [0,1]. required Returns: Type Description array An array of observed values in real-world units. Source code in spotPython/build/kriging.py 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 def cod_to_nat_y ( self , cod_y ): \"\"\" Args: cod_y (array): A normalized array of coded (model) units in the range of [0,1]. Returns: (array): An array of observed values in real-world units. \"\"\" if self . cod_type == \"norm\" : return ( cod_y * ( self . nat_range_y [ 1 ] - self . nat_range_y [ 0 ]) ) + self . nat_range_y [ 0 ] elif self . cod_type == \"std\" : return cod_y * self . nat_std_y + self . nat_mean_y else : return cod_y exp_imp ( y0 , s0 ) Returns the expected improvement for y0 and error s0 (in coded units). Parameters: Name Type Description Default y0 float function value (in coded units) required s0 float error required Returns: Type Description float The expected improvement value. Source code in spotPython/build/kriging.py 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def exp_imp ( self , y0 , s0 ): \"\"\" Returns the expected improvement for y0 and error s0 (in coded units). Args: y0 (float): function value (in coded units) s0 (float): error Returns: (float): The expected improvement value. \"\"\" # y_min = min(self.cod_y) y_min = min ( self . mean_cod_y ) if s0 <= 0.0 : EI = 0.0 elif s0 > 0.0 : EI_one = ( y_min - y0 ) * ( 0.5 + 0.5 * erf (( 1.0 / sqrt ( 2.0 )) * (( y_min - y0 ) / s0 )) ) EI_two = ( s0 * ( 1.0 / sqrt ( 2.0 * pi ))) * ( exp ( - ( 1.0 / 2.0 ) * (( y_min - y0 ) ** 2.0 / s0 ** 2.0 )) ) EI = EI_one + EI_two return EI extract_from_bounds ( new_theta_p_Lambda ) Extract theta , p , and Lambda from bounds. The kriging object stores theta as an array, p as an array, and Lambda as a float. Parameters: Name Type Description Default new_theta_p_Lambda numpy . array 1d-array with theta, p, and Lambda values. Order is important. required Source code in spotPython/build/kriging.py 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 def extract_from_bounds ( self , new_theta_p_Lambda ): \"\"\" Extract `theta`, `p`, and `Lambda` from bounds. The kriging object stores `theta` as an array, `p` as an array, and `Lambda` as a float. Args: new_theta_p_Lambda (numpy.array): 1d-array with theta, p, and Lambda values. Order is important. \"\"\" for i in range ( self . n_theta ): self . theta [ i ] = new_theta_p_Lambda [ i ] if self . optim_p : for i in range ( self . n_p ): self . p [ i ] = new_theta_p_Lambda [ i + self . n_theta ] if self . noise : self . Lambda = new_theta_p_Lambda [ self . n_theta + self . n_p ] else : if self . noise : self . Lambda = new_theta_p_Lambda [ self . n_theta ] fit ( nat_X , nat_y ) The function fits the hyperparameters ( theta , p , Lambda ) of the Kriging model, i.e., the following internal values are computed: theta , p , and Lambda values via optimization of the function fun_likelihood() . Correlation matrix Psi via rebuildPsi() . Parameters: Name Type Description Default nat_X array sample points required nat_y array function values required Returns: Name Type Description surrogate object Fitted estimator. Attributes: Name Type Description theta numpy . ndarray Kriging theta values. Shape (k,). p numpy . ndarray Kriging p values. Shape (k,). LnDetPsi numpy . float64 Determinant Psi matrix. Psi numpy . matrix Correlation matrix Psi. Shape (n,n). psi numpy . ndarray psi vector. Shape (n,). one numpy . ndarray vector of ones. Shape (n,). mu numpy . float64 Kriging expected mean value mu. U numpy . matrix Kriging U matrix, Cholesky decomposition. Shape (n,n). SigmaSqr numpy . float64 Sigma squared value. Lambda float lambda noise value. Source code in spotPython/build/kriging.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 def fit ( self , nat_X , nat_y ): \"\"\" The function fits the hyperparameters (`theta`, `p`, `Lambda`) of the Kriging model, i.e., the following internal values are computed: 1. `theta`, `p`, and `Lambda` values via optimization of the function `fun_likelihood()`. 2. Correlation matrix `Psi` via `rebuildPsi()`. Args: nat_X (array): sample points nat_y (array): function values Returns: surrogate (object): Fitted estimator. Attributes: theta (numpy.ndarray): Kriging theta values. Shape (k,). p (numpy.ndarray): Kriging p values. Shape (k,). LnDetPsi (numpy.float64): Determinant Psi matrix. Psi (numpy.matrix): Correlation matrix Psi. Shape (n,n). psi (numpy.ndarray): psi vector. Shape (n,). one (numpy.ndarray): vector of ones. Shape (n,). mu (numpy.float64): Kriging expected mean value mu. U (numpy.matrix): Kriging U matrix, Cholesky decomposition. Shape (n,n). SigmaSqr (numpy.float64): Sigma squared value. Lambda (float): lambda noise value. \"\"\" self . nat_X = copy . deepcopy ( nat_X ) self . nat_y = copy . deepcopy ( nat_y ) self . n = self . nat_X . shape [ 0 ] self . k = self . nat_X . shape [ 1 ] self . cod_X = empty_like ( self . nat_X ) self . cod_y = empty_like ( self . nat_y ) # assume all variable types are \"num\" if \"num\" is # specified once: if len ( self . var_type ) < self . k : self . var_type = self . var_type * self . k logger . warning ( \"Warning: All variable types forced to 'num'.\" ) self . num_mask = array ( list ( map ( lambda x : x == \"num\" , self . var_type ))) self . factor_mask = array ( list ( map ( lambda x : x == \"factor\" , self . var_type ))) self . int_mask = array ( list ( map ( lambda x : x == \"int\" , self . var_type ))) self . ordered_mask = array ( list ( map ( lambda x : x == \"int\" or x == \"num\" , self . var_type ))) self . nat_to_cod_init () if self . n_theta > self . k : self . n_theta = self . k logger . warning ( \"Warning: More theta values than dimensions. `n_theta` set to `k`.\" ) self . theta = zeros ( self . n_theta ) # TODO: Currently not used: self . x0_theta = ones (( self . n_theta ,)) * self . n / ( 100 * self . k ) self . p = ones ( self . n_p ) * 2.0 self . pen_val = self . n * log ( var ( self . nat_y )) + 1e4 self . negLnLike = None self . gen = spacefilling ( k = self . k , seed = self . seed ) # matrix related self . LnDetPsi = None self . Psi = zeros (( self . n , self . n ), dtype = float64 ) self . psi = zeros (( self . n , 1 )) self . one = ones ( self . n ) self . mu = None self . U = None self . SigmaSqr = None self . Lambda = None # build_Psi() and build_U() are called in fun_likelihood self . set_de_bounds () if self . model_optimizer . __name__ == 'dual_annealing' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) elif self . model_optimizer . __name__ == 'differential_evolution' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds , maxiter = self . model_fun_evals , seed = self . seed ) elif self . model_optimizer . __name__ == 'direct' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds , # maxfun=self.model_fun_evals, eps = 1e-2 ) elif self . model_optimizer . __name__ == 'shgo' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) elif self . model_optimizer . __name__ == 'basinhopping' : result = self . model_optimizer ( func = self . fun_likelihood , x0 = mean ( self . de_bounds , axis = 1 )) else : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) # Finally, set new theta and p values and update the surrogate again # for new_theta_p_Lambda in de_results[\"x\"]: new_theta_p_Lambda = result [ \"x\" ] self . extract_from_bounds ( new_theta_p_Lambda ) self . build_Psi () self . build_U () # TODO: check if the following line is necessary! self . likelihood () self . log [ \"negLnLike\" ] = append ( self . log [ \"negLnLike\" ], self . negLnLike ) self . log [ \"theta\" ] = append ( self . log [ \"theta\" ], self . theta ) self . log [ \"p\" ] = append ( self . log [ \"p\" ], self . p ) self . log [ \"Lambda\" ] = append ( self . log [ \"Lambda\" ], self . Lambda ) fun_likelihood ( new_theta_p_Lambda ) Compute log likelihood for a set of hyperparameters (theta, p, Lambda). Performs the following steps: Build Psi via build_Psi() and build_U() . Compute negLnLikelihood via `likelihood() If successful, the return negLnLike value, otherwise a penalty value ( pen_val ). Parameters: Name Type Description Default new_theta_p_Lambda array theta , p , and Lambda values stored in an array. required Returns: Type Description float negLnLike, th negative log likelihood of the surface at the hyperparameters specified. Source code in spotPython/build/kriging.py 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 def fun_likelihood ( self , new_theta_p_Lambda ): \"\"\" Compute log likelihood for a set of hyperparameters (theta, p, Lambda). Performs the following steps: 1. Build Psi via `build_Psi()` and `build_U()`. 2. Compute negLnLikelihood via `likelihood() 3. If successful, the return `negLnLike` value, otherwise a penalty value (`pen_val`). Args: new_theta_p_Lambda (array): `theta`, `p`, and `Lambda` values stored in an array. Returns: (float): negLnLike, th negative log likelihood of the surface at the hyperparameters specified. \"\"\" self . extract_from_bounds ( new_theta_p_Lambda ) if self . __is_any__ ( power ( 10.0 , self . theta ), 0 ): # print(f\"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to {self.pen_val:.2f}.\") logger . warning ( \"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to %s \" , self . pen_val ) return self . pen_val self . build_Psi () if ( self . inf_Psi or self . cnd_Psi > 1e9 ): # print(f\"\\nFailure in fun_likelihood: Psi is ill conditioned ({self.cnd_Psi}).\") # print(f\"Setting negLnLike to {self.pen_val:.2f}.\") logger . warning ( \"Failure in fun_likelihood: Psi is ill conditioned: %s \" , self . cnd_Psi ) logger . warning ( \"Setting negLnLike to: %s \" , self . pen_val ) return self . pen_val else : try : self . build_U () except Exception as err : f = self . pen_val print ( f \"Error in fun_likelihood(). Call to build_U() failed. { err =} , { type ( err ) =} \" ) print ( f \"Setting negLnLike to { self . pen_val : .2f } .\" ) return f self . likelihood () return self . negLnLike likelihood () Calculates the negative of the concentrated log-likelihood. Implementation of (2.32) in [Forr08a]. See also function krigingLikelihood() in spot. Note build_Psi and build_U should be called first. Modifies mu , SigmaSqr , LnDetPsi , and negLnLike , concentrated log-likelihood *-1 for minimizing Source code in spotPython/build/kriging.py 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 def likelihood ( self ): \"\"\" Calculates the negative of the concentrated log-likelihood. Implementation of (2.32) in [Forr08a]. See also function krigingLikelihood() in spot. Note: `build_Psi` and `build_U` should be called first. Modifies: `mu`, `SigmaSqr`, `LnDetPsi`, and `negLnLike`, concentrated log-likelihood *-1 for minimizing \"\"\" # (2.20) in [Forr08a]: mu = ( self . one . T . dot ( solve ( self . U , solve ( self . U . T , self . cod_y )) ) ) / self . one . T . dot ( solve ( self . U , solve ( self . U . T , self . one ))) self . mu = mu # (2.31) in [Forr08a] self . SigmaSqr = ( ( self . cod_y - self . one . dot ( self . mu )) . T . dot ( solve ( self . U , solve ( self . U . T , ( self . cod_y - self . one . dot ( self . mu ))), ) ) ) / self . n # (2.32) in [Forr08a] self . LnDetPsi = 2.0 * sum ( log ( abs ( diag ( self . U )))) self . negLnLike = - 1.0 * ( - ( self . n / 2.0 ) * log ( self . SigmaSqr ) - 0.5 * self . LnDetPsi ) nat_to_cod_init () Determine max and min of each dimension and normalize that axis to a range of [0,1]. Called when 1) surrogate is initialized and 2) new points arrive, i.e., suggested by the surrogate as infill points. This method calls nat_to_cod_x and nat_to_cod_y and updates the ranges nat_range_X and nat_range_y . Source code in spotPython/build/kriging.py 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 def nat_to_cod_init ( self ): \"\"\" Determine max and min of each dimension and normalize that axis to a range of [0,1]. Called when 1) surrogate is initialized and 2) new points arrive, i.e., suggested by the surrogate as infill points. This method calls `nat_to_cod_x` and `nat_to_cod_y` and updates the ranges `nat_range_X` and `nat_range_y`. \"\"\" self . nat_range_X = [] self . nat_range_y = [] for i in range ( self . k ): self . nat_range_X . append ([ min ( self . nat_X [:, i ]), max ( self . nat_X [:, i ])]) self . nat_range_y . append ( min ( self . nat_y )) self . nat_range_y . append ( max ( self . nat_y )) self . nat_mean_X = mean ( self . nat_X , axis = 0 ) self . nat_std_X = std ( self . nat_X , axis = 0 ) self . nat_mean_y = mean ( self . nat_y ) self . nat_std_y = std ( self . nat_y ) Z = aggregate_mean_var ( X = self . nat_X , y = self . nat_y ) mu = Z [ 1 ] self . mean_cod_y = empty_like ( mu ) for i in range ( self . n ): self . cod_X [ i ] = self . nat_to_cod_x ( self . nat_X [ i ]) for i in range ( self . n ): self . cod_y [ i ] = self . nat_to_cod_y ( self . nat_y [ i ]) for i in range ( mu . shape [ 0 ]): self . mean_cod_y [ i ] = self . nat_to_cod_y ( mu [ i ]) nat_to_cod_x ( nat_X ) Normalize one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated. Parameters: Name Type Description Default nat_X array An array representing one points (self.k long) in natural (physical or real world) units. required Returns: Type Description array An array of coded values in the range of [0,1] for each dimension. Source code in spotPython/build/kriging.py 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 def nat_to_cod_x ( self , nat_X ): \"\"\" Normalize one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated. Args: nat_X (array): An array representing one points (self.k long) in natural (physical or real world) units. Returns: (array): An array of coded values in the range of [0,1] for each dimension. \"\"\" X = copy . deepcopy ( nat_X ) if self . cod_type == \"norm\" : for i in range ( self . k ): X [ i ] = ( X [ i ] - self . nat_range_X [ i ][ 0 ]) / float ( self . nat_range_X [ i ][ 1 ] - self . nat_range_X [ i ][ 0 ]) # TODO: Implement range correction if range == 0: # rangex <- xmax - xmin # rangey <- ymax - ymin # xmin[rangex == 0] <- xmin[rangex == 0] - 0.5 # xmax[rangex == 0] <- xmax[rangex == 0] + 0.5 # rangex[rangex == 0] <- 1 # logger.debug(f\"self.nat_range_X[{i}]:\\n {self.nat_range_X[i]}\") # logger.debug(f\"X[{i}]:\\n {X[i]}\") return X elif self . cod_type == \"std\" : for i in range ( self . k ): X [ i ] = ( X [ i ] - self . nat_mean_X [ i ]) / self . nat_std_X [ i ] return X else : return nat_X nat_to_cod_y ( nat_y ) Normalize natural y values to [0,1]. Parameters: Name Type Description Default nat_y array An array of observed values in natural (real-world) units. required Returns: Type Description array A normalized array of coded (model) units in the range of [0,1]. Source code in spotPython/build/kriging.py 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 def nat_to_cod_y ( self , nat_y ): \"\"\" Normalize natural y values to [0,1]. Args: nat_y (array): An array of observed values in natural (real-world) units. Returns: (array): A normalized array of coded (model) units in the range of [0,1]. \"\"\" if self . use_cod_y : if self . cod_type == \"norm\" : return ( nat_y - self . nat_range_y [ 0 ]) / ( self . nat_range_y [ 1 ] - self . nat_range_y [ 0 ]) elif self . cod_type == \"std\" : return ( nat_y - self . nat_mean_y ) / self . nat_std_y else : return nat_y else : return nat_y plot ( show = True ) This function plots 1d and 2d surrogates. Parameters: Name Type Description Default show boolean If True , the plots are displayed. If False , plt.show() should be called outside this function. True Source code in spotPython/build/kriging.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 def plot ( self , show = True ): \"\"\" This function plots 1d and 2d surrogates. Args: show (boolean): If `True`, the plots are displayed. If `False`, `plt.show()` should be called outside this function. \"\"\" if self . k == 1 : # TODO: Improve plot (add conf. interval etc.) fig = pylab . figure ( figsize = ( 9 , 6 )) # t1 = array(arange(0.0, 1.0, 0.01)) # y1 = array([self.predict(array([x]), return_val=\"y\") for x in t1]) # plt.figure() # plt.plot(t1, y1, \"k\") # if show: # plt.show() # n_grid = 100 x = linspace ( self . nat_range_X [ 0 ][ 0 ], self . nat_range_X [ 0 ][ 1 ], num = n_grid ) y = self . predict ( x ) plt . figure () plt . plot ( x , y , \"k\" ) if show : plt . show () if self . k == 2 : fig = pylab . figure ( figsize = ( 9 , 6 )) n_grid = 100 x = linspace ( self . nat_range_X [ 0 ][ 0 ], self . nat_range_X [ 0 ][ 1 ], num = n_grid ) y = linspace ( self . nat_range_X [ 1 ][ 0 ], self . nat_range_X [ 1 ][ 1 ], num = n_grid ) X , Y = meshgrid ( x , y ) # Predict based on the optimized results zz = array ( [ self . predict ( array ([ x , y ]), return_val = \"all\" ) for x , y in zip ( ravel ( X ), ravel ( Y ))] ) zs = zz [:, 0 , :] zse = zz [:, 1 , :] Z = zs . reshape ( X . shape ) Ze = zse . reshape ( X . shape ) if self . cod_type == \"norm\" : nat_point_X = ( self . cod_X [:, 0 ] * ( self . nat_range_X [ 0 ][ 1 ] - self . nat_range_X [ 0 ][ 0 ]) ) + self . nat_range_X [ 0 ][ 0 ] nat_point_Y = ( self . cod_X [:, 1 ] * ( self . nat_range_X [ 1 ][ 1 ] - self . nat_range_X [ 1 ][ 0 ]) ) + self . nat_range_X [ 1 ][ 0 ] elif self . cod_type == \"std\" : nat_point_X = self . cod_X [:, 0 ] * self . nat_std_X [ 0 ] + self . nat_mean_X [ 0 ] nat_point_Y = self . cod_X [:, 1 ] * self . nat_std_X [ 1 ] + self . nat_mean_X [ 1 ] else : nat_point_X = self . cod_X [:, 0 ] nat_point_Y = self . cod_X [:, 1 ] contour_levels = 30 ax = fig . add_subplot ( 224 ) # plot predicted values: pylab . contourf ( X , Y , Ze , contour_levels , cmap = \"jet\" ) pylab . title ( \"Error\" ) pylab . colorbar () # plot observed points: pylab . plot ( nat_point_X , nat_point_Y , \"ow\" ) # ax = fig . add_subplot ( 223 ) # plot predicted values: plt . contourf ( X , Y , Z , contour_levels , zorder = 1 , cmap = \"jet\" ) plt . title ( \"Surrogate\" ) # plot observed points: pylab . plot ( nat_point_X , nat_point_Y , \"ow\" , zorder = 3 ) pylab . colorbar () # ax = fig . add_subplot ( 221 , projection = \"3d\" ) ax . plot_surface ( X , Y , Z , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" ) # ax = fig . add_subplot ( 222 , projection = \"3d\" ) ax . plot_surface ( X , Y , Ze , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" ) # pylab . show () predict ( nat_X , nat = True , return_val = 'y' ) This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X. Parameters: Name Type Description Default nat_X array Design variable to evaluate in natural units. required nat bool argument nat_X is in natural range. Default: True . If set to False , nat_X will not be normalized (which might be useful if already normalized y values are used). True return_val string whether y , s , neg. ei (negative expected improvement), or all three values are returned. Default is (for compatibility with sklearn) \"y\". To return s , select \"s\", to return neg. ei , select \"ei\". To return the tuple (y, s, ei) , select \"all\". 'y' Returns: Type Description float The predicted value in natural units. float predicted error float expected improvement Source code in spotPython/build/kriging.py 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 def predict ( self , nat_X , nat = True , return_val = \"y\" ): \"\"\" This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X. Args: nat_X (array): Design variable to evaluate in natural units. nat (bool): argument `nat_X` is in natural range. Default: `True`. If set to `False`, `nat_X` will not be normalized (which might be useful if already normalized y values are used). return_val (string): whether `y`, `s`, neg. `ei` (negative expected improvement), or all three values are returned. Default is (for compatibility with sklearn) \"y\". To return `s`, select \"s\", to return neg. `ei`, select \"ei\". To return the tuple `(y, s, ei)`, select \"all\". Returns: (float): The predicted value in natural units. (float): predicted error (float): expected improvement \"\"\" # Check for the shape and the type of the Input if isinstance ( nat_X , ndarray ): try : X = nat_X . reshape ( - 1 , self . nat_X . shape [ 1 ]) X = repair_non_numeric ( X , self . var_type ) except Exception : raise TypeError ( \"13.1: Input to predict was not convertible to the size of X\" ) else : raise TypeError ( f \"type of the given input is an { type ( nat_X ) } instead of an ndarray\" ) # Iterate through the Input y = array ([], dtype = float ) s = array ([], dtype = float ) ei = array ([], dtype = float ) for i in range ( X . shape [ 0 ]): # logger.debug(f\"13.2: predict() Step 2: x (reshaped nat_X):\\n {x}\") if nat : x = self . nat_to_cod_x ( X [ i , :]) else : x = X [ i , :] y0 , s0 , ei0 = self . predict_coded ( x ) y = append ( y , y0 ) s = append ( s , s0 ) ei = append ( ei , ei0 ) if return_val == \"y\" : return y elif return_val == \"s\" : return s elif return_val == \"ei\" : return - 1.0 * ei else : return y , s , - 1.0 * ei predict_coded ( cod_x ) Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a]. The error is returned as well. See also [Forr08a, p.60]. Note self.mu and self.SigmaSqr are computed in likelihood , not here. Parameters: Name Type Description Default cod_x array point in coded units to make prediction at required Returns: Type Description float predicted value in coded units. float predicted error. Source code in spotPython/build/kriging.py 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 def predict_coded ( self , cod_x ): \"\"\" Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a]. The error is returned as well. See also [Forr08a, p.60]. Note: `self.mu` and `self.SigmaSqr` are computed in `likelihood`, not here. Args: cod_x (array): point in coded units to make prediction at Returns: (float): predicted value in coded units. (float): predicted error. \"\"\" self . build_psi_vec ( cod_x ) f = self . mu + self . psi . T . dot ( solve ( self . U , solve ( self . U . T , self . cod_y - self . one . dot ( self . mu ))) ) try : if self . noise : Lambda = self . Lambda else : Lambda = 0.0 # Error in [Forr08a, p.87]: SSqr = self . SigmaSqr * ( 1 + Lambda - self . psi . T . dot ( solve ( self . U , solve ( self . U . T , self . psi )))) except Exception as err : print ( f \"Could not determine SSqr. Wrong or missing Lambda? { err =} , { type ( err ) =} \" ) SSqr = power ( abs ( SSqr [ 0 ]), 0.5 )[ 0 ] EI = self . exp_imp ( y0 = f [ 0 ], s0 = SSqr ) return f [ 0 ], SSqr , EI set_de_bounds () Determine search bounds for model_optimizer, e.g., differential evolution. Source code in spotPython/build/kriging.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 def set_de_bounds ( self ): \"\"\" Determine search bounds for model_optimizer, e.g., differential evolution. \"\"\" de_bounds = [] for i in range ( self . n_theta ): de_bounds . append ([ self . min_theta , self . max_theta ]) if self . optim_p : for i in range ( self . n_p ): de_bounds . append ([ self . min_p , self . max_p ]) if self . noise : de_bounds . append ([ self . min_Lambda , self . max_Lambda ]) else : if self . noise : de_bounds . append ([ self . min_Lambda , self . max_Lambda ]) self . de_bounds = de_bounds weighted_exp_imp ( cod_x , w ) Weighted expected improvement. References [Sobester et al. 2005]. Parameters: Name Type Description Default cod_x array A coded design vector. required w float weight required Returns: Type Description float weighted expected improvement. Source code in spotPython/build/kriging.py 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 def weighted_exp_imp ( self , cod_x , w ): \"\"\" Weighted expected improvement. References: [Sobester et al. 2005]. Args: cod_x (array): A coded design vector. w (float): weight Returns: (float): weighted expected improvement. \"\"\" y0 , s0 = self . predict_coded ( cod_x ) y_min = min ( self . cod_y ) if s0 <= 0.0 : EI = 0.0 elif s0 > 0.0 : EI_one = w * ( ( y_min - y0 ) * ( 0.5 + 0.5 * erf (( 1.0 / sqrt ( 2.0 )) * (( y_min - y0 ) / s0 ))) ) EI_two = ( ( 1.0 - w ) * ( s0 * ( 1.0 / sqrt ( 2.0 * pi ))) * ( exp ( - ( 1.0 / 2.0 ) * (( y_min - y0 ) ** 2.0 / s0 ** 2.0 ))) ) EI = EI_one + EI_two return EI","title":"kriging"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging","text":"Bases: surrogates Source code in spotPython/build/kriging.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 class Kriging ( surrogates ): def __init__ ( self , noise = False , cod_type = \"norm\" , var_type = [ \"num\" ], use_cod_y = False , name = \"kriging\" , seed = 124 , model_optimizer = None , model_fun_evals = None , min_theta =- 3 , # TODO max_theta = 2 , # TODO n_theta = 1 , n_p = 1 , optim_p = False , log_level = 50 , ** kwargs ): \"\"\" Kriging surrogate. Args: noise (bool): use regression instead of interpolation kriging. Defaults to \"False\". cod_type (bool): normalize or standardize X and values. Can be None, \"norm\", or \"std\". Defaults to \"norm\". var_type (str): variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor). Defaults to `\"num\"`. use_cod_y (bool): use coded y values (instead of natural one). Defaults to `False`. name (str): Surrogate name. Defaults to `\"kriging\"`. seed (int): Random seed. Defaults to `124`. model_optimizer (object): Optimizer on the surrogate. If `None`, `differential_evolution` is selected. model_fun_evals (int): Number of iterations used by the optimizer on the surrogate. min_theta (float): min log10 theta value. Defaults to `-6.`. max_theta (float): max log10 theta value. Defaults to `3.`. n_theta (int): number of theta values. Defaults to `1`. n_p (int): number of p values. Defaults to `1`. optim_p (bool): Determines whether `p` should be optimized. log_level (int): logging level, e.g., `20` is `\"INFO\"`. Defaults to `50` (`\"CRITICAL\"`). Attributes: nat_range_X (list): List of X natural ranges. nat_range_y (list): List of y nat ranges. noise (bool): noisy objective function. Default: False. If `True`, regression kriging will be used. var_type (str): variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor). num_mask (array): array of bool variables. `True` represent numerical (float) variables. factor_mask (array): array of factor variables. `True` represents factor (unordered) variables. int_mask (array): array of integer variables. `True` represents integers (ordered) variables. ordered_mask (array): array of ordered variables. `True` represents integers or float (ordered) variables. Set of veriables which an order relation, i.e., they are either num (float) or int. name (str): Surrogate name seed (int): Random seed. use_cod_y (bool): Use coded y values. sigma (float): Kriging sigma. gen (method): Design generator, e.g., spotPython.design.spacefilling.spacefilling. min_theta (float): min log10 theta value. Defaults: -6. max_theta (float): max log10 theta value. Defaults: 3. min_p (float): min p value. Default: 1. max_p (float): max p value. Default: 2. Examples: Surrogate of the x*sin(x) function. See: [scikit-learn](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html) >>> from spotPython.build.kriging import Kriging >>> import numpy as np >>> import matplotlib.pyplot as plt >>> rng = np.random.RandomState(1) >>> X = linspace(start=0, stop=10, num=1_000).reshape(-1, 1) >>> y = np.squeeze(X * np.sin(X)) >>> training_indices = rng.choice(arange(y.size), size=6, replace=False) >>> X_train, y_train = X[training_indices], y[training_indices] >>> S = Kriging(name='kriging', seed=124) >>> S.fit(X_train, y_train) >>> mean_prediction, std_prediction = S.predict(X) >>> plt.plot(X, y, label=r\"$f(x)$\", linestyle=\"dotted\") >>> plt.scatter(X_train, y_train, label=\"Observations\") >>> plt.plot(X, mean_prediction, label=\"Mean prediction\") >>> plt.fill_between( X.ravel(), mean_prediction - 1.96 * std_prediction, mean_prediction + 1.96 * std_prediction, alpha=0.5, label=r\"95% confidence interval\", ) >>> plt.legend() >>> plt.xlabel(\"$x$\") >>> plt.ylabel(\"$f(x)$\") >>> _ = plt.title(\"Gaussian process regression on noise-free dataset\") \"\"\" super () . __init__ ( name , seed , log_level ) self . noise = noise self . var_type = var_type self . cod_type = cod_type self . use_cod_y = use_cod_y self . name = name self . seed = seed self . log_level = log_level self . sigma = 0 self . eps = sqrt ( spacing ( 1 )) self . min_theta = min_theta self . max_theta = max_theta self . min_p = 1 self . max_p = 2 self . min_Lambda = 1e-9 self . max_Lambda = 1. self . n_theta = n_theta self . n_p = n_p self . optim_p = optim_p # Psi matrix condition: self . cnd_Psi = 0 self . inf_Psi = False self . model_optimizer = model_optimizer if self . model_optimizer is None : self . model_optimizer = differential_evolution self . model_fun_evals = model_fun_evals # differential evaluation uses maxiter = 1000 # and sets the number of function evaluations to # (maxiter + 1) * popsize * N, which results in # 1000 * 15 * k, because the default popsize is 15 and # N is the number of parameters. This seems to be quite large: # for k=2 these are 30 000 iterations. Therefore we set this value to # 100 if self . model_fun_evals is None : self . model_fun_evals = 100 # Logging information self . log [ \"negLnLike\" ] = [] self . log [ \"theta\" ] = [] self . log [ \"p\" ] = [] self . log [ \"Lambda\" ] = [] # Logger logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) def exp_imp ( self , y0 , s0 ): \"\"\" Returns the expected improvement for y0 and error s0 (in coded units). Args: y0 (float): function value (in coded units) s0 (float): error Returns: (float): The expected improvement value. \"\"\" # y_min = min(self.cod_y) y_min = min ( self . mean_cod_y ) if s0 <= 0.0 : EI = 0.0 elif s0 > 0.0 : EI_one = ( y_min - y0 ) * ( 0.5 + 0.5 * erf (( 1.0 / sqrt ( 2.0 )) * (( y_min - y0 ) / s0 )) ) EI_two = ( s0 * ( 1.0 / sqrt ( 2.0 * pi ))) * ( exp ( - ( 1.0 / 2.0 ) * (( y_min - y0 ) ** 2.0 / s0 ** 2.0 )) ) EI = EI_one + EI_two return EI def set_de_bounds ( self ): \"\"\" Determine search bounds for model_optimizer, e.g., differential evolution. \"\"\" de_bounds = [] for i in range ( self . n_theta ): de_bounds . append ([ self . min_theta , self . max_theta ]) if self . optim_p : for i in range ( self . n_p ): de_bounds . append ([ self . min_p , self . max_p ]) if self . noise : de_bounds . append ([ self . min_Lambda , self . max_Lambda ]) else : if self . noise : de_bounds . append ([ self . min_Lambda , self . max_Lambda ]) self . de_bounds = de_bounds def extract_from_bounds ( self , new_theta_p_Lambda ): \"\"\" Extract `theta`, `p`, and `Lambda` from bounds. The kriging object stores `theta` as an array, `p` as an array, and `Lambda` as a float. Args: new_theta_p_Lambda (numpy.array): 1d-array with theta, p, and Lambda values. Order is important. \"\"\" for i in range ( self . n_theta ): self . theta [ i ] = new_theta_p_Lambda [ i ] if self . optim_p : for i in range ( self . n_p ): self . p [ i ] = new_theta_p_Lambda [ i + self . n_theta ] if self . noise : self . Lambda = new_theta_p_Lambda [ self . n_theta + self . n_p ] else : if self . noise : self . Lambda = new_theta_p_Lambda [ self . n_theta ] def fit ( self , nat_X , nat_y ): \"\"\" The function fits the hyperparameters (`theta`, `p`, `Lambda`) of the Kriging model, i.e., the following internal values are computed: 1. `theta`, `p`, and `Lambda` values via optimization of the function `fun_likelihood()`. 2. Correlation matrix `Psi` via `rebuildPsi()`. Args: nat_X (array): sample points nat_y (array): function values Returns: surrogate (object): Fitted estimator. Attributes: theta (numpy.ndarray): Kriging theta values. Shape (k,). p (numpy.ndarray): Kriging p values. Shape (k,). LnDetPsi (numpy.float64): Determinant Psi matrix. Psi (numpy.matrix): Correlation matrix Psi. Shape (n,n). psi (numpy.ndarray): psi vector. Shape (n,). one (numpy.ndarray): vector of ones. Shape (n,). mu (numpy.float64): Kriging expected mean value mu. U (numpy.matrix): Kriging U matrix, Cholesky decomposition. Shape (n,n). SigmaSqr (numpy.float64): Sigma squared value. Lambda (float): lambda noise value. \"\"\" self . nat_X = copy . deepcopy ( nat_X ) self . nat_y = copy . deepcopy ( nat_y ) self . n = self . nat_X . shape [ 0 ] self . k = self . nat_X . shape [ 1 ] self . cod_X = empty_like ( self . nat_X ) self . cod_y = empty_like ( self . nat_y ) # assume all variable types are \"num\" if \"num\" is # specified once: if len ( self . var_type ) < self . k : self . var_type = self . var_type * self . k logger . warning ( \"Warning: All variable types forced to 'num'.\" ) self . num_mask = array ( list ( map ( lambda x : x == \"num\" , self . var_type ))) self . factor_mask = array ( list ( map ( lambda x : x == \"factor\" , self . var_type ))) self . int_mask = array ( list ( map ( lambda x : x == \"int\" , self . var_type ))) self . ordered_mask = array ( list ( map ( lambda x : x == \"int\" or x == \"num\" , self . var_type ))) self . nat_to_cod_init () if self . n_theta > self . k : self . n_theta = self . k logger . warning ( \"Warning: More theta values than dimensions. `n_theta` set to `k`.\" ) self . theta = zeros ( self . n_theta ) # TODO: Currently not used: self . x0_theta = ones (( self . n_theta ,)) * self . n / ( 100 * self . k ) self . p = ones ( self . n_p ) * 2.0 self . pen_val = self . n * log ( var ( self . nat_y )) + 1e4 self . negLnLike = None self . gen = spacefilling ( k = self . k , seed = self . seed ) # matrix related self . LnDetPsi = None self . Psi = zeros (( self . n , self . n ), dtype = float64 ) self . psi = zeros (( self . n , 1 )) self . one = ones ( self . n ) self . mu = None self . U = None self . SigmaSqr = None self . Lambda = None # build_Psi() and build_U() are called in fun_likelihood self . set_de_bounds () if self . model_optimizer . __name__ == 'dual_annealing' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) elif self . model_optimizer . __name__ == 'differential_evolution' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds , maxiter = self . model_fun_evals , seed = self . seed ) elif self . model_optimizer . __name__ == 'direct' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds , # maxfun=self.model_fun_evals, eps = 1e-2 ) elif self . model_optimizer . __name__ == 'shgo' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) elif self . model_optimizer . __name__ == 'basinhopping' : result = self . model_optimizer ( func = self . fun_likelihood , x0 = mean ( self . de_bounds , axis = 1 )) else : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) # Finally, set new theta and p values and update the surrogate again # for new_theta_p_Lambda in de_results[\"x\"]: new_theta_p_Lambda = result [ \"x\" ] self . extract_from_bounds ( new_theta_p_Lambda ) self . build_Psi () self . build_U () # TODO: check if the following line is necessary! self . likelihood () self . log [ \"negLnLike\" ] = append ( self . log [ \"negLnLike\" ], self . negLnLike ) self . log [ \"theta\" ] = append ( self . log [ \"theta\" ], self . theta ) self . log [ \"p\" ] = append ( self . log [ \"p\" ], self . p ) self . log [ \"Lambda\" ] = append ( self . log [ \"Lambda\" ], self . Lambda ) # TODO: return self def fun_likelihood ( self , new_theta_p_Lambda ): \"\"\" Compute log likelihood for a set of hyperparameters (theta, p, Lambda). Performs the following steps: 1. Build Psi via `build_Psi()` and `build_U()`. 2. Compute negLnLikelihood via `likelihood() 3. If successful, the return `negLnLike` value, otherwise a penalty value (`pen_val`). Args: new_theta_p_Lambda (array): `theta`, `p`, and `Lambda` values stored in an array. Returns: (float): negLnLike, th negative log likelihood of the surface at the hyperparameters specified. \"\"\" self . extract_from_bounds ( new_theta_p_Lambda ) if self . __is_any__ ( power ( 10.0 , self . theta ), 0 ): # print(f\"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to {self.pen_val:.2f}.\") logger . warning ( \"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to %s \" , self . pen_val ) return self . pen_val self . build_Psi () if ( self . inf_Psi or self . cnd_Psi > 1e9 ): # print(f\"\\nFailure in fun_likelihood: Psi is ill conditioned ({self.cnd_Psi}).\") # print(f\"Setting negLnLike to {self.pen_val:.2f}.\") logger . warning ( \"Failure in fun_likelihood: Psi is ill conditioned: %s \" , self . cnd_Psi ) logger . warning ( \"Setting negLnLike to: %s \" , self . pen_val ) return self . pen_val else : try : self . build_U () except Exception as err : f = self . pen_val print ( f \"Error in fun_likelihood(). Call to build_U() failed. { err =} , { type ( err ) =} \" ) print ( f \"Setting negLnLike to { self . pen_val : .2f } .\" ) return f self . likelihood () return self . negLnLike def __is_any__ ( self , x , v ): if not isinstance ( x , ndarray ): x = array ([ x ]) return any ( x == v ) def build_Psi ( self ): \"\"\" New construction (rebuild to reflect new data or a change in hyperparameters) of the (nxn) correlation matrix Psi as described in [Forr08a, p.57]. Note: Method uses `theta`, `p`, and coded `X` values. \"\"\" self . Psi = zeros (( self . n , self . n ), dtype = float64 ) theta = power ( 10.0 , self . theta ) if self . n_theta == 1 : theta = theta * ones ( self . k ) try : D = zeros (( self . n , self . n )) if self . ordered_mask . any (): X_ordered = self . cod_X [:, self . ordered_mask ] D = squareform ( pdist ( X_ordered , metric = 'sqeuclidean' , out = None , w = theta [ self . ordered_mask ])) if self . factor_mask . any (): X_factor = self . cod_X [:, self . factor_mask ] D = ( D + squareform ( pdist ( X_factor , metric = 'hamming' , out = None , w = theta [ self . factor_mask ]))) self . Psi = exp ( - D ) except LinAlgError as err : print ( f \"Building Psi failed: \\n { self . Psi } . { err =} , { type ( err ) =} \" ) if self . noise : self . Psi = self . Psi + multiply ( eye ( self . n ), self . Lambda ) else : self . Psi = self . Psi + multiply ( eye ( self . n ), self . eps ) if ( isinf ( self . Psi )) . any (): self . inf_Psi = True self . cnd_Psi = cond ( self . Psi ) def build_U ( self , scipy = True ): \"\"\" Cholesky factorization of Psi as U as described in [Forr08a, p.57]. Args: scipy (bool): Use `scipy_cholesky`. If `False`, numpy's `cholesky` is used. \"\"\" try : if scipy : self . U = scipy_cholesky ( self . Psi , lower = True ) else : self . U = cholesky ( self . Psi ) self . U = self . U . T except LinAlgError as err : print ( f \"build_U() Cholesky failed for Psi: \\n { self . Psi } . { err =} , { type ( err ) =} \" ) def likelihood ( self ): \"\"\" Calculates the negative of the concentrated log-likelihood. Implementation of (2.32) in [Forr08a]. See also function krigingLikelihood() in spot. Note: `build_Psi` and `build_U` should be called first. Modifies: `mu`, `SigmaSqr`, `LnDetPsi`, and `negLnLike`, concentrated log-likelihood *-1 for minimizing \"\"\" # (2.20) in [Forr08a]: mu = ( self . one . T . dot ( solve ( self . U , solve ( self . U . T , self . cod_y )) ) ) / self . one . T . dot ( solve ( self . U , solve ( self . U . T , self . one ))) self . mu = mu # (2.31) in [Forr08a] self . SigmaSqr = ( ( self . cod_y - self . one . dot ( self . mu )) . T . dot ( solve ( self . U , solve ( self . U . T , ( self . cod_y - self . one . dot ( self . mu ))), ) ) ) / self . n # (2.32) in [Forr08a] self . LnDetPsi = 2.0 * sum ( log ( abs ( diag ( self . U )))) self . negLnLike = - 1.0 * ( - ( self . n / 2.0 ) * log ( self . SigmaSqr ) - 0.5 * self . LnDetPsi ) def plot ( self , show = True ): \"\"\" This function plots 1d and 2d surrogates. Args: show (boolean): If `True`, the plots are displayed. If `False`, `plt.show()` should be called outside this function. \"\"\" if self . k == 1 : # TODO: Improve plot (add conf. interval etc.) fig = pylab . figure ( figsize = ( 9 , 6 )) # t1 = array(arange(0.0, 1.0, 0.01)) # y1 = array([self.predict(array([x]), return_val=\"y\") for x in t1]) # plt.figure() # plt.plot(t1, y1, \"k\") # if show: # plt.show() # n_grid = 100 x = linspace ( self . nat_range_X [ 0 ][ 0 ], self . nat_range_X [ 0 ][ 1 ], num = n_grid ) y = self . predict ( x ) plt . figure () plt . plot ( x , y , \"k\" ) if show : plt . show () if self . k == 2 : fig = pylab . figure ( figsize = ( 9 , 6 )) n_grid = 100 x = linspace ( self . nat_range_X [ 0 ][ 0 ], self . nat_range_X [ 0 ][ 1 ], num = n_grid ) y = linspace ( self . nat_range_X [ 1 ][ 0 ], self . nat_range_X [ 1 ][ 1 ], num = n_grid ) X , Y = meshgrid ( x , y ) # Predict based on the optimized results zz = array ( [ self . predict ( array ([ x , y ]), return_val = \"all\" ) for x , y in zip ( ravel ( X ), ravel ( Y ))] ) zs = zz [:, 0 , :] zse = zz [:, 1 , :] Z = zs . reshape ( X . shape ) Ze = zse . reshape ( X . shape ) if self . cod_type == \"norm\" : nat_point_X = ( self . cod_X [:, 0 ] * ( self . nat_range_X [ 0 ][ 1 ] - self . nat_range_X [ 0 ][ 0 ]) ) + self . nat_range_X [ 0 ][ 0 ] nat_point_Y = ( self . cod_X [:, 1 ] * ( self . nat_range_X [ 1 ][ 1 ] - self . nat_range_X [ 1 ][ 0 ]) ) + self . nat_range_X [ 1 ][ 0 ] elif self . cod_type == \"std\" : nat_point_X = self . cod_X [:, 0 ] * self . nat_std_X [ 0 ] + self . nat_mean_X [ 0 ] nat_point_Y = self . cod_X [:, 1 ] * self . nat_std_X [ 1 ] + self . nat_mean_X [ 1 ] else : nat_point_X = self . cod_X [:, 0 ] nat_point_Y = self . cod_X [:, 1 ] contour_levels = 30 ax = fig . add_subplot ( 224 ) # plot predicted values: pylab . contourf ( X , Y , Ze , contour_levels , cmap = \"jet\" ) pylab . title ( \"Error\" ) pylab . colorbar () # plot observed points: pylab . plot ( nat_point_X , nat_point_Y , \"ow\" ) # ax = fig . add_subplot ( 223 ) # plot predicted values: plt . contourf ( X , Y , Z , contour_levels , zorder = 1 , cmap = \"jet\" ) plt . title ( \"Surrogate\" ) # plot observed points: pylab . plot ( nat_point_X , nat_point_Y , \"ow\" , zorder = 3 ) pylab . colorbar () # ax = fig . add_subplot ( 221 , projection = \"3d\" ) ax . plot_surface ( X , Y , Z , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" ) # ax = fig . add_subplot ( 222 , projection = \"3d\" ) ax . plot_surface ( X , Y , Ze , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" ) # pylab . show () def predict ( self , nat_X , nat = True , return_val = \"y\" ): \"\"\" This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X. Args: nat_X (array): Design variable to evaluate in natural units. nat (bool): argument `nat_X` is in natural range. Default: `True`. If set to `False`, `nat_X` will not be normalized (which might be useful if already normalized y values are used). return_val (string): whether `y`, `s`, neg. `ei` (negative expected improvement), or all three values are returned. Default is (for compatibility with sklearn) \"y\". To return `s`, select \"s\", to return neg. `ei`, select \"ei\". To return the tuple `(y, s, ei)`, select \"all\". Returns: (float): The predicted value in natural units. (float): predicted error (float): expected improvement \"\"\" # Check for the shape and the type of the Input if isinstance ( nat_X , ndarray ): try : X = nat_X . reshape ( - 1 , self . nat_X . shape [ 1 ]) X = repair_non_numeric ( X , self . var_type ) except Exception : raise TypeError ( \"13.1: Input to predict was not convertible to the size of X\" ) else : raise TypeError ( f \"type of the given input is an { type ( nat_X ) } instead of an ndarray\" ) # Iterate through the Input y = array ([], dtype = float ) s = array ([], dtype = float ) ei = array ([], dtype = float ) for i in range ( X . shape [ 0 ]): # logger.debug(f\"13.2: predict() Step 2: x (reshaped nat_X):\\n {x}\") if nat : x = self . nat_to_cod_x ( X [ i , :]) else : x = X [ i , :] y0 , s0 , ei0 = self . predict_coded ( x ) y = append ( y , y0 ) s = append ( s , s0 ) ei = append ( ei , ei0 ) if return_val == \"y\" : return y elif return_val == \"s\" : return s elif return_val == \"ei\" : return - 1.0 * ei else : return y , s , - 1.0 * ei def build_psi_vec ( self , cod_x ): \"\"\" Build the psi vector. Needed by `predict_cod`, `predict_err_coded`, `regression_predict_coded`. Modifies `self.psi`. Args: cod_x (array): point to calculate psi \"\"\" self . psi = zeros (( self . n )) # theta = self.theta # TODO: theta = power ( 10.0 , self . theta ) if self . n_theta == 1 : theta = theta * ones ( self . k ) try : D = zeros (( self . n )) if self . ordered_mask . any (): X_ordered = self . cod_X [:, self . ordered_mask ] x_ordered = cod_x [ self . ordered_mask ] D = cdist ( x_ordered . reshape ( - 1 , sum ( self . ordered_mask )), X_ordered . reshape ( - 1 , sum ( self . ordered_mask )), metric = 'sqeuclidean' , out = None , w = theta [ self . ordered_mask ]) if self . factor_mask . any (): X_factor = self . cod_X [:, self . factor_mask ] x_factor = cod_x [ self . factor_mask ] D = ( D + cdist ( x_factor . reshape ( - 1 , sum ( self . factor_mask )), X_factor . reshape ( - 1 , sum ( self . factor_mask )), metric = 'hamming' , out = None , w = theta [ self . factor_mask ])) self . psi = exp ( - D ) . T except LinAlgError as err : print ( f \"Building psi failed: \\n { self . psi } . { err =} , { type ( err ) =} \" ) def predict_coded ( self , cod_x ): \"\"\" Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a]. The error is returned as well. See also [Forr08a, p.60]. Note: `self.mu` and `self.SigmaSqr` are computed in `likelihood`, not here. Args: cod_x (array): point in coded units to make prediction at Returns: (float): predicted value in coded units. (float): predicted error. \"\"\" self . build_psi_vec ( cod_x ) f = self . mu + self . psi . T . dot ( solve ( self . U , solve ( self . U . T , self . cod_y - self . one . dot ( self . mu ))) ) try : if self . noise : Lambda = self . Lambda else : Lambda = 0.0 # Error in [Forr08a, p.87]: SSqr = self . SigmaSqr * ( 1 + Lambda - self . psi . T . dot ( solve ( self . U , solve ( self . U . T , self . psi )))) except Exception as err : print ( f \"Could not determine SSqr. Wrong or missing Lambda? { err =} , { type ( err ) =} \" ) SSqr = power ( abs ( SSqr [ 0 ]), 0.5 )[ 0 ] EI = self . exp_imp ( y0 = f [ 0 ], s0 = SSqr ) return f [ 0 ], SSqr , EI def weighted_exp_imp ( self , cod_x , w ): \"\"\" Weighted expected improvement. References: [Sobester et al. 2005]. Args: cod_x (array): A coded design vector. w (float): weight Returns: (float): weighted expected improvement. \"\"\" y0 , s0 = self . predict_coded ( cod_x ) y_min = min ( self . cod_y ) if s0 <= 0.0 : EI = 0.0 elif s0 > 0.0 : EI_one = w * ( ( y_min - y0 ) * ( 0.5 + 0.5 * erf (( 1.0 / sqrt ( 2.0 )) * (( y_min - y0 ) / s0 ))) ) EI_two = ( ( 1.0 - w ) * ( s0 * ( 1.0 / sqrt ( 2.0 * pi ))) * ( exp ( - ( 1.0 / 2.0 ) * (( y_min - y0 ) ** 2.0 / s0 ** 2.0 ))) ) EI = EI_one + EI_two return EI def calculate_mean_MSE ( self , n_samples = 200 , points = None ): \"\"\" This function calculates the mean MSE metric of the model by evaluating MSE at a number of points. Args: n_samples (integer): Number of points to sample the mean squared error at. Ignored if the points argument is specified. points (array): an array of points to sample the model at. Returns: (float): the mean value of MSE and the standard deviation of the MSE points \"\"\" if points is None : points = self . gen . lhd ( n_samples ) values = zeros ( len ( points )) for enu , point in enumerate ( points ): s0 = self . predict ( cod_X = point , nat = True , return_val = \"s\" ) values [ enu ] = s0 return mean ( values ), std ( values ) def cod_to_nat_x ( self , cod_X ): \"\"\" Args: cod_X (array): An array representing one point (self.k long) in normalized (coded) units. Returns: (array): An array of natural (physical or real world) units. \"\"\" X = copy . deepcopy ( cod_X ) if self . cod_type == \"norm\" : for i in range ( self . k ): X [ i ] = ( X [ i ] * float ( self . nat_range_X [ i ][ 1 ] - self . nat_range_X [ i ][ 0 ]) ) + self . nat_range_X [ i ][ 0 ] return X elif self . cod_type == \"std\" : for i in range ( self . k ): X [ i ] = X [ i ] * self . nat_std_X [ i ] + self . nat_mean_X [ i ] return X else : return cod_X def cod_to_nat_y ( self , cod_y ): \"\"\" Args: cod_y (array): A normalized array of coded (model) units in the range of [0,1]. Returns: (array): An array of observed values in real-world units. \"\"\" if self . cod_type == \"norm\" : return ( cod_y * ( self . nat_range_y [ 1 ] - self . nat_range_y [ 0 ]) ) + self . nat_range_y [ 0 ] elif self . cod_type == \"std\" : return cod_y * self . nat_std_y + self . nat_mean_y else : return cod_y def nat_to_cod_x ( self , nat_X ): \"\"\" Normalize one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated. Args: nat_X (array): An array representing one points (self.k long) in natural (physical or real world) units. Returns: (array): An array of coded values in the range of [0,1] for each dimension. \"\"\" X = copy . deepcopy ( nat_X ) if self . cod_type == \"norm\" : for i in range ( self . k ): X [ i ] = ( X [ i ] - self . nat_range_X [ i ][ 0 ]) / float ( self . nat_range_X [ i ][ 1 ] - self . nat_range_X [ i ][ 0 ]) # TODO: Implement range correction if range == 0: # rangex <- xmax - xmin # rangey <- ymax - ymin # xmin[rangex == 0] <- xmin[rangex == 0] - 0.5 # xmax[rangex == 0] <- xmax[rangex == 0] + 0.5 # rangex[rangex == 0] <- 1 # logger.debug(f\"self.nat_range_X[{i}]:\\n {self.nat_range_X[i]}\") # logger.debug(f\"X[{i}]:\\n {X[i]}\") return X elif self . cod_type == \"std\" : for i in range ( self . k ): X [ i ] = ( X [ i ] - self . nat_mean_X [ i ]) / self . nat_std_X [ i ] return X else : return nat_X def nat_to_cod_y ( self , nat_y ): \"\"\" Normalize natural y values to [0,1]. Args: nat_y (array): An array of observed values in natural (real-world) units. Returns: (array): A normalized array of coded (model) units in the range of [0,1]. \"\"\" if self . use_cod_y : if self . cod_type == \"norm\" : return ( nat_y - self . nat_range_y [ 0 ]) / ( self . nat_range_y [ 1 ] - self . nat_range_y [ 0 ]) elif self . cod_type == \"std\" : return ( nat_y - self . nat_mean_y ) / self . nat_std_y else : return nat_y else : return nat_y def nat_to_cod_init ( self ): \"\"\" Determine max and min of each dimension and normalize that axis to a range of [0,1]. Called when 1) surrogate is initialized and 2) new points arrive, i.e., suggested by the surrogate as infill points. This method calls `nat_to_cod_x` and `nat_to_cod_y` and updates the ranges `nat_range_X` and `nat_range_y`. \"\"\" self . nat_range_X = [] self . nat_range_y = [] for i in range ( self . k ): self . nat_range_X . append ([ min ( self . nat_X [:, i ]), max ( self . nat_X [:, i ])]) self . nat_range_y . append ( min ( self . nat_y )) self . nat_range_y . append ( max ( self . nat_y )) self . nat_mean_X = mean ( self . nat_X , axis = 0 ) self . nat_std_X = std ( self . nat_X , axis = 0 ) self . nat_mean_y = mean ( self . nat_y ) self . nat_std_y = std ( self . nat_y ) Z = aggregate_mean_var ( X = self . nat_X , y = self . nat_y ) mu = Z [ 1 ] self . mean_cod_y = empty_like ( mu ) for i in range ( self . n ): self . cod_X [ i ] = self . nat_to_cod_x ( self . nat_X [ i ]) for i in range ( self . n ): self . cod_y [ i ] = self . nat_to_cod_y ( self . nat_y [ i ]) for i in range ( mu . shape [ 0 ]): self . mean_cod_y [ i ] = self . nat_to_cod_y ( mu [ i ])","title":"Kriging"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.__init__","text":"Kriging surrogate. Parameters: Name Type Description Default noise bool use regression instead of interpolation kriging. Defaults to \"False\". False cod_type bool normalize or standardize X and values. Can be None, \"norm\", or \"std\". Defaults to \"norm\". 'norm' var_type str variable type. Can be either \"num \" (numerical) of \"factor\" (factor). Defaults to \"num\" . ['num'] use_cod_y bool use coded y values (instead of natural one). Defaults to False . False name str Surrogate name. Defaults to \"kriging\" . 'kriging' seed int Random seed. Defaults to 124 . 124 model_optimizer object Optimizer on the surrogate. If None , differential_evolution is selected. None model_fun_evals int Number of iterations used by the optimizer on the surrogate. None min_theta float min log10 theta value. Defaults to -6. . -3 max_theta float max log10 theta value. Defaults to 3. . 2 n_theta int number of theta values. Defaults to 1 . 1 n_p int number of p values. Defaults to 1 . 1 optim_p bool Determines whether p should be optimized. False log_level int logging level, e.g., 20 is \"INFO\" . Defaults to 50 ( \"CRITICAL\" ). 50 Attributes: Name Type Description nat_range_X list List of X natural ranges. nat_range_y list List of y nat ranges. noise bool noisy objective function. Default: False. If True , regression kriging will be used. var_type str variable type. Can be either \"num \" (numerical) of \"factor\" (factor). num_mask array array of bool variables. True represent numerical (float) variables. factor_mask array array of factor variables. True represents factor (unordered) variables. int_mask array array of integer variables. True represents integers (ordered) variables. ordered_mask array array of ordered variables. True represents integers or float (ordered) variables. Set of veriables which an order relation, i.e., they are either num (float) or int. name str Surrogate name seed int Random seed. use_cod_y bool Use coded y values. sigma float Kriging sigma. gen method Design generator, e.g., spotPython.design.spacefilling.spacefilling. min_theta float min log10 theta value. Defaults: -6. max_theta float max log10 theta value. Defaults: 3. min_p float min p value. Default: 1. max_p float max p value. Default: 2. Examples: Surrogate of the x*sin(x) function. See: scikit-learn >>> from spotPython.build.kriging import Kriging >>> import numpy as np >>> import matplotlib.pyplot as plt >>> rng = np . random . RandomState ( 1 ) >>> X = linspace ( start = 0 , stop = 10 , num = 1_000 ) . reshape ( - 1 , 1 ) >>> y = np . squeeze ( X * np . sin ( X )) >>> training_indices = rng . choice ( arange ( y . size ), size = 6 , replace = False ) >>> X_train , y_train = X [ training_indices ], y [ training_indices ] >>> S = Kriging ( name = 'kriging' , seed = 124 ) >>> S . fit ( X_train , y_train ) >>> mean_prediction , std_prediction = S . predict ( X ) >>> plt . plot ( X , y , label = r \"$f(x)$\" , linestyle = \"dotted\" ) >>> plt . scatter ( X_train , y_train , label = \"Observations\" ) >>> plt . plot ( X , mean_prediction , label = \"Mean prediction\" ) >>> plt . fill_between ( X.ravel(), mean_prediction - 1.96 * std_prediction, mean_prediction + 1.96 * std_prediction, alpha=0.5, label=r\"95% confidence interval\", ) >>> plt . legend () >>> plt . xlabel ( \"$x$\" ) >>> plt . ylabel ( \"$f(x)$\" ) >>> _ = plt . title ( \"Gaussian process regression on noise-free dataset\" ) Source code in spotPython/build/kriging.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 def __init__ ( self , noise = False , cod_type = \"norm\" , var_type = [ \"num\" ], use_cod_y = False , name = \"kriging\" , seed = 124 , model_optimizer = None , model_fun_evals = None , min_theta =- 3 , # TODO max_theta = 2 , # TODO n_theta = 1 , n_p = 1 , optim_p = False , log_level = 50 , ** kwargs ): \"\"\" Kriging surrogate. Args: noise (bool): use regression instead of interpolation kriging. Defaults to \"False\". cod_type (bool): normalize or standardize X and values. Can be None, \"norm\", or \"std\". Defaults to \"norm\". var_type (str): variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor). Defaults to `\"num\"`. use_cod_y (bool): use coded y values (instead of natural one). Defaults to `False`. name (str): Surrogate name. Defaults to `\"kriging\"`. seed (int): Random seed. Defaults to `124`. model_optimizer (object): Optimizer on the surrogate. If `None`, `differential_evolution` is selected. model_fun_evals (int): Number of iterations used by the optimizer on the surrogate. min_theta (float): min log10 theta value. Defaults to `-6.`. max_theta (float): max log10 theta value. Defaults to `3.`. n_theta (int): number of theta values. Defaults to `1`. n_p (int): number of p values. Defaults to `1`. optim_p (bool): Determines whether `p` should be optimized. log_level (int): logging level, e.g., `20` is `\"INFO\"`. Defaults to `50` (`\"CRITICAL\"`). Attributes: nat_range_X (list): List of X natural ranges. nat_range_y (list): List of y nat ranges. noise (bool): noisy objective function. Default: False. If `True`, regression kriging will be used. var_type (str): variable type. Can be either `\"num`\" (numerical) of `\"factor\"` (factor). num_mask (array): array of bool variables. `True` represent numerical (float) variables. factor_mask (array): array of factor variables. `True` represents factor (unordered) variables. int_mask (array): array of integer variables. `True` represents integers (ordered) variables. ordered_mask (array): array of ordered variables. `True` represents integers or float (ordered) variables. Set of veriables which an order relation, i.e., they are either num (float) or int. name (str): Surrogate name seed (int): Random seed. use_cod_y (bool): Use coded y values. sigma (float): Kriging sigma. gen (method): Design generator, e.g., spotPython.design.spacefilling.spacefilling. min_theta (float): min log10 theta value. Defaults: -6. max_theta (float): max log10 theta value. Defaults: 3. min_p (float): min p value. Default: 1. max_p (float): max p value. Default: 2. Examples: Surrogate of the x*sin(x) function. See: [scikit-learn](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html) >>> from spotPython.build.kriging import Kriging >>> import numpy as np >>> import matplotlib.pyplot as plt >>> rng = np.random.RandomState(1) >>> X = linspace(start=0, stop=10, num=1_000).reshape(-1, 1) >>> y = np.squeeze(X * np.sin(X)) >>> training_indices = rng.choice(arange(y.size), size=6, replace=False) >>> X_train, y_train = X[training_indices], y[training_indices] >>> S = Kriging(name='kriging', seed=124) >>> S.fit(X_train, y_train) >>> mean_prediction, std_prediction = S.predict(X) >>> plt.plot(X, y, label=r\"$f(x)$\", linestyle=\"dotted\") >>> plt.scatter(X_train, y_train, label=\"Observations\") >>> plt.plot(X, mean_prediction, label=\"Mean prediction\") >>> plt.fill_between( X.ravel(), mean_prediction - 1.96 * std_prediction, mean_prediction + 1.96 * std_prediction, alpha=0.5, label=r\"95% confidence interval\", ) >>> plt.legend() >>> plt.xlabel(\"$x$\") >>> plt.ylabel(\"$f(x)$\") >>> _ = plt.title(\"Gaussian process regression on noise-free dataset\") \"\"\" super () . __init__ ( name , seed , log_level ) self . noise = noise self . var_type = var_type self . cod_type = cod_type self . use_cod_y = use_cod_y self . name = name self . seed = seed self . log_level = log_level self . sigma = 0 self . eps = sqrt ( spacing ( 1 )) self . min_theta = min_theta self . max_theta = max_theta self . min_p = 1 self . max_p = 2 self . min_Lambda = 1e-9 self . max_Lambda = 1. self . n_theta = n_theta self . n_p = n_p self . optim_p = optim_p # Psi matrix condition: self . cnd_Psi = 0 self . inf_Psi = False self . model_optimizer = model_optimizer if self . model_optimizer is None : self . model_optimizer = differential_evolution self . model_fun_evals = model_fun_evals # differential evaluation uses maxiter = 1000 # and sets the number of function evaluations to # (maxiter + 1) * popsize * N, which results in # 1000 * 15 * k, because the default popsize is 15 and # N is the number of parameters. This seems to be quite large: # for k=2 these are 30 000 iterations. Therefore we set this value to # 100 if self . model_fun_evals is None : self . model_fun_evals = 100 # Logging information self . log [ \"negLnLike\" ] = [] self . log [ \"theta\" ] = [] self . log [ \"p\" ] = [] self . log [ \"Lambda\" ] = [] # Logger logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" )","title":"__init__()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.build_Psi","text":"New construction (rebuild to reflect new data or a change in hyperparameters) of the (nxn) correlation matrix Psi as described in [Forr08a, p.57]. Note Method uses theta , p , and coded X values. Source code in spotPython/build/kriging.py 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 def build_Psi ( self ): \"\"\" New construction (rebuild to reflect new data or a change in hyperparameters) of the (nxn) correlation matrix Psi as described in [Forr08a, p.57]. Note: Method uses `theta`, `p`, and coded `X` values. \"\"\" self . Psi = zeros (( self . n , self . n ), dtype = float64 ) theta = power ( 10.0 , self . theta ) if self . n_theta == 1 : theta = theta * ones ( self . k ) try : D = zeros (( self . n , self . n )) if self . ordered_mask . any (): X_ordered = self . cod_X [:, self . ordered_mask ] D = squareform ( pdist ( X_ordered , metric = 'sqeuclidean' , out = None , w = theta [ self . ordered_mask ])) if self . factor_mask . any (): X_factor = self . cod_X [:, self . factor_mask ] D = ( D + squareform ( pdist ( X_factor , metric = 'hamming' , out = None , w = theta [ self . factor_mask ]))) self . Psi = exp ( - D ) except LinAlgError as err : print ( f \"Building Psi failed: \\n { self . Psi } . { err =} , { type ( err ) =} \" ) if self . noise : self . Psi = self . Psi + multiply ( eye ( self . n ), self . Lambda ) else : self . Psi = self . Psi + multiply ( eye ( self . n ), self . eps ) if ( isinf ( self . Psi )) . any (): self . inf_Psi = True self . cnd_Psi = cond ( self . Psi )","title":"build_Psi()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.build_U","text":"Cholesky factorization of Psi as U as described in [Forr08a, p.57]. Parameters: Name Type Description Default scipy bool Use scipy_cholesky . If False , numpy's cholesky is used. True Source code in spotPython/build/kriging.py 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 def build_U ( self , scipy = True ): \"\"\" Cholesky factorization of Psi as U as described in [Forr08a, p.57]. Args: scipy (bool): Use `scipy_cholesky`. If `False`, numpy's `cholesky` is used. \"\"\" try : if scipy : self . U = scipy_cholesky ( self . Psi , lower = True ) else : self . U = cholesky ( self . Psi ) self . U = self . U . T except LinAlgError as err : print ( f \"build_U() Cholesky failed for Psi: \\n { self . Psi } . { err =} , { type ( err ) =} \" )","title":"build_U()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.build_psi_vec","text":"Build the psi vector. Needed by predict_cod , predict_err_coded , regression_predict_coded . Modifies self.psi . Parameters: Name Type Description Default cod_x array point to calculate psi required Source code in spotPython/build/kriging.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 def build_psi_vec ( self , cod_x ): \"\"\" Build the psi vector. Needed by `predict_cod`, `predict_err_coded`, `regression_predict_coded`. Modifies `self.psi`. Args: cod_x (array): point to calculate psi \"\"\" self . psi = zeros (( self . n )) # theta = self.theta # TODO: theta = power ( 10.0 , self . theta ) if self . n_theta == 1 : theta = theta * ones ( self . k ) try : D = zeros (( self . n )) if self . ordered_mask . any (): X_ordered = self . cod_X [:, self . ordered_mask ] x_ordered = cod_x [ self . ordered_mask ] D = cdist ( x_ordered . reshape ( - 1 , sum ( self . ordered_mask )), X_ordered . reshape ( - 1 , sum ( self . ordered_mask )), metric = 'sqeuclidean' , out = None , w = theta [ self . ordered_mask ]) if self . factor_mask . any (): X_factor = self . cod_X [:, self . factor_mask ] x_factor = cod_x [ self . factor_mask ] D = ( D + cdist ( x_factor . reshape ( - 1 , sum ( self . factor_mask )), X_factor . reshape ( - 1 , sum ( self . factor_mask )), metric = 'hamming' , out = None , w = theta [ self . factor_mask ])) self . psi = exp ( - D ) . T except LinAlgError as err : print ( f \"Building psi failed: \\n { self . psi } . { err =} , { type ( err ) =} \" )","title":"build_psi_vec()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.calculate_mean_MSE","text":"This function calculates the mean MSE metric of the model by evaluating MSE at a number of points. Parameters: Name Type Description Default n_samples integer Number of points to sample the mean squared error at. Ignored if the points argument is specified. 200 points array an array of points to sample the model at. None Returns: Type Description float the mean value of MSE and the standard deviation of the MSE points Source code in spotPython/build/kriging.py 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 def calculate_mean_MSE ( self , n_samples = 200 , points = None ): \"\"\" This function calculates the mean MSE metric of the model by evaluating MSE at a number of points. Args: n_samples (integer): Number of points to sample the mean squared error at. Ignored if the points argument is specified. points (array): an array of points to sample the model at. Returns: (float): the mean value of MSE and the standard deviation of the MSE points \"\"\" if points is None : points = self . gen . lhd ( n_samples ) values = zeros ( len ( points )) for enu , point in enumerate ( points ): s0 = self . predict ( cod_X = point , nat = True , return_val = \"s\" ) values [ enu ] = s0 return mean ( values ), std ( values )","title":"calculate_mean_MSE()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.cod_to_nat_x","text":"Parameters: Name Type Description Default cod_X array An array representing one point (self.k long) in normalized (coded) units. required Returns: Type Description array An array of natural (physical or real world) units. Source code in spotPython/build/kriging.py 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 def cod_to_nat_x ( self , cod_X ): \"\"\" Args: cod_X (array): An array representing one point (self.k long) in normalized (coded) units. Returns: (array): An array of natural (physical or real world) units. \"\"\" X = copy . deepcopy ( cod_X ) if self . cod_type == \"norm\" : for i in range ( self . k ): X [ i ] = ( X [ i ] * float ( self . nat_range_X [ i ][ 1 ] - self . nat_range_X [ i ][ 0 ]) ) + self . nat_range_X [ i ][ 0 ] return X elif self . cod_type == \"std\" : for i in range ( self . k ): X [ i ] = X [ i ] * self . nat_std_X [ i ] + self . nat_mean_X [ i ] return X else : return cod_X","title":"cod_to_nat_x()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.cod_to_nat_y","text":"Parameters: Name Type Description Default cod_y array A normalized array of coded (model) units in the range of [0,1]. required Returns: Type Description array An array of observed values in real-world units. Source code in spotPython/build/kriging.py 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 def cod_to_nat_y ( self , cod_y ): \"\"\" Args: cod_y (array): A normalized array of coded (model) units in the range of [0,1]. Returns: (array): An array of observed values in real-world units. \"\"\" if self . cod_type == \"norm\" : return ( cod_y * ( self . nat_range_y [ 1 ] - self . nat_range_y [ 0 ]) ) + self . nat_range_y [ 0 ] elif self . cod_type == \"std\" : return cod_y * self . nat_std_y + self . nat_mean_y else : return cod_y","title":"cod_to_nat_y()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.exp_imp","text":"Returns the expected improvement for y0 and error s0 (in coded units). Parameters: Name Type Description Default y0 float function value (in coded units) required s0 float error required Returns: Type Description float The expected improvement value. Source code in spotPython/build/kriging.py 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def exp_imp ( self , y0 , s0 ): \"\"\" Returns the expected improvement for y0 and error s0 (in coded units). Args: y0 (float): function value (in coded units) s0 (float): error Returns: (float): The expected improvement value. \"\"\" # y_min = min(self.cod_y) y_min = min ( self . mean_cod_y ) if s0 <= 0.0 : EI = 0.0 elif s0 > 0.0 : EI_one = ( y_min - y0 ) * ( 0.5 + 0.5 * erf (( 1.0 / sqrt ( 2.0 )) * (( y_min - y0 ) / s0 )) ) EI_two = ( s0 * ( 1.0 / sqrt ( 2.0 * pi ))) * ( exp ( - ( 1.0 / 2.0 ) * (( y_min - y0 ) ** 2.0 / s0 ** 2.0 )) ) EI = EI_one + EI_two return EI","title":"exp_imp()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.extract_from_bounds","text":"Extract theta , p , and Lambda from bounds. The kriging object stores theta as an array, p as an array, and Lambda as a float. Parameters: Name Type Description Default new_theta_p_Lambda numpy . array 1d-array with theta, p, and Lambda values. Order is important. required Source code in spotPython/build/kriging.py 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 def extract_from_bounds ( self , new_theta_p_Lambda ): \"\"\" Extract `theta`, `p`, and `Lambda` from bounds. The kriging object stores `theta` as an array, `p` as an array, and `Lambda` as a float. Args: new_theta_p_Lambda (numpy.array): 1d-array with theta, p, and Lambda values. Order is important. \"\"\" for i in range ( self . n_theta ): self . theta [ i ] = new_theta_p_Lambda [ i ] if self . optim_p : for i in range ( self . n_p ): self . p [ i ] = new_theta_p_Lambda [ i + self . n_theta ] if self . noise : self . Lambda = new_theta_p_Lambda [ self . n_theta + self . n_p ] else : if self . noise : self . Lambda = new_theta_p_Lambda [ self . n_theta ]","title":"extract_from_bounds()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.fit","text":"The function fits the hyperparameters ( theta , p , Lambda ) of the Kriging model, i.e., the following internal values are computed: theta , p , and Lambda values via optimization of the function fun_likelihood() . Correlation matrix Psi via rebuildPsi() . Parameters: Name Type Description Default nat_X array sample points required nat_y array function values required Returns: Name Type Description surrogate object Fitted estimator. Attributes: Name Type Description theta numpy . ndarray Kriging theta values. Shape (k,). p numpy . ndarray Kriging p values. Shape (k,). LnDetPsi numpy . float64 Determinant Psi matrix. Psi numpy . matrix Correlation matrix Psi. Shape (n,n). psi numpy . ndarray psi vector. Shape (n,). one numpy . ndarray vector of ones. Shape (n,). mu numpy . float64 Kriging expected mean value mu. U numpy . matrix Kriging U matrix, Cholesky decomposition. Shape (n,n). SigmaSqr numpy . float64 Sigma squared value. Lambda float lambda noise value. Source code in spotPython/build/kriging.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 def fit ( self , nat_X , nat_y ): \"\"\" The function fits the hyperparameters (`theta`, `p`, `Lambda`) of the Kriging model, i.e., the following internal values are computed: 1. `theta`, `p`, and `Lambda` values via optimization of the function `fun_likelihood()`. 2. Correlation matrix `Psi` via `rebuildPsi()`. Args: nat_X (array): sample points nat_y (array): function values Returns: surrogate (object): Fitted estimator. Attributes: theta (numpy.ndarray): Kriging theta values. Shape (k,). p (numpy.ndarray): Kriging p values. Shape (k,). LnDetPsi (numpy.float64): Determinant Psi matrix. Psi (numpy.matrix): Correlation matrix Psi. Shape (n,n). psi (numpy.ndarray): psi vector. Shape (n,). one (numpy.ndarray): vector of ones. Shape (n,). mu (numpy.float64): Kriging expected mean value mu. U (numpy.matrix): Kriging U matrix, Cholesky decomposition. Shape (n,n). SigmaSqr (numpy.float64): Sigma squared value. Lambda (float): lambda noise value. \"\"\" self . nat_X = copy . deepcopy ( nat_X ) self . nat_y = copy . deepcopy ( nat_y ) self . n = self . nat_X . shape [ 0 ] self . k = self . nat_X . shape [ 1 ] self . cod_X = empty_like ( self . nat_X ) self . cod_y = empty_like ( self . nat_y ) # assume all variable types are \"num\" if \"num\" is # specified once: if len ( self . var_type ) < self . k : self . var_type = self . var_type * self . k logger . warning ( \"Warning: All variable types forced to 'num'.\" ) self . num_mask = array ( list ( map ( lambda x : x == \"num\" , self . var_type ))) self . factor_mask = array ( list ( map ( lambda x : x == \"factor\" , self . var_type ))) self . int_mask = array ( list ( map ( lambda x : x == \"int\" , self . var_type ))) self . ordered_mask = array ( list ( map ( lambda x : x == \"int\" or x == \"num\" , self . var_type ))) self . nat_to_cod_init () if self . n_theta > self . k : self . n_theta = self . k logger . warning ( \"Warning: More theta values than dimensions. `n_theta` set to `k`.\" ) self . theta = zeros ( self . n_theta ) # TODO: Currently not used: self . x0_theta = ones (( self . n_theta ,)) * self . n / ( 100 * self . k ) self . p = ones ( self . n_p ) * 2.0 self . pen_val = self . n * log ( var ( self . nat_y )) + 1e4 self . negLnLike = None self . gen = spacefilling ( k = self . k , seed = self . seed ) # matrix related self . LnDetPsi = None self . Psi = zeros (( self . n , self . n ), dtype = float64 ) self . psi = zeros (( self . n , 1 )) self . one = ones ( self . n ) self . mu = None self . U = None self . SigmaSqr = None self . Lambda = None # build_Psi() and build_U() are called in fun_likelihood self . set_de_bounds () if self . model_optimizer . __name__ == 'dual_annealing' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) elif self . model_optimizer . __name__ == 'differential_evolution' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds , maxiter = self . model_fun_evals , seed = self . seed ) elif self . model_optimizer . __name__ == 'direct' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds , # maxfun=self.model_fun_evals, eps = 1e-2 ) elif self . model_optimizer . __name__ == 'shgo' : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) elif self . model_optimizer . __name__ == 'basinhopping' : result = self . model_optimizer ( func = self . fun_likelihood , x0 = mean ( self . de_bounds , axis = 1 )) else : result = self . model_optimizer ( func = self . fun_likelihood , bounds = self . de_bounds ) # Finally, set new theta and p values and update the surrogate again # for new_theta_p_Lambda in de_results[\"x\"]: new_theta_p_Lambda = result [ \"x\" ] self . extract_from_bounds ( new_theta_p_Lambda ) self . build_Psi () self . build_U () # TODO: check if the following line is necessary! self . likelihood () self . log [ \"negLnLike\" ] = append ( self . log [ \"negLnLike\" ], self . negLnLike ) self . log [ \"theta\" ] = append ( self . log [ \"theta\" ], self . theta ) self . log [ \"p\" ] = append ( self . log [ \"p\" ], self . p ) self . log [ \"Lambda\" ] = append ( self . log [ \"Lambda\" ], self . Lambda )","title":"fit()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.fun_likelihood","text":"Compute log likelihood for a set of hyperparameters (theta, p, Lambda). Performs the following steps: Build Psi via build_Psi() and build_U() . Compute negLnLikelihood via `likelihood() If successful, the return negLnLike value, otherwise a penalty value ( pen_val ). Parameters: Name Type Description Default new_theta_p_Lambda array theta , p , and Lambda values stored in an array. required Returns: Type Description float negLnLike, th negative log likelihood of the surface at the hyperparameters specified. Source code in spotPython/build/kriging.py 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 def fun_likelihood ( self , new_theta_p_Lambda ): \"\"\" Compute log likelihood for a set of hyperparameters (theta, p, Lambda). Performs the following steps: 1. Build Psi via `build_Psi()` and `build_U()`. 2. Compute negLnLikelihood via `likelihood() 3. If successful, the return `negLnLike` value, otherwise a penalty value (`pen_val`). Args: new_theta_p_Lambda (array): `theta`, `p`, and `Lambda` values stored in an array. Returns: (float): negLnLike, th negative log likelihood of the surface at the hyperparameters specified. \"\"\" self . extract_from_bounds ( new_theta_p_Lambda ) if self . __is_any__ ( power ( 10.0 , self . theta ), 0 ): # print(f\"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to {self.pen_val:.2f}.\") logger . warning ( \"Failure in fun_likelihood: 10^theta == 0. Setting negLnLike to %s \" , self . pen_val ) return self . pen_val self . build_Psi () if ( self . inf_Psi or self . cnd_Psi > 1e9 ): # print(f\"\\nFailure in fun_likelihood: Psi is ill conditioned ({self.cnd_Psi}).\") # print(f\"Setting negLnLike to {self.pen_val:.2f}.\") logger . warning ( \"Failure in fun_likelihood: Psi is ill conditioned: %s \" , self . cnd_Psi ) logger . warning ( \"Setting negLnLike to: %s \" , self . pen_val ) return self . pen_val else : try : self . build_U () except Exception as err : f = self . pen_val print ( f \"Error in fun_likelihood(). Call to build_U() failed. { err =} , { type ( err ) =} \" ) print ( f \"Setting negLnLike to { self . pen_val : .2f } .\" ) return f self . likelihood () return self . negLnLike","title":"fun_likelihood()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.likelihood","text":"Calculates the negative of the concentrated log-likelihood. Implementation of (2.32) in [Forr08a]. See also function krigingLikelihood() in spot. Note build_Psi and build_U should be called first. Modifies mu , SigmaSqr , LnDetPsi , and negLnLike , concentrated log-likelihood *-1 for minimizing Source code in spotPython/build/kriging.py 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 def likelihood ( self ): \"\"\" Calculates the negative of the concentrated log-likelihood. Implementation of (2.32) in [Forr08a]. See also function krigingLikelihood() in spot. Note: `build_Psi` and `build_U` should be called first. Modifies: `mu`, `SigmaSqr`, `LnDetPsi`, and `negLnLike`, concentrated log-likelihood *-1 for minimizing \"\"\" # (2.20) in [Forr08a]: mu = ( self . one . T . dot ( solve ( self . U , solve ( self . U . T , self . cod_y )) ) ) / self . one . T . dot ( solve ( self . U , solve ( self . U . T , self . one ))) self . mu = mu # (2.31) in [Forr08a] self . SigmaSqr = ( ( self . cod_y - self . one . dot ( self . mu )) . T . dot ( solve ( self . U , solve ( self . U . T , ( self . cod_y - self . one . dot ( self . mu ))), ) ) ) / self . n # (2.32) in [Forr08a] self . LnDetPsi = 2.0 * sum ( log ( abs ( diag ( self . U )))) self . negLnLike = - 1.0 * ( - ( self . n / 2.0 ) * log ( self . SigmaSqr ) - 0.5 * self . LnDetPsi )","title":"likelihood()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.nat_to_cod_init","text":"Determine max and min of each dimension and normalize that axis to a range of [0,1]. Called when 1) surrogate is initialized and 2) new points arrive, i.e., suggested by the surrogate as infill points. This method calls nat_to_cod_x and nat_to_cod_y and updates the ranges nat_range_X and nat_range_y . Source code in spotPython/build/kriging.py 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 def nat_to_cod_init ( self ): \"\"\" Determine max and min of each dimension and normalize that axis to a range of [0,1]. Called when 1) surrogate is initialized and 2) new points arrive, i.e., suggested by the surrogate as infill points. This method calls `nat_to_cod_x` and `nat_to_cod_y` and updates the ranges `nat_range_X` and `nat_range_y`. \"\"\" self . nat_range_X = [] self . nat_range_y = [] for i in range ( self . k ): self . nat_range_X . append ([ min ( self . nat_X [:, i ]), max ( self . nat_X [:, i ])]) self . nat_range_y . append ( min ( self . nat_y )) self . nat_range_y . append ( max ( self . nat_y )) self . nat_mean_X = mean ( self . nat_X , axis = 0 ) self . nat_std_X = std ( self . nat_X , axis = 0 ) self . nat_mean_y = mean ( self . nat_y ) self . nat_std_y = std ( self . nat_y ) Z = aggregate_mean_var ( X = self . nat_X , y = self . nat_y ) mu = Z [ 1 ] self . mean_cod_y = empty_like ( mu ) for i in range ( self . n ): self . cod_X [ i ] = self . nat_to_cod_x ( self . nat_X [ i ]) for i in range ( self . n ): self . cod_y [ i ] = self . nat_to_cod_y ( self . nat_y [ i ]) for i in range ( mu . shape [ 0 ]): self . mean_cod_y [ i ] = self . nat_to_cod_y ( mu [ i ])","title":"nat_to_cod_init()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.nat_to_cod_x","text":"Normalize one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated. Parameters: Name Type Description Default nat_X array An array representing one points (self.k long) in natural (physical or real world) units. required Returns: Type Description array An array of coded values in the range of [0,1] for each dimension. Source code in spotPython/build/kriging.py 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 def nat_to_cod_x ( self , nat_X ): \"\"\" Normalize one point (row) of nat_X array to [0,1]. The internal nat_range_X values are not updated. Args: nat_X (array): An array representing one points (self.k long) in natural (physical or real world) units. Returns: (array): An array of coded values in the range of [0,1] for each dimension. \"\"\" X = copy . deepcopy ( nat_X ) if self . cod_type == \"norm\" : for i in range ( self . k ): X [ i ] = ( X [ i ] - self . nat_range_X [ i ][ 0 ]) / float ( self . nat_range_X [ i ][ 1 ] - self . nat_range_X [ i ][ 0 ]) # TODO: Implement range correction if range == 0: # rangex <- xmax - xmin # rangey <- ymax - ymin # xmin[rangex == 0] <- xmin[rangex == 0] - 0.5 # xmax[rangex == 0] <- xmax[rangex == 0] + 0.5 # rangex[rangex == 0] <- 1 # logger.debug(f\"self.nat_range_X[{i}]:\\n {self.nat_range_X[i]}\") # logger.debug(f\"X[{i}]:\\n {X[i]}\") return X elif self . cod_type == \"std\" : for i in range ( self . k ): X [ i ] = ( X [ i ] - self . nat_mean_X [ i ]) / self . nat_std_X [ i ] return X else : return nat_X","title":"nat_to_cod_x()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.nat_to_cod_y","text":"Normalize natural y values to [0,1]. Parameters: Name Type Description Default nat_y array An array of observed values in natural (real-world) units. required Returns: Type Description array A normalized array of coded (model) units in the range of [0,1]. Source code in spotPython/build/kriging.py 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 def nat_to_cod_y ( self , nat_y ): \"\"\" Normalize natural y values to [0,1]. Args: nat_y (array): An array of observed values in natural (real-world) units. Returns: (array): A normalized array of coded (model) units in the range of [0,1]. \"\"\" if self . use_cod_y : if self . cod_type == \"norm\" : return ( nat_y - self . nat_range_y [ 0 ]) / ( self . nat_range_y [ 1 ] - self . nat_range_y [ 0 ]) elif self . cod_type == \"std\" : return ( nat_y - self . nat_mean_y ) / self . nat_std_y else : return nat_y else : return nat_y","title":"nat_to_cod_y()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.plot","text":"This function plots 1d and 2d surrogates. Parameters: Name Type Description Default show boolean If True , the plots are displayed. If False , plt.show() should be called outside this function. True Source code in spotPython/build/kriging.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 def plot ( self , show = True ): \"\"\" This function plots 1d and 2d surrogates. Args: show (boolean): If `True`, the plots are displayed. If `False`, `plt.show()` should be called outside this function. \"\"\" if self . k == 1 : # TODO: Improve plot (add conf. interval etc.) fig = pylab . figure ( figsize = ( 9 , 6 )) # t1 = array(arange(0.0, 1.0, 0.01)) # y1 = array([self.predict(array([x]), return_val=\"y\") for x in t1]) # plt.figure() # plt.plot(t1, y1, \"k\") # if show: # plt.show() # n_grid = 100 x = linspace ( self . nat_range_X [ 0 ][ 0 ], self . nat_range_X [ 0 ][ 1 ], num = n_grid ) y = self . predict ( x ) plt . figure () plt . plot ( x , y , \"k\" ) if show : plt . show () if self . k == 2 : fig = pylab . figure ( figsize = ( 9 , 6 )) n_grid = 100 x = linspace ( self . nat_range_X [ 0 ][ 0 ], self . nat_range_X [ 0 ][ 1 ], num = n_grid ) y = linspace ( self . nat_range_X [ 1 ][ 0 ], self . nat_range_X [ 1 ][ 1 ], num = n_grid ) X , Y = meshgrid ( x , y ) # Predict based on the optimized results zz = array ( [ self . predict ( array ([ x , y ]), return_val = \"all\" ) for x , y in zip ( ravel ( X ), ravel ( Y ))] ) zs = zz [:, 0 , :] zse = zz [:, 1 , :] Z = zs . reshape ( X . shape ) Ze = zse . reshape ( X . shape ) if self . cod_type == \"norm\" : nat_point_X = ( self . cod_X [:, 0 ] * ( self . nat_range_X [ 0 ][ 1 ] - self . nat_range_X [ 0 ][ 0 ]) ) + self . nat_range_X [ 0 ][ 0 ] nat_point_Y = ( self . cod_X [:, 1 ] * ( self . nat_range_X [ 1 ][ 1 ] - self . nat_range_X [ 1 ][ 0 ]) ) + self . nat_range_X [ 1 ][ 0 ] elif self . cod_type == \"std\" : nat_point_X = self . cod_X [:, 0 ] * self . nat_std_X [ 0 ] + self . nat_mean_X [ 0 ] nat_point_Y = self . cod_X [:, 1 ] * self . nat_std_X [ 1 ] + self . nat_mean_X [ 1 ] else : nat_point_X = self . cod_X [:, 0 ] nat_point_Y = self . cod_X [:, 1 ] contour_levels = 30 ax = fig . add_subplot ( 224 ) # plot predicted values: pylab . contourf ( X , Y , Ze , contour_levels , cmap = \"jet\" ) pylab . title ( \"Error\" ) pylab . colorbar () # plot observed points: pylab . plot ( nat_point_X , nat_point_Y , \"ow\" ) # ax = fig . add_subplot ( 223 ) # plot predicted values: plt . contourf ( X , Y , Z , contour_levels , zorder = 1 , cmap = \"jet\" ) plt . title ( \"Surrogate\" ) # plot observed points: pylab . plot ( nat_point_X , nat_point_Y , \"ow\" , zorder = 3 ) pylab . colorbar () # ax = fig . add_subplot ( 221 , projection = \"3d\" ) ax . plot_surface ( X , Y , Z , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" ) # ax = fig . add_subplot ( 222 , projection = \"3d\" ) ax . plot_surface ( X , Y , Ze , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" ) # pylab . show ()","title":"plot()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.predict","text":"This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X. Parameters: Name Type Description Default nat_X array Design variable to evaluate in natural units. required nat bool argument nat_X is in natural range. Default: True . If set to False , nat_X will not be normalized (which might be useful if already normalized y values are used). True return_val string whether y , s , neg. ei (negative expected improvement), or all three values are returned. Default is (for compatibility with sklearn) \"y\". To return s , select \"s\", to return neg. ei , select \"ei\". To return the tuple (y, s, ei) , select \"all\". 'y' Returns: Type Description float The predicted value in natural units. float predicted error float expected improvement Source code in spotPython/build/kriging.py 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 def predict ( self , nat_X , nat = True , return_val = \"y\" ): \"\"\" This function returns the prediction (in natural units) of the surrogate at the natural coordinates of X. Args: nat_X (array): Design variable to evaluate in natural units. nat (bool): argument `nat_X` is in natural range. Default: `True`. If set to `False`, `nat_X` will not be normalized (which might be useful if already normalized y values are used). return_val (string): whether `y`, `s`, neg. `ei` (negative expected improvement), or all three values are returned. Default is (for compatibility with sklearn) \"y\". To return `s`, select \"s\", to return neg. `ei`, select \"ei\". To return the tuple `(y, s, ei)`, select \"all\". Returns: (float): The predicted value in natural units. (float): predicted error (float): expected improvement \"\"\" # Check for the shape and the type of the Input if isinstance ( nat_X , ndarray ): try : X = nat_X . reshape ( - 1 , self . nat_X . shape [ 1 ]) X = repair_non_numeric ( X , self . var_type ) except Exception : raise TypeError ( \"13.1: Input to predict was not convertible to the size of X\" ) else : raise TypeError ( f \"type of the given input is an { type ( nat_X ) } instead of an ndarray\" ) # Iterate through the Input y = array ([], dtype = float ) s = array ([], dtype = float ) ei = array ([], dtype = float ) for i in range ( X . shape [ 0 ]): # logger.debug(f\"13.2: predict() Step 2: x (reshaped nat_X):\\n {x}\") if nat : x = self . nat_to_cod_x ( X [ i , :]) else : x = X [ i , :] y0 , s0 , ei0 = self . predict_coded ( x ) y = append ( y , y0 ) s = append ( s , s0 ) ei = append ( ei , ei0 ) if return_val == \"y\" : return y elif return_val == \"s\" : return s elif return_val == \"ei\" : return - 1.0 * ei else : return y , s , - 1.0 * ei","title":"predict()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.predict_coded","text":"Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a]. The error is returned as well. See also [Forr08a, p.60]. Note self.mu and self.SigmaSqr are computed in likelihood , not here. Parameters: Name Type Description Default cod_x array point in coded units to make prediction at required Returns: Type Description float predicted value in coded units. float predicted error. Source code in spotPython/build/kriging.py 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 def predict_coded ( self , cod_x ): \"\"\" Kriging prediction of one point in the coded units as described in (2.20) in [Forr08a]. The error is returned as well. See also [Forr08a, p.60]. Note: `self.mu` and `self.SigmaSqr` are computed in `likelihood`, not here. Args: cod_x (array): point in coded units to make prediction at Returns: (float): predicted value in coded units. (float): predicted error. \"\"\" self . build_psi_vec ( cod_x ) f = self . mu + self . psi . T . dot ( solve ( self . U , solve ( self . U . T , self . cod_y - self . one . dot ( self . mu ))) ) try : if self . noise : Lambda = self . Lambda else : Lambda = 0.0 # Error in [Forr08a, p.87]: SSqr = self . SigmaSqr * ( 1 + Lambda - self . psi . T . dot ( solve ( self . U , solve ( self . U . T , self . psi )))) except Exception as err : print ( f \"Could not determine SSqr. Wrong or missing Lambda? { err =} , { type ( err ) =} \" ) SSqr = power ( abs ( SSqr [ 0 ]), 0.5 )[ 0 ] EI = self . exp_imp ( y0 = f [ 0 ], s0 = SSqr ) return f [ 0 ], SSqr , EI","title":"predict_coded()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.set_de_bounds","text":"Determine search bounds for model_optimizer, e.g., differential evolution. Source code in spotPython/build/kriging.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 def set_de_bounds ( self ): \"\"\" Determine search bounds for model_optimizer, e.g., differential evolution. \"\"\" de_bounds = [] for i in range ( self . n_theta ): de_bounds . append ([ self . min_theta , self . max_theta ]) if self . optim_p : for i in range ( self . n_p ): de_bounds . append ([ self . min_p , self . max_p ]) if self . noise : de_bounds . append ([ self . min_Lambda , self . max_Lambda ]) else : if self . noise : de_bounds . append ([ self . min_Lambda , self . max_Lambda ]) self . de_bounds = de_bounds","title":"set_de_bounds()"},{"location":"reference/spotPython/build/kriging/#spotPython.build.kriging.Kriging.weighted_exp_imp","text":"Weighted expected improvement. References [Sobester et al. 2005]. Parameters: Name Type Description Default cod_x array A coded design vector. required w float weight required Returns: Type Description float weighted expected improvement. Source code in spotPython/build/kriging.py 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 def weighted_exp_imp ( self , cod_x , w ): \"\"\" Weighted expected improvement. References: [Sobester et al. 2005]. Args: cod_x (array): A coded design vector. w (float): weight Returns: (float): weighted expected improvement. \"\"\" y0 , s0 = self . predict_coded ( cod_x ) y_min = min ( self . cod_y ) if s0 <= 0.0 : EI = 0.0 elif s0 > 0.0 : EI_one = w * ( ( y_min - y0 ) * ( 0.5 + 0.5 * erf (( 1.0 / sqrt ( 2.0 )) * (( y_min - y0 ) / s0 ))) ) EI_two = ( ( 1.0 - w ) * ( s0 * ( 1.0 / sqrt ( 2.0 * pi ))) * ( exp ( - ( 1.0 / 2.0 ) * (( y_min - y0 ) ** 2.0 / s0 ** 2.0 ))) ) EI = EI_one + EI_two return EI","title":"weighted_exp_imp()"},{"location":"reference/spotPython/build/surrogates/","text":"surrogates Super class for all surrogate model classes (e.g., Kriging) Source code in spotPython/build/surrogates.py 4 5 6 7 8 9 10 11 12 13 class surrogates : \"\"\" Super class for all surrogate model classes (e.g., Kriging) \"\"\" def __init__ ( self , name = \"\" , seed = 123 , verbosity = 0 ): self . name = name self . seed = seed self . rng = default_rng ( self . seed ) self . log = {} self . verbosity = verbosity","title":"surrogates"},{"location":"reference/spotPython/build/surrogates/#spotPython.build.surrogates.surrogates","text":"Super class for all surrogate model classes (e.g., Kriging) Source code in spotPython/build/surrogates.py 4 5 6 7 8 9 10 11 12 13 class surrogates : \"\"\" Super class for all surrogate model classes (e.g., Kriging) \"\"\" def __init__ ( self , name = \"\" , seed = 123 , verbosity = 0 ): self . name = name self . seed = seed self . rng = default_rng ( self . seed ) self . log = {} self . verbosity = verbosity","title":"surrogates"},{"location":"reference/spotPython/design/designs/","text":"designs Super class for all design classes (factorial and spacefilling) Source code in spotPython/design/designs.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class designs : \"\"\" Super class for all design classes (factorial and spacefilling) \"\"\" def __init__ ( self , k = 2 , seed = 123 ): self . designs = [] self . k = k self . seed = seed self . rng = default_rng ( self . seed ) def get_dim ( self ): \"\"\"Return design dimension.\"\"\" print ( self . k ) get_dim () Return design dimension. Source code in spotPython/design/designs.py 15 16 17 def get_dim ( self ): \"\"\"Return design dimension.\"\"\" print ( self . k )","title":"designs"},{"location":"reference/spotPython/design/designs/#spotPython.design.designs.designs","text":"Super class for all design classes (factorial and spacefilling) Source code in spotPython/design/designs.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class designs : \"\"\" Super class for all design classes (factorial and spacefilling) \"\"\" def __init__ ( self , k = 2 , seed = 123 ): self . designs = [] self . k = k self . seed = seed self . rng = default_rng ( self . seed ) def get_dim ( self ): \"\"\"Return design dimension.\"\"\" print ( self . k )","title":"designs"},{"location":"reference/spotPython/design/designs/#spotPython.design.designs.designs.get_dim","text":"Return design dimension. Source code in spotPython/design/designs.py 15 16 17 def get_dim ( self ): \"\"\"Return design dimension.\"\"\" print ( self . k )","title":"get_dim()"},{"location":"reference/spotPython/design/factorial/","text":"factorial Bases: designs Super class for factorial designs. Source code in spotPython/design/factorial.py 5 6 7 8 9 10 11 12 13 14 15 class factorial ( designs ): \"\"\" Super class for factorial designs. \"\"\" def __init__ ( self , k = 2 , seed = 123 ): super () . __init__ ( k , seed ) def full_factorial ( self , p ): i = ( slice ( 0 , 1 , p * 1 j ),) * self . k return mgrid [ i ] . reshape ( self . k , p ** self . k ) . T","title":"factorial"},{"location":"reference/spotPython/design/factorial/#spotPython.design.factorial.factorial","text":"Bases: designs Super class for factorial designs. Source code in spotPython/design/factorial.py 5 6 7 8 9 10 11 12 13 14 15 class factorial ( designs ): \"\"\" Super class for factorial designs. \"\"\" def __init__ ( self , k = 2 , seed = 123 ): super () . __init__ ( k , seed ) def full_factorial ( self , p ): i = ( slice ( 0 , 1 , p * 1 j ),) * self . k return mgrid [ i ] . reshape ( self . k , p ** self . k ) . T","title":"factorial"},{"location":"reference/spotPython/design/spacefilling/","text":"spacefilling Bases: designs Source code in spotPython/design/spacefilling.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class spacefilling ( designs ): def __init__ ( self , k = 2 , seed = 123 ): \"\"\" Spacefilling design class Args: k (int, optional): number of design variables (dimensions). Defaults to 2. seed (int, optional): random seed. Defaults to 123. \"\"\" self . k = k self . seed = seed super () . __init__ ( k , seed ) self . sampler = LatinHypercube ( d = self . k , seed = self . seed ) def scipy_lhd ( self , n , repeats = 1 , lower = None , upper = None ): \"\"\" Latin hypercube sampling based on scipy. Args: n (int): number of samples repeats (int): number of repeats (replicates) lower (int, optional): lower bound. Defaults to 0. upper (int, optional): upper bound. Defaults to 1. Returns: (numpy.ndarray): Latin hypercube design. \"\"\" if lower is None : lower = zeros ( self . k ) if upper is None : upper = ones ( self . k ) sample = self . sampler . random ( n = n ) des = scale ( sample , lower , upper ) return repeat ( des , repeats , axis = 0 ) __init__ ( k = 2 , seed = 123 ) Spacefilling design class Parameters: Name Type Description Default k int number of design variables (dimensions). Defaults to 2. 2 seed int random seed. Defaults to 123. 123 Source code in spotPython/design/spacefilling.py 10 11 12 13 14 15 16 17 18 19 20 21 def __init__ ( self , k = 2 , seed = 123 ): \"\"\" Spacefilling design class Args: k (int, optional): number of design variables (dimensions). Defaults to 2. seed (int, optional): random seed. Defaults to 123. \"\"\" self . k = k self . seed = seed super () . __init__ ( k , seed ) self . sampler = LatinHypercube ( d = self . k , seed = self . seed ) scipy_lhd ( n , repeats = 1 , lower = None , upper = None ) Latin hypercube sampling based on scipy. Parameters: Name Type Description Default n int number of samples required repeats int number of repeats (replicates) 1 lower int lower bound. Defaults to 0. None upper int upper bound. Defaults to 1. None Returns: Type Description numpy . ndarray Latin hypercube design. Source code in spotPython/design/spacefilling.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def scipy_lhd ( self , n , repeats = 1 , lower = None , upper = None ): \"\"\" Latin hypercube sampling based on scipy. Args: n (int): number of samples repeats (int): number of repeats (replicates) lower (int, optional): lower bound. Defaults to 0. upper (int, optional): upper bound. Defaults to 1. Returns: (numpy.ndarray): Latin hypercube design. \"\"\" if lower is None : lower = zeros ( self . k ) if upper is None : upper = ones ( self . k ) sample = self . sampler . random ( n = n ) des = scale ( sample , lower , upper ) return repeat ( des , repeats , axis = 0 )","title":"spacefilling"},{"location":"reference/spotPython/design/spacefilling/#spotPython.design.spacefilling.spacefilling","text":"Bases: designs Source code in spotPython/design/spacefilling.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class spacefilling ( designs ): def __init__ ( self , k = 2 , seed = 123 ): \"\"\" Spacefilling design class Args: k (int, optional): number of design variables (dimensions). Defaults to 2. seed (int, optional): random seed. Defaults to 123. \"\"\" self . k = k self . seed = seed super () . __init__ ( k , seed ) self . sampler = LatinHypercube ( d = self . k , seed = self . seed ) def scipy_lhd ( self , n , repeats = 1 , lower = None , upper = None ): \"\"\" Latin hypercube sampling based on scipy. Args: n (int): number of samples repeats (int): number of repeats (replicates) lower (int, optional): lower bound. Defaults to 0. upper (int, optional): upper bound. Defaults to 1. Returns: (numpy.ndarray): Latin hypercube design. \"\"\" if lower is None : lower = zeros ( self . k ) if upper is None : upper = ones ( self . k ) sample = self . sampler . random ( n = n ) des = scale ( sample , lower , upper ) return repeat ( des , repeats , axis = 0 )","title":"spacefilling"},{"location":"reference/spotPython/design/spacefilling/#spotPython.design.spacefilling.spacefilling.__init__","text":"Spacefilling design class Parameters: Name Type Description Default k int number of design variables (dimensions). Defaults to 2. 2 seed int random seed. Defaults to 123. 123 Source code in spotPython/design/spacefilling.py 10 11 12 13 14 15 16 17 18 19 20 21 def __init__ ( self , k = 2 , seed = 123 ): \"\"\" Spacefilling design class Args: k (int, optional): number of design variables (dimensions). Defaults to 2. seed (int, optional): random seed. Defaults to 123. \"\"\" self . k = k self . seed = seed super () . __init__ ( k , seed ) self . sampler = LatinHypercube ( d = self . k , seed = self . seed )","title":"__init__()"},{"location":"reference/spotPython/design/spacefilling/#spotPython.design.spacefilling.spacefilling.scipy_lhd","text":"Latin hypercube sampling based on scipy. Parameters: Name Type Description Default n int number of samples required repeats int number of repeats (replicates) 1 lower int lower bound. Defaults to 0. None upper int upper bound. Defaults to 1. None Returns: Type Description numpy . ndarray Latin hypercube design. Source code in spotPython/design/spacefilling.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def scipy_lhd ( self , n , repeats = 1 , lower = None , upper = None ): \"\"\" Latin hypercube sampling based on scipy. Args: n (int): number of samples repeats (int): number of repeats (replicates) lower (int, optional): lower bound. Defaults to 0. upper (int, optional): upper bound. Defaults to 1. Returns: (numpy.ndarray): Latin hypercube design. \"\"\" if lower is None : lower = zeros ( self . k ) if upper is None : upper = ones ( self . k ) sample = self . sampler . random ( n = n ) des = scale ( sample , lower , upper ) return repeat ( des , repeats , axis = 0 )","title":"scipy_lhd()"},{"location":"reference/spotPython/fun/objectivefunctions/","text":"analytical Analytical test functions. Parameters: Name Type Description Default offset float offset 0.0 hz float hz 0 seed int seed. See Numpy Random Sampling 126 Source code in spotPython/fun/objectivefunctions.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 class analytical : \"\"\" Analytical test functions. Args: offset (float): offset hz (float): hz seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) \"\"\" def __init__ ( self , offset = 0.0 , hz = 0 , seed = 126 ): self . offset = offset self . hz = hz self . seed = seed self . rng = default_rng ( seed = self . seed ) self . fun_control = { \"sigma\" : 0 , \"seed\" : None , \"sel_var\" : None } def add_noise ( self , y ): # Use own rng: if self . fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = self . fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for y_i in y : noise_y = np . append ( noise_y , y_i + rng . normal ( loc = 0 , scale = self . fun_control [ \"sigma\" ], size = 1 ), ) return noise_y def fun_linear ( self , X , fun_control = None ): \"\"\"Linear function. Args: X (array): input Returns: (float): objective function value. \"\"\" if fun_control is not None : self . fun_control = fun_control try : X . shape [ 1 ] except ValueError as err : print ( \"error message:\" , err ) X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum ( X [ i ])) if self . fun_control [ \"sigma\" ] > 0 : return self . add_noise ( y ) else : return y def fun_sphere ( self , X , fun_control = None ): \"\"\"Sphere function. Args: X (array): input fun_control (dict): dict with entries `seed` and `sigma`. Returns: (float): function values \"\"\" if fun_control is not None : self . fun_control = fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum (( X [ i ] - offset ) ** 2 )) # TODO: move to a separate function: if self . fun_control [ \"sigma\" ] > 0 : # Use own rng: if self . fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for y_i in y : noise_y = np . append ( noise_y , y_i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_cubed ( self , X , fun_control = None ): if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum (( X [ i ] - offset ) ** 3 )) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_forrester ( self , X , fun_control = None ): \"\"\" Function used by [Forr08a, p.83]. f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. Starts with three sample points at x=0, x=0.5, and x=1. Args: X (flooat): input values (1-dim) Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , ( 6.0 * X [ i ] - 2 ) ** 2 * np . sin ( 12 * X [ i ] - 4 )) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_branin ( self , X , fun_control = None ): \"\"\"Branin function. The 2-dim Branin function is y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s, where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2), c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi). It has three global minima: f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15]. Args: X (array): input value fun_control (dict): dict with entries `seed` and `sigma`. Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x1 = X [:, 0 ] x2 = X [:, 1 ] a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi r = 6 s = 10 t = 1 / ( 8 * np . pi ) y = a * ( x2 - b * x1 ** 2 + c * x1 - r ) ** 2 + s * ( 1 - t ) * np . cos ( x1 ) + s # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_branin_factor ( self , X , fun_control = None ): \"\"\"Branin function with factor variable x_3. The 2-dim Branin, or Branin-Hoo, function has three global minima. The recommended values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2), c = 5 / \u03c0, r = 6, s = 10 and t = 1 / (8*pi). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15] and with x3 from the set {0, 1, 2}, i.e., x3 is a factor variable with three levels. Global Minimum: f(x) = 0.397887 -1 at (-pi, 12.275, 2), (pi, 2.275, 2), and (9.42478, 2.475, 2). Args: X (array): input value Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 3 : raise Exception x1 = X [:, 0 ] x2 = X [:, 1 ] x3 = X [:, 2 ] a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi r = 6 s = 10 t = 1 / ( 8 * np . pi ) y = a * ( x2 - b * x1 ** 2 + c * x1 - r ) ** 2 + s * ( 1 - t ) * np . cos ( x1 ) + s for j in range ( X . shape [ 0 ]): if x3 [ j ] == 1 : y [ j ] = y [ j ] + 10 elif x3 [ j ] == 2 : y [ j ] = y [ j ] - 10 # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_branin_modified ( self , X , fun_control = None ): if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x = X [:, 0 ] y = X [:, 1 ] X1 = 15 * x - 5 X2 = 15 * y a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi d = 6 e = 10 ff = 1 / ( 8 * np . pi ) y = ( a * ( X2 - b * X1 ** 2 + c * X1 - d ) ** 2 + e * ( 1 - ff ) * np . cos ( X1 ) + e ) + 5 * x # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def branin_noise ( self , X ): try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x = X [:, 0 ] y = X [:, 1 ] X1 = 15 * x - 5 X2 = 15 * y a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi d = 6 e = 10 ff = 1 / ( 8 * np . pi ) noiseFree = ( a * ( X2 - b * X1 ** 2 + c * X1 - d ) ** 2 + e * ( 1 - ff ) * np . cos ( X1 ) + e ) + 5 * x noise_y = [] for i in noiseFree : noise_y . append ( i + np . random . standard_normal () * 15 ) return np . array ( noise_y ) def fun_sin_cos ( self , X , fun_control = None ): if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x0 = X [:, 0 ] x1 = X [:, 1 ] y = 2.0 * np . sin ( x0 + self . hz ) + 0.5 * np . cos ( x1 + self . hz ) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y # def fun_forrester_2(self, X): # \"\"\" # Function used by [Forr08a, p.83]. # f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. # Starts with three sample points at x=0, x=0.5, and x=1. # Args: # X (flooat): input values (1-dim) # Returns: # float: function value # \"\"\" # try: # X.shape[1] # except ValueError: # X = np.array(X) # if len(X.shape) < 2: # X = np.array([X]) # # y = X[:, 1] # y = (6.0 * X - 2) ** 2 * np.sin(12 * X - 4) # if self.sigma != 0: # noise_y = np.array([], dtype=float) # for i in y: # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) # ) # return noise_y # else: # return y def fun_runge ( self , X , fun_control = None ): \"\"\" Runge function. Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2 Dim: k >= 1 Interval: -5 <= x <= 5 Args: X (numpy.array): input fun_control (dictionary, optional): control parameters. Defaults to None. Returns: (float) : function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , ( 1 / ( 1 + np . sum (( X [ i ] - offset ) ** 2 )))) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_wingwt ( self , X , fun_control = None ): \"\"\" Wing weight function. Example from Forrester et al. to understand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters: W = 0.036 S_W**0.758 * Wfw**0.0035 ( A / (cos**2 Lambda))**0.6 * q**0.006 * lambda**0.04 * ( (100 Rtc)/(cos Lambda) ))**-0.3* (Nz Wdg)**0.49 | Symbol | Parameter | Baseline | Minimum | Maximum | |-----------|----------------------------------------|----------|---------|---------| | $S_W$ | Wing area ($ft^2$) | 174 | 150 | 200 | | $W_{fw}$ | Weight of fuel in wing (lb) | 252 | 220 | 300 | | $A$ | Aspect ratio | 7.52 | 6 | 10 | | $Lambda$ | Quarter-chord sweep (deg) | 0 | -10 | 10 | | $q$ | Dynamic pressure at cruise ($lb/ft^2$) | 34 | 16 | 45 | | $lambda$ | Taper ratio | 0.672 | 0.5 | 1 | | $R_{tc}$ | Aerofoil thickness to chord ratio | 0.12 | 0.08 | 0.18 | | $N_z$ | Ultimate load factor | 3.8 | 2.5 | 6 | | $W_{dg}$ | Flight design gross weight (lb) | 2000 | 1700 | 2500 | | $W_p$ | paint weight (lb/ft^2) | 0.064 | 0.025 | 0.08 | Args: X (numpy.array): 10-dim input vector fun_control (dictionary, optional): control parameters. Defaults to None. Returns: (float) : function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) # W_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): Sw = X [ i , 0 ] * ( 200 - 150 ) + 150 Wfw = X [ i , 1 ] * ( 300 - 220 ) + 220 A = X [ i , 2 ] * ( 10 - 6 ) + 6 L = ( X [ i , 3 ] * ( 10 - ( - 10 )) - 10 ) * np . pi / 180 q = X [ i , 4 ] * ( 45 - 16 ) + 16 la = X [ i , 5 ] * ( 1 - 0.5 ) + 0.5 Rtc = X [ i , 6 ] * ( 0.18 - 0.08 ) + 0.08 Nz = X [ i , 7 ] * ( 6 - 2.5 ) + 2.5 Wdg = X [ i , 8 ] * ( 2500 - 1700 ) + 1700 Wp = X [ i , 9 ] * ( 0.08 - 0.025 ) + 0.025 # calculation on natural scale W = 0.036 * Sw ** 0.758 * Wfw ** 0.0035 * ( A / np . cos ( L ) ** 2 ) ** 0.6 * q ** 0.006 W = W * la ** 0.04 * ( 100 * Rtc / np . cos ( L )) ** ( - 0.3 ) * ( Nz * Wdg ) ** ( 0.49 ) + Sw * Wp W_res = np . append ( W_res , W ) return W_res def fun_xsin ( self , X , fun_control = None ): \"\"\" Args: X (float): input values (1-dim) Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , X [ i ] * np . sin ( 1.0 / X [ i ])) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_rosen ( self , X , fun_control = None ): if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x0 = X [:, 0 ] x1 = X [:, 1 ] b = 10 y = ( x0 - 1 ) ** 2 + b * ( x1 - x0 ** 2 ) ** 2 if self . fun_control [ \"sigma\" ] > 0 : return self . add_noise ( y ) else : return y fun_branin ( X , fun_control = None ) Branin function. The 2-dim Branin function is y = a * (x2 - b * x1 2 + c * x1 - r) 2 + s * (1 - t) * np.cos(x1) + s, where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4 pi 2), c = 5 / pi, r = 6, s = 10 and t = 1 / (8 pi). It has three global minima: f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15]. Parameters: Name Type Description Default X array input value required fun_control dict dict with entries seed and sigma . None Returns: Type Description float function value Source code in spotPython/fun/objectivefunctions.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def fun_branin ( self , X , fun_control = None ): \"\"\"Branin function. The 2-dim Branin function is y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s, where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2), c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi). It has three global minima: f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15]. Args: X (array): input value fun_control (dict): dict with entries `seed` and `sigma`. Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x1 = X [:, 0 ] x2 = X [:, 1 ] a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi r = 6 s = 10 t = 1 / ( 8 * np . pi ) y = a * ( x2 - b * x1 ** 2 + c * x1 - r ) ** 2 + s * ( 1 - t ) * np . cos ( x1 ) + s # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y fun_branin_factor ( X , fun_control = None ) Branin function with factor variable x_3. The 2-dim Branin, or Branin-Hoo, function has three global minima. The recommended values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4 pi 2), c = 5 / \u03c0, r = 6, s = 10 and t = 1 / (8 pi). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15] and with x3 from the set {0, 1, 2}, i.e., x3 is a factor variable with three levels. Global Minimum: f(x) = 0.397887 -1 at (-pi, 12.275, 2), (pi, 2.275, 2), and (9.42478, 2.475, 2). Parameters: Name Type Description Default X array input value required Returns: Type Description float function value Source code in spotPython/fun/objectivefunctions.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 def fun_branin_factor ( self , X , fun_control = None ): \"\"\"Branin function with factor variable x_3. The 2-dim Branin, or Branin-Hoo, function has three global minima. The recommended values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2), c = 5 / \u03c0, r = 6, s = 10 and t = 1 / (8*pi). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15] and with x3 from the set {0, 1, 2}, i.e., x3 is a factor variable with three levels. Global Minimum: f(x) = 0.397887 -1 at (-pi, 12.275, 2), (pi, 2.275, 2), and (9.42478, 2.475, 2). Args: X (array): input value Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 3 : raise Exception x1 = X [:, 0 ] x2 = X [:, 1 ] x3 = X [:, 2 ] a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi r = 6 s = 10 t = 1 / ( 8 * np . pi ) y = a * ( x2 - b * x1 ** 2 + c * x1 - r ) ** 2 + s * ( 1 - t ) * np . cos ( x1 ) + s for j in range ( X . shape [ 0 ]): if x3 [ j ] == 1 : y [ j ] = y [ j ] + 10 elif x3 [ j ] == 2 : y [ j ] = y [ j ] - 10 # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y fun_forrester ( X , fun_control = None ) Function used by [Forr08a, p.83]. f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. Starts with three sample points at x=0, x=0.5, and x=1. Parameters: Name Type Description Default X flooat input values (1-dim) required Returns: Type Description float function value Source code in spotPython/fun/objectivefunctions.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def fun_forrester ( self , X , fun_control = None ): \"\"\" Function used by [Forr08a, p.83]. f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. Starts with three sample points at x=0, x=0.5, and x=1. Args: X (flooat): input values (1-dim) Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , ( 6.0 * X [ i ] - 2 ) ** 2 * np . sin ( 12 * X [ i ] - 4 )) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y fun_linear ( X , fun_control = None ) Linear function. Parameters: Name Type Description Default X array input required Returns: Type Description float objective function value. Source code in spotPython/fun/objectivefunctions.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def fun_linear ( self , X , fun_control = None ): \"\"\"Linear function. Args: X (array): input Returns: (float): objective function value. \"\"\" if fun_control is not None : self . fun_control = fun_control try : X . shape [ 1 ] except ValueError as err : print ( \"error message:\" , err ) X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum ( X [ i ])) if self . fun_control [ \"sigma\" ] > 0 : return self . add_noise ( y ) else : return y fun_runge ( X , fun_control = None ) Runge function. Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2 Dim: k >= 1 Interval: -5 <= x <= 5 Parameters: Name Type Description Default X numpy . array required fun_control dictionary None Returns: Type Description (float) : function value Source code in spotPython/fun/objectivefunctions.py 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 def fun_runge ( self , X , fun_control = None ): \"\"\" Runge function. Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2 Dim: k >= 1 Interval: -5 <= x <= 5 Args: X (numpy.array): input fun_control (dictionary, optional): control parameters. Defaults to None. Returns: (float) : function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , ( 1 / ( 1 + np . sum (( X [ i ] - offset ) ** 2 )))) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y fun_sphere ( X , fun_control = None ) Sphere function. Parameters: Name Type Description Default X array input required fun_control dict dict with entries seed and sigma . None Returns: Type Description float function values Source code in spotPython/fun/objectivefunctions.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def fun_sphere ( self , X , fun_control = None ): \"\"\"Sphere function. Args: X (array): input fun_control (dict): dict with entries `seed` and `sigma`. Returns: (float): function values \"\"\" if fun_control is not None : self . fun_control = fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum (( X [ i ] - offset ) ** 2 )) # TODO: move to a separate function: if self . fun_control [ \"sigma\" ] > 0 : # Use own rng: if self . fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for y_i in y : noise_y = np . append ( noise_y , y_i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y fun_wingwt ( X , fun_control = None ) Wing weight function. Example from Forrester et al. to understand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters: W = 0.036 S_W 0.758 * Wfw 0.0035 ( A / (cos 2 Lambda)) 0.6 * q 0.006 * lambda 0.04 * ( (100 Rtc)/(cos Lambda) )) -0.3* (Nz Wdg) 0.49 Symbol Parameter Baseline Minimum Maximum $S_W$ Wing area ($ft^2$) 174 150 200 $W_{fw}$ Weight of fuel in wing (lb) 252 220 300 $A$ Aspect ratio 7.52 6 10 $Lambda$ Quarter-chord sweep (deg) 0 -10 10 $q$ Dynamic pressure at cruise ($lb/ft^2$) 34 16 45 $lambda$ Taper ratio 0.672 0.5 1 $R_{tc}$ Aerofoil thickness to chord ratio 0.12 0.08 0.18 $N_z$ Ultimate load factor 3.8 2.5 6 $W_{dg}$ Flight design gross weight (lb) 2000 1700 2500 $W_p$ paint weight (lb/ft^2) 0.064 0.025 0.08 Parameters: Name Type Description Default X numpy . array 10-dim input vector required fun_control dictionary control parameters. Defaults to None. None Returns: Type Description (float) : function value Source code in spotPython/fun/objectivefunctions.py 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 def fun_wingwt ( self , X , fun_control = None ): \"\"\" Wing weight function. Example from Forrester et al. to understand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters: W = 0.036 S_W**0.758 * Wfw**0.0035 ( A / (cos**2 Lambda))**0.6 * q**0.006 * lambda**0.04 * ( (100 Rtc)/(cos Lambda) ))**-0.3* (Nz Wdg)**0.49 | Symbol | Parameter | Baseline | Minimum | Maximum | |-----------|----------------------------------------|----------|---------|---------| | $S_W$ | Wing area ($ft^2$) | 174 | 150 | 200 | | $W_{fw}$ | Weight of fuel in wing (lb) | 252 | 220 | 300 | | $A$ | Aspect ratio | 7.52 | 6 | 10 | | $Lambda$ | Quarter-chord sweep (deg) | 0 | -10 | 10 | | $q$ | Dynamic pressure at cruise ($lb/ft^2$) | 34 | 16 | 45 | | $lambda$ | Taper ratio | 0.672 | 0.5 | 1 | | $R_{tc}$ | Aerofoil thickness to chord ratio | 0.12 | 0.08 | 0.18 | | $N_z$ | Ultimate load factor | 3.8 | 2.5 | 6 | | $W_{dg}$ | Flight design gross weight (lb) | 2000 | 1700 | 2500 | | $W_p$ | paint weight (lb/ft^2) | 0.064 | 0.025 | 0.08 | Args: X (numpy.array): 10-dim input vector fun_control (dictionary, optional): control parameters. Defaults to None. Returns: (float) : function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) # W_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): Sw = X [ i , 0 ] * ( 200 - 150 ) + 150 Wfw = X [ i , 1 ] * ( 300 - 220 ) + 220 A = X [ i , 2 ] * ( 10 - 6 ) + 6 L = ( X [ i , 3 ] * ( 10 - ( - 10 )) - 10 ) * np . pi / 180 q = X [ i , 4 ] * ( 45 - 16 ) + 16 la = X [ i , 5 ] * ( 1 - 0.5 ) + 0.5 Rtc = X [ i , 6 ] * ( 0.18 - 0.08 ) + 0.08 Nz = X [ i , 7 ] * ( 6 - 2.5 ) + 2.5 Wdg = X [ i , 8 ] * ( 2500 - 1700 ) + 1700 Wp = X [ i , 9 ] * ( 0.08 - 0.025 ) + 0.025 # calculation on natural scale W = 0.036 * Sw ** 0.758 * Wfw ** 0.0035 * ( A / np . cos ( L ) ** 2 ) ** 0.6 * q ** 0.006 W = W * la ** 0.04 * ( 100 * Rtc / np . cos ( L )) ** ( - 0.3 ) * ( Nz * Wdg ) ** ( 0.49 ) + Sw * Wp W_res = np . append ( W_res , W ) return W_res fun_xsin ( X , fun_control = None ) Parameters: Name Type Description Default X float input values (1-dim) required Returns: Type Description float function value Source code in spotPython/fun/objectivefunctions.py 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 def fun_xsin ( self , X , fun_control = None ): \"\"\" Args: X (float): input values (1-dim) Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , X [ i ] * np . sin ( 1.0 / X [ i ])) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y","title":"objectivefunctions"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical","text":"Analytical test functions. Parameters: Name Type Description Default offset float offset 0.0 hz float hz 0 seed int seed. See Numpy Random Sampling 126 Source code in spotPython/fun/objectivefunctions.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 class analytical : \"\"\" Analytical test functions. Args: offset (float): offset hz (float): hz seed (int): seed. See [Numpy Random Sampling](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start) \"\"\" def __init__ ( self , offset = 0.0 , hz = 0 , seed = 126 ): self . offset = offset self . hz = hz self . seed = seed self . rng = default_rng ( seed = self . seed ) self . fun_control = { \"sigma\" : 0 , \"seed\" : None , \"sel_var\" : None } def add_noise ( self , y ): # Use own rng: if self . fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = self . fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for y_i in y : noise_y = np . append ( noise_y , y_i + rng . normal ( loc = 0 , scale = self . fun_control [ \"sigma\" ], size = 1 ), ) return noise_y def fun_linear ( self , X , fun_control = None ): \"\"\"Linear function. Args: X (array): input Returns: (float): objective function value. \"\"\" if fun_control is not None : self . fun_control = fun_control try : X . shape [ 1 ] except ValueError as err : print ( \"error message:\" , err ) X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum ( X [ i ])) if self . fun_control [ \"sigma\" ] > 0 : return self . add_noise ( y ) else : return y def fun_sphere ( self , X , fun_control = None ): \"\"\"Sphere function. Args: X (array): input fun_control (dict): dict with entries `seed` and `sigma`. Returns: (float): function values \"\"\" if fun_control is not None : self . fun_control = fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum (( X [ i ] - offset ) ** 2 )) # TODO: move to a separate function: if self . fun_control [ \"sigma\" ] > 0 : # Use own rng: if self . fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for y_i in y : noise_y = np . append ( noise_y , y_i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_cubed ( self , X , fun_control = None ): if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum (( X [ i ] - offset ) ** 3 )) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_forrester ( self , X , fun_control = None ): \"\"\" Function used by [Forr08a, p.83]. f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. Starts with three sample points at x=0, x=0.5, and x=1. Args: X (flooat): input values (1-dim) Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , ( 6.0 * X [ i ] - 2 ) ** 2 * np . sin ( 12 * X [ i ] - 4 )) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_branin ( self , X , fun_control = None ): \"\"\"Branin function. The 2-dim Branin function is y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s, where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2), c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi). It has three global minima: f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15]. Args: X (array): input value fun_control (dict): dict with entries `seed` and `sigma`. Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x1 = X [:, 0 ] x2 = X [:, 1 ] a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi r = 6 s = 10 t = 1 / ( 8 * np . pi ) y = a * ( x2 - b * x1 ** 2 + c * x1 - r ) ** 2 + s * ( 1 - t ) * np . cos ( x1 ) + s # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_branin_factor ( self , X , fun_control = None ): \"\"\"Branin function with factor variable x_3. The 2-dim Branin, or Branin-Hoo, function has three global minima. The recommended values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2), c = 5 / \u03c0, r = 6, s = 10 and t = 1 / (8*pi). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15] and with x3 from the set {0, 1, 2}, i.e., x3 is a factor variable with three levels. Global Minimum: f(x) = 0.397887 -1 at (-pi, 12.275, 2), (pi, 2.275, 2), and (9.42478, 2.475, 2). Args: X (array): input value Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 3 : raise Exception x1 = X [:, 0 ] x2 = X [:, 1 ] x3 = X [:, 2 ] a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi r = 6 s = 10 t = 1 / ( 8 * np . pi ) y = a * ( x2 - b * x1 ** 2 + c * x1 - r ) ** 2 + s * ( 1 - t ) * np . cos ( x1 ) + s for j in range ( X . shape [ 0 ]): if x3 [ j ] == 1 : y [ j ] = y [ j ] + 10 elif x3 [ j ] == 2 : y [ j ] = y [ j ] - 10 # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_branin_modified ( self , X , fun_control = None ): if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x = X [:, 0 ] y = X [:, 1 ] X1 = 15 * x - 5 X2 = 15 * y a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi d = 6 e = 10 ff = 1 / ( 8 * np . pi ) y = ( a * ( X2 - b * X1 ** 2 + c * X1 - d ) ** 2 + e * ( 1 - ff ) * np . cos ( X1 ) + e ) + 5 * x # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def branin_noise ( self , X ): try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x = X [:, 0 ] y = X [:, 1 ] X1 = 15 * x - 5 X2 = 15 * y a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi d = 6 e = 10 ff = 1 / ( 8 * np . pi ) noiseFree = ( a * ( X2 - b * X1 ** 2 + c * X1 - d ) ** 2 + e * ( 1 - ff ) * np . cos ( X1 ) + e ) + 5 * x noise_y = [] for i in noiseFree : noise_y . append ( i + np . random . standard_normal () * 15 ) return np . array ( noise_y ) def fun_sin_cos ( self , X , fun_control = None ): if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x0 = X [:, 0 ] x1 = X [:, 1 ] y = 2.0 * np . sin ( x0 + self . hz ) + 0.5 * np . cos ( x1 + self . hz ) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y # def fun_forrester_2(self, X): # \"\"\" # Function used by [Forr08a, p.83]. # f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. # Starts with three sample points at x=0, x=0.5, and x=1. # Args: # X (flooat): input values (1-dim) # Returns: # float: function value # \"\"\" # try: # X.shape[1] # except ValueError: # X = np.array(X) # if len(X.shape) < 2: # X = np.array([X]) # # y = X[:, 1] # y = (6.0 * X - 2) ** 2 * np.sin(12 * X - 4) # if self.sigma != 0: # noise_y = np.array([], dtype=float) # for i in y: # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) # ) # return noise_y # else: # return y def fun_runge ( self , X , fun_control = None ): \"\"\" Runge function. Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2 Dim: k >= 1 Interval: -5 <= x <= 5 Args: X (numpy.array): input fun_control (dictionary, optional): control parameters. Defaults to None. Returns: (float) : function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , ( 1 / ( 1 + np . sum (( X [ i ] - offset ) ** 2 )))) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_wingwt ( self , X , fun_control = None ): \"\"\" Wing weight function. Example from Forrester et al. to understand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters: W = 0.036 S_W**0.758 * Wfw**0.0035 ( A / (cos**2 Lambda))**0.6 * q**0.006 * lambda**0.04 * ( (100 Rtc)/(cos Lambda) ))**-0.3* (Nz Wdg)**0.49 | Symbol | Parameter | Baseline | Minimum | Maximum | |-----------|----------------------------------------|----------|---------|---------| | $S_W$ | Wing area ($ft^2$) | 174 | 150 | 200 | | $W_{fw}$ | Weight of fuel in wing (lb) | 252 | 220 | 300 | | $A$ | Aspect ratio | 7.52 | 6 | 10 | | $Lambda$ | Quarter-chord sweep (deg) | 0 | -10 | 10 | | $q$ | Dynamic pressure at cruise ($lb/ft^2$) | 34 | 16 | 45 | | $lambda$ | Taper ratio | 0.672 | 0.5 | 1 | | $R_{tc}$ | Aerofoil thickness to chord ratio | 0.12 | 0.08 | 0.18 | | $N_z$ | Ultimate load factor | 3.8 | 2.5 | 6 | | $W_{dg}$ | Flight design gross weight (lb) | 2000 | 1700 | 2500 | | $W_p$ | paint weight (lb/ft^2) | 0.064 | 0.025 | 0.08 | Args: X (numpy.array): 10-dim input vector fun_control (dictionary, optional): control parameters. Defaults to None. Returns: (float) : function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) # W_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): Sw = X [ i , 0 ] * ( 200 - 150 ) + 150 Wfw = X [ i , 1 ] * ( 300 - 220 ) + 220 A = X [ i , 2 ] * ( 10 - 6 ) + 6 L = ( X [ i , 3 ] * ( 10 - ( - 10 )) - 10 ) * np . pi / 180 q = X [ i , 4 ] * ( 45 - 16 ) + 16 la = X [ i , 5 ] * ( 1 - 0.5 ) + 0.5 Rtc = X [ i , 6 ] * ( 0.18 - 0.08 ) + 0.08 Nz = X [ i , 7 ] * ( 6 - 2.5 ) + 2.5 Wdg = X [ i , 8 ] * ( 2500 - 1700 ) + 1700 Wp = X [ i , 9 ] * ( 0.08 - 0.025 ) + 0.025 # calculation on natural scale W = 0.036 * Sw ** 0.758 * Wfw ** 0.0035 * ( A / np . cos ( L ) ** 2 ) ** 0.6 * q ** 0.006 W = W * la ** 0.04 * ( 100 * Rtc / np . cos ( L )) ** ( - 0.3 ) * ( Nz * Wdg ) ** ( 0.49 ) + Sw * Wp W_res = np . append ( W_res , W ) return W_res def fun_xsin ( self , X , fun_control = None ): \"\"\" Args: X (float): input values (1-dim) Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , X [ i ] * np . sin ( 1.0 / X [ i ])) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y def fun_rosen ( self , X , fun_control = None ): if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x0 = X [:, 0 ] x1 = X [:, 1 ] b = 10 y = ( x0 - 1 ) ** 2 + b * ( x1 - x0 ** 2 ) ** 2 if self . fun_control [ \"sigma\" ] > 0 : return self . add_noise ( y ) else : return y","title":"analytical"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_branin","text":"Branin function. The 2-dim Branin function is y = a * (x2 - b * x1 2 + c * x1 - r) 2 + s * (1 - t) * np.cos(x1) + s, where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4 pi 2), c = 5 / pi, r = 6, s = 10 and t = 1 / (8 pi). It has three global minima: f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15]. Parameters: Name Type Description Default X array input value required fun_control dict dict with entries seed and sigma . None Returns: Type Description float function value Source code in spotPython/fun/objectivefunctions.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def fun_branin ( self , X , fun_control = None ): \"\"\"Branin function. The 2-dim Branin function is y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s, where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2), c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi). It has three global minima: f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15]. Args: X (array): input value fun_control (dict): dict with entries `seed` and `sigma`. Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 2 : raise Exception x1 = X [:, 0 ] x2 = X [:, 1 ] a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi r = 6 s = 10 t = 1 / ( 8 * np . pi ) y = a * ( x2 - b * x1 ** 2 + c * x1 - r ) ** 2 + s * ( 1 - t ) * np . cos ( x1 ) + s # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y","title":"fun_branin()"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_branin_factor","text":"Branin function with factor variable x_3. The 2-dim Branin, or Branin-Hoo, function has three global minima. The recommended values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4 pi 2), c = 5 / \u03c0, r = 6, s = 10 and t = 1 / (8 pi). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15] and with x3 from the set {0, 1, 2}, i.e., x3 is a factor variable with three levels. Global Minimum: f(x) = 0.397887 -1 at (-pi, 12.275, 2), (pi, 2.275, 2), and (9.42478, 2.475, 2). Parameters: Name Type Description Default X array input value required Returns: Type Description float function value Source code in spotPython/fun/objectivefunctions.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 def fun_branin_factor ( self , X , fun_control = None ): \"\"\"Branin function with factor variable x_3. The 2-dim Branin, or Branin-Hoo, function has three global minima. The recommended values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2), c = 5 / \u03c0, r = 6, s = 10 and t = 1 / (8*pi). Input Domain: This function is usually evaluated on the square x1 in [-5, 10] x x2 in [0, 15] and with x3 from the set {0, 1, 2}, i.e., x3 is a factor variable with three levels. Global Minimum: f(x) = 0.397887 -1 at (-pi, 12.275, 2), (pi, 2.275, 2), and (9.42478, 2.475, 2). Args: X (array): input value Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ([ X ]) if X . shape [ 1 ] != 3 : raise Exception x1 = X [:, 0 ] x2 = X [:, 1 ] x3 = X [:, 2 ] a = 1 b = 5.1 / ( 4 * np . pi ** 2 ) c = 5 / np . pi r = 6 s = 10 t = 1 / ( 8 * np . pi ) y = a * ( x2 - b * x1 ** 2 + c * x1 - r ) ** 2 + s * ( 1 - t ) * np . cos ( x1 ) + s for j in range ( X . shape [ 0 ]): if x3 [ j ] == 1 : y [ j ] = y [ j ] + 10 elif x3 [ j ] == 2 : y [ j ] = y [ j ] - 10 # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y","title":"fun_branin_factor()"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_forrester","text":"Function used by [Forr08a, p.83]. f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. Starts with three sample points at x=0, x=0.5, and x=1. Parameters: Name Type Description Default X flooat input values (1-dim) required Returns: Type Description float function value Source code in spotPython/fun/objectivefunctions.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def fun_forrester ( self , X , fun_control = None ): \"\"\" Function used by [Forr08a, p.83]. f(x) = (6x- 2)^2 sin(12x-4) for x in [0,1]. Starts with three sample points at x=0, x=0.5, and x=1. Args: X (flooat): input values (1-dim) Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , ( 6.0 * X [ i ] - 2 ) ** 2 * np . sin ( 12 * X [ i ] - 4 )) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y","title":"fun_forrester()"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_linear","text":"Linear function. Parameters: Name Type Description Default X array input required Returns: Type Description float objective function value. Source code in spotPython/fun/objectivefunctions.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def fun_linear ( self , X , fun_control = None ): \"\"\"Linear function. Args: X (array): input Returns: (float): objective function value. \"\"\" if fun_control is not None : self . fun_control = fun_control try : X . shape [ 1 ] except ValueError as err : print ( \"error message:\" , err ) X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum ( X [ i ])) if self . fun_control [ \"sigma\" ] > 0 : return self . add_noise ( y ) else : return y","title":"fun_linear()"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_runge","text":"Runge function. Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2 Dim: k >= 1 Interval: -5 <= x <= 5 Parameters: Name Type Description Default X numpy . array required fun_control dictionary None Returns: Type Description (float) : function value Source code in spotPython/fun/objectivefunctions.py 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 def fun_runge ( self , X , fun_control = None ): \"\"\" Runge function. Formula: f(x) = 1/ (1 + sum(x_i) - offset)^2 Dim: k >= 1 Interval: -5 <= x <= 5 Args: X (numpy.array): input fun_control (dictionary, optional): control parameters. Defaults to None. Returns: (float) : function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , ( 1 / ( 1 + np . sum (( X [ i ] - offset ) ** 2 )))) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y","title":"fun_runge()"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_sphere","text":"Sphere function. Parameters: Name Type Description Default X array input required fun_control dict dict with entries seed and sigma . None Returns: Type Description float function values Source code in spotPython/fun/objectivefunctions.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def fun_sphere ( self , X , fun_control = None ): \"\"\"Sphere function. Args: X (array): input fun_control (dict): dict with entries `seed` and `sigma`. Returns: (float): function values \"\"\" if fun_control is not None : self . fun_control = fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) offset = np . ones ( X . shape [ 1 ]) * self . offset y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , np . sum (( X [ i ] - offset ) ** 2 )) # TODO: move to a separate function: if self . fun_control [ \"sigma\" ] > 0 : # Use own rng: if self . fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for y_i in y : noise_y = np . append ( noise_y , y_i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y","title":"fun_sphere()"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_wingwt","text":"Wing weight function. Example from Forrester et al. to understand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters: W = 0.036 S_W 0.758 * Wfw 0.0035 ( A / (cos 2 Lambda)) 0.6 * q 0.006 * lambda 0.04 * ( (100 Rtc)/(cos Lambda) )) -0.3* (Nz Wdg) 0.49 Symbol Parameter Baseline Minimum Maximum $S_W$ Wing area ($ft^2$) 174 150 200 $W_{fw}$ Weight of fuel in wing (lb) 252 220 300 $A$ Aspect ratio 7.52 6 10 $Lambda$ Quarter-chord sweep (deg) 0 -10 10 $q$ Dynamic pressure at cruise ($lb/ft^2$) 34 16 45 $lambda$ Taper ratio 0.672 0.5 1 $R_{tc}$ Aerofoil thickness to chord ratio 0.12 0.08 0.18 $N_z$ Ultimate load factor 3.8 2.5 6 $W_{dg}$ Flight design gross weight (lb) 2000 1700 2500 $W_p$ paint weight (lb/ft^2) 0.064 0.025 0.08 Parameters: Name Type Description Default X numpy . array 10-dim input vector required fun_control dictionary control parameters. Defaults to None. None Returns: Type Description (float) : function value Source code in spotPython/fun/objectivefunctions.py 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 def fun_wingwt ( self , X , fun_control = None ): \"\"\" Wing weight function. Example from Forrester et al. to understand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters: W = 0.036 S_W**0.758 * Wfw**0.0035 ( A / (cos**2 Lambda))**0.6 * q**0.006 * lambda**0.04 * ( (100 Rtc)/(cos Lambda) ))**-0.3* (Nz Wdg)**0.49 | Symbol | Parameter | Baseline | Minimum | Maximum | |-----------|----------------------------------------|----------|---------|---------| | $S_W$ | Wing area ($ft^2$) | 174 | 150 | 200 | | $W_{fw}$ | Weight of fuel in wing (lb) | 252 | 220 | 300 | | $A$ | Aspect ratio | 7.52 | 6 | 10 | | $Lambda$ | Quarter-chord sweep (deg) | 0 | -10 | 10 | | $q$ | Dynamic pressure at cruise ($lb/ft^2$) | 34 | 16 | 45 | | $lambda$ | Taper ratio | 0.672 | 0.5 | 1 | | $R_{tc}$ | Aerofoil thickness to chord ratio | 0.12 | 0.08 | 0.18 | | $N_z$ | Ultimate load factor | 3.8 | 2.5 | 6 | | $W_{dg}$ | Flight design gross weight (lb) | 2000 | 1700 | 2500 | | $W_p$ | paint weight (lb/ft^2) | 0.064 | 0.025 | 0.08 | Args: X (numpy.array): 10-dim input vector fun_control (dictionary, optional): control parameters. Defaults to None. Returns: (float) : function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) # W_res = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): Sw = X [ i , 0 ] * ( 200 - 150 ) + 150 Wfw = X [ i , 1 ] * ( 300 - 220 ) + 220 A = X [ i , 2 ] * ( 10 - 6 ) + 6 L = ( X [ i , 3 ] * ( 10 - ( - 10 )) - 10 ) * np . pi / 180 q = X [ i , 4 ] * ( 45 - 16 ) + 16 la = X [ i , 5 ] * ( 1 - 0.5 ) + 0.5 Rtc = X [ i , 6 ] * ( 0.18 - 0.08 ) + 0.08 Nz = X [ i , 7 ] * ( 6 - 2.5 ) + 2.5 Wdg = X [ i , 8 ] * ( 2500 - 1700 ) + 1700 Wp = X [ i , 9 ] * ( 0.08 - 0.025 ) + 0.025 # calculation on natural scale W = 0.036 * Sw ** 0.758 * Wfw ** 0.0035 * ( A / np . cos ( L ) ** 2 ) ** 0.6 * q ** 0.006 W = W * la ** 0.04 * ( 100 * Rtc / np . cos ( L )) ** ( - 0.3 ) * ( Nz * Wdg ) ** ( 0.49 ) + Sw * Wp W_res = np . append ( W_res , W ) return W_res","title":"fun_wingwt()"},{"location":"reference/spotPython/fun/objectivefunctions/#spotPython.fun.objectivefunctions.analytical.fun_xsin","text":"Parameters: Name Type Description Default X float input values (1-dim) required Returns: Type Description float function value Source code in spotPython/fun/objectivefunctions.py 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 def fun_xsin ( self , X , fun_control = None ): \"\"\" Args: X (float): input values (1-dim) Returns: (float): function value \"\"\" if fun_control is None : fun_control = self . fun_control try : X . shape [ 1 ] except ValueError : X = np . array ( X ) if len ( X . shape ) < 2 : X = np . array ([ X ]) y = np . array ([], dtype = float ) for i in range ( X . shape [ 0 ]): y = np . append ( y , X [ i ] * np . sin ( 1.0 / X [ i ])) # TODO: move to a separate function: if fun_control [ \"sigma\" ] > 0 : # Use own rng: if fun_control [ \"seed\" ] is not None : rng = default_rng ( seed = fun_control [ \"seed\" ]) # Use class rng: else : rng = self . rng noise_y = np . array ([], dtype = float ) for i in y : # noise_y = np.append( # noise_y, i + np.random.normal(loc=0, scale=self.sigma, size=1) noise_y = np . append ( noise_y , i + rng . normal ( loc = 0 , scale = fun_control [ \"sigma\" ], size = 1 )) return noise_y else : return y","title":"fun_xsin()"},{"location":"reference/spotPython/plot/contour/","text":"simple_contour ( fun , min_x =- 1 , max_x = 1 , min_y =- 1 , max_y = 1 , min_z = None , max_z = None , n_samples = 100 , n_levels = 30 ) Simple contour plot Parameters: Name Type Description Default fun _type_ description required min_x int description . Defaults to -1. -1 max_x int description . Defaults to 1. 1 min_y int description . Defaults to -1. -1 max_y int description . Defaults to 1. 1 min_z int description . Defaults to 0. None max_z int description . Defaults to 1. None n_samples int description . Defaults to 100. 100 n_levels int description . Defaults to 5. 30 Example import matplotlib.pyplot as plt import numpy as np from spotPython.fun.objectivefunctions import analytical fun = analytical().fun_branin simple_contour(fun=fun, n_levels=30, min_x=-5, max_x=10, min_y=0, max_y=15) Source code in spotPython/plot/contour.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def simple_contour ( fun , min_x =- 1 , max_x = 1 , min_y =- 1 , max_y = 1 , min_z = None , max_z = None , n_samples = 100 , n_levels = 30 , ): \"\"\" Simple contour plot Args: fun (_type_): _description_ min_x (int, optional): _description_. Defaults to -1. max_x (int, optional): _description_. Defaults to 1. min_y (int, optional): _description_. Defaults to -1. max_y (int, optional): _description_. Defaults to 1. min_z (int, optional): _description_. Defaults to 0. max_z (int, optional): _description_. Defaults to 1. n_samples (int, optional): _description_. Defaults to 100. n_levels (int, optional): _description_. Defaults to 5. Example: >>> import matplotlib.pyplot as plt >>> import numpy as np >>> from spotPython.fun.objectivefunctions import analytical >>> fun = analytical().fun_branin >>> simple_contour(fun=fun, n_levels=30, min_x=-5, max_x=10, min_y=0, max_y=15) \"\"\" XX , YY = np . meshgrid ( np . linspace ( min_x , max_x , n_samples ), np . linspace ( min_y , max_y , n_samples )) zz = np . array ([ fun ( np . array ([ xi , yi ]) . reshape ( - 1 , 2 )) for xi , yi in zip ( np . ravel ( XX ), np . ravel ( YY ))]) . reshape ( n_samples , n_samples ) fig , ax = plt . subplots ( figsize = ( 5 , 2.7 ), layout = \"constrained\" ) if min_z is None : min_z = np . min ( zz ) if max_z is None : max_z = np . max ( zz ) plt . contourf ( XX , YY , zz , levels = np . linspace ( min_z , max_z , n_levels ), zorder = 1 , cmap = \"jet\" , vmin = min_z , vmax = max_z , ) plt . colorbar ()","title":"contour"},{"location":"reference/spotPython/plot/contour/#spotPython.plot.contour.simple_contour","text":"Simple contour plot Parameters: Name Type Description Default fun _type_ description required min_x int description . Defaults to -1. -1 max_x int description . Defaults to 1. 1 min_y int description . Defaults to -1. -1 max_y int description . Defaults to 1. 1 min_z int description . Defaults to 0. None max_z int description . Defaults to 1. None n_samples int description . Defaults to 100. 100 n_levels int description . Defaults to 5. 30 Example import matplotlib.pyplot as plt import numpy as np from spotPython.fun.objectivefunctions import analytical fun = analytical().fun_branin simple_contour(fun=fun, n_levels=30, min_x=-5, max_x=10, min_y=0, max_y=15) Source code in spotPython/plot/contour.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def simple_contour ( fun , min_x =- 1 , max_x = 1 , min_y =- 1 , max_y = 1 , min_z = None , max_z = None , n_samples = 100 , n_levels = 30 , ): \"\"\" Simple contour plot Args: fun (_type_): _description_ min_x (int, optional): _description_. Defaults to -1. max_x (int, optional): _description_. Defaults to 1. min_y (int, optional): _description_. Defaults to -1. max_y (int, optional): _description_. Defaults to 1. min_z (int, optional): _description_. Defaults to 0. max_z (int, optional): _description_. Defaults to 1. n_samples (int, optional): _description_. Defaults to 100. n_levels (int, optional): _description_. Defaults to 5. Example: >>> import matplotlib.pyplot as plt >>> import numpy as np >>> from spotPython.fun.objectivefunctions import analytical >>> fun = analytical().fun_branin >>> simple_contour(fun=fun, n_levels=30, min_x=-5, max_x=10, min_y=0, max_y=15) \"\"\" XX , YY = np . meshgrid ( np . linspace ( min_x , max_x , n_samples ), np . linspace ( min_y , max_y , n_samples )) zz = np . array ([ fun ( np . array ([ xi , yi ]) . reshape ( - 1 , 2 )) for xi , yi in zip ( np . ravel ( XX ), np . ravel ( YY ))]) . reshape ( n_samples , n_samples ) fig , ax = plt . subplots ( figsize = ( 5 , 2.7 ), layout = \"constrained\" ) if min_z is None : min_z = np . min ( zz ) if max_z is None : max_z = np . max ( zz ) plt . contourf ( XX , YY , zz , levels = np . linspace ( min_z , max_z , n_levels ), zorder = 1 , cmap = \"jet\" , vmin = min_z , vmax = max_z , ) plt . colorbar ()","title":"simple_contour()"},{"location":"reference/spotPython/spot/spot/","text":"Spot Spot base class to handle the following tasks in a uniform manner: Getting and setting parameters. This is done via the Spot initilaization. Running surrogate based hyperparameter optimization. After the class is initialized, hyperparameter tuning runs can be performed via the run method. Displaying information. The plot method can be used for visualizing results. The print methods summarizes information about the tuning run. The Spot class is build in a modular manner. It combines the following three components: 1. Design 2. Surrogate 3. Optimizer For each of the three components different implementations can be selected and combined. Internal components are selected as default. These can be replaced by components from other packages, e.g., scikit-learn or scikit-optimize. Parameters: Name Type Description Default fun object objective function required lower numpy . array lower bound required upper numpy . array upper bound required fun_evals int number of function evaluations 15 fun_repeats int number of repeats (replicates). 1 max_time int maximum time (in minutes) inf noise bool deterministic or noisy objective function False tolerance_x float tolerance for new x solutions. Minimum distance of new solutions, generated by suggest_new_X , to already existing solutions. If zero (which is the default), every new solution is accepted. 0 ocba_delta int OCBA increment (only used if noise==True ) 0 var_type list list of type information, can be either \"num\" or \"factor\" ['num'] infill_criterion string Can be \"y\" , \"s\" , \"ei\" (negative expected improvement), or \"all\" . 'y' n_points int number of infill points 1 seed int initial seed 123 log_level int log level with the following settings: NOTSET ( 0 ), DEBUG ( 10 : Detailed information, typically of interest only when diagnosing problems.), INFO ( 20 : Confirmation that things are working as expected.), WARNING ( 30 : An indication that something unexpected happened, or indicative of some problem in the near future (e.g. \u2018disk space low\u2019). The software is still working as expected.), ERROR ( 40 : Due to a more serious problem, the software has not been able to perform some function.), and CRITICAL ( 50 : A serious error, indicating that the program itself may be unable to continue running.) 50 show_models bool Plot model. Currently only 1-dim functions are supported. False design object experimental design. None design_control dict experimental design information stored as a dictionary with the following entries: \"init_size\": 10 , \"repeats\": 1 . {} surrogate object surrogate model. If None , spotPython's kriging is used. None surrogate_control dict surrogate model information stored as a dictionary with the following entries: \"model_optimizer\": differential_evolution , \"model_fun_evals\": None , \"min_theta\": -3. , \"max_theta\": 3. , \"n_theta\": 1 , \"n_p\": 1 , \"optim_p\": False , \"cod_type\": \"norm\" , \"var_type\": self.var_type , \"use_cod_y\": False . {} optimizer object optimizer. If None , scipy.optimize 's differential_evolution is used. None optimizer_control dict information about the optimizer stored as a dictionary with the following entries: \"max_iter\": 1000 . {} Note Description in the source code refers to [bart21i]: Bartz-Beielstein, T., and Zaefferer, M. Hyperparameter tuning approaches. In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, E. Bartz, T. Bartz-Beielstein, M. Zaefferer, and O. Mersmann, Eds. Springer, 2022, ch. 4, pp. 67\u2013114. Source code in spotPython/spot/spot.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 class Spot : \"\"\" Spot base class to handle the following tasks in a uniform manner: * Getting and setting parameters. This is done via the `Spot` initilaization. * Running surrogate based hyperparameter optimization. After the class is initialized, hyperparameter tuning runs can be performed via the `run` method. * Displaying information. The `plot` method can be used for visualizing results. The `print` methods summarizes information about the tuning run. The `Spot` class is build in a modular manner. It combines the following three components: 1. Design 2. Surrogate 3. Optimizer For each of the three components different implementations can be selected and combined. Internal components are selected as default. These can be replaced by components from other packages, e.g., scikit-learn or scikit-optimize. Args: fun (object): objective function lower (numpy.array): lower bound upper (numpy.array): upper bound fun_evals (int): number of function evaluations fun_repeats (int): number of repeats (replicates). max_time (int): maximum time (in minutes) noise (bool): deterministic or noisy objective function tolerance_x (float): tolerance for new x solutions. Minimum distance of new solutions, generated by `suggest_new_X`, to already existing solutions. If zero (which is the default), every new solution is accepted. ocba_delta (int): OCBA increment (only used if `noise==True`) var_type (list): list of type information, can be either \"num\" or \"factor\" infill_criterion (string): Can be `\"y\"`, `\"s\"`, `\"ei\"` (negative expected improvement), or `\"all\"`. n_points (int): number of infill points seed (int): initial seed log_level (int): log level with the following settings: `NOTSET` (`0`), `DEBUG` (`10`: Detailed information, typically of interest only when diagnosing problems.), `INFO` (`20`: Confirmation that things are working as expected.), `WARNING` (`30`: An indication that something unexpected happened, or indicative of some problem in the near future (e.g. \u2018disk space low\u2019). The software is still working as expected.), `ERROR` (`40`: Due to a more serious problem, the software has not been able to perform some function.), and `CRITICAL` (`50`: A serious error, indicating that the program itself may be unable to continue running.) show_models (bool): Plot model. Currently only 1-dim functions are supported. show_progress (bool). Show progress bar. design (object): experimental design. design_control (dict): experimental design information stored as a dictionary with the following entries: \"init_size\": `10`, \"repeats\": `1`. surrogate (object): surrogate model. If `None`, spotPython's `kriging` is used. surrogate_control (dict): surrogate model information stored as a dictionary with the following entries: \"model_optimizer\": `differential_evolution`, \"model_fun_evals\": `None`, \"min_theta\": `-3.`, \"max_theta\": `3.`, \"n_theta\": `1`, \"n_p\": `1`, \"optim_p\": `False`, \"cod_type\": `\"norm\"`, \"var_type\": `self.var_type`, \"use_cod_y\": `False`. optimizer (object): optimizer. If `None`, `scipy.optimize`'s `differential_evolution` is used. optimizer_control (dict): information about the optimizer stored as a dictionary with the following entries: \"max_iter\": `1000`. Note: Description in the source code refers to [bart21i]: Bartz-Beielstein, T., and Zaefferer, M. Hyperparameter tuning approaches. In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, E. Bartz, T. Bartz-Beielstein, M. Zaefferer, and O. Mersmann, Eds. Springer, 2022, ch. 4, pp. 67\u2013114. \"\"\" def __str__ ( self ): return self . __class__ . __name__ def __init__ ( self , fun , lower , upper , fun_evals = 15 , fun_repeats = 1 , fun_control = {}, max_time = inf , noise = False , tolerance_x = 0 , var_type = [ \"num\" ], infill_criterion = \"y\" , n_points = 1 , ocba_delta = 0 , seed = 123 , log_level = 50 , show_models = False , show_progress = False , design = None , design_control = {}, surrogate = None , surrogate_control = {}, optimizer = None , optimizer_control = {}, ): # small value: self . eps = sqrt ( spacing ( 1 )) self . fun = fun self . lower = lower self . upper = upper self . var_type = var_type # Reduce dim based on lower == upper logic: # modifies lower, upper, and var_type self . to_red_dim () self . k = self . lower . size self . fun_evals = fun_evals self . fun_repeats = fun_repeats self . max_time = max_time self . noise = noise self . tolerance_x = tolerance_x self . ocba_delta = ocba_delta self . log_level = log_level self . show_models = show_models self . show_progress = show_progress # Random number generator: self . seed = seed self . rng = default_rng ( self . seed ) # Force numeric type as default in every dim: # assume all variable types are \"num\" if \"num\" is # specified once: if len ( self . var_type ) < self . k : self . var_type = self . var_type * self . k logger . warning ( \"Warning: All variable types forced to 'num'.\" ) self . infill_criterion = infill_criterion # Bounds de_bounds = [] for j in range ( self . k ): de_bounds . append ([ self . lower [ j ], self . upper [ j ]]) self . de_bounds = de_bounds # Infill points: self . n_points = n_points # Objective function related information: self . fun_control = { \"sigma\" : 0 , \"seed\" : None } self . fun_control . update ( fun_control ) # Design related information: self . design = design if design is None : self . design = spacefilling ( k = self . k , seed = self . seed ) self . design_control = { \"init_size\" : 10 , \"repeats\" : 1 } self . design_control . update ( design_control ) # Surrogate related information: self . surrogate = surrogate self . surrogate_control = { \"noise\" : self . noise , \"model_optimizer\" : differential_evolution , \"model_fun_evals\" : None , \"min_theta\" : - 3. , \"max_theta\" : 3. , \"n_theta\" : 1 , \"n_p\" : 1 , \"optim_p\" : False , \"cod_type\" : \"norm\" , \"var_type\" : self . var_type , \"seed\" : 124 , \"use_cod_y\" : False } self . surrogate_control . update ( surrogate_control ) # If no surrogate model is specified, use the internal # spotPython kriging surrogate: if self . surrogate is None : # Call kriging with surrogate_control parameters: self . surrogate = Kriging ( name = \"kriging\" , noise = self . surrogate_control [ \"noise\" ], model_optimizer = self . surrogate_control [ \"model_optimizer\" ], model_fun_evals = self . surrogate_control [ \"model_fun_evals\" ], seed = self . surrogate_control [ \"seed\" ], log_level = self . log_level , min_theta = self . surrogate_control [ \"min_theta\" ], max_theta = self . surrogate_control [ \"max_theta\" ], n_theta = self . surrogate_control [ \"n_theta\" ], n_p = self . surrogate_control [ \"n_p\" ], optim_p = self . surrogate_control [ \"optim_p\" ], cod_type = self . surrogate_control [ \"cod_type\" ], var_type = self . surrogate_control [ \"var_type\" ], use_cod_y = self . surrogate_control [ \"use_cod_y\" ] ) # Optimizer related information: self . optimizer = optimizer self . optimizer_control = { \"max_iter\" : 1000 , \"seed\" : 125 } self . optimizer_control . update ( optimizer_control ) if self . optimizer is None : self . optimizer = optimize . differential_evolution # Logging information: self . counter = 0 self . min_y = None self . min_X = None self . min_mean_X = None self . min_mean_y = None self . mean_X = None self . mean_y = None self . var_y = None logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) def to_red_dim ( self ): self . all_lower = self . lower self . all_upper = self . upper self . ident = ( self . upper - self . lower ) == 0 self . lower = self . lower [ ~ self . ident ] self . upper = self . upper [ ~ self . ident ] self . red_dim = self . ident . any () self . all_var_type = self . var_type self . var_type = [ x for x , y in zip ( self . all_var_type , self . ident ) if not y ] def to_all_dim ( self , X0 ): n = X0 . shape [ 0 ] k = len ( self . ident ) X = np . zeros (( n , k )) j = 0 for i in range ( k ): if self . ident [ i ]: X [:, i ] = self . all_lower [ i ] j = j + 1 else : X [:, i ] = X0 [:, i - j ] return X def run ( self ): \"\"\" Run spot. Returns: (object): spot \"\"\" # (S-2) Initial Design: X0 = self . generate_design ( size = self . design_control [ \"init_size\" ], repeats = self . design_control [ \"repeats\" ], lower = self . lower , upper = self . upper ) X0 = repair_non_numeric ( X0 , self . var_type ) self . X = X0 # (S-3): Eval initial design: if self . red_dim : X_all = self . to_all_dim ( X0 ) else : X_all = X0 self . y = self . fun ( X = X_all , fun_control = self . fun_control ) self . X , self . y = remove_nan ( self . X , self . y ) self . update_stats () # (S-4): Imputation: # Not implemented yet. self . surrogate . fit ( self . X , self . y ) # (S-5) Calling the spotLoop Function # and # (S-9) Termination Criteria, Conditions: timeout_start = time . time () while ( self . counter < self . fun_evals ) and ( time . time () < timeout_start + self . max_time * 60 ): # OCBA (only if noise) if self . noise and self . ocba_delta > 0 : # and self.fun_repeats > 0 and self.design_control[\"repeats\"] > 0: X_ocba = get_ocba_X ( self . mean_X , self . mean_y , self . var_y , self . ocba_delta ) else : X_ocba = None # (S-15) Compile Surrogate Results: X0 = self . suggest_new_X () X0 = repair_non_numeric ( X0 , self . var_type ) # (S-16) Duplicate Handling: # Condition: select only X= that have min distance # to existing solutions X0 , X0_ind = selectNew ( A = X0 , X = self . X , tolerance = self . tolerance_x ) logger . debug ( \"XO values are new: %s \" , X0_ind ) # 1. There are X0 that fullfil the condition. # Note: The number of new X0 can be smaller than self.n_points! if X0 . shape [ 0 ] > 0 : X0 = repeat ( X0 , self . fun_repeats , axis = 0 ) # 2. No X0 found. Then generate self.n_points new solutions: else : self . design = spacefilling ( k = self . k , seed = self . seed + self . counter ) X0 = self . generate_design ( size = self . n_points , repeats = self . design_control [ \"repeats\" ], lower = self . lower , upper = self . upper ) X0 = repair_non_numeric ( X0 , self . var_type ) logger . warning ( \"No new XO found on surrogate. Generate new solution %s \" , X0 ) # (S-18): Evaluating New Solutions: if self . noise and self . ocba_delta > 0 : X0 = append ( X_ocba , X0 , axis = 0 ) if self . red_dim : X_all = self . to_all_dim ( X0 ) else : X_all = X0 y0 = self . fun ( X = X_all , fun_control = self . fun_control ) X0 , y0 = remove_nan ( X0 , y0 ) # Append New Solutions: self . X = np . append ( self . X , X0 , axis = 0 ) self . y = np . append ( self . y , y0 ) # (S-10): Subset Selection for the Surrogate: # Not implemented yet. # Update stats self . update_stats () # (S-11) Surrogate Fit: self . surrogate . fit ( self . X , self . y ) if self . show_models : self . plot_model () # progress bar: if self . show_progress : if isfinite ( self . fun_evals ): progress_bar ( self . counter / self . fun_evals ) else : progress_bar (( time . time () - timeout_start ) / ( self . max_time * 60 )) return self def generate_design ( self , size , repeats , lower , upper ): return self . design . scipy_lhd ( n = size , repeats = repeats , lower = lower , upper = upper ) def update_stats ( self ): \"\"\" Update the following stats: 1. `min_y` 2. `min_X` 3. `counter` If `noise` is `True`, additionally the following stats are computed: 1. `mean_X` 2. `mean_y` 3. `min_mean_y` 4. `min_mean_X`. \"\"\" self . min_y = min ( self . y ) self . min_X = self . X [ argmin ( self . y )] self . counter = self . y . size # Update aggregated x and y values (if noise): if self . noise : Z = aggregate_mean_var ( X = self . X , y = self . y ) self . mean_X = Z [ 0 ] self . mean_y = Z [ 1 ] self . var_y = Z [ 2 ] self . min_mean_y = min ( self . mean_y ) self . min_mean_X = self . mean_X [ argmin ( self . mean_y )] def suggest_new_X ( self ): \"\"\" Compute `n_points` new infill points in natural units. The optimizer searches in the ranges from `lower_j` to `upper_j`. The method `infill()` is used as the objective function. Returns: (numpy.ndarray): `n_points` infill points in natural units, each of dim k Note: This is step (S-14a) in [bart21i]. \"\"\" # (S-14a) Optimization on the surrogate: new_X = np . zeros ([ self . n_points , self . k ], dtype = float ) for i in range ( self . n_points ): if self . optimizer . __name__ == 'dual_annealing' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) elif self . optimizer . __name__ == 'differential_evolution' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds , maxiter = self . optimizer_control [ \"max_iter\" ], seed = self . optimizer_control [ \"seed\" ], # popsize=10, # updating=\"deferred\" ) elif self . optimizer . __name__ == 'direct' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds , eps = 1e-2 ) elif self . optimizer . __name__ == 'shgo' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) elif self . optimizer . __name__ == 'basinhopping' : result = self . optimizer ( func = self . infill , x0 = self . min_X ) else : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) new_X [ i ][:] = result . x return new_X def infill ( self , x ): \"\"\" Infill (acquisition) function. Evaluates one point on the surrogate via `surrogate.predict(x.reshape(1,-1))`, if `sklearn` surrogates are used or `surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion)` if the internal surrogate `kriging` is selected. This method is passed to the optimizer in `suggest_new_X`, i.e., the optimizer is called via `self.optimizer(func=self.infill)`. Args: x (array): point in natural units with shape `(1, dim)`. Returns: (numpy.ndarray): value based on infill criterion, e.g., `\"ei\"`. Shape `(1,)`. The objective function value `y` that is used as a base value for the infill criterion is calculated in natural units. Note: This is step (S-12) in [bart21i]. \"\"\" # (S-12) Objective Function on the Surrogate (Predict) # res = self.surrogate.predict(x.reshape(1, -1)) # if isinstance(self.surrogate, Kriging): # if self.infill_criterion == \"ei\": # y = -1.0 * res[2] # ei # else: # y = res[0] # f # else: # y = res # sklearn etc. # return y if isinstance ( self . surrogate , Kriging ): return self . surrogate . predict ( x . reshape ( 1 , - 1 ), return_val = self . infill_criterion ) else : return self . surrogate . predict ( x . reshape ( 1 , - 1 )) def plot_progress ( self , show = True , log_y = False ): \"\"\" Generate progress plot, i.e., plot y versus x values. Usually called after the run is finished. Args: show (bool, optional): Show plot. Defaults to True. log_y (bool, optional): log y-axis. Defaults to False. \"\"\" fig = pylab . figure ( figsize = ( 9 , 6 )) # TODO: Consider y_min of the initial design, e.g., via: # best_y = list(itertools.repeat(min(y), self.init_size)) s_y = pd . Series ( self . y ) s_c = s_y . cummin () ax = fig . add_subplot ( 211 ) ax . plot ( range ( len ( s_c )), s_c ) if log_y : ax . set_yscale ( \"log\" ) if show : pylab . show () def plot_model ( self , y_min = None , y_max = None ): \"\"\" Plot the model fit for 1-dim objective functions. Args: y_min (float, optional): y range, lower bound. y_max (float, optional): y range, upper bound. \"\"\" if self . k == 1 : X_test = np . linspace ( self . lower [ 0 ], self . upper [ 0 ], 100 ) y_test = self . fun ( X = X_test . reshape ( - 1 , 1 ), fun_control = self . fun_control ) if isinstance ( self . surrogate , Kriging ): y_hat = self . surrogate . predict ( X_test [:, np . newaxis ], return_val = \"y\" ) else : y_hat = self . surrogate . predict ( X_test [:, np . newaxis ]) plt . plot ( X_test , y_hat , label = \"Model\" ) plt . plot ( X_test , y_test , label = \"True function\" ) plt . scatter ( self . X , self . y , edgecolor = \"b\" , s = 20 , label = \"Samples\" ) plt . scatter ( self . X [ - 1 ], self . y [ - 1 ], edgecolor = \"r\" , s = 30 , label = \"Last Sample\" ) if self . noise : plt . scatter ( self . min_mean_X , self . min_mean_y , edgecolor = \"g\" , s = 30 , label = \"Best Sample (mean)\" ) else : plt . scatter ( self . min_X , self . min_y , edgecolor = \"g\" , s = 30 , label = \"Best Sample\" ) plt . xlabel ( \"x\" ) plt . ylabel ( \"y\" ) plt . xlim (( self . lower [ 0 ], self . upper [ 0 ])) if y_min is None : y_min = min ( min ( self . y ), min ( y_test )) if y_max is None : y_max = max ( max ( self . y ), max ( y_test )) plt . ylim (( y_min , y_max )) plt . legend ( loc = \"best\" ) # plt.title(self.surrogate.__class__.__name__ + \". \" + str(self.counter) + \": \" + str(self.min_y)) if self . noise : plt . title ( str ( self . counter ) + \". y (noise): \" + str ( np . round ( self . min_y , 6 )) + \" y mean: \" + str ( np . round ( self . min_mean_y , 6 ))) else : plt . title ( str ( self . counter ) + \". y: \" + str ( np . round ( self . min_y , 6 ))) plt . show () def print_results ( self ): \"\"\" Print results from the run: 1. min y 2. min X If `noise == True`, additinally the following values are printed: 3. min mean y 4. min mean X \"\"\" print ( f \"min y: { self . min_y } \" ) print ( f \"min X: { self . to_all_dim ( self . min_X . reshape ( 1 , - 1 )) } \" ) if self . noise : print ( f \"min mean y: { self . min_mean_y } \" ) print ( f \"min mean X: { self . to_all_dim ( self . min_mean_X . reshape ( 1 , - 1 )) } \" ) def chg ( self , x , y , z0 , i , j ): z0 [ i ] = x z0 [ j ] = y return z0 def plot_contour ( self , i = 0 , j = 1 , min_z = None , max_z = None , show = True ): \"\"\" This function plots surrogates of any dimension. Args: show (boolean): If `True`, the plots are displayed. If `False`, `plt.show()` should be called outside this function. \"\"\" fig = pylab . figure ( figsize = ( 9 , 6 )) n_grid = 100 # lower and upper x = np . linspace ( self . lower [ i ], self . upper [ i ], num = n_grid ) y = np . linspace ( self . lower [ j ], self . upper [ j ], num = n_grid ) X , Y = meshgrid ( x , y ) # Predict based on the optimized results z0 = np . mean ( np . array ([ self . lower , self . upper ]), axis = 0 ) zz = array ( [ self . surrogate . predict ( array ([ self . chg ( x , y , z0 , i , j )])) for x , y in zip ( ravel ( X ), ravel ( Y ))] ) zs = zz [:, 0 ] Z = zs . reshape ( X . shape ) if min_z is None : min_z = np . min ( Z ) if max_z is None : max_z = np . max ( Z ) contour_levels = 30 ax = fig . add_subplot ( 221 ) # plot predicted values: plt . contourf ( X , Y , Z , contour_levels , zorder = 1 , cmap = \"jet\" , vmin = min_z , vmax = max_z ) plt . xlabel ( \"x\" + str ( i )) plt . ylabel ( \"x\" + str ( j )) plt . title ( \"Surrogate\" ) pylab . colorbar () # ax = fig . add_subplot ( 222 , projection = \"3d\" ) ax . plot_surface ( X , Y , Z , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" , vmin = min_z , vmax = max_z ) ax . set_xlabel ( \"x\" + str ( i )) ax . set_ylabel ( \"x\" + str ( j )) # # pylab . show () def print_importance ( self ): theta = np . power ( 10 , self . surrogate . theta ) print ( \"Importance relative to the most important parameter:\" ) imp = 100 * theta / np . max ( theta ) for i in range ( len ( imp )): print ( \"Parameter\" , i , \": \" , imp [ i ]) infill ( x ) Infill (acquisition) function. Evaluates one point on the surrogate via surrogate.predict(x.reshape(1,-1)) , if sklearn surrogates are used or surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion) if the internal surrogate kriging is selected. This method is passed to the optimizer in suggest_new_X , i.e., the optimizer is called via self.optimizer(func=self.infill) . Parameters: Name Type Description Default x array point in natural units with shape (1, dim) . required Returns: Type Description numpy . ndarray value based on infill criterion, e.g., \"ei\" . Shape (1,) . The objective function value y that is used as a base value for the infill criterion is calculated in natural units. Note This is step (S-12) in [bart21i]. Source code in spotPython/spot/spot.py 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 def infill ( self , x ): \"\"\" Infill (acquisition) function. Evaluates one point on the surrogate via `surrogate.predict(x.reshape(1,-1))`, if `sklearn` surrogates are used or `surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion)` if the internal surrogate `kriging` is selected. This method is passed to the optimizer in `suggest_new_X`, i.e., the optimizer is called via `self.optimizer(func=self.infill)`. Args: x (array): point in natural units with shape `(1, dim)`. Returns: (numpy.ndarray): value based on infill criterion, e.g., `\"ei\"`. Shape `(1,)`. The objective function value `y` that is used as a base value for the infill criterion is calculated in natural units. Note: This is step (S-12) in [bart21i]. \"\"\" # (S-12) Objective Function on the Surrogate (Predict) # res = self.surrogate.predict(x.reshape(1, -1)) # if isinstance(self.surrogate, Kriging): # if self.infill_criterion == \"ei\": # y = -1.0 * res[2] # ei # else: # y = res[0] # f # else: # y = res # sklearn etc. # return y if isinstance ( self . surrogate , Kriging ): return self . surrogate . predict ( x . reshape ( 1 , - 1 ), return_val = self . infill_criterion ) else : return self . surrogate . predict ( x . reshape ( 1 , - 1 )) plot_contour ( i = 0 , j = 1 , min_z = None , max_z = None , show = True ) This function plots surrogates of any dimension. Parameters: Name Type Description Default show boolean If True , the plots are displayed. If False , plt.show() should be called outside this function. True Source code in spotPython/spot/spot.py 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 def plot_contour ( self , i = 0 , j = 1 , min_z = None , max_z = None , show = True ): \"\"\" This function plots surrogates of any dimension. Args: show (boolean): If `True`, the plots are displayed. If `False`, `plt.show()` should be called outside this function. \"\"\" fig = pylab . figure ( figsize = ( 9 , 6 )) n_grid = 100 # lower and upper x = np . linspace ( self . lower [ i ], self . upper [ i ], num = n_grid ) y = np . linspace ( self . lower [ j ], self . upper [ j ], num = n_grid ) X , Y = meshgrid ( x , y ) # Predict based on the optimized results z0 = np . mean ( np . array ([ self . lower , self . upper ]), axis = 0 ) zz = array ( [ self . surrogate . predict ( array ([ self . chg ( x , y , z0 , i , j )])) for x , y in zip ( ravel ( X ), ravel ( Y ))] ) zs = zz [:, 0 ] Z = zs . reshape ( X . shape ) if min_z is None : min_z = np . min ( Z ) if max_z is None : max_z = np . max ( Z ) contour_levels = 30 ax = fig . add_subplot ( 221 ) # plot predicted values: plt . contourf ( X , Y , Z , contour_levels , zorder = 1 , cmap = \"jet\" , vmin = min_z , vmax = max_z ) plt . xlabel ( \"x\" + str ( i )) plt . ylabel ( \"x\" + str ( j )) plt . title ( \"Surrogate\" ) pylab . colorbar () # ax = fig . add_subplot ( 222 , projection = \"3d\" ) ax . plot_surface ( X , Y , Z , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" , vmin = min_z , vmax = max_z ) ax . set_xlabel ( \"x\" + str ( i )) ax . set_ylabel ( \"x\" + str ( j )) # # pylab . show () plot_model ( y_min = None , y_max = None ) Plot the model fit for 1-dim objective functions. Parameters: Name Type Description Default y_min float y range, lower bound. None y_max float y range, upper bound. None Source code in spotPython/spot/spot.py 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 def plot_model ( self , y_min = None , y_max = None ): \"\"\" Plot the model fit for 1-dim objective functions. Args: y_min (float, optional): y range, lower bound. y_max (float, optional): y range, upper bound. \"\"\" if self . k == 1 : X_test = np . linspace ( self . lower [ 0 ], self . upper [ 0 ], 100 ) y_test = self . fun ( X = X_test . reshape ( - 1 , 1 ), fun_control = self . fun_control ) if isinstance ( self . surrogate , Kriging ): y_hat = self . surrogate . predict ( X_test [:, np . newaxis ], return_val = \"y\" ) else : y_hat = self . surrogate . predict ( X_test [:, np . newaxis ]) plt . plot ( X_test , y_hat , label = \"Model\" ) plt . plot ( X_test , y_test , label = \"True function\" ) plt . scatter ( self . X , self . y , edgecolor = \"b\" , s = 20 , label = \"Samples\" ) plt . scatter ( self . X [ - 1 ], self . y [ - 1 ], edgecolor = \"r\" , s = 30 , label = \"Last Sample\" ) if self . noise : plt . scatter ( self . min_mean_X , self . min_mean_y , edgecolor = \"g\" , s = 30 , label = \"Best Sample (mean)\" ) else : plt . scatter ( self . min_X , self . min_y , edgecolor = \"g\" , s = 30 , label = \"Best Sample\" ) plt . xlabel ( \"x\" ) plt . ylabel ( \"y\" ) plt . xlim (( self . lower [ 0 ], self . upper [ 0 ])) if y_min is None : y_min = min ( min ( self . y ), min ( y_test )) if y_max is None : y_max = max ( max ( self . y ), max ( y_test )) plt . ylim (( y_min , y_max )) plt . legend ( loc = \"best\" ) # plt.title(self.surrogate.__class__.__name__ + \". \" + str(self.counter) + \": \" + str(self.min_y)) if self . noise : plt . title ( str ( self . counter ) + \". y (noise): \" + str ( np . round ( self . min_y , 6 )) + \" y mean: \" + str ( np . round ( self . min_mean_y , 6 ))) else : plt . title ( str ( self . counter ) + \". y: \" + str ( np . round ( self . min_y , 6 ))) plt . show () plot_progress ( show = True , log_y = False ) Generate progress plot, i.e., plot y versus x values. Usually called after the run is finished. Parameters: Name Type Description Default show bool Show plot. Defaults to True. True log_y bool log y-axis. Defaults to False. False Source code in spotPython/spot/spot.py 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 def plot_progress ( self , show = True , log_y = False ): \"\"\" Generate progress plot, i.e., plot y versus x values. Usually called after the run is finished. Args: show (bool, optional): Show plot. Defaults to True. log_y (bool, optional): log y-axis. Defaults to False. \"\"\" fig = pylab . figure ( figsize = ( 9 , 6 )) # TODO: Consider y_min of the initial design, e.g., via: # best_y = list(itertools.repeat(min(y), self.init_size)) s_y = pd . Series ( self . y ) s_c = s_y . cummin () ax = fig . add_subplot ( 211 ) ax . plot ( range ( len ( s_c )), s_c ) if log_y : ax . set_yscale ( \"log\" ) if show : pylab . show () print_results () Print results from the run min y min X If noise == True , additinally the following values are printed: min mean y min mean X Source code in spotPython/spot/spot.py 518 519 520 521 522 523 524 525 526 527 528 529 530 531 def print_results ( self ): \"\"\" Print results from the run: 1. min y 2. min X If `noise == True`, additinally the following values are printed: 3. min mean y 4. min mean X \"\"\" print ( f \"min y: { self . min_y } \" ) print ( f \"min X: { self . to_all_dim ( self . min_X . reshape ( 1 , - 1 )) } \" ) if self . noise : print ( f \"min mean y: { self . min_mean_y } \" ) print ( f \"min mean X: { self . to_all_dim ( self . min_mean_X . reshape ( 1 , - 1 )) } \" ) run () Run spot. Returns: Type Description object spot Source code in spotPython/spot/spot.py 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 def run ( self ): \"\"\" Run spot. Returns: (object): spot \"\"\" # (S-2) Initial Design: X0 = self . generate_design ( size = self . design_control [ \"init_size\" ], repeats = self . design_control [ \"repeats\" ], lower = self . lower , upper = self . upper ) X0 = repair_non_numeric ( X0 , self . var_type ) self . X = X0 # (S-3): Eval initial design: if self . red_dim : X_all = self . to_all_dim ( X0 ) else : X_all = X0 self . y = self . fun ( X = X_all , fun_control = self . fun_control ) self . X , self . y = remove_nan ( self . X , self . y ) self . update_stats () # (S-4): Imputation: # Not implemented yet. self . surrogate . fit ( self . X , self . y ) # (S-5) Calling the spotLoop Function # and # (S-9) Termination Criteria, Conditions: timeout_start = time . time () while ( self . counter < self . fun_evals ) and ( time . time () < timeout_start + self . max_time * 60 ): # OCBA (only if noise) if self . noise and self . ocba_delta > 0 : # and self.fun_repeats > 0 and self.design_control[\"repeats\"] > 0: X_ocba = get_ocba_X ( self . mean_X , self . mean_y , self . var_y , self . ocba_delta ) else : X_ocba = None # (S-15) Compile Surrogate Results: X0 = self . suggest_new_X () X0 = repair_non_numeric ( X0 , self . var_type ) # (S-16) Duplicate Handling: # Condition: select only X= that have min distance # to existing solutions X0 , X0_ind = selectNew ( A = X0 , X = self . X , tolerance = self . tolerance_x ) logger . debug ( \"XO values are new: %s \" , X0_ind ) # 1. There are X0 that fullfil the condition. # Note: The number of new X0 can be smaller than self.n_points! if X0 . shape [ 0 ] > 0 : X0 = repeat ( X0 , self . fun_repeats , axis = 0 ) # 2. No X0 found. Then generate self.n_points new solutions: else : self . design = spacefilling ( k = self . k , seed = self . seed + self . counter ) X0 = self . generate_design ( size = self . n_points , repeats = self . design_control [ \"repeats\" ], lower = self . lower , upper = self . upper ) X0 = repair_non_numeric ( X0 , self . var_type ) logger . warning ( \"No new XO found on surrogate. Generate new solution %s \" , X0 ) # (S-18): Evaluating New Solutions: if self . noise and self . ocba_delta > 0 : X0 = append ( X_ocba , X0 , axis = 0 ) if self . red_dim : X_all = self . to_all_dim ( X0 ) else : X_all = X0 y0 = self . fun ( X = X_all , fun_control = self . fun_control ) X0 , y0 = remove_nan ( X0 , y0 ) # Append New Solutions: self . X = np . append ( self . X , X0 , axis = 0 ) self . y = np . append ( self . y , y0 ) # (S-10): Subset Selection for the Surrogate: # Not implemented yet. # Update stats self . update_stats () # (S-11) Surrogate Fit: self . surrogate . fit ( self . X , self . y ) if self . show_models : self . plot_model () # progress bar: if self . show_progress : if isfinite ( self . fun_evals ): progress_bar ( self . counter / self . fun_evals ) else : progress_bar (( time . time () - timeout_start ) / ( self . max_time * 60 )) return self suggest_new_X () Compute n_points new infill points in natural units. The optimizer searches in the ranges from lower_j to upper_j . The method infill() is used as the objective function. Returns: Type Description numpy . ndarray n_points infill points in natural units, each of dim k Note This is step (S-14a) in [bart21i]. Source code in spotPython/spot/spot.py 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 def suggest_new_X ( self ): \"\"\" Compute `n_points` new infill points in natural units. The optimizer searches in the ranges from `lower_j` to `upper_j`. The method `infill()` is used as the objective function. Returns: (numpy.ndarray): `n_points` infill points in natural units, each of dim k Note: This is step (S-14a) in [bart21i]. \"\"\" # (S-14a) Optimization on the surrogate: new_X = np . zeros ([ self . n_points , self . k ], dtype = float ) for i in range ( self . n_points ): if self . optimizer . __name__ == 'dual_annealing' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) elif self . optimizer . __name__ == 'differential_evolution' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds , maxiter = self . optimizer_control [ \"max_iter\" ], seed = self . optimizer_control [ \"seed\" ], # popsize=10, # updating=\"deferred\" ) elif self . optimizer . __name__ == 'direct' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds , eps = 1e-2 ) elif self . optimizer . __name__ == 'shgo' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) elif self . optimizer . __name__ == 'basinhopping' : result = self . optimizer ( func = self . infill , x0 = self . min_X ) else : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) new_X [ i ][:] = result . x return new_X update_stats () Update the following stats: 1. min_y 2. min_X 3. counter If noise is True , additionally the following stats are computed: 1. mean_X 2. mean_y 3. min_mean_y 4. min_mean_X . Source code in spotPython/spot/spot.py 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 def update_stats ( self ): \"\"\" Update the following stats: 1. `min_y` 2. `min_X` 3. `counter` If `noise` is `True`, additionally the following stats are computed: 1. `mean_X` 2. `mean_y` 3. `min_mean_y` 4. `min_mean_X`. \"\"\" self . min_y = min ( self . y ) self . min_X = self . X [ argmin ( self . y )] self . counter = self . y . size # Update aggregated x and y values (if noise): if self . noise : Z = aggregate_mean_var ( X = self . X , y = self . y ) self . mean_X = Z [ 0 ] self . mean_y = Z [ 1 ] self . var_y = Z [ 2 ] self . min_mean_y = min ( self . mean_y ) self . min_mean_X = self . mean_X [ argmin ( self . mean_y )]","title":"spot"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot","text":"Spot base class to handle the following tasks in a uniform manner: Getting and setting parameters. This is done via the Spot initilaization. Running surrogate based hyperparameter optimization. After the class is initialized, hyperparameter tuning runs can be performed via the run method. Displaying information. The plot method can be used for visualizing results. The print methods summarizes information about the tuning run. The Spot class is build in a modular manner. It combines the following three components: 1. Design 2. Surrogate 3. Optimizer For each of the three components different implementations can be selected and combined. Internal components are selected as default. These can be replaced by components from other packages, e.g., scikit-learn or scikit-optimize. Parameters: Name Type Description Default fun object objective function required lower numpy . array lower bound required upper numpy . array upper bound required fun_evals int number of function evaluations 15 fun_repeats int number of repeats (replicates). 1 max_time int maximum time (in minutes) inf noise bool deterministic or noisy objective function False tolerance_x float tolerance for new x solutions. Minimum distance of new solutions, generated by suggest_new_X , to already existing solutions. If zero (which is the default), every new solution is accepted. 0 ocba_delta int OCBA increment (only used if noise==True ) 0 var_type list list of type information, can be either \"num\" or \"factor\" ['num'] infill_criterion string Can be \"y\" , \"s\" , \"ei\" (negative expected improvement), or \"all\" . 'y' n_points int number of infill points 1 seed int initial seed 123 log_level int log level with the following settings: NOTSET ( 0 ), DEBUG ( 10 : Detailed information, typically of interest only when diagnosing problems.), INFO ( 20 : Confirmation that things are working as expected.), WARNING ( 30 : An indication that something unexpected happened, or indicative of some problem in the near future (e.g. \u2018disk space low\u2019). The software is still working as expected.), ERROR ( 40 : Due to a more serious problem, the software has not been able to perform some function.), and CRITICAL ( 50 : A serious error, indicating that the program itself may be unable to continue running.) 50 show_models bool Plot model. Currently only 1-dim functions are supported. False design object experimental design. None design_control dict experimental design information stored as a dictionary with the following entries: \"init_size\": 10 , \"repeats\": 1 . {} surrogate object surrogate model. If None , spotPython's kriging is used. None surrogate_control dict surrogate model information stored as a dictionary with the following entries: \"model_optimizer\": differential_evolution , \"model_fun_evals\": None , \"min_theta\": -3. , \"max_theta\": 3. , \"n_theta\": 1 , \"n_p\": 1 , \"optim_p\": False , \"cod_type\": \"norm\" , \"var_type\": self.var_type , \"use_cod_y\": False . {} optimizer object optimizer. If None , scipy.optimize 's differential_evolution is used. None optimizer_control dict information about the optimizer stored as a dictionary with the following entries: \"max_iter\": 1000 . {} Note Description in the source code refers to [bart21i]: Bartz-Beielstein, T., and Zaefferer, M. Hyperparameter tuning approaches. In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, E. Bartz, T. Bartz-Beielstein, M. Zaefferer, and O. Mersmann, Eds. Springer, 2022, ch. 4, pp. 67\u2013114. Source code in spotPython/spot/spot.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 class Spot : \"\"\" Spot base class to handle the following tasks in a uniform manner: * Getting and setting parameters. This is done via the `Spot` initilaization. * Running surrogate based hyperparameter optimization. After the class is initialized, hyperparameter tuning runs can be performed via the `run` method. * Displaying information. The `plot` method can be used for visualizing results. The `print` methods summarizes information about the tuning run. The `Spot` class is build in a modular manner. It combines the following three components: 1. Design 2. Surrogate 3. Optimizer For each of the three components different implementations can be selected and combined. Internal components are selected as default. These can be replaced by components from other packages, e.g., scikit-learn or scikit-optimize. Args: fun (object): objective function lower (numpy.array): lower bound upper (numpy.array): upper bound fun_evals (int): number of function evaluations fun_repeats (int): number of repeats (replicates). max_time (int): maximum time (in minutes) noise (bool): deterministic or noisy objective function tolerance_x (float): tolerance for new x solutions. Minimum distance of new solutions, generated by `suggest_new_X`, to already existing solutions. If zero (which is the default), every new solution is accepted. ocba_delta (int): OCBA increment (only used if `noise==True`) var_type (list): list of type information, can be either \"num\" or \"factor\" infill_criterion (string): Can be `\"y\"`, `\"s\"`, `\"ei\"` (negative expected improvement), or `\"all\"`. n_points (int): number of infill points seed (int): initial seed log_level (int): log level with the following settings: `NOTSET` (`0`), `DEBUG` (`10`: Detailed information, typically of interest only when diagnosing problems.), `INFO` (`20`: Confirmation that things are working as expected.), `WARNING` (`30`: An indication that something unexpected happened, or indicative of some problem in the near future (e.g. \u2018disk space low\u2019). The software is still working as expected.), `ERROR` (`40`: Due to a more serious problem, the software has not been able to perform some function.), and `CRITICAL` (`50`: A serious error, indicating that the program itself may be unable to continue running.) show_models (bool): Plot model. Currently only 1-dim functions are supported. show_progress (bool). Show progress bar. design (object): experimental design. design_control (dict): experimental design information stored as a dictionary with the following entries: \"init_size\": `10`, \"repeats\": `1`. surrogate (object): surrogate model. If `None`, spotPython's `kriging` is used. surrogate_control (dict): surrogate model information stored as a dictionary with the following entries: \"model_optimizer\": `differential_evolution`, \"model_fun_evals\": `None`, \"min_theta\": `-3.`, \"max_theta\": `3.`, \"n_theta\": `1`, \"n_p\": `1`, \"optim_p\": `False`, \"cod_type\": `\"norm\"`, \"var_type\": `self.var_type`, \"use_cod_y\": `False`. optimizer (object): optimizer. If `None`, `scipy.optimize`'s `differential_evolution` is used. optimizer_control (dict): information about the optimizer stored as a dictionary with the following entries: \"max_iter\": `1000`. Note: Description in the source code refers to [bart21i]: Bartz-Beielstein, T., and Zaefferer, M. Hyperparameter tuning approaches. In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, E. Bartz, T. Bartz-Beielstein, M. Zaefferer, and O. Mersmann, Eds. Springer, 2022, ch. 4, pp. 67\u2013114. \"\"\" def __str__ ( self ): return self . __class__ . __name__ def __init__ ( self , fun , lower , upper , fun_evals = 15 , fun_repeats = 1 , fun_control = {}, max_time = inf , noise = False , tolerance_x = 0 , var_type = [ \"num\" ], infill_criterion = \"y\" , n_points = 1 , ocba_delta = 0 , seed = 123 , log_level = 50 , show_models = False , show_progress = False , design = None , design_control = {}, surrogate = None , surrogate_control = {}, optimizer = None , optimizer_control = {}, ): # small value: self . eps = sqrt ( spacing ( 1 )) self . fun = fun self . lower = lower self . upper = upper self . var_type = var_type # Reduce dim based on lower == upper logic: # modifies lower, upper, and var_type self . to_red_dim () self . k = self . lower . size self . fun_evals = fun_evals self . fun_repeats = fun_repeats self . max_time = max_time self . noise = noise self . tolerance_x = tolerance_x self . ocba_delta = ocba_delta self . log_level = log_level self . show_models = show_models self . show_progress = show_progress # Random number generator: self . seed = seed self . rng = default_rng ( self . seed ) # Force numeric type as default in every dim: # assume all variable types are \"num\" if \"num\" is # specified once: if len ( self . var_type ) < self . k : self . var_type = self . var_type * self . k logger . warning ( \"Warning: All variable types forced to 'num'.\" ) self . infill_criterion = infill_criterion # Bounds de_bounds = [] for j in range ( self . k ): de_bounds . append ([ self . lower [ j ], self . upper [ j ]]) self . de_bounds = de_bounds # Infill points: self . n_points = n_points # Objective function related information: self . fun_control = { \"sigma\" : 0 , \"seed\" : None } self . fun_control . update ( fun_control ) # Design related information: self . design = design if design is None : self . design = spacefilling ( k = self . k , seed = self . seed ) self . design_control = { \"init_size\" : 10 , \"repeats\" : 1 } self . design_control . update ( design_control ) # Surrogate related information: self . surrogate = surrogate self . surrogate_control = { \"noise\" : self . noise , \"model_optimizer\" : differential_evolution , \"model_fun_evals\" : None , \"min_theta\" : - 3. , \"max_theta\" : 3. , \"n_theta\" : 1 , \"n_p\" : 1 , \"optim_p\" : False , \"cod_type\" : \"norm\" , \"var_type\" : self . var_type , \"seed\" : 124 , \"use_cod_y\" : False } self . surrogate_control . update ( surrogate_control ) # If no surrogate model is specified, use the internal # spotPython kriging surrogate: if self . surrogate is None : # Call kriging with surrogate_control parameters: self . surrogate = Kriging ( name = \"kriging\" , noise = self . surrogate_control [ \"noise\" ], model_optimizer = self . surrogate_control [ \"model_optimizer\" ], model_fun_evals = self . surrogate_control [ \"model_fun_evals\" ], seed = self . surrogate_control [ \"seed\" ], log_level = self . log_level , min_theta = self . surrogate_control [ \"min_theta\" ], max_theta = self . surrogate_control [ \"max_theta\" ], n_theta = self . surrogate_control [ \"n_theta\" ], n_p = self . surrogate_control [ \"n_p\" ], optim_p = self . surrogate_control [ \"optim_p\" ], cod_type = self . surrogate_control [ \"cod_type\" ], var_type = self . surrogate_control [ \"var_type\" ], use_cod_y = self . surrogate_control [ \"use_cod_y\" ] ) # Optimizer related information: self . optimizer = optimizer self . optimizer_control = { \"max_iter\" : 1000 , \"seed\" : 125 } self . optimizer_control . update ( optimizer_control ) if self . optimizer is None : self . optimizer = optimize . differential_evolution # Logging information: self . counter = 0 self . min_y = None self . min_X = None self . min_mean_X = None self . min_mean_y = None self . mean_X = None self . mean_y = None self . var_y = None logger . setLevel ( self . log_level ) logger . info ( f \"Starting the logger at level { self . log_level } for module { __name__ } :\" ) def to_red_dim ( self ): self . all_lower = self . lower self . all_upper = self . upper self . ident = ( self . upper - self . lower ) == 0 self . lower = self . lower [ ~ self . ident ] self . upper = self . upper [ ~ self . ident ] self . red_dim = self . ident . any () self . all_var_type = self . var_type self . var_type = [ x for x , y in zip ( self . all_var_type , self . ident ) if not y ] def to_all_dim ( self , X0 ): n = X0 . shape [ 0 ] k = len ( self . ident ) X = np . zeros (( n , k )) j = 0 for i in range ( k ): if self . ident [ i ]: X [:, i ] = self . all_lower [ i ] j = j + 1 else : X [:, i ] = X0 [:, i - j ] return X def run ( self ): \"\"\" Run spot. Returns: (object): spot \"\"\" # (S-2) Initial Design: X0 = self . generate_design ( size = self . design_control [ \"init_size\" ], repeats = self . design_control [ \"repeats\" ], lower = self . lower , upper = self . upper ) X0 = repair_non_numeric ( X0 , self . var_type ) self . X = X0 # (S-3): Eval initial design: if self . red_dim : X_all = self . to_all_dim ( X0 ) else : X_all = X0 self . y = self . fun ( X = X_all , fun_control = self . fun_control ) self . X , self . y = remove_nan ( self . X , self . y ) self . update_stats () # (S-4): Imputation: # Not implemented yet. self . surrogate . fit ( self . X , self . y ) # (S-5) Calling the spotLoop Function # and # (S-9) Termination Criteria, Conditions: timeout_start = time . time () while ( self . counter < self . fun_evals ) and ( time . time () < timeout_start + self . max_time * 60 ): # OCBA (only if noise) if self . noise and self . ocba_delta > 0 : # and self.fun_repeats > 0 and self.design_control[\"repeats\"] > 0: X_ocba = get_ocba_X ( self . mean_X , self . mean_y , self . var_y , self . ocba_delta ) else : X_ocba = None # (S-15) Compile Surrogate Results: X0 = self . suggest_new_X () X0 = repair_non_numeric ( X0 , self . var_type ) # (S-16) Duplicate Handling: # Condition: select only X= that have min distance # to existing solutions X0 , X0_ind = selectNew ( A = X0 , X = self . X , tolerance = self . tolerance_x ) logger . debug ( \"XO values are new: %s \" , X0_ind ) # 1. There are X0 that fullfil the condition. # Note: The number of new X0 can be smaller than self.n_points! if X0 . shape [ 0 ] > 0 : X0 = repeat ( X0 , self . fun_repeats , axis = 0 ) # 2. No X0 found. Then generate self.n_points new solutions: else : self . design = spacefilling ( k = self . k , seed = self . seed + self . counter ) X0 = self . generate_design ( size = self . n_points , repeats = self . design_control [ \"repeats\" ], lower = self . lower , upper = self . upper ) X0 = repair_non_numeric ( X0 , self . var_type ) logger . warning ( \"No new XO found on surrogate. Generate new solution %s \" , X0 ) # (S-18): Evaluating New Solutions: if self . noise and self . ocba_delta > 0 : X0 = append ( X_ocba , X0 , axis = 0 ) if self . red_dim : X_all = self . to_all_dim ( X0 ) else : X_all = X0 y0 = self . fun ( X = X_all , fun_control = self . fun_control ) X0 , y0 = remove_nan ( X0 , y0 ) # Append New Solutions: self . X = np . append ( self . X , X0 , axis = 0 ) self . y = np . append ( self . y , y0 ) # (S-10): Subset Selection for the Surrogate: # Not implemented yet. # Update stats self . update_stats () # (S-11) Surrogate Fit: self . surrogate . fit ( self . X , self . y ) if self . show_models : self . plot_model () # progress bar: if self . show_progress : if isfinite ( self . fun_evals ): progress_bar ( self . counter / self . fun_evals ) else : progress_bar (( time . time () - timeout_start ) / ( self . max_time * 60 )) return self def generate_design ( self , size , repeats , lower , upper ): return self . design . scipy_lhd ( n = size , repeats = repeats , lower = lower , upper = upper ) def update_stats ( self ): \"\"\" Update the following stats: 1. `min_y` 2. `min_X` 3. `counter` If `noise` is `True`, additionally the following stats are computed: 1. `mean_X` 2. `mean_y` 3. `min_mean_y` 4. `min_mean_X`. \"\"\" self . min_y = min ( self . y ) self . min_X = self . X [ argmin ( self . y )] self . counter = self . y . size # Update aggregated x and y values (if noise): if self . noise : Z = aggregate_mean_var ( X = self . X , y = self . y ) self . mean_X = Z [ 0 ] self . mean_y = Z [ 1 ] self . var_y = Z [ 2 ] self . min_mean_y = min ( self . mean_y ) self . min_mean_X = self . mean_X [ argmin ( self . mean_y )] def suggest_new_X ( self ): \"\"\" Compute `n_points` new infill points in natural units. The optimizer searches in the ranges from `lower_j` to `upper_j`. The method `infill()` is used as the objective function. Returns: (numpy.ndarray): `n_points` infill points in natural units, each of dim k Note: This is step (S-14a) in [bart21i]. \"\"\" # (S-14a) Optimization on the surrogate: new_X = np . zeros ([ self . n_points , self . k ], dtype = float ) for i in range ( self . n_points ): if self . optimizer . __name__ == 'dual_annealing' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) elif self . optimizer . __name__ == 'differential_evolution' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds , maxiter = self . optimizer_control [ \"max_iter\" ], seed = self . optimizer_control [ \"seed\" ], # popsize=10, # updating=\"deferred\" ) elif self . optimizer . __name__ == 'direct' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds , eps = 1e-2 ) elif self . optimizer . __name__ == 'shgo' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) elif self . optimizer . __name__ == 'basinhopping' : result = self . optimizer ( func = self . infill , x0 = self . min_X ) else : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) new_X [ i ][:] = result . x return new_X def infill ( self , x ): \"\"\" Infill (acquisition) function. Evaluates one point on the surrogate via `surrogate.predict(x.reshape(1,-1))`, if `sklearn` surrogates are used or `surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion)` if the internal surrogate `kriging` is selected. This method is passed to the optimizer in `suggest_new_X`, i.e., the optimizer is called via `self.optimizer(func=self.infill)`. Args: x (array): point in natural units with shape `(1, dim)`. Returns: (numpy.ndarray): value based on infill criterion, e.g., `\"ei\"`. Shape `(1,)`. The objective function value `y` that is used as a base value for the infill criterion is calculated in natural units. Note: This is step (S-12) in [bart21i]. \"\"\" # (S-12) Objective Function on the Surrogate (Predict) # res = self.surrogate.predict(x.reshape(1, -1)) # if isinstance(self.surrogate, Kriging): # if self.infill_criterion == \"ei\": # y = -1.0 * res[2] # ei # else: # y = res[0] # f # else: # y = res # sklearn etc. # return y if isinstance ( self . surrogate , Kriging ): return self . surrogate . predict ( x . reshape ( 1 , - 1 ), return_val = self . infill_criterion ) else : return self . surrogate . predict ( x . reshape ( 1 , - 1 )) def plot_progress ( self , show = True , log_y = False ): \"\"\" Generate progress plot, i.e., plot y versus x values. Usually called after the run is finished. Args: show (bool, optional): Show plot. Defaults to True. log_y (bool, optional): log y-axis. Defaults to False. \"\"\" fig = pylab . figure ( figsize = ( 9 , 6 )) # TODO: Consider y_min of the initial design, e.g., via: # best_y = list(itertools.repeat(min(y), self.init_size)) s_y = pd . Series ( self . y ) s_c = s_y . cummin () ax = fig . add_subplot ( 211 ) ax . plot ( range ( len ( s_c )), s_c ) if log_y : ax . set_yscale ( \"log\" ) if show : pylab . show () def plot_model ( self , y_min = None , y_max = None ): \"\"\" Plot the model fit for 1-dim objective functions. Args: y_min (float, optional): y range, lower bound. y_max (float, optional): y range, upper bound. \"\"\" if self . k == 1 : X_test = np . linspace ( self . lower [ 0 ], self . upper [ 0 ], 100 ) y_test = self . fun ( X = X_test . reshape ( - 1 , 1 ), fun_control = self . fun_control ) if isinstance ( self . surrogate , Kriging ): y_hat = self . surrogate . predict ( X_test [:, np . newaxis ], return_val = \"y\" ) else : y_hat = self . surrogate . predict ( X_test [:, np . newaxis ]) plt . plot ( X_test , y_hat , label = \"Model\" ) plt . plot ( X_test , y_test , label = \"True function\" ) plt . scatter ( self . X , self . y , edgecolor = \"b\" , s = 20 , label = \"Samples\" ) plt . scatter ( self . X [ - 1 ], self . y [ - 1 ], edgecolor = \"r\" , s = 30 , label = \"Last Sample\" ) if self . noise : plt . scatter ( self . min_mean_X , self . min_mean_y , edgecolor = \"g\" , s = 30 , label = \"Best Sample (mean)\" ) else : plt . scatter ( self . min_X , self . min_y , edgecolor = \"g\" , s = 30 , label = \"Best Sample\" ) plt . xlabel ( \"x\" ) plt . ylabel ( \"y\" ) plt . xlim (( self . lower [ 0 ], self . upper [ 0 ])) if y_min is None : y_min = min ( min ( self . y ), min ( y_test )) if y_max is None : y_max = max ( max ( self . y ), max ( y_test )) plt . ylim (( y_min , y_max )) plt . legend ( loc = \"best\" ) # plt.title(self.surrogate.__class__.__name__ + \". \" + str(self.counter) + \": \" + str(self.min_y)) if self . noise : plt . title ( str ( self . counter ) + \". y (noise): \" + str ( np . round ( self . min_y , 6 )) + \" y mean: \" + str ( np . round ( self . min_mean_y , 6 ))) else : plt . title ( str ( self . counter ) + \". y: \" + str ( np . round ( self . min_y , 6 ))) plt . show () def print_results ( self ): \"\"\" Print results from the run: 1. min y 2. min X If `noise == True`, additinally the following values are printed: 3. min mean y 4. min mean X \"\"\" print ( f \"min y: { self . min_y } \" ) print ( f \"min X: { self . to_all_dim ( self . min_X . reshape ( 1 , - 1 )) } \" ) if self . noise : print ( f \"min mean y: { self . min_mean_y } \" ) print ( f \"min mean X: { self . to_all_dim ( self . min_mean_X . reshape ( 1 , - 1 )) } \" ) def chg ( self , x , y , z0 , i , j ): z0 [ i ] = x z0 [ j ] = y return z0 def plot_contour ( self , i = 0 , j = 1 , min_z = None , max_z = None , show = True ): \"\"\" This function plots surrogates of any dimension. Args: show (boolean): If `True`, the plots are displayed. If `False`, `plt.show()` should be called outside this function. \"\"\" fig = pylab . figure ( figsize = ( 9 , 6 )) n_grid = 100 # lower and upper x = np . linspace ( self . lower [ i ], self . upper [ i ], num = n_grid ) y = np . linspace ( self . lower [ j ], self . upper [ j ], num = n_grid ) X , Y = meshgrid ( x , y ) # Predict based on the optimized results z0 = np . mean ( np . array ([ self . lower , self . upper ]), axis = 0 ) zz = array ( [ self . surrogate . predict ( array ([ self . chg ( x , y , z0 , i , j )])) for x , y in zip ( ravel ( X ), ravel ( Y ))] ) zs = zz [:, 0 ] Z = zs . reshape ( X . shape ) if min_z is None : min_z = np . min ( Z ) if max_z is None : max_z = np . max ( Z ) contour_levels = 30 ax = fig . add_subplot ( 221 ) # plot predicted values: plt . contourf ( X , Y , Z , contour_levels , zorder = 1 , cmap = \"jet\" , vmin = min_z , vmax = max_z ) plt . xlabel ( \"x\" + str ( i )) plt . ylabel ( \"x\" + str ( j )) plt . title ( \"Surrogate\" ) pylab . colorbar () # ax = fig . add_subplot ( 222 , projection = \"3d\" ) ax . plot_surface ( X , Y , Z , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" , vmin = min_z , vmax = max_z ) ax . set_xlabel ( \"x\" + str ( i )) ax . set_ylabel ( \"x\" + str ( j )) # # pylab . show () def print_importance ( self ): theta = np . power ( 10 , self . surrogate . theta ) print ( \"Importance relative to the most important parameter:\" ) imp = 100 * theta / np . max ( theta ) for i in range ( len ( imp )): print ( \"Parameter\" , i , \": \" , imp [ i ])","title":"Spot"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.infill","text":"Infill (acquisition) function. Evaluates one point on the surrogate via surrogate.predict(x.reshape(1,-1)) , if sklearn surrogates are used or surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion) if the internal surrogate kriging is selected. This method is passed to the optimizer in suggest_new_X , i.e., the optimizer is called via self.optimizer(func=self.infill) . Parameters: Name Type Description Default x array point in natural units with shape (1, dim) . required Returns: Type Description numpy . ndarray value based on infill criterion, e.g., \"ei\" . Shape (1,) . The objective function value y that is used as a base value for the infill criterion is calculated in natural units. Note This is step (S-12) in [bart21i]. Source code in spotPython/spot/spot.py 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 def infill ( self , x ): \"\"\" Infill (acquisition) function. Evaluates one point on the surrogate via `surrogate.predict(x.reshape(1,-1))`, if `sklearn` surrogates are used or `surrogate.predict(x.reshape(1,-1), return_val=self.infill_criterion)` if the internal surrogate `kriging` is selected. This method is passed to the optimizer in `suggest_new_X`, i.e., the optimizer is called via `self.optimizer(func=self.infill)`. Args: x (array): point in natural units with shape `(1, dim)`. Returns: (numpy.ndarray): value based on infill criterion, e.g., `\"ei\"`. Shape `(1,)`. The objective function value `y` that is used as a base value for the infill criterion is calculated in natural units. Note: This is step (S-12) in [bart21i]. \"\"\" # (S-12) Objective Function on the Surrogate (Predict) # res = self.surrogate.predict(x.reshape(1, -1)) # if isinstance(self.surrogate, Kriging): # if self.infill_criterion == \"ei\": # y = -1.0 * res[2] # ei # else: # y = res[0] # f # else: # y = res # sklearn etc. # return y if isinstance ( self . surrogate , Kriging ): return self . surrogate . predict ( x . reshape ( 1 , - 1 ), return_val = self . infill_criterion ) else : return self . surrogate . predict ( x . reshape ( 1 , - 1 ))","title":"infill()"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.plot_contour","text":"This function plots surrogates of any dimension. Parameters: Name Type Description Default show boolean If True , the plots are displayed. If False , plt.show() should be called outside this function. True Source code in spotPython/spot/spot.py 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 def plot_contour ( self , i = 0 , j = 1 , min_z = None , max_z = None , show = True ): \"\"\" This function plots surrogates of any dimension. Args: show (boolean): If `True`, the plots are displayed. If `False`, `plt.show()` should be called outside this function. \"\"\" fig = pylab . figure ( figsize = ( 9 , 6 )) n_grid = 100 # lower and upper x = np . linspace ( self . lower [ i ], self . upper [ i ], num = n_grid ) y = np . linspace ( self . lower [ j ], self . upper [ j ], num = n_grid ) X , Y = meshgrid ( x , y ) # Predict based on the optimized results z0 = np . mean ( np . array ([ self . lower , self . upper ]), axis = 0 ) zz = array ( [ self . surrogate . predict ( array ([ self . chg ( x , y , z0 , i , j )])) for x , y in zip ( ravel ( X ), ravel ( Y ))] ) zs = zz [:, 0 ] Z = zs . reshape ( X . shape ) if min_z is None : min_z = np . min ( Z ) if max_z is None : max_z = np . max ( Z ) contour_levels = 30 ax = fig . add_subplot ( 221 ) # plot predicted values: plt . contourf ( X , Y , Z , contour_levels , zorder = 1 , cmap = \"jet\" , vmin = min_z , vmax = max_z ) plt . xlabel ( \"x\" + str ( i )) plt . ylabel ( \"x\" + str ( j )) plt . title ( \"Surrogate\" ) pylab . colorbar () # ax = fig . add_subplot ( 222 , projection = \"3d\" ) ax . plot_surface ( X , Y , Z , rstride = 3 , cstride = 3 , alpha = 0.9 , cmap = \"jet\" , vmin = min_z , vmax = max_z ) ax . set_xlabel ( \"x\" + str ( i )) ax . set_ylabel ( \"x\" + str ( j )) # # pylab . show ()","title":"plot_contour()"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.plot_model","text":"Plot the model fit for 1-dim objective functions. Parameters: Name Type Description Default y_min float y range, lower bound. None y_max float y range, upper bound. None Source code in spotPython/spot/spot.py 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 def plot_model ( self , y_min = None , y_max = None ): \"\"\" Plot the model fit for 1-dim objective functions. Args: y_min (float, optional): y range, lower bound. y_max (float, optional): y range, upper bound. \"\"\" if self . k == 1 : X_test = np . linspace ( self . lower [ 0 ], self . upper [ 0 ], 100 ) y_test = self . fun ( X = X_test . reshape ( - 1 , 1 ), fun_control = self . fun_control ) if isinstance ( self . surrogate , Kriging ): y_hat = self . surrogate . predict ( X_test [:, np . newaxis ], return_val = \"y\" ) else : y_hat = self . surrogate . predict ( X_test [:, np . newaxis ]) plt . plot ( X_test , y_hat , label = \"Model\" ) plt . plot ( X_test , y_test , label = \"True function\" ) plt . scatter ( self . X , self . y , edgecolor = \"b\" , s = 20 , label = \"Samples\" ) plt . scatter ( self . X [ - 1 ], self . y [ - 1 ], edgecolor = \"r\" , s = 30 , label = \"Last Sample\" ) if self . noise : plt . scatter ( self . min_mean_X , self . min_mean_y , edgecolor = \"g\" , s = 30 , label = \"Best Sample (mean)\" ) else : plt . scatter ( self . min_X , self . min_y , edgecolor = \"g\" , s = 30 , label = \"Best Sample\" ) plt . xlabel ( \"x\" ) plt . ylabel ( \"y\" ) plt . xlim (( self . lower [ 0 ], self . upper [ 0 ])) if y_min is None : y_min = min ( min ( self . y ), min ( y_test )) if y_max is None : y_max = max ( max ( self . y ), max ( y_test )) plt . ylim (( y_min , y_max )) plt . legend ( loc = \"best\" ) # plt.title(self.surrogate.__class__.__name__ + \". \" + str(self.counter) + \": \" + str(self.min_y)) if self . noise : plt . title ( str ( self . counter ) + \". y (noise): \" + str ( np . round ( self . min_y , 6 )) + \" y mean: \" + str ( np . round ( self . min_mean_y , 6 ))) else : plt . title ( str ( self . counter ) + \". y: \" + str ( np . round ( self . min_y , 6 ))) plt . show ()","title":"plot_model()"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.plot_progress","text":"Generate progress plot, i.e., plot y versus x values. Usually called after the run is finished. Parameters: Name Type Description Default show bool Show plot. Defaults to True. True log_y bool log y-axis. Defaults to False. False Source code in spotPython/spot/spot.py 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 def plot_progress ( self , show = True , log_y = False ): \"\"\" Generate progress plot, i.e., plot y versus x values. Usually called after the run is finished. Args: show (bool, optional): Show plot. Defaults to True. log_y (bool, optional): log y-axis. Defaults to False. \"\"\" fig = pylab . figure ( figsize = ( 9 , 6 )) # TODO: Consider y_min of the initial design, e.g., via: # best_y = list(itertools.repeat(min(y), self.init_size)) s_y = pd . Series ( self . y ) s_c = s_y . cummin () ax = fig . add_subplot ( 211 ) ax . plot ( range ( len ( s_c )), s_c ) if log_y : ax . set_yscale ( \"log\" ) if show : pylab . show ()","title":"plot_progress()"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.print_results","text":"Print results from the run min y min X If noise == True , additinally the following values are printed: min mean y min mean X Source code in spotPython/spot/spot.py 518 519 520 521 522 523 524 525 526 527 528 529 530 531 def print_results ( self ): \"\"\" Print results from the run: 1. min y 2. min X If `noise == True`, additinally the following values are printed: 3. min mean y 4. min mean X \"\"\" print ( f \"min y: { self . min_y } \" ) print ( f \"min X: { self . to_all_dim ( self . min_X . reshape ( 1 , - 1 )) } \" ) if self . noise : print ( f \"min mean y: { self . min_mean_y } \" ) print ( f \"min mean X: { self . to_all_dim ( self . min_mean_X . reshape ( 1 , - 1 )) } \" )","title":"print_results()"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.run","text":"Run spot. Returns: Type Description object spot Source code in spotPython/spot/spot.py 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 def run ( self ): \"\"\" Run spot. Returns: (object): spot \"\"\" # (S-2) Initial Design: X0 = self . generate_design ( size = self . design_control [ \"init_size\" ], repeats = self . design_control [ \"repeats\" ], lower = self . lower , upper = self . upper ) X0 = repair_non_numeric ( X0 , self . var_type ) self . X = X0 # (S-3): Eval initial design: if self . red_dim : X_all = self . to_all_dim ( X0 ) else : X_all = X0 self . y = self . fun ( X = X_all , fun_control = self . fun_control ) self . X , self . y = remove_nan ( self . X , self . y ) self . update_stats () # (S-4): Imputation: # Not implemented yet. self . surrogate . fit ( self . X , self . y ) # (S-5) Calling the spotLoop Function # and # (S-9) Termination Criteria, Conditions: timeout_start = time . time () while ( self . counter < self . fun_evals ) and ( time . time () < timeout_start + self . max_time * 60 ): # OCBA (only if noise) if self . noise and self . ocba_delta > 0 : # and self.fun_repeats > 0 and self.design_control[\"repeats\"] > 0: X_ocba = get_ocba_X ( self . mean_X , self . mean_y , self . var_y , self . ocba_delta ) else : X_ocba = None # (S-15) Compile Surrogate Results: X0 = self . suggest_new_X () X0 = repair_non_numeric ( X0 , self . var_type ) # (S-16) Duplicate Handling: # Condition: select only X= that have min distance # to existing solutions X0 , X0_ind = selectNew ( A = X0 , X = self . X , tolerance = self . tolerance_x ) logger . debug ( \"XO values are new: %s \" , X0_ind ) # 1. There are X0 that fullfil the condition. # Note: The number of new X0 can be smaller than self.n_points! if X0 . shape [ 0 ] > 0 : X0 = repeat ( X0 , self . fun_repeats , axis = 0 ) # 2. No X0 found. Then generate self.n_points new solutions: else : self . design = spacefilling ( k = self . k , seed = self . seed + self . counter ) X0 = self . generate_design ( size = self . n_points , repeats = self . design_control [ \"repeats\" ], lower = self . lower , upper = self . upper ) X0 = repair_non_numeric ( X0 , self . var_type ) logger . warning ( \"No new XO found on surrogate. Generate new solution %s \" , X0 ) # (S-18): Evaluating New Solutions: if self . noise and self . ocba_delta > 0 : X0 = append ( X_ocba , X0 , axis = 0 ) if self . red_dim : X_all = self . to_all_dim ( X0 ) else : X_all = X0 y0 = self . fun ( X = X_all , fun_control = self . fun_control ) X0 , y0 = remove_nan ( X0 , y0 ) # Append New Solutions: self . X = np . append ( self . X , X0 , axis = 0 ) self . y = np . append ( self . y , y0 ) # (S-10): Subset Selection for the Surrogate: # Not implemented yet. # Update stats self . update_stats () # (S-11) Surrogate Fit: self . surrogate . fit ( self . X , self . y ) if self . show_models : self . plot_model () # progress bar: if self . show_progress : if isfinite ( self . fun_evals ): progress_bar ( self . counter / self . fun_evals ) else : progress_bar (( time . time () - timeout_start ) / ( self . max_time * 60 )) return self","title":"run()"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.suggest_new_X","text":"Compute n_points new infill points in natural units. The optimizer searches in the ranges from lower_j to upper_j . The method infill() is used as the objective function. Returns: Type Description numpy . ndarray n_points infill points in natural units, each of dim k Note This is step (S-14a) in [bart21i]. Source code in spotPython/spot/spot.py 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 def suggest_new_X ( self ): \"\"\" Compute `n_points` new infill points in natural units. The optimizer searches in the ranges from `lower_j` to `upper_j`. The method `infill()` is used as the objective function. Returns: (numpy.ndarray): `n_points` infill points in natural units, each of dim k Note: This is step (S-14a) in [bart21i]. \"\"\" # (S-14a) Optimization on the surrogate: new_X = np . zeros ([ self . n_points , self . k ], dtype = float ) for i in range ( self . n_points ): if self . optimizer . __name__ == 'dual_annealing' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) elif self . optimizer . __name__ == 'differential_evolution' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds , maxiter = self . optimizer_control [ \"max_iter\" ], seed = self . optimizer_control [ \"seed\" ], # popsize=10, # updating=\"deferred\" ) elif self . optimizer . __name__ == 'direct' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds , eps = 1e-2 ) elif self . optimizer . __name__ == 'shgo' : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) elif self . optimizer . __name__ == 'basinhopping' : result = self . optimizer ( func = self . infill , x0 = self . min_X ) else : result = self . optimizer ( func = self . infill , bounds = self . de_bounds ) new_X [ i ][:] = result . x return new_X","title":"suggest_new_X()"},{"location":"reference/spotPython/spot/spot/#spotPython.spot.spot.Spot.update_stats","text":"Update the following stats: 1. min_y 2. min_X 3. counter If noise is True , additionally the following stats are computed: 1. mean_X 2. mean_y 3. min_mean_y 4. min_mean_X . Source code in spotPython/spot/spot.py 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 def update_stats ( self ): \"\"\" Update the following stats: 1. `min_y` 2. `min_X` 3. `counter` If `noise` is `True`, additionally the following stats are computed: 1. `mean_X` 2. `mean_y` 3. `min_mean_y` 4. `min_mean_X`. \"\"\" self . min_y = min ( self . y ) self . min_X = self . X [ argmin ( self . y )] self . counter = self . y . size # Update aggregated x and y values (if noise): if self . noise : Z = aggregate_mean_var ( X = self . X , y = self . y ) self . mean_X = Z [ 0 ] self . mean_y = Z [ 1 ] self . var_y = Z [ 2 ] self . min_mean_y = min ( self . mean_y ) self . min_mean_X = self . mean_X [ argmin ( self . mean_y )]","title":"update_stats()"},{"location":"reference/spotPython/utils/aggregate/","text":"aggregate_mean_var ( X , y , sort = False ) Aggregate array to mean. Parameters: Name Type Description Default X numpy . ndarray X array, shape (n, k) . required y numpy . ndarray values, shape (n,) . required Returns: Type Description numpy . ndarray aggregated X values, shape (n-m, k) , if m duplicates in X . numpy . ndarray aggregated (mean per group) y values, shape (1,) , if m duplicates in X . numpy . ndarray aggregated (variance per group) y values, shape (1,) , if m duplicates in X . Source code in spotPython/utils/aggregate.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def aggregate_mean_var ( X , y , sort = False ): \"\"\" Aggregate array to mean. Args: X (numpy.ndarray): X array, shape `(n, k)`. y (numpy.ndarray): values, shape `(n,)`. Returns: (numpy.ndarray): aggregated `X` values, shape `(n-m, k)`, if `m`duplicates in `X`. (numpy.ndarray): aggregated (mean per group) `y` values, shape `(1,)`, if `m`duplicates in `X`. (numpy.ndarray): aggregated (variance per group) `y` values, shape `(1,)`, if `m`duplicates in `X`. \"\"\" df = pd . DataFrame ( X , dtype = pd . Float64Dtype ) # df.columns=[\"X\"+str(i) for i in range(df.shape[1])] df = df . assign ( y = y ) df_m = df . groupby ( list ( df . columns . difference ([ \"y\" ])), as_index = False , sort = sort ) . mean () df_var = df . groupby ( list ( df . columns . difference ([ \"y\" ])), as_index = False , sort = sort ) . var () A = df_m . to_numpy ( dtype = np . float64 ) B = df_var . to_numpy () return np . delete ( A , - 1 , 1 ), A [:, - 1 ], B [:, - 1 ] get_ranks ( x ) Returns a numpy array containing ranks of numbers within an input numpy array x: Examples: get_ranks([2, 1]) [1, 0] get_ranks([20, 10, 100]) [1, 0, 2] Parameters: Name Type Description Default x numpy . ndarray numpy array required Returns: Type Description numpy . ndarray ranks Source code in spotPython/utils/aggregate.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def get_ranks ( x ): \"\"\" Returns a numpy array containing ranks of numbers within an input numpy array x: Examples: get_ranks([2, 1]) [1, 0] get_ranks([20, 10, 100]) [1, 0, 2] Args: x (numpy.ndarray): numpy array Returns: (numpy.ndarray): ranks \"\"\" ts = x . argsort () ranks = np . empty_like ( ts ) ranks [ ts ] = np . arange ( len ( x )) return ranks","title":"aggregate"},{"location":"reference/spotPython/utils/aggregate/#spotPython.utils.aggregate.aggregate_mean_var","text":"Aggregate array to mean. Parameters: Name Type Description Default X numpy . ndarray X array, shape (n, k) . required y numpy . ndarray values, shape (n,) . required Returns: Type Description numpy . ndarray aggregated X values, shape (n-m, k) , if m duplicates in X . numpy . ndarray aggregated (mean per group) y values, shape (1,) , if m duplicates in X . numpy . ndarray aggregated (variance per group) y values, shape (1,) , if m duplicates in X . Source code in spotPython/utils/aggregate.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def aggregate_mean_var ( X , y , sort = False ): \"\"\" Aggregate array to mean. Args: X (numpy.ndarray): X array, shape `(n, k)`. y (numpy.ndarray): values, shape `(n,)`. Returns: (numpy.ndarray): aggregated `X` values, shape `(n-m, k)`, if `m`duplicates in `X`. (numpy.ndarray): aggregated (mean per group) `y` values, shape `(1,)`, if `m`duplicates in `X`. (numpy.ndarray): aggregated (variance per group) `y` values, shape `(1,)`, if `m`duplicates in `X`. \"\"\" df = pd . DataFrame ( X , dtype = pd . Float64Dtype ) # df.columns=[\"X\"+str(i) for i in range(df.shape[1])] df = df . assign ( y = y ) df_m = df . groupby ( list ( df . columns . difference ([ \"y\" ])), as_index = False , sort = sort ) . mean () df_var = df . groupby ( list ( df . columns . difference ([ \"y\" ])), as_index = False , sort = sort ) . var () A = df_m . to_numpy ( dtype = np . float64 ) B = df_var . to_numpy () return np . delete ( A , - 1 , 1 ), A [:, - 1 ], B [:, - 1 ]","title":"aggregate_mean_var()"},{"location":"reference/spotPython/utils/aggregate/#spotPython.utils.aggregate.get_ranks","text":"Returns a numpy array containing ranks of numbers within an input numpy array x: Examples: get_ranks([2, 1]) [1, 0] get_ranks([20, 10, 100]) [1, 0, 2] Parameters: Name Type Description Default x numpy . ndarray numpy array required Returns: Type Description numpy . ndarray ranks Source code in spotPython/utils/aggregate.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def get_ranks ( x ): \"\"\" Returns a numpy array containing ranks of numbers within an input numpy array x: Examples: get_ranks([2, 1]) [1, 0] get_ranks([20, 10, 100]) [1, 0, 2] Args: x (numpy.ndarray): numpy array Returns: (numpy.ndarray): ranks \"\"\" ts = x . argsort () ranks = np . empty_like ( ts ) ranks [ ts ] = np . arange ( len ( x )) return ranks","title":"get_ranks()"},{"location":"reference/spotPython/utils/compare/","text":"selectNew ( A , X , tolerance = 0 ) Select rows from A that are not in X. Parameters: Name Type Description Default A numpy . ndarray A array with new values required X numpy . ndarray X array with known values required Returns: Type Description numpy . ndarray array with unknown (new) values numpy . ndarray array with True if value is new, otherwise False . Source code in spotPython/utils/compare.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def selectNew ( A , X , tolerance = 0 ): \"\"\" Select rows from A that are not in X. Args: A (numpy.ndarray): A array with new values X (numpy.ndarray): X array with known values Returns: (numpy.ndarray): array with unknown (new) values (numpy.ndarray): array with `True` if value is new, otherwise `False`. \"\"\" ind = np . zeros ( A . shape [ 0 ], dtype = bool ) for i in range ( X . shape [ 0 ]): B = np . abs ( A - X [ i , :]) ind = ind + np . all ( B <= tolerance , axis = 1 ) return A [ ~ ind ], ~ ind","title":"compare"},{"location":"reference/spotPython/utils/compare/#spotPython.utils.compare.selectNew","text":"Select rows from A that are not in X. Parameters: Name Type Description Default A numpy . ndarray A array with new values required X numpy . ndarray X array with known values required Returns: Type Description numpy . ndarray array with unknown (new) values numpy . ndarray array with True if value is new, otherwise False . Source code in spotPython/utils/compare.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def selectNew ( A , X , tolerance = 0 ): \"\"\" Select rows from A that are not in X. Args: A (numpy.ndarray): A array with new values X (numpy.ndarray): X array with known values Returns: (numpy.ndarray): array with unknown (new) values (numpy.ndarray): array with `True` if value is new, otherwise `False`. \"\"\" ind = np . zeros ( A . shape [ 0 ], dtype = bool ) for i in range ( X . shape [ 0 ]): B = np . abs ( A - X [ i , :]) ind = ind + np . all ( B <= tolerance , axis = 1 ) return A [ ~ ind ], ~ ind","title":"selectNew()"},{"location":"reference/spotPython/utils/progress/","text":"progress_bar ( progress , bar_length = 10 ) Displays or updates a console progress bar. See: https://stackoverflow.com/a/15860757 Parameters: Name Type Description Default (float) progress a float between 0 and 1. Any int will be converted to a float. required Source code in spotPython/utils/progress.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def progress_bar ( progress , bar_length = 10 ): \"\"\" Displays or updates a console progress bar. See: https://stackoverflow.com/a/15860757 Args: (float) progress: a float between 0 and 1. Any int will be converted to a float. A value under 0 represents a halt. A value at 1 or bigger represents 100%. \"\"\" status = \"\" if isinstance ( progress , int ): progress = float ( progress ) if not isinstance ( progress , float ): progress = 0 status = \"error: progress var must be float \\r\\n \" if progress < 0 : progress = 0 status = \"Halt... \\r\\n \" if progress >= 1 : progress = 1 status = \"Done... \\r\\n \" block = int ( round ( bar_length * progress )) text = \"spotPython tuning: [ {0} ] {1:.2f} % {2} \\r \" . format ( \"#\" * block + \"-\" * ( bar_length - block ), progress * 100 , status ) stdout . write ( text ) stdout . flush ()","title":"progress"},{"location":"reference/spotPython/utils/progress/#spotPython.utils.progress.progress_bar","text":"Displays or updates a console progress bar. See: https://stackoverflow.com/a/15860757 Parameters: Name Type Description Default (float) progress a float between 0 and 1. Any int will be converted to a float. required Source code in spotPython/utils/progress.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def progress_bar ( progress , bar_length = 10 ): \"\"\" Displays or updates a console progress bar. See: https://stackoverflow.com/a/15860757 Args: (float) progress: a float between 0 and 1. Any int will be converted to a float. A value under 0 represents a halt. A value at 1 or bigger represents 100%. \"\"\" status = \"\" if isinstance ( progress , int ): progress = float ( progress ) if not isinstance ( progress , float ): progress = 0 status = \"error: progress var must be float \\r\\n \" if progress < 0 : progress = 0 status = \"Halt... \\r\\n \" if progress >= 1 : progress = 1 status = \"Done... \\r\\n \" block = int ( round ( bar_length * progress )) text = \"spotPython tuning: [ {0} ] {1:.2f} % {2} \\r \" . format ( \"#\" * block + \"-\" * ( bar_length - block ), progress * 100 , status ) stdout . write ( text ) stdout . flush ()","title":"progress_bar()"},{"location":"reference/spotPython/utils/repair/","text":"repair_non_numeric ( X , var_type ) Round non-numeric values to integers. Parameters: Name Type Description Default X numpy . ndarray X array required var_type list list with type information required Source code in spotPython/utils/repair.py 5 6 7 8 9 10 11 12 13 14 15 16 def repair_non_numeric ( X , var_type ): \"\"\" Round non-numeric values to integers. Args: X (numpy.ndarray): X array var_type (list): list with type information \"\"\" for i in range ( X . shape [ 1 ]): if var_type [ i ] != \"num\" : X [:, i ] = around ( X [:, i ]) return X","title":"repair"},{"location":"reference/spotPython/utils/repair/#spotPython.utils.repair.repair_non_numeric","text":"Round non-numeric values to integers. Parameters: Name Type Description Default X numpy . ndarray X array required var_type list list with type information required Source code in spotPython/utils/repair.py 5 6 7 8 9 10 11 12 13 14 15 16 def repair_non_numeric ( X , var_type ): \"\"\" Round non-numeric values to integers. Args: X (numpy.ndarray): X array var_type (list): list with type information \"\"\" for i in range ( X . shape [ 1 ]): if var_type [ i ] != \"num\" : X [:, i ] = around ( X [:, i ]) return X","title":"repair_non_numeric()"},{"location":"reference/spotPython/utils/transform/","text":"scale ( X , lower , upper ) Sample scaling from unit hypercube to different bounds. Converts a sample from [0, 1) to [a, b) . Note: equal lower and upper bounds are feasible. The following transformation is used: (b - a) * X + a X (array): Sample to scale. lower (array): lower bound of transformed data. upper (array): upper bounds of transformed data. (array): Scaled sample. Examples: Transform three samples in the unit hypercube to (lower, upper) bounds: import numpy as np from scipy.stats import qmc from spotPython.utils.transform import scale lower = np.array([6, 0]) upper = np.array([6, 5]) sample = np.array([[0.5 , 0.75], [0.5 , 0.5], [0.75, 0.25]]) scale(sample, lower, upper) Source code in spotPython/utils/transform.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def scale ( X , lower , upper ): \"\"\" Sample scaling from unit hypercube to different bounds. Converts a sample from `[0, 1)` to `[a, b)`. Note: equal lower and upper bounds are feasible. The following transformation is used: `(b - a) * X + a` Args: X (array): Sample to scale. lower (array): lower bound of transformed data. upper (array): upper bounds of transformed data. Returns: (array): Scaled sample. Examples: Transform three samples in the unit hypercube to (lower, upper) bounds: >>> import numpy as np >>> from scipy.stats import qmc >>> from spotPython.utils.transform import scale >>> lower = np.array([6, 0]) >>> upper = np.array([6, 5]) >>> sample = np.array([[0.5 , 0.75], >>> [0.5 , 0.5], >>> [0.75, 0.25]]) >>> scale(sample, lower, upper) \"\"\" # Checking that X is within (0,1) interval if ( X . max () > 1.0 ) or ( X . min () < 0.0 ): raise ValueError ( \"Sample is not in unit hypercube\" ) for i in range ( X . shape [ 1 ]): if lower [ i ] == upper [ i ]: X [:, i ] = lower [ i ] else : X [:, i ] = X [:, i ] * ( upper [ i ] - lower [ i ]) + lower [ i ] return X","title":"transform"},{"location":"reference/spotPython/utils/transform/#spotPython.utils.transform.scale","text":"Sample scaling from unit hypercube to different bounds. Converts a sample from [0, 1) to [a, b) . Note: equal lower and upper bounds are feasible. The following transformation is used: (b - a) * X + a X (array): Sample to scale. lower (array): lower bound of transformed data. upper (array): upper bounds of transformed data. (array): Scaled sample. Examples: Transform three samples in the unit hypercube to (lower, upper) bounds: import numpy as np from scipy.stats import qmc from spotPython.utils.transform import scale lower = np.array([6, 0]) upper = np.array([6, 5]) sample = np.array([[0.5 , 0.75], [0.5 , 0.5], [0.75, 0.25]]) scale(sample, lower, upper) Source code in spotPython/utils/transform.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def scale ( X , lower , upper ): \"\"\" Sample scaling from unit hypercube to different bounds. Converts a sample from `[0, 1)` to `[a, b)`. Note: equal lower and upper bounds are feasible. The following transformation is used: `(b - a) * X + a` Args: X (array): Sample to scale. lower (array): lower bound of transformed data. upper (array): upper bounds of transformed data. Returns: (array): Scaled sample. Examples: Transform three samples in the unit hypercube to (lower, upper) bounds: >>> import numpy as np >>> from scipy.stats import qmc >>> from spotPython.utils.transform import scale >>> lower = np.array([6, 0]) >>> upper = np.array([6, 5]) >>> sample = np.array([[0.5 , 0.75], >>> [0.5 , 0.5], >>> [0.75, 0.25]]) >>> scale(sample, lower, upper) \"\"\" # Checking that X is within (0,1) interval if ( X . max () > 1.0 ) or ( X . min () < 0.0 ): raise ValueError ( \"Sample is not in unit hypercube\" ) for i in range ( X . shape [ 1 ]): if lower [ i ] == upper [ i ]: X [:, i ] = lower [ i ] else : X [:, i ] = X [:, i ] * ( upper [ i ] - lower [ i ]) + lower [ i ] return X","title":"scale()"}]}