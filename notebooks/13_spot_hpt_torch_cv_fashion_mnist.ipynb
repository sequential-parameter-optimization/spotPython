{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"pytorch Hyperparameter Tuning with SPOT: fashionMNIST\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME = 1\n",
    "INIT_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13-torch_bartz09_1min_5init_2023-05-01_20-47-14'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "start_time = datetime.now(tzlocal())\n",
    "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
    "experiment_name = '13-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
    "experiment_name = experiment_name.replace(':', '-')\n",
    "experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: Sequential Parameter Optimization\n",
    "## Hyperparameter Tuning: pytorch cross validation  with fashionMNIST Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook exemplifies hyperparameter tuning with SPOT (spotPython).\n",
    "* The hyperparameter software SPOT was developed in R (statistical programming language), see Open Access book \"Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide\", available here: [https://link.springer.com/book/10.1007/978-981-19-5170-1](https://link.springer.com/book/10.1007/978-981-19-5170-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython                                0.0.46\n",
      "spotRiver                                 0.0.92\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep  \"spot[RiverPython]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "import warnings\n",
    "import numbers\n",
    "import json\n",
    "import calendar\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.hyperparameters.values import (\n",
    "    add_core_model_to_fun_control,\n",
    "    assign_values,\n",
    "    convert_keys,\n",
    "    get_bound_values,\n",
    "    get_default_hyperparameters_for_core_model,\n",
    "    get_default_hyperparameters_for_fun,\n",
    "    get_default_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    get_values_from_dict,\n",
    "    get_var_name,\n",
    "    get_var_type,\n",
    "    iterate_dict_values,\n",
    "    modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds,\n",
    "    replace_levels_with_positions,\n",
    "    return_conf_list_from_var_dict,\n",
    "    get_one_core_model_from_X)\n",
    "from spotPython.hyperparameters.prepare import (\n",
    "    transform_hyper_parameter_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    convert_keys,\n",
    "    iterate_dict_values,\n",
    ")\n",
    "\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.utils.eda import (\n",
    "    get_stars,\n",
    "    gen_design_table)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "\n",
    "from spotPython.data.torch_hyper_dict import TorchHyperDict\n",
    "from spotPython.fun.hypertorch import HyperTorch\n",
    "from spotPython.utils.convert import get_Xy_from_df\n",
    "from spotPython.plot.validation import plot_cv_predictions, plot_roc, plot_confusion_matrix\n",
    "from spotPython.torch.netcvfashionMNIST import Net_CV_fashionMNIST\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import partial\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "MPS device:  mps\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS device: \", mps_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization of the Empty `fun_control` Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load fashionMNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape, test.data.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train)\n",
    "# add the dataset to the fun_control\n",
    "fun_control.update({\"data\": None, # dataset,\n",
    "               \"train\": train,\n",
    "               \"test\": test,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"target_column\": None})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specification of the Preprocessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns = []\n",
    "# one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "# prep_model = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "#         ],\n",
    "#         remainder=StandardScaler(),\n",
    "#     )\n",
    "prep_model = None\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select `algorithm` and `core_model_hyper_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_model  = RidgeCV\n",
    "core_model = Net_CV_fashionMNIST\n",
    "fun_control = add_core_model_to_fun_control(core_model=core_model,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=TorchHyperDict,\n",
    "                              filename=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_model\", [\"LinearRegression\"])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type numeric and integer (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"delta\", bounds=[1e-10, 1e-6])\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[3, 20])\n",
    "#fun_control = modify_hyper_parameter_bounds(fun_control, \"merit_preprune\", bounds=[0, 0])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selection of the Objective (Loss) Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two metrics:\n",
    "\n",
    "    1. `metric` is used for the river based evaluation via `eval_oml_iter_progressive`.\n",
    "    2. `metric_sklearn` is used for the sklearn based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = HyperTorch(seed=123, log_level=50).fun_torch\n",
    "weights = 1.0\n",
    "horizon = 7*24\n",
    "oml_grace_period = 2\n",
    "step = 100\n",
    "weight_coeff = 1.0\n",
    "\n",
    "fun_control.update({\n",
    "               \"data_dir\": None,\n",
    "               \"checkpoint_dir\": None,\n",
    "               \"horizon\": horizon,\n",
    "               \"oml_grace_period\": oml_grace_period,\n",
    "               \"weights\": weights,\n",
    "               \"step\": step,\n",
    "               \"log_level\": 50,\n",
    "               \"weight_coeff\": weight_coeff,\n",
    "               \"metric\": None,\n",
    "               \"metric_sklearn\": None\n",
    "               })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calling the SPOT Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SPOT Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get types and variable names as well as lower and upper bounds for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "fun_control.update({\"var_type\": var_type,\n",
    "                    \"var_name\": var_name})\n",
    "\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |\n",
      "|------------|--------|-----------|---------|---------|\n",
      "| l1         | int    |     5     |  2      |     9   |\n",
      "| l2         | int    |     5     |  2      |     9   |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 |\n",
      "| batch_size | int    |     4     |  1      |     4   |\n",
      "| epochs     | int    |     3     |  1      |     4   |\n",
      "| k_folds    | int    |     2     |  2      |     3   |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `Spot` Optimizer\n",
    "\n",
    "* Run SPOT for approx. x mins (`max_time`).\n",
    "* Note: the run takes longer, because the evaluation time of initial design (here: `initi_size`, 20 points) is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Fold 0\n",
      "[1,  2000] loss: 2.163\n",
      "[1,  4000] loss: 1.162\n",
      "[1,  6000] loss: 0.775\n",
      "[2,  2000] loss: 2.323\n",
      "[2,  4000] loss: 1.161\n",
      "[2,  6000] loss: 0.774\n",
      "[3,  2000] loss: 2.320\n",
      "[3,  4000] loss: 1.162\n",
      "[3,  6000] loss: 0.775\n",
      "[4,  2000] loss: 2.324\n",
      "[4,  4000] loss: 1.161\n",
      "[4,  6000] loss: 0.775\n",
      "[5,  2000] loss: 2.322\n",
      "[5,  4000] loss: 1.160\n",
      "[5,  6000] loss: 0.774\n",
      "[6,  2000] loss: 2.323\n",
      "[6,  4000] loss: 1.162\n",
      "[6,  6000] loss: 0.775\n",
      "[7,  2000] loss: 2.324\n",
      "[7,  4000] loss: 1.161\n",
      "[7,  6000] loss: 0.774\n",
      "[8,  2000] loss: 2.324\n",
      "[8,  4000] loss: 1.161\n",
      "[8,  6000] loss: 0.774\n",
      "[9,  2000] loss: 2.320\n",
      "[9,  4000] loss: 1.161\n",
      "[9,  6000] loss: 0.774\n",
      "[10,  2000] loss: 2.321\n",
      "[10,  4000] loss: 1.162\n",
      "[10,  6000] loss: 0.774\n",
      "[11,  2000] loss: 2.322\n",
      "[11,  4000] loss: 1.161\n",
      "[11,  6000] loss: 0.774\n",
      "[12,  2000] loss: 2.322\n",
      "[12,  4000] loss: 1.160\n",
      "[12,  6000] loss: 0.775\n",
      "[13,  2000] loss: 2.317\n",
      "[13,  4000] loss: 1.160\n",
      "[13,  6000] loss: 0.774\n",
      "[14,  2000] loss: 2.322\n",
      "[14,  4000] loss: 1.161\n",
      "[14,  6000] loss: 0.774\n",
      "[15,  2000] loss: 2.322\n",
      "[15,  4000] loss: 1.163\n",
      "[15,  6000] loss: 0.775\n",
      "[16,  2000] loss: 2.322\n",
      "[16,  4000] loss: 1.161\n",
      "[16,  6000] loss: 0.773\n",
      "Accuracy for fold 0: 10 %\n",
      "--------------------------------\n",
      "Fold 1\n",
      "[1,  2000] loss: 2.323\n",
      "[1,  4000] loss: 1.162\n",
      "[1,  6000] loss: 0.775\n",
      "[2,  2000] loss: 2.323\n",
      "[2,  4000] loss: 1.161\n",
      "[2,  6000] loss: 0.774\n",
      "[3,  2000] loss: 2.322\n",
      "[3,  4000] loss: 1.162\n",
      "[3,  6000] loss: 0.775\n",
      "[4,  2000] loss: 2.323\n",
      "[4,  4000] loss: 1.160\n",
      "[4,  6000] loss: 0.774\n",
      "[5,  2000] loss: 2.323\n",
      "[5,  4000] loss: 1.162\n",
      "[5,  6000] loss: 0.774\n",
      "[6,  2000] loss: 2.322\n",
      "[6,  4000] loss: 1.161\n",
      "[6,  6000] loss: 0.774\n",
      "[7,  2000] loss: 2.323\n",
      "[7,  4000] loss: 1.161\n",
      "[7,  6000] loss: 0.774\n",
      "[8,  2000] loss: 2.322\n",
      "[8,  4000] loss: 1.161\n",
      "[8,  6000] loss: 0.773\n",
      "[9,  2000] loss: 2.323\n",
      "[9,  4000] loss: 1.162\n",
      "[9,  6000] loss: 0.774\n",
      "[10,  2000] loss: 2.324\n",
      "[10,  4000] loss: 1.161\n",
      "[10,  6000] loss: 0.774\n",
      "[11,  2000] loss: 2.321\n",
      "[11,  4000] loss: 1.162\n",
      "[11,  6000] loss: 0.775\n",
      "[12,  2000] loss: 2.324\n",
      "[12,  4000] loss: 1.161\n",
      "[12,  6000] loss: 0.774\n",
      "[13,  2000] loss: 2.323\n",
      "[13,  4000] loss: 1.162\n",
      "[13,  6000] loss: 0.774\n",
      "[14,  2000] loss: 2.323\n",
      "[14,  4000] loss: 1.162\n",
      "[14,  6000] loss: 0.774\n",
      "[15,  2000] loss: 2.324\n",
      "[15,  4000] loss: 1.160\n",
      "[15,  6000] loss: 0.774\n",
      "[16,  2000] loss: 2.323\n",
      "[16,  4000] loss: 1.161\n",
      "[16,  6000] loss: 0.775\n",
      "Accuracy for fold 1: 10 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 2 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 10.07 %\n",
      "Fold 1: 10.040000000000001 %\n",
      "Average: 10.055 %\n",
      "Accuracy of the network on the validation data: 0.1004\n",
      "Using mps device\n",
      "Fold 0\n",
      "[1,  2000] loss: 2.269\n",
      "[1,  4000] loss: 1.169\n",
      "[1,  6000] loss: 0.780\n",
      "[2,  2000] loss: 2.340\n",
      "[2,  4000] loss: 1.169\n",
      "[2,  6000] loss: 0.779\n",
      "[3,  2000] loss: 2.339\n",
      "[3,  4000] loss: 1.168\n",
      "[3,  6000] loss: 0.779\n",
      "[4,  2000] loss: 2.336\n",
      "[4,  4000] loss: 1.172\n",
      "[4,  6000] loss: 0.780\n",
      "[5,  2000] loss: 2.335\n",
      "[5,  4000] loss: 1.170\n",
      "[5,  6000] loss: 0.779\n",
      "[6,  2000] loss: 2.337\n",
      "[6,  4000] loss: 1.170\n",
      "[6,  6000] loss: 0.780\n",
      "[7,  2000] loss: 2.339\n",
      "[7,  4000] loss: 1.170\n",
      "[7,  6000] loss: 0.779\n",
      "[8,  2000] loss: 2.337\n",
      "[8,  4000] loss: 1.171\n",
      "[8,  6000] loss: 0.780\n",
      "Accuracy for fold 0: 9 %\n",
      "--------------------------------\n",
      "Fold 1\n",
      "[1,  2000] loss: 2.335\n",
      "[1,  4000] loss: 1.170\n",
      "[1,  6000] loss: 0.779\n",
      "[2,  2000] loss: 2.339\n",
      "[2,  4000] loss: 1.170\n",
      "[2,  6000] loss: 0.780\n",
      "[3,  2000] loss: 2.337\n",
      "[3,  4000] loss: 1.170\n",
      "[3,  6000] loss: 0.779\n",
      "[4,  2000] loss: 2.342\n",
      "[4,  4000] loss: 1.170\n",
      "[4,  6000] loss: 0.779\n",
      "[5,  2000] loss: 2.341\n",
      "[5,  4000] loss: 1.172\n",
      "[5,  6000] loss: 0.779\n",
      "[6,  2000] loss: 2.340\n",
      "[6,  4000] loss: 1.169\n",
      "[6,  6000] loss: 0.779\n",
      "[7,  2000] loss: 2.338\n",
      "[7,  4000] loss: 1.170\n",
      "[7,  6000] loss: 0.781\n",
      "[8,  2000] loss: 2.338\n",
      "[8,  4000] loss: 1.170\n",
      "[8,  6000] loss: 0.781\n",
      "Accuracy for fold 1: 10 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 2 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 9.969999999999999 %\n",
      "Fold 1: 10.100000000000001 %\n",
      "Average: 10.035 %\n",
      "Accuracy of the network on the validation data: 0.101\n",
      "Using mps device\n",
      "Fold 0\n",
      "[1,  2000] loss: 1.592\n",
      "[2,  2000] loss: 1.788\n",
      "Accuracy for fold 0: 19 %\n",
      "--------------------------------\n",
      "Fold 1\n",
      "[1,  2000] loss: 1.755\n",
      "[2,  2000] loss: 1.774\n",
      "Accuracy for fold 1: 19 %\n",
      "--------------------------------\n",
      "Fold 2\n",
      "[1,  2000] loss: 1.821\n",
      "[2,  2000] loss: 2.216\n",
      "Accuracy for fold 2: 10 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 3 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 19.939999999999998 %\n",
      "Fold 1: 19.7 %\n",
      "Fold 2: 10.005 %\n",
      "Average: 16.548333333333336 %\n",
      "Accuracy of the network on the validation data: 0.10005\n",
      "Using mps device\n",
      "Fold 0\n",
      "[1,  2000] loss: 2.324\n",
      "[1,  4000] loss: 1.169\n",
      "[1,  6000] loss: 0.778\n",
      "[1,  8000] loss: 0.584\n",
      "[1, 10000] loss: 0.467\n",
      "[2,  2000] loss: 2.335\n",
      "[2,  4000] loss: 1.166\n",
      "[2,  6000] loss: 0.778\n",
      "[2,  8000] loss: 0.584\n",
      "[2, 10000] loss: 0.467\n",
      "[3,  2000] loss: 2.332\n",
      "[3,  4000] loss: 1.168\n",
      "[3,  6000] loss: 0.778\n",
      "[3,  8000] loss: 0.584\n",
      "[3, 10000] loss: 0.467\n",
      "[4,  2000] loss: 2.334\n",
      "[4,  4000] loss: 1.167\n",
      "[4,  6000] loss: 0.778\n",
      "[4,  8000] loss: 0.583\n",
      "[4, 10000] loss: 0.467\n",
      "Accuracy for fold 0: 9 %\n",
      "--------------------------------\n",
      "Fold 1\n",
      "[1,  2000] loss: 2.332\n",
      "[1,  4000] loss: 1.169\n",
      "[1,  6000] loss: 0.779\n",
      "[1,  8000] loss: 0.583\n",
      "[1, 10000] loss: 0.466\n",
      "[2,  2000] loss: 2.333\n",
      "[2,  4000] loss: 1.165\n",
      "[2,  6000] loss: 0.778\n",
      "[2,  8000] loss: 0.583\n",
      "[2, 10000] loss: 0.466\n",
      "[3,  2000] loss: 2.336\n",
      "[3,  4000] loss: 1.168\n",
      "[3,  6000] loss: 0.778\n",
      "[3,  8000] loss: 0.583\n",
      "[3, 10000] loss: 0.467\n",
      "[4,  2000] loss: 2.334\n",
      "[4,  4000] loss: 1.166\n",
      "[4,  6000] loss: 0.776\n",
      "[4,  8000] loss: 0.583\n",
      "[4, 10000] loss: 0.467\n",
      "Accuracy for fold 1: 10 %\n",
      "--------------------------------\n",
      "Fold 2\n",
      "[1,  2000] loss: 2.335\n",
      "[1,  4000] loss: 1.167\n",
      "[1,  6000] loss: 0.779\n",
      "[1,  8000] loss: 0.584\n",
      "[1, 10000] loss: 0.466\n",
      "[2,  2000] loss: 2.330\n",
      "[2,  4000] loss: 1.168\n",
      "[2,  6000] loss: 0.778\n",
      "[2,  8000] loss: 0.583\n",
      "[2, 10000] loss: 0.467\n",
      "[3,  2000] loss: 2.336\n",
      "[3,  4000] loss: 1.166\n",
      "[3,  6000] loss: 0.778\n",
      "[3,  8000] loss: 0.584\n",
      "[3, 10000] loss: 0.466\n",
      "[4,  2000] loss: 2.330\n",
      "[4,  4000] loss: 1.167\n",
      "[4,  6000] loss: 0.778\n",
      "[4,  8000] loss: 0.584\n",
      "[4, 10000] loss: 0.467\n",
      "Accuracy for fold 2: 10 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 3 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 9.82 %\n",
      "Fold 1: 10.100000000000001 %\n",
      "Fold 2: 10.015 %\n",
      "Average: 9.978333333333333 %\n",
      "Accuracy of the network on the validation data: 0.10015\n",
      "Using mps device\n",
      "Fold 0\n",
      "[1,  2000] loss: 0.699\n",
      "[2,  2000] loss: 0.458\n",
      "[3,  2000] loss: 0.412\n",
      "[4,  2000] loss: 0.386\n",
      "Accuracy for fold 0: 85 %\n",
      "--------------------------------\n",
      "Fold 1\n",
      "[1,  2000] loss: 0.419\n",
      "[2,  2000] loss: 0.380\n",
      "[3,  2000] loss: 0.358\n",
      "[4,  2000] loss: 0.343\n",
      "Accuracy for fold 1: 86 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 2 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 85.83666666666666 %\n",
      "Fold 1: 86.90333333333334 %\n",
      "Average: 86.37 %\n",
      "Accuracy of the network on the validation data: 0.8690333333333333\n",
      "Using mps device\n",
      "Fold 0\n",
      "[1,  2000] loss: 2.334\n",
      "[1,  4000] loss: 1.167\n",
      "[1,  6000] loss: 0.778\n",
      "[1,  8000] loss: 0.583\n",
      "[1, 10000] loss: 0.467\n",
      "[2,  2000] loss: 2.333\n",
      "[2,  4000] loss: 1.167\n",
      "[2,  6000] loss: 0.778\n",
      "[2,  8000] loss: 0.583\n",
      "[2, 10000] loss: 0.467\n",
      "Accuracy for fold 0: 10 %\n",
      "--------------------------------\n",
      "Fold 1\n",
      "[1,  2000] loss: 2.334\n",
      "[1,  4000] loss: 1.166\n",
      "[1,  6000] loss: 0.778\n",
      "[1,  8000] loss: 0.584\n",
      "[1, 10000] loss: 0.467\n",
      "[2,  2000] loss: 2.337\n",
      "[2,  4000] loss: 1.168\n",
      "[2,  6000] loss: 0.778\n",
      "[2,  8000] loss: 0.584\n",
      "[2, 10000] loss: 0.467\n",
      "Accuracy for fold 1: 9 %\n",
      "--------------------------------\n",
      "Fold 2\n",
      "[1,  2000] loss: 2.333\n",
      "[1,  4000] loss: 1.168\n",
      "[1,  6000] loss: 0.778\n",
      "[1,  8000] loss: 0.584\n",
      "[1, 10000] loss: 0.467\n",
      "[2,  2000] loss: 2.336\n",
      "[2,  4000] loss: 1.168\n",
      "[2,  6000] loss: 0.778\n",
      "[2,  8000] loss: 0.583\n",
      "[2, 10000] loss: 0.467\n",
      "Accuracy for fold 2: 9 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 3 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 10.165000000000001 %\n",
      "Fold 1: 9.955 %\n",
      "Fold 2: 9.93 %\n",
      "Average: 10.016666666666667 %\n",
      "Accuracy of the network on the validation data: 0.0993\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x2c0fe7040>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot_torch = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = MAX_TIME,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_torch.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "LOAD = False\n",
    "\n",
    "if SAVE:\n",
    "    result_file_name = \"res_\" + experiment_name + \".pkl\"\n",
    "    with open(result_file_name, 'wb') as f:\n",
    "        pickle.dump(spot_torch, f)\n",
    "\n",
    "if LOAD:\n",
    "    result_file_name = \"res_ch10-friedman-hpt-0_maans03_60min_20init_1K_2023-04-14_10-11-19.pkl\"\n",
    "    with open(result_file_name, 'rb') as f:\n",
    "        spot_torch =  pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress of the hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_torch.plot_progress(log_y=False, filename=\"../Figures.d/\" + experiment_name+\"_progress.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Parameter   |     Value |\n",
      "|-------------|-----------|\n",
      "| l1          |         4 |\n",
      "| l2          |         4 |\n",
      "| lr          | 0.0554135 |\n",
      "| batch_size  |         2 |\n",
      "| epochs      |         2 |\n",
      "| k_folds     |         3 |\n"
     ]
    }
   ],
   "source": [
    "res = spot_torch.print_results(print_screen=False)\n",
    "print(tabulate(\n",
    "   res,\n",
    "   headers=[\"Parameter\", \"Value\"],\n",
    "   numalign=\"right\",\n",
    "   tablefmt=\"github\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_torch.plot_importance(threshold=0.025, filename=\"../Figures.d/\" + experiment_name+\"_importance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |             tuned |   importance | stars   |\n",
      "|------------|--------|-----------|---------|---------|-------------------|--------------|---------|\n",
      "| l1         | int    |       5.0 |     2.0 |     9.0 |               4.0 |         0.00 |         |\n",
      "| l2         | int    |       5.0 |     2.0 |     9.0 |               4.0 |         0.00 |         |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 | 0.055413518616155 |         0.00 |         |\n",
      "| batch_size | int    |       4.0 |     1.0 |     4.0 |               2.0 |       100.00 | ***     |\n",
      "| epochs     | int    |       3.0 |     1.0 |     4.0 |               2.0 |         0.00 |         |\n",
      "| k_folds    | int    |       2.0 |     2.0 |     3.0 |               3.0 |         0.00 |         |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_torch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_default = get_default_hyperparameters_for_core_model(fun_control=fun_control,\n",
    "                                                   hyper_dict=TorchHyperDict)\n",
    "values_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_CV_fashionMNIST(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default = fun_control[\"core_model\"](**values_default)\n",
    "model_default\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SPOT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.         4.         0.05541352 2.         2.         3.        ]]\n"
     ]
    }
   ],
   "source": [
    "X = spot_torch.to_all_dim(spot_torch.min_X.reshape(1,-1))\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_CV_fashionMNIST(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spot = get_one_core_model_from_X(X, fun_control)\n",
    "model_spot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0905"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(x, fun_control):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "    x.to(device)\n",
    "\n",
    "    # trainset, testset = load_data()\n",
    "    testset = fun_control[\"test\"]\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=x.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = x(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0977"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spot.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.978333333333333, 86.37)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(spot_torch.y), max(spot_torch.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hyperparameter Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For productive use, you might want to select:\n",
    "  * `min_z=min(spot_torch.y)` and\n",
    "  * `max_z = max(spot_torch.y)`\n",
    "* These settings are not so colorful as visualizations that use `None` for the ranges, but give better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:  100.0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.025\n",
    "impo = spot_torch.print_importance(threshold=threshold, print_screen=True)\n",
    "var_plots = [i for i, x in enumerate(impo) if x[1] > threshold]\n",
    "min_z = min(spot_torch.y)\n",
    "max_z = max(spot_torch.y)\n",
    "n = spot_torch.k\n",
    "for i in var_plots:\n",
    "    for j in var_plots:\n",
    "        if j > i:\n",
    "            filename = \"../Figures.d/\" + experiment_name+\"_contour_\"+str(i)+\"_\"+str(j)+\".pdf\"\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z, filename=filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_torch.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
