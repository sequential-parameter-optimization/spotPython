{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HPT: PyTorch With VBDP {#sec-vbdp}\n",
        "\n",
        "In this tutorial, we will show how `spotPython` can be integrated into the `PyTorch`\n",
        "training workflow for a classifiaction task.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Data must be downloaded manually\n",
        "\n",
        "* Ensure that the correspondiing data is available as `./data/VBDP/train.csv`.\n",
        "\n",
        ":::\n",
        "\n",
        "This document refers to the following software versions:\n",
        "\n",
        "- ``python``: 3.10.10\n",
        "- ``torch``: 2.0.1\n",
        "- ``torchvision``: 0.15.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spotPython                                0.2.41\n",
            "spotRiver                                 0.0.94\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip list | grep  \"spot[RiverPython]\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`spotPython` can be installed via pip. Alternatively, the source code can be downloaded from gitHub: [https://github.com/sequential-parameter-optimization/spotPython](https://github.com/sequential-parameter-optimization/spotPython).\n",
        "\n",
        "```{raw}\n",
        "!pip install spotPython\n",
        "```\n",
        "\n",
        "* Uncomment the following lines if you want to for (re-)installation the latest version of `spotPython` from gitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install --upgrade build\n",
        "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup {#sec-setup-25}\n",
        "\n",
        "Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Run time and initial design size should be increased for real experiments\n",
        "\n",
        "* MAX_TIME is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\n",
        "* INIT_SIZE is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-note}\n",
        "### Note: Device selection\n",
        "\n",
        "* The device can be selected by setting the variable `DEVICE`.\n",
        "* Since we are using a simple neural net, the setting `\"cpu\"` is preferred (on Mac).\n",
        "* If you have a GPU, you can use `\"cuda:0\"` instead.\n",
        "* If DEVICE is set to `None`, `spotPython` will automatically select the device.\n",
        "  * This might result in `\"mps\"` on Macs, which is not the best choice for simple neural nets.\n",
        "\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_TIME = 1\n",
        "INIT_SIZE = 5\n",
        "DEVICE = None # \"cpu\" # \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "from spotPython.utils.device import getDevice\n",
        "DEVICE = getDevice(DEVICE)\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30-light_bartz08-2_1min_5init_2023-06-25_17-58-41\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "import socket\n",
        "from datetime import datetime\n",
        "from dateutil.tz import tzlocal\n",
        "start_time = datetime.now(tzlocal())\n",
        "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
        "experiment_name = '30-light' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
        "experiment_name = experiment_name.replace(':', '-')\n",
        "print(experiment_name)\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialization of the `fun_control` Dictionary\n",
        "\n",
        ":::{.callout-caution}\n",
        "### Caution: Tensorboard does not work under Windows\n",
        "* Since tensorboard does not work under Windows, we recommend setting the parameter `tensorboard_path` to `None` if you are working under Windows.\n",
        ":::\n",
        "\n",
        "`spotPython` uses a Python dictionary for storing the information required for the hyperparameter tuning process, which was described in @sec-initialization-fun-control-14, see [Initialization of the fun_control Dictionary](https://sequential-parameter-optimization.github.io/spotPython/14_spot_ray_hpt_torch_cifar10.html#sec-initialization-fun-control-14) in the documentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(task=\"classification\",\n",
        "    tensorboard_path=\"./runs/\" + experiment_name,\n",
        "    num_workers=10,\n",
        "    device=DEVICE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: PyTorch Data Loading {#sec-data-loading-25}\n",
        "\n",
        "### 1. Load VBDP Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64])\n",
            "tensor([1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from spotPython.light.csvdataset import CSVDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Create an instance of CSVDataset\n",
        "dataset = CSVDataset(csv_file=\"./data/VBDP/train.csv\", train=True)\n",
        "# show the dimensions of the dataset\n",
        "print(dataset[0][0].shape)\n",
        "# show the first element of the dataset\n",
        "print(dataset[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Size: 707\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of CSVDataset\n",
        "dataset = CSVDataset(csv_file=\"./data/VBDP/train.csv\", train=False)\n",
        "# show the size of the dataset\n",
        "print(f\"Dataset Size: {len(dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size: 3\n",
            "---------------\n",
            "Inputs: tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
            "         1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
            "         1., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
            "         0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "Targets: tensor([6, 2, 4])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 3\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import OrdinalEncoder\n",
        "# train_df = pd.read_csv('./data/VBDP/train.csv')\n",
        "# # remove the id column\n",
        "# train_df = train_df.drop(columns=['id'])\n",
        "# n_samples = train_df.shape[0]\n",
        "# n_features = train_df.shape[1] - 1\n",
        "# target_column = \"prognosis\"\n",
        "# # # Encoder our prognosis labels as integers for easier decoding later\n",
        "# enc = OrdinalEncoder()\n",
        "# train_df[target_column] = enc.fit_transform(train_df[[target_column]])\n",
        "# train_df.head()\n",
        "\n",
        "# # convert all entries to int for faster processing\n",
        "# train_df = train_df.astype(int)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Add logical combinations (AND, OR, XOR) of the features to the data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.utils.convert import add_logical_columns\n",
        "# df_new = train_df.copy()\n",
        "# # save the target column using \"target_column\" as the column name\n",
        "# target = train_df[target_column]\n",
        "# # remove the target column\n",
        "# df_new = df_new.drop(columns=[target_column])\n",
        "# train_df = add_logical_columns(df_new)\n",
        "# # add the target column back\n",
        "# train_df[target_column] = target\n",
        "# train_df = train_df.astype(int)\n",
        "# train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import numpy as np\n",
        "\n",
        "# n_samples = train_df.shape[0]\n",
        "# n_features = train_df.shape[1] - 1\n",
        "# train_df.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "# train_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check content of the target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(train_df.drop(target_column, axis=1), train_df[target_column],\n",
        "#                                                     random_state=42,\n",
        "#                                                     test_size=0.25,\n",
        "#                                                     stratify=train_df[target_column])\n",
        "# trainset = pd.DataFrame(np.hstack((X_train, np.array(y_train).reshape(-1, 1))))\n",
        "# testset = pd.DataFrame(np.hstack((X_test, np.array(y_test).reshape(-1, 1))))\n",
        "# trainset.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "# testset.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "# print(train_df.shape)\n",
        "# print(trainset.shape)\n",
        "# print(testset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from spotPython.torch.dataframedataset import DataFrameDataset\n",
        "# dtype_x = torch.float32\n",
        "# dtype_y = torch.long\n",
        "# train_df = DataFrameDataset(train_df, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "# train = DataFrameDataset(trainset, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "# test = DataFrameDataset(testset, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "# n_samples = len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # add the dataset to the fun_control\n",
        "# fun_control.update({\"data\": train_df, # full dataset,\n",
        "#                \"train\": trainset,\n",
        "#                \"test\": testset,\n",
        "#                \"n_samples\": n_samples,\n",
        "#                \"target_column\": target_column})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Specification of the Preprocessing Model {#sec-specification-of-preprocessing-model-25}\n",
        "\n",
        "After the training and test data are specified and added to the `fun_control` dictionary, `spotPython` allows the specification of a data preprocessing pipeline, e.g., for the scaling of the data or for the one-hot encoding of categorical variables, see @sec-specification-of-preprocessing-model-14. This feature is not used here, so we do not change the default value (which is `None`).\n",
        "\n",
        "## Step 5: Select `algorithm` and `core_model_hyper_dict` {#sec-selection-of-the-algorithm-25}\n",
        "\n",
        "### Implementing a Configurable Neural Network With spotPython \n",
        "\n",
        "`spotPython` includes the `Net_vbdp` class which is implemented in the file `netvbdp.py`.\n",
        "The class is imported here.\n",
        "\n",
        "This class  inherits from the class `Net_Core` which is implemented in the file `netcore.py`, see @sec-the-netcore-class-14.\n",
        "\n",
        "### Add the NN Model to the fun_control Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.csvmodel import CSVModel \n",
        "from spotPython.data.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "fun_control = add_core_model_to_fun_control(core_model=CSVModel,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict= LightHyperDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spotPython.light.csvmodel.CSVModel"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fun_control[\"core_model\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The corresponding entries for the `core_model` class are shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'l1': {'type': 'int',\n",
              "  'default': 3,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 3,\n",
              "  'upper': 8},\n",
              " 'epochs': {'type': 'int',\n",
              "  'default': 4,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 4,\n",
              "  'upper': 9},\n",
              " 'batch_size': {'type': 'int',\n",
              "  'default': 4,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 1,\n",
              "  'upper': 4},\n",
              " 'act_fn': {'levels': ['ReLU'],\n",
              "  'type': 'factor',\n",
              "  'default': 'ReLU',\n",
              "  'transform': 'None',\n",
              "  'class_name': 'torch.nn',\n",
              "  'core_model_parameter_type': 'instance()',\n",
              "  'lower': 0,\n",
              "  'upper': 0},\n",
              " 'optimizer': {'levels': ['Adadelta',\n",
              "   'Adagrad',\n",
              "   'Adam',\n",
              "   'AdamW',\n",
              "   'SparseAdam',\n",
              "   'Adamax',\n",
              "   'ASGD',\n",
              "   'NAdam',\n",
              "   'RAdam',\n",
              "   'RMSprop',\n",
              "   'Rprop',\n",
              "   'SGD'],\n",
              "  'type': 'factor',\n",
              "  'default': 'SGD',\n",
              "  'transform': 'None',\n",
              "  'class_name': 'torch.optim',\n",
              "  'core_model_parameter_type': 'str',\n",
              "  'lower': 0,\n",
              "  'upper': 12},\n",
              " 'dropout_prob': {'type': 'float',\n",
              "  'default': 0.01,\n",
              "  'transform': 'None',\n",
              "  'lower': 0.0,\n",
              "  'upper': 0.1}}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fun_control['core_model_hyper_dict']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model` {#sec-modification-of-hyperparameters-25}\n",
        "\n",
        " `spotPython` provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions were described in @sec-modification-of-hyperparameters-14.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Small number of epochs for demonstration purposes\n",
        "\n",
        "* `epochs` and `patience` are set to small values for demonstration purposes. These values are too small for a real application.\n",
        "* More resonable values are, e.g.:\n",
        "  * `fun_control = modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[7, 9])` and\n",
        "  * `fun_control = modify_hyper_parameter_bounds(fun_control, \"patience\", bounds=[2, 7])`\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"l1\", bounds=[3, 10])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[4, 6])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"batch_size\", bounds=[2, 8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import modify_hyper_parameter_levels\n",
        "fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
        "# fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\", [\"Adam\"])\n",
        "# fun_control[\"core_model_hyper_dict\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Selection of the Objective (Loss) Function\n",
        "\n",
        "### Evaluation  {#sec-selection-of-target-function-25}\n",
        "\n",
        "The evaluation procedure requires the specification of two elements:\n",
        "\n",
        "1. the way how the data is split into a train and a test set (see @sec-data-splitting-14)\n",
        "2. the loss function (and a metric).\n",
        "\n",
        "\n",
        "### Loss Functions and Metrics {#sec-loss-functions-and-metrics-25}\n",
        "\n",
        "The loss function is specified by the key `\"loss_function\"`.\n",
        "We will use CrossEntropy loss for the multiclass-classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.nn import CrossEntropyLoss\n",
        "# loss_function = CrossEntropyLoss()\n",
        "# fun_control.update({\"loss_function\": loss_function})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metric {#sec-metric-25}\n",
        "\n",
        "* We will use the MAP@k metric for the evaluation of the model. Here is an example how this metric is calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6250)\n"
          ]
        }
      ],
      "source": [
        "from spotPython.torch.mapk import MAPK\n",
        "import torch\n",
        "mapk = MAPK(k=2)\n",
        "target = torch.tensor([0, 1, 2, 2])\n",
        "preds = torch.tensor(\n",
        "    [\n",
        "        [0.5, 0.2, 0.2],  # 0 is in top 2\n",
        "        [0.3, 0.4, 0.2],  # 1 is in top 2\n",
        "        [0.2, 0.4, 0.3],  # 2 is in top 2\n",
        "        [0.7, 0.2, 0.1],  # 2 isn't in top 2\n",
        "    ]\n",
        ")\n",
        "mapk.update(preds, target)\n",
        "print(mapk.compute()) # tensor(0.6250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.torch.mapk import MAPK\n",
        "# import torchmetrics\n",
        "# metric_torch = MAPK(k=3)\n",
        "# fun_control.update({\"metric_torch\": metric_torch})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Calling the SPOT Function\n",
        "\n",
        "### Preparing the SPOT Call {#sec-prepare-spot-call-25}\n",
        "\n",
        "The following code passes the information about the parameter ranges and bounds to `spot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract the variable types, names, and bounds\n",
        "from spotPython.hyperparameters.values import (get_bound_values,\n",
        "    get_var_name,\n",
        "    get_var_type,)\n",
        "var_type = get_var_type(fun_control)\n",
        "var_name = get_var_name(fun_control)\n",
        "fun_control.update({\"var_type\": var_type,\n",
        "                    \"var_name\": var_name})\n",
        "lower = get_bound_values(fun_control, \"lower\")\n",
        "upper = get_bound_values(fun_control, \"upper\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the dictionary `fun_control` contains all information needed for the hyperparameter tuning. Before the hyperparameter tuning is started, it is recommended to take a look at the experimental design. The method `gen_design_table` generates a design table as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "fig-label": "tbl-design-25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| name         | type   | default   |   lower |   upper | transform             |\n",
            "|--------------|--------|-----------|---------|---------|-----------------------|\n",
            "| l1           | int    | 3         |       3 |    10   | transform_power_2_int |\n",
            "| epochs       | int    | 4         |       4 |     6   | transform_power_2_int |\n",
            "| batch_size   | int    | 4         |       2 |     8   | transform_power_2_int |\n",
            "| act_fn       | factor | ReLU      |       0 |     0   | None                  |\n",
            "| optimizer    | factor | SGD       |       0 |     3   | None                  |\n",
            "| dropout_prob | float  | 0.01      |       0 |     0.1 | None                  |\n"
          ]
        }
      ],
      "source": [
        "#| fig-cap: Experimental design for the hyperparameter tuning.\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows to check if all information is available and if the information is correct.\n",
        "\n",
        "### The Objective Function `fun_torch` {#sec-the-objective-function-25}\n",
        "\n",
        "The objective function `fun_torch` is selected next. It implements an interface from `PyTorch`'s training, validation, and  testing methods to `spotPython`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.hyperlight import HyperLight\n",
        "fun = HyperLight().fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3.0e+00, 4.0e+00, 4.0e+00, 0.0e+00, 1.1e+01, 1.0e-02]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from spotPython.hyperparameters.values import get_default_hyperparameters_as_array\n",
        "hyper_dict=LightHyperDict().load()\n",
        "X_start = get_default_hyperparameters_as_array(fun_control, hyper_dict)\n",
        "X_start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'./runs/30-light_bartz08-2_1min_5init_2023-06-25_17-58-41'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fun_control[\"tensorboard_path\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Starting the Hyperparameter Tuning {#sec-call-the-hyperparameter-tuner-25}\n",
        "\n",
        "The `spotPython` hyperparameter tuning is started by calling the `Spot` function as described in @sec-call-the-hyperparameter-tuner-14.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "config: {'l1': 256, 'epochs': 16, 'batch_size': 256, 'act_fn': ReLU(), 'optimizer': 'Adamax', 'dropout_prob': 0.036481881978299394}\n",
            "model: CSVModel(\n",
            "  (act_fn): ReLU()\n",
            "  (train_mapk): MAPK()\n",
            "  (valid_mapk): MAPK()\n",
            "  (test_mapk): MAPK()\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.036481881978299394, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.036481881978299394, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.036481881978299394, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Dropout(p=0.036481881978299394, inplace=False)\n",
            "    (12): Linear(in_features=64, out_features=11, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name       | Type       | Params\n",
            "------------------------------------------\n",
            "0 | act_fn     | ReLU       | 0     \n",
            "1 | train_mapk | MAPK       | 0     \n",
            "2 | valid_mapk | MAPK       | 0     \n",
            "3 | test_mapk  | MAPK       | 0     \n",
            "4 | model      | Sequential | 75.0 K\n",
            "------------------------------------------\n",
            "75.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "75.0 K    Total params\n",
            "0.300     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1376824ff7f34209a9a79426875d87f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "795b0d5d6dad40dca96bbfed003b3014",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f38c9d4e7f9b47419f099aa060708bdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8365ca3d05b8421f9569324de3906852",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a7b7eee669f47ed9fb0c6fd714062b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df5fab30bf3049f2afef7a5aa111d34a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aca9a1c61f141e8b7442213e8b8512b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebaa0b545879414c983630d00186e658",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61b623478db74b81aa99db7995178796",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da57d32cf9c44792b8d46892a0087dcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc28966d6a7845a9a3fb4ad9f7761de6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00d669a443be4ca7a9efef4a29054fa9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd66aa31e4b04f13a3813c59e8b53147",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ac8dae5f52c47f2afad50d758f3a477",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ae0d925032f4040ae789a643138f87e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff1f62ca21b5444d9c0fdf6393435a71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee438add5a5b401baacf7e4a652ec969",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1be52c31a9345d481c0eec351e65ccb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3f833cb6f0a43debb28fbcf218a2469",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14134275913238525    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.3961915969848633     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">        valid_mapk         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22147473692893982    </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14134275913238525   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.3961915969848633    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m       valid_mapk        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22147473692893982   \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name       | Type       | Params\n",
            "------------------------------------------\n",
            "0 | act_fn     | ReLU       | 0     \n",
            "1 | train_mapk | MAPK       | 0     \n",
            "2 | valid_mapk | MAPK       | 0     \n",
            "3 | test_mapk  | MAPK       | 0     \n",
            "4 | model      | Sequential | 3.1 K \n",
            "------------------------------------------\n",
            "3.1 K     Trainable params\n",
            "0         Non-trainable params\n",
            "3.1 K     Total params\n",
            "0.012     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'valid_mapk': 0.22147473692893982, 'val_loss': 2.3961915969848633, 'val_acc': 0.14134275913238525}\n",
            "\n",
            "config: {'l1': 32, 'epochs': 16, 'batch_size': 32, 'act_fn': ReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.06220214613777628}\n",
            "model: CSVModel(\n",
            "  (act_fn): ReLU()\n",
            "  (train_mapk): MAPK()\n",
            "  (valid_mapk): MAPK()\n",
            "  (test_mapk): MAPK()\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.06220214613777628, inplace=False)\n",
            "    (3): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.06220214613777628, inplace=False)\n",
            "    (6): Linear(in_features=16, out_features=16, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.06220214613777628, inplace=False)\n",
            "    (9): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Dropout(p=0.06220214613777628, inplace=False)\n",
            "    (12): Linear(in_features=8, out_features=11, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "230552256e4f4cfe8d7813200a07722a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f2798a391ac444eb099945559635d7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fe6cc2c34954de6b9e7d6c2e3a471b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d83d1f644e834068bcca1450798c16fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc32dd7d591e4678aeaf421b253eed7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d83d30698c794731bb5d945e7f80ae6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b9fa6981ca14b54910569dcb6e104a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6d819852ba64d6daccac9b7bc81229c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70fc714ae2fc40a7abfec43a0b7f1aea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fbe8b49f7e347d58e9bead978a578bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da52a9e9a2944331b419cef36ad3d62f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8edeb74b548f4d1bb6837a83e3c33844",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e754408391354e1eac96864ffd5cb14e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3190a9b380e44b31827ab5735eaab0ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d2782fd33d947cbaff6cbde424c4baa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b46dbc80176412cafdf2c140f29c968",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59b0988a149d431b8cdd376e4dea5e5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4913aa391d294489b7a171ac8a41a930",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd12bdd371034b8c8d06c4725475f6e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12014134228229523    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.397022008895874     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">        valid_mapk         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18825016915798187    </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12014134228229523   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.397022008895874    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m       valid_mapk        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18825016915798187   \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name       | Type       | Params\n",
            "------------------------------------------\n",
            "0 | act_fn     | ReLU       | 0     \n",
            "1 | train_mapk | MAPK       | 0     \n",
            "2 | valid_mapk | MAPK       | 0     \n",
            "3 | test_mapk  | MAPK       | 0     \n",
            "4 | model      | Sequential | 264 K \n",
            "------------------------------------------\n",
            "264 K     Trainable params\n",
            "0         Non-trainable params\n",
            "264 K     Total params\n",
            "1.059     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'valid_mapk': 0.18825016915798187, 'val_loss': 2.397022008895874, 'val_acc': 0.12014134228229523}\n",
            "\n",
            "config: {'l1': 512, 'epochs': 64, 'batch_size': 4, 'act_fn': ReLU(), 'optimizer': 'Adamax', 'dropout_prob': 0.0851706589553058}\n",
            "model: CSVModel(\n",
            "  (act_fn): ReLU()\n",
            "  (train_mapk): MAPK()\n",
            "  (valid_mapk): MAPK()\n",
            "  (test_mapk): MAPK()\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.0851706589553058, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.0851706589553058, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.0851706589553058, inplace=False)\n",
            "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Dropout(p=0.0851706589553058, inplace=False)\n",
            "    (12): Linear(in_features=128, out_features=11, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3547aa35a8d54d9d8e35cf4c40030b2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d23605438a347cb9e2209263faca726",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e4696b9139d4fd4accdb915727eb871",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d3abc0659c14094947676785ddc652e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "591756b9e7b549a8b5b096d09905682b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from spotPython.spot import spot\n",
        "from math import inf\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                   lower = lower,\n",
        "                   upper = upper,\n",
        "                   fun_evals = inf,\n",
        "                   fun_repeats = 1,\n",
        "                   max_time = MAX_TIME,\n",
        "                   noise = False,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type = var_type,\n",
        "                   var_name = var_name,\n",
        "                   infill_criterion = \"y\",\n",
        "                   n_points = 1,\n",
        "                   seed=123,\n",
        "                   log_level = 50,\n",
        "                   show_models= False,\n",
        "                   show_progress= True,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": INIT_SIZE,\n",
        "                                   \"repeats\": 1},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"cod_type\": \"norm\",\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": len(var_name),\n",
        "                                      \"model_fun_evals\": 10_000,\n",
        "                                      \"log_level\": 50\n",
        "                                      })\n",
        "spot_tuner.run(X_start=X_start)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Tensorboard {#sec-tensorboard-25}\n",
        "\n",
        "The textual output shown in the console (or code cell) can be visualized with Tensorboard as described in @sec-tensorboard-14, see also the description in the documentation: [Tensorboard.](https://sequential-parameter-optimization.github.io/spotPython/14_spot_ray_hpt_torch_cifar10.html#sec-tensorboard-14)\n",
        "\n",
        "## Step 10: Results {#sec-results-25}\n",
        "\n",
        "After the hyperparameter tuning run is finished, the results can be analyzed as described in @sec-results-14."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-progress-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Progress plot. *Black* dots denote results from the initial design. *Red* dots  illustrate the improvement found by the surrogate model based optimization.\n",
        "spot_tuner.plot_progress(log_y=False, \n",
        "    filename=\"./figures/\" + experiment_name+\"_progress.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "tbl-results-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Results of the hyperparameter tuning.\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-importance-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: 'Variable importance plot, threshold 0.025.'\n",
        "spot_tuner.plot_importance(threshold=0.025,\n",
        "    filename=\"./figures/\" + experiment_name+\"_importance.png\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the Tuned Architecture {#sec-get-spot-results-25}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import get_one_config_from_X\n",
        "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
        "config = get_one_config_from_X(X, fun_control)\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.traintest import test_model\n",
        "test_model(config, fun_control)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of the Tuned Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.torch.traintest import (\n",
        "    train_tuned,\n",
        "    test_tuned,\n",
        "    )\n",
        "train_tuned(net=model_spot, train_dataset=train,\n",
        "        loss_function=fun_control[\"loss_function\"],\n",
        "        metric=fun_control[\"metric_torch\"],\n",
        "        shuffle=True,\n",
        "        device = fun_control[\"device\"],\n",
        "        path=None,\n",
        "        task=fun_control[\"task\"],)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If `path` is set to a filename, e.g., `path = \"model_spot_trained.pt\"`, the weights of the trained model will be loaded from this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_tuned(net=model_spot, test_dataset=test,\n",
        "            shuffle=False,\n",
        "            loss_function=fun_control[\"loss_function\"],\n",
        "            metric=fun_control[\"metric_torch\"],\n",
        "            device = fun_control[\"device\"],\n",
        "            task=fun_control[\"task\"],)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-validated Evaluations\n",
        "\n",
        "* This is the evaluation that will be used in the comparison.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Cross-validated Evaluations\n",
        "\n",
        "* The number of folds is set to 1 by default.\n",
        "* Here it was changed to 3 for demonstration purposes.\n",
        "* Set the number of folds to a reasonable value, e.g., 10.\n",
        "* This can be done by setting the `k_folds` attribute of the model as follows:\n",
        "* `setattr(model_spot, \"k_folds\",  10)`\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.torch.traintest import evaluate_cv\n",
        "# modify k-kolds:\n",
        "setattr(model_spot, \"k_folds\",  3)\n",
        "df_eval, df_preds, df_metrics = evaluate_cv(net=model_spot,\n",
        "    dataset=fun_control[\"data\"],\n",
        "    loss_function=fun_control[\"loss_function\"],\n",
        "    metric=fun_control[\"metric_torch\"],\n",
        "    task=fun_control[\"task\"],\n",
        "    writer=fun_control[\"writer\"],\n",
        "    writerId=\"model_spot_cv\",\n",
        "    device = fun_control[\"device\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric_name = type(fun_control[\"metric_torch\"]).__name__\n",
        "print(f\"loss: {df_eval}, Cross-validated {metric_name}: {df_metrics}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Detailed Hyperparameter Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-contour-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Contour plots.\n",
        "filename = \"./figures/\" + experiment_name\n",
        "spot_tuner.plot_important_hyperparameter_contour(filename=filename)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallel Coordinates Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-parallel-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Parallel coordinates plots\n",
        "spot_tuner.parallel_plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot all Combinations of Hyperparameters\n",
        "\n",
        "* Warning: this may take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PLOT_ALL = False\n",
        "if PLOT_ALL:\n",
        "    n = spot_tuner.k\n",
        "    for i in range(n-1):\n",
        "        for j in range(i+1, n):\n",
        "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
