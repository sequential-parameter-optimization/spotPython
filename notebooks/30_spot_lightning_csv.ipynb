{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HPT: PyTorch With VBDP {#sec-vbdp}\n",
        "\n",
        "In this tutorial, we will show how `spotPython` can be integrated into the `PyTorch`\n",
        "training workflow for a classifiaction task.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Data must be downloaded manually\n",
        "\n",
        "* Ensure that the correspondiing data is available as `./data/VBDP/train.csv`.\n",
        "\n",
        ":::\n",
        "\n",
        "This document refers to the following software versions:\n",
        "\n",
        "- ``python``: 3.10.10\n",
        "- ``torch``: 2.0.1\n",
        "- ``torchvision``: 0.15.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip list | grep  \"spot[RiverPython]\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`spotPython` can be installed via pip. Alternatively, the source code can be downloaded from gitHub: [https://github.com/sequential-parameter-optimization/spotPython](https://github.com/sequential-parameter-optimization/spotPython).\n",
        "\n",
        "```{raw}\n",
        "!pip install spotPython\n",
        "```\n",
        "\n",
        "* Uncomment the following lines if you want to for (re-)installation the latest version of `spotPython` from gitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install --upgrade build\n",
        "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup {#sec-setup-25}\n",
        "\n",
        "Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Run time and initial design size should be increased for real experiments\n",
        "\n",
        "* MAX_TIME is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\n",
        "* INIT_SIZE is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-note}\n",
        "### Note: Device selection\n",
        "\n",
        "* The device can be selected by setting the variable `DEVICE`.\n",
        "* Since we are using a simple neural net, the setting `\"cpu\"` is preferred (on Mac).\n",
        "* If you have a GPU, you can use `\"cuda:0\"` instead.\n",
        "* If DEVICE is set to `None`, `spotPython` will automatically select the device.\n",
        "  * This might result in `\"mps\"` on Macs, which is not the best choice for simple neural nets.\n",
        "\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_TIME = 1\n",
        "INIT_SIZE = 5\n",
        "DEVICE = None, #\"cpu\" # \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.device import getDevice\n",
        "DEVICE = getDevice(DEVICE)\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import socket\n",
        "from datetime import datetime\n",
        "from dateutil.tz import tzlocal\n",
        "start_time = datetime.now(tzlocal())\n",
        "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
        "experiment_name = '30-light' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
        "experiment_name = experiment_name.replace(':', '-')\n",
        "print(experiment_name)\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialization of the `fun_control` Dictionary\n",
        "\n",
        ":::{.callout-caution}\n",
        "### Caution: Tensorboard does not work under Windows\n",
        "* Since tensorboard does not work under Windows, we recommend setting the parameter `tensorboard_path` to `None` if you are working under Windows.\n",
        ":::\n",
        "\n",
        "`spotPython` uses a Python dictionary for storing the information required for the hyperparameter tuning process, which was described in @sec-initialization-fun-control-14, see [Initialization of the fun_control Dictionary](https://sequential-parameter-optimization.github.io/spotPython/14_spot_ray_hpt_torch_cifar10.html#sec-initialization-fun-control-14) in the documentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(task=\"classification\",\n",
        "    tensorboard_path=\"./runs/\" + experiment_name,\n",
        "    num_workers=10,\n",
        "    device=DEVICE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: PyTorch Data Loading {#sec-data-loading-25}\n",
        "\n",
        "### 1. Load VBDP Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from spotPython.light.csvdataset import CSVDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Create an instance of CSVDataset\n",
        "dataset = CSVDataset(csv_file=\"./data/VBDP/train.csv\", train=True)\n",
        "# show the dimensions of the dataset\n",
        "print(dataset[0][0].shape)\n",
        "# show the first element of the dataset\n",
        "print(dataset[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an instance of CSVDataset\n",
        "dataset = CSVDataset(csv_file=\"./data/VBDP/train.csv\", train=False)\n",
        "# show the size of the dataset\n",
        "print(f\"Dataset Size: {len(dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 3\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "dataset_full = CSVDataset(csv_file=\"./data/VBDP/train.csv\", train=False)\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=123)\n",
        "all_splits = [k for k in kf.split(dataset_full)]\n",
        "train_indexes, val_indexes = all_splits[8]\n",
        "train_indexes, val_indexes = train_indexes.tolist(), val_indexes.tolist()\n",
        "\n",
        "# Create subsets using Subset class\n",
        "train_subset = Subset(dataset_full, train_indexes)\n",
        "val_subset = Subset(dataset_full, val_indexes)\n",
        "\n",
        "# Create DataLoaders for training and validation subsets\n",
        "train_dataloader = DataLoader(train_subset, batch_size=3, shuffle=True)\n",
        "val_dataloader = DataLoader(val_subset, batch_size=3, shuffle=True)\n",
        "\n",
        "# Iterate over the data in the validation DataLoader\n",
        "for batch in val_dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Specification of the Preprocessing Model {#sec-specification-of-preprocessing-model-25}\n",
        "\n",
        "After the training and test data are specified and added to the `fun_control` dictionary, `spotPython` allows the specification of a data preprocessing pipeline, e.g., for the scaling of the data or for the one-hot encoding of categorical variables, see @sec-specification-of-preprocessing-model-14. This feature is not used here, so we do not change the default value (which is `None`).\n",
        "\n",
        ":::{.callout-note}\n",
        "Lightning allows the data preprocessing to be specified in the `LightningDataModule` class. It is not considered here, because it should be computed at one location only.\n",
        ":::\n",
        "\n",
        "\n",
        "## Step 5: Select `algorithm` and `core_model_hyper_dict` {#sec-selection-of-the-algorithm-25}\n",
        "\n",
        "### Implementing a Configurable Neural Network With spotPython \n",
        "\n",
        "`spotPython` includes the `Net_vbdp` class which is implemented in the file `netvbdp.py`.\n",
        "The class is imported here.\n",
        "\n",
        "This class  inherits from the class `Net_Core` which is implemented in the file `netcore.py`, see @sec-the-netcore-class-14.\n",
        "\n",
        "### Add the NN Model to the fun_control Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.csvmodel import CSVModel \n",
        "from spotPython.data.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "fun_control = add_core_model_to_fun_control(core_model=CSVModel,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict= LightHyperDict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The corresponding entries for the `core_model` class are shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fun_control['core_model_hyper_dict']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model` {#sec-modification-of-hyperparameters-25}\n",
        "\n",
        " `spotPython` provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions were described in @sec-modification-of-hyperparameters-14.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Small number of epochs for demonstration purposes\n",
        "\n",
        "* `epochs` and `patience` are set to small values for demonstration purposes. These values are too small for a real application.\n",
        "* More resonable values are, e.g.:\n",
        "  * `fun_control = modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[7, 9])` and\n",
        "  * `fun_control = modify_hyper_parameter_bounds(fun_control, \"patience\", bounds=[2, 7])`\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"l1\", bounds=[2,3])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[1,2])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"batch_size\", bounds=[6, 8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import modify_hyper_parameter_levels\n",
        "fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
        "# fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\", [\"Adam\"])\n",
        "# fun_control[\"core_model_hyper_dict\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Selection of the Objective (Loss) Function\n",
        "\n",
        "### Evaluation  {#sec-selection-of-target-function-25}\n",
        "\n",
        "The evaluation procedure requires the specification of two elements:\n",
        "\n",
        "1. the way how the data is split into a train and a test set (see @sec-data-splitting-14)\n",
        "2. the loss function (and a metric).\n",
        "\n",
        "\n",
        "### Loss Functions and Metrics {#sec-loss-functions-and-metrics-25}\n",
        "\n",
        "The loss function is specified by the key `\"loss_function\"`.\n",
        "We will use CrossEntropy loss for the multiclass-classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.nn import CrossEntropyLoss\n",
        "# loss_function = CrossEntropyLoss()\n",
        "# fun_control.update({\"loss_function\": loss_function})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metric {#sec-metric-25}\n",
        "\n",
        "* We will use the MAP@k metric for the evaluation of the model. Here is an example how this metric is calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.torch.mapk import MAPK\n",
        "import torch\n",
        "mapk = MAPK(k=2)\n",
        "target = torch.tensor([0, 1, 2, 2])\n",
        "preds = torch.tensor(\n",
        "    [\n",
        "        [0.5, 0.2, 0.2],  # 0 is in top 2\n",
        "        [0.3, 0.4, 0.2],  # 1 is in top 2\n",
        "        [0.2, 0.4, 0.3],  # 2 is in top 2\n",
        "        [0.7, 0.2, 0.1],  # 2 isn't in top 2\n",
        "    ]\n",
        ")\n",
        "mapk.update(preds, target)\n",
        "print(mapk.compute()) # tensor(0.6250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.torch.mapk import MAPK\n",
        "# import torchmetrics\n",
        "# metric_torch = MAPK(k=3)\n",
        "# fun_control.update({\"metric_torch\": metric_torch})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Calling the SPOT Function\n",
        "\n",
        "### Preparing the SPOT Call {#sec-prepare-spot-call-25}\n",
        "\n",
        "The following code passes the information about the parameter ranges and bounds to `spot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract the variable types, names, and bounds\n",
        "from spotPython.hyperparameters.values import (get_bound_values,\n",
        "    get_var_name,\n",
        "    get_var_type,)\n",
        "var_type = get_var_type(fun_control)\n",
        "var_name = get_var_name(fun_control)\n",
        "fun_control.update({\"var_type\": var_type,\n",
        "                    \"var_name\": var_name})\n",
        "lower = get_bound_values(fun_control, \"lower\")\n",
        "upper = get_bound_values(fun_control, \"upper\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the dictionary `fun_control` contains all information needed for the hyperparameter tuning. Before the hyperparameter tuning is started, it is recommended to take a look at the experimental design. The method `gen_design_table` generates a design table as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "tbl-design-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Experimental design for the hyperparameter tuning.\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows to check if all information is available and if the information is correct.\n",
        "\n",
        "### The Objective Function `fun_torch` {#sec-the-objective-function-25}\n",
        "\n",
        "The objective function `fun_torch` is selected next. It implements an interface from `PyTorch`'s training, validation, and  testing methods to `spotPython`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.hyperlight import HyperLight\n",
        "fun = HyperLight().fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import get_default_hyperparameters_as_array\n",
        "hyper_dict=LightHyperDict().load()\n",
        "X_start = get_default_hyperparameters_as_array(fun_control, hyper_dict)\n",
        "X_start"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Starting the Hyperparameter Tuning {#sec-call-the-hyperparameter-tuner-25}\n",
        "\n",
        "The `spotPython` hyperparameter tuning is started by calling the `Spot` function as described in @sec-call-the-hyperparameter-tuner-14.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from spotPython.spot import spot\n",
        "from math import inf\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                   lower = lower,\n",
        "                   upper = upper,\n",
        "                   fun_evals = inf,\n",
        "                   fun_repeats = 1,\n",
        "                   max_time = MAX_TIME,\n",
        "                   noise = False,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type = var_type,\n",
        "                   var_name = var_name,\n",
        "                   infill_criterion = \"y\",\n",
        "                   n_points = 1,\n",
        "                   seed=123,\n",
        "                   log_level = 50,\n",
        "                   show_models= False,\n",
        "                   show_progress= True,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": INIT_SIZE,\n",
        "                                   \"repeats\": 1},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"cod_type\": \"norm\",\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": len(var_name),\n",
        "                                      \"model_fun_evals\": 10_000,\n",
        "                                      \"log_level\": 50\n",
        "                                      })\n",
        "spot_tuner.run(X_start=X_start)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Tensorboard {#sec-tensorboard-25}\n",
        "\n",
        "The textual output shown in the console (or code cell) can be visualized with Tensorboard as described in @sec-tensorboard-14, see also the description in the documentation: [Tensorboard.](https://sequential-parameter-optimization.github.io/spotPython/14_spot_ray_hpt_torch_cifar10.html#sec-tensorboard-14)\n",
        "\n",
        "## Step 10: Results {#sec-results-25}\n",
        "\n",
        "After the hyperparameter tuning run is finished, the results can be analyzed as described in @sec-results-14."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-progress-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Progress plot. *Black* dots denote results from the initial design. *Red* dots  illustrate the improvement found by the surrogate model based optimization.\n",
        "spot_tuner.plot_progress(log_y=False, \n",
        "    filename=\"./figures/\" + experiment_name+\"_progress.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "tbl-results-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Results of the hyperparameter tuning.\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-importance-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: 'Variable importance plot, threshold 0.025.'\n",
        "spot_tuner.plot_importance(threshold=0.025,\n",
        "    filename=\"./figures/\" + experiment_name+\"_importance.png\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the Tuned Architecture {#sec-get-spot-results-25}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import get_one_config_from_X\n",
        "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
        "config = get_one_config_from_X(X, fun_control)\n",
        "config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Test on the full data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.traintest import test_model\n",
        "test_model(config, fun_control)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross Validation With Lightning\n",
        "\n",
        "* This is the evaluation that will be used in the comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.traintest import cv_model\n",
        "cv_model(config, fun_control)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Detailed Hyperparameter Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-contour-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Contour plots.\n",
        "filename = \"./figures/\" + experiment_name\n",
        "spot_tuner.plot_important_hyperparameter_contour(filename=filename)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallel Coordinates Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-parallel-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Parallel coordinates plots\n",
        "spot_tuner.parallel_plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot all Combinations of Hyperparameters\n",
        "\n",
        "* Warning: this may take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PLOT_ALL = False\n",
        "if PLOT_ALL:\n",
        "    n = spot_tuner.k\n",
        "    for i in range(n-1):\n",
        "        for j in range(i+1, n):\n",
        "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
