{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "title: 'spotPython Tests'\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fun_control_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(_L_in=64, _L_out=11, num_workers=0, device=None)\n",
        "fun_control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def class_attributes_to_dataframe(class_obj):\n",
        "    # Get the attributes and their values of the class object\n",
        "    attributes = [attr for attr in dir(class_obj) if not callable(getattr(class_obj, attr)) and not attr.startswith(\"__\")]\n",
        "    values = [getattr(class_obj, attr) for attr in attributes]\n",
        "    \n",
        "    # Create a DataFrame from the attributes and values\n",
        "    df = pd.DataFrame({'Attribute Name': attributes, 'Attribute Value': values})\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        self.name = \"John\"\n",
        "        self.age = 30\n",
        "        self.salary = 50000\n",
        "\n",
        "my_instance = MyClass()\n",
        "df = class_attributes_to_dataframe(my_instance)\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import inf\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "# number of initial points:\n",
        "ni = 7\n",
        "# number of points\n",
        "n = 10\n",
        "\n",
        "fun = analytical().fun_sphere\n",
        "lower = np.array([-1])\n",
        "upper = np.array([1])\n",
        "design_control={\"init_size\": ni}\n",
        "\n",
        "spot_1 = spot.Spot(fun=fun,\n",
        "            lower = lower,\n",
        "            upper= upper,\n",
        "            fun_evals = n,\n",
        "            show_progress=True,\n",
        "            design_control=design_control,)\n",
        "spot_1.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sys import stdout\n",
        "df = spot_1.class_attributes_to_dataframe()\n",
        "stdout.write(df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from river import datasets\n",
        "from river import evaluate\n",
        "from river.linear_model import LogisticRegression\n",
        "from river import metrics\n",
        "from river import optim\n",
        "from river import preprocessing\n",
        "\n",
        "dataset = datasets.Phishing()\n",
        "\n",
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "metric = metrics.Accuracy()\n",
        "\n",
        "evaluate.progressive_val_score(dataset, model, metric)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.csvdataset import CSVDataset\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data.csv', target_column='prognosis')\n",
        "dataset = CSVDataset(target_column='prognosis')\n",
        "print(dataset.data.shape)\n",
        "print(dataset.targets.shape)            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.extra_repr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 3\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSV Data set VBDP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the csv_file='./data/spotPython/data.csv' as a pandas df and save it as a pickle file\n",
        "import pandas as pd\n",
        "df = pd.read_csv('./data/spotPython/data.csv')\n",
        "df.to_pickle('./data/spotPython/data.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyHcf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyhcf.data.daten_sensitive import DatenSensitive\n",
        "from pyhcf.utils.names import get_short_parameter_names\n",
        "daten = DatenSensitive()\n",
        "df = daten.load()\n",
        "names =  df.columns\n",
        "names = get_short_parameter_names(names)\n",
        "# rename columns with short names\n",
        "df.columns = names\n",
        "df.head()\n",
        "# save the df as a csv file\n",
        "df.to_csv('./data/spotPython/data_sensitive.csv', index=False)\n",
        "# save the df as a pickle file\n",
        "df.to_pickle('./data/spotPython/data_sensitive.pkl')\n",
        "# remove all rows with NaN values\n",
        "df = df.dropna()\n",
        "# save the df as a csv file\n",
        "df.to_csv('./data/spotPython/data_sensitive_rmNA.csv', index=False)\n",
        "# save the df as a pickle file\n",
        "df.to_pickle('./data/spotPython/data_sensitive_rmNA.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyHcf data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.light.csvdataset import CSVDataset\n",
        "# import torch\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data_sensitive.csv', target_column='N', feature_type=torch.float32, target_type=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5000\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     # print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.light.csvdataset import CSVDataset\n",
        "# import torch\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data_sensitive.csv', target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5000\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     # print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pickle data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)\n",
        "dataset.feature_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Sensitive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(pkl_file='./data/spotPython/data_sensitive.pkl', target_column='A', feature_type=torch.long, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test lightdatamodule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
        "# dataset = PKLDataset(directory=\"./data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_module.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Training set size: {len(data_module.data_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Validation set size: {len(data_module.data_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Test set size: {len(data_module.data_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set the DataModule in fun_control "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_data_module\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=7)\n",
        "dm.setup()\n",
        "set_data_module(fun_control=fun_control,\n",
        "                data_module=dm)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## same with the sensitive data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_data_module\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=77)\n",
        "dm.setup()\n",
        "set_data_module(fun_control=fun_control,\n",
        "                data_module=dm)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## same, but VBDO data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_data_module\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = CSVDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/VBDP/\", filename=\"train.csv\",target_column='prognosis', feature_type=torch.long)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=77)\n",
        "dm.setup()\n",
        "set_data_module(fun_control=fun_control,\n",
        "                data_module=dm)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# load Hyperdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "lhd = LightHyperDict()\n",
        "lhd.hyper_dict\n",
        "user_lhd = LightHyperDict(filename=\"user_hyper_dict.json\", directory=\"./hyperdict/\")\n",
        "user_lhd.hyper_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diabetes data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes  \n",
        "import torch\n",
        "\n",
        "# Load the diabetes dataset\n",
        "feature_df, target_df = load_diabetes(return_X_y=True, as_frame=True)\n",
        "feature_tensor = torch.tensor(feature_df.values, dtype=torch.float32)\n",
        "target_tensor = torch.tensor(target_df.values, dtype=torch.float32)\n",
        "feature_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.diabetes import Diabetes\n",
        "dataset = Diabetes()\n",
        "print(dataset.data.shape)\n",
        "print(dataset.targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# add core model to fun control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.netlightregressione import NetLightRegression\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "fun_control[\"core_model\"].__name__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the fun_control[\"core_model_hyper_dict\"] is a LightHyperDict\n",
        "isinstance(fun_control[\"core_model_hyper_dict\"], dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test check_X_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.hyperparameters.values import get_var_name\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "hyper_light = HyperLight(seed=126, log_level=50)\n",
        "n_hyperparams = len(get_var_name(fun_control))\n",
        "# generate a random np.array X with shape (2, n_hyperparams)\n",
        "X = np.random.rand(2, n_hyperparams)\n",
        "X == hyper_light.check_X_shape(X, fun_control)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test hyperlight fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.hyperparameters.values import set_data_set\n",
        "import numpy as np\n",
        "fun_control = fun_control_init(\n",
        "    _L_in=10,\n",
        "    _L_out=1,)\n",
        "\n",
        "dataset = Diabetes()\n",
        "set_data_set(fun_control=fun_control,\n",
        "                data_set=dataset)\n",
        "\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "hyper_light = HyperLight(seed=126, log_level=50)\n",
        "X = get_default_hyperparameters_as_array(fun_control)\n",
        "# combine X and X to a np.array with shape (2, n_hyperparams)\n",
        "X = np.vstack((X, X))\n",
        "y = hyper_light.fun(X, fun_control)\n",
        "y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test  NetLightRegression Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from torch import nn\n",
        "import lightning as L\n",
        "PATH_DATASETS = './data'\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "dataset = Diabetes()\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "batch_x, batch_y = next(iter(train_loader)) \n",
        "print(batch_x.shape)\n",
        "print(batch_y.shape)\n",
        "\n",
        "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
        "                                initialization='xavier', act_fn=nn.ReLU(),\n",
        "                                optimizer='Adam', dropout_prob=0.1, lr_mult=0.1,\n",
        "                                patience=5, _L_in=10, _L_out=1)\n",
        "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
        "trainer.fit(net_light_base, train_loader)\n",
        "trainer.validate(net_light_base, val_loader)\n",
        "trainer.test(net_light_base, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# tests optimizer_handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from torch import nn\n",
        "import lightning as L\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "lr_mult=0.1\n",
        "\n",
        "dataset = Diabetes()\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
        "                                initialization='xavier', act_fn=nn.ReLU(),\n",
        "                                optimizer='Adam', dropout_prob=0.1, lr_mult=lr_mult,\n",
        "                                patience=5, _L_in=10, _L_out=1)\n",
        "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
        "trainer.fit(net_light_base, train_loader)\n",
        "# Adam uses a lr which is calculated as lr=lr_mult * 0.001, so this value\n",
        "# should be 0.1 * 0.001 = 0.0001 \n",
        "trainer.optimizers[0].param_groups[0][\"lr\"] == lr_mult*0.001\n",
        "\n",
        "\n",
        "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
        "                                initialization='xavier', act_fn=nn.ReLU(),\n",
        "                                optimizer='Adadelta', dropout_prob=0.1, lr_mult=lr_mult,\n",
        "                                patience=5, _L_in=10, _L_out=1)\n",
        "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
        "trainer.fit(net_light_base, train_loader)\n",
        "# Adadelta uses a lr which is calculated as lr=lr_mult * 1.0, so this value\n",
        "# should be 1.0 * 0.1 = 0.1 \n",
        "trainer.optimizers[0].param_groups[0][\"lr\"] == lr_mult*1.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.hyperparameters.values import set_data_set\n",
        "from spotPython.hyperparameters.values import get_var_name, assign_values, generate_one_config_from_var_dict\n",
        "from spotPython.light.traintest import train_model, test_model\n",
        "fun_control = fun_control_init(\n",
        "    _L_in=10,\n",
        "    _L_out=1,)\n",
        "\n",
        "dataset = Diabetes()\n",
        "set_data_set(fun_control=fun_control,\n",
        "                data_set=dataset)\n",
        "\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "X = get_default_hyperparameters_as_array(fun_control)\n",
        "var_dict = assign_values(X, get_var_name(fun_control))\n",
        "for config in generate_one_config_from_var_dict(var_dict, fun_control):\n",
        "    y_train = train_model(config, fun_control)\n",
        "    y_test = test_model(config, fun_control)\n",
        "    break\n",
        "print(y_train)\n",
        "print(y_test[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.hyperparameters.values import set_data_set\n",
        "from spotPython.hyperparameters.values import get_var_name, assign_values, generate_one_config_from_var_dict\n",
        "from spotPython.light.traintest import test_model\n",
        "\n",
        "\n",
        "def test_traintest_test_model():\n",
        "    fun_control = fun_control_init(\n",
        "        _L_in=10,\n",
        "        _L_out=1,)\n",
        "\n",
        "    dataset = Diabetes()\n",
        "    set_data_set(fun_control=fun_control,\n",
        "                    data_set=dataset)\n",
        "\n",
        "    add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                                fun_control=fun_control,\n",
        "                                hyper_dict=LightHyperDict)\n",
        "    X = get_default_hyperparameters_as_array(fun_control)\n",
        "    var_dict = assign_values(X, get_var_name(fun_control))\n",
        "    for vals in generate_one_config_from_var_dict(var_dict, fun_control):\n",
        "        y_test = test_model(test_config=vals,\n",
        "                            fun_control=fun_control)\n",
        "        break\n",
        "    # check if y is a float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test getVarName()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import get_var_name\n",
        "fun_control = {\"core_model_hyper_dict\":{\n",
        "            \"leaf_prediction\": {\n",
        "                \"levels\": [\"mean\", \"model\", \"adaptive\"],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": \"mean\",\n",
        "                \"core_model_parameter_type\": \"str\"},\n",
        "            \"leaf_model\": {\n",
        "                \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": \"LinearRegression\",\n",
        "                \"core_model_parameter_type\": \"instance\"},\n",
        "            \"splitter\": {\n",
        "                \"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": \"EBSTSplitter\",\n",
        "                \"core_model_parameter_type\": \"instance()\"},\n",
        "            \"binary_split\": {\n",
        "                \"levels\": [0, 1],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": 0,\n",
        "                \"core_model_parameter_type\": \"bool\"},\n",
        "            \"stop_mem_management\": {\n",
        "                \"levels\": [0, 1],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": 0,\n",
        "                \"core_model_parameter_type\": \"bool\"}}}\n",
        "len(get_var_name(fun_control))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test netlightregression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from spotPython.spot import spot\n",
        "from math import inf\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.utils.file import get_experiment_name, get_spot_tensorboard_path\n",
        "from spotPython.utils.device import getDevice\n",
        "from spotPython.hyperparameters.values import set_data_set\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "from spotPython.hyperparameters.values import modify_hyper_parameter_levels\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.hyperparameters.values import (get_bound_values,\n",
        "    get_var_name,\n",
        "    get_var_type,)\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "from spotPython.hyperparameters.values import get_tuned_architecture\n",
        "from spotPython.light.testmodel import test_model\n",
        "from spotPython.light.loadmodel import load_light_from_checkpoint\n",
        "\n",
        "MAX_TIME = 1\n",
        "INIT_SIZE = 5\n",
        "WORKERS = 0\n",
        "PREFIX=\"031\"\n",
        "\n",
        "experiment_name = get_experiment_name(prefix=PREFIX)\n",
        "fun_control = fun_control_init(\n",
        "    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name),\n",
        "    num_workers=WORKERS,\n",
        "    device=getDevice(),\n",
        "    _L_in=133,\n",
        "    _L_out=1,\n",
        "    TENSORBOARD_CLEAN=True)\n",
        "\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True)\n",
        "set_data_set(fun_control=fun_control,\n",
        "                data_set=dataset)\n",
        "\n",
        "\n",
        "\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "modify_hyper_parameter_bounds(fun_control, \"l1\", bounds=[5,8])\n",
        "modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[3,5])\n",
        "modify_hyper_parameter_bounds(fun_control, \"batch_size\", bounds=[2, 8])\n",
        "modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
        "\n",
        "print(gen_design_table(fun_control))\n",
        "\n",
        "var_type = get_var_type(fun_control)\n",
        "var_name = get_var_name(fun_control)\n",
        "lower = get_bound_values(fun_control, \"lower\")\n",
        "upper = get_bound_values(fun_control, \"upper\")\n",
        "fun = HyperLight(log_level=50).fun\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                       log_level=50,\n",
        "                   lower = lower,\n",
        "                   upper = upper,\n",
        "                   fun_evals = inf,\n",
        "                   max_time = MAX_TIME,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type = var_type,\n",
        "                   var_name = var_name,\n",
        "                   show_progress= True,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": INIT_SIZE},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": len(var_name),\n",
        "                                      \"model_fun_evals\": 10_000,\n",
        "                                      })\n",
        "spot_tuner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.plot_progress(log_y=False, filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.plot_importance(threshold=0.025, filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = get_tuned_architecture(spot_tuner, fun_control)\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model(config, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_loaded = load_light_from_checkpoint(config, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.plot_important_hyperparameter_contour(filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.parallel_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.cvmodel import cv_model\n",
        "# set the number of folds to 10\n",
        "fun_control[\"k_folds\"] = 10\n",
        "cv_model(config, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "import numpy as np\n",
        "y = np.array([1, 2, 3, 4, 5])\n",
        "fun = analytical(sigma=1.0, seed=123)\n",
        "fun.add_noise(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "import numpy as np\n",
        "print(np.array([1, 2, 3, 4, 5]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import inf\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "from scipy.optimize import shgo\n",
        "from scipy.optimize import direct\n",
        "from scipy.optimize import differential_evolution\n",
        "import matplotlib.pyplot as plt\n",
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(seed=4321, sigma=0.1)\n",
        "fun = analytical(seed=222, sigma=0.0).fun_sphere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_1 = spot.Spot(fun=fun,\n",
        "                   lower = np.array([-10]),\n",
        "                   upper = np.array([100]),\n",
        "                   fun_evals = 100,\n",
        "                   fun_repeats = 3,\n",
        "                   max_time = inf,\n",
        "                   noise = True,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type=[\"num\"],\n",
        "                   infill_criterion = \"y\",\n",
        "                   n_points = 1,\n",
        "                   seed=111,\n",
        "                   log_level = 10,\n",
        "                   show_models=False,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": 5,\n",
        "                                   \"repeats\": 1},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"cod_type\": \"norm\",\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": 1,\n",
        "                                      \"model_optimizer\": differential_evolution,\n",
        "                                      \"model_fun_evals\": 1000,\n",
        "                                      })\n",
        "spot_1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def squared_euclidean_distance(X_0, X, theta):\n",
        "    return np.sum(theta*(X_0 - X)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import array, zeros, power, ones, exp, multiply, eye, linspace, mat, spacing, sqrt, arange, append, ravel\n",
        "from numpy.linalg import cholesky, solve\n",
        "from numpy.random import multivariate_normal\n",
        "def build_Psi(X, theta):\n",
        "    n = X.shape[0]\n",
        "    k = X.shape[1]\n",
        "    D = zeros((k, n, n))\n",
        "    for l in range(k):\n",
        "        for i in range(n):\n",
        "            for j in range(i, n):\n",
        "                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n",
        "    D = sum(D)\n",
        "    D = D + D.T\n",
        "    return exp(-D)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "theta = np.array([1.0, 1.0])\n",
        "X = np.array([[1.0, 0.0], [1.0, 1.0], [0.0, 1.0]])\n",
        "print(X.shape)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "build_Psi(X, theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "import numpy as np\n",
        "X = np.array([[0, 0, 0], [0, 0, 1], [0, 0, 2]])\n",
        "fun = analytical()\n",
        "fun.fun_branin_factor(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "pi = np.pi\n",
        "X = np.array([[0,0], [-pi, 12.275], [pi, 2.275], [9.42478, 2.475]])\n",
        "fun = analytical()\n",
        "fun.fun_branin(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "import numpy as np\n",
        "pi = np.pi\n",
        "X_0 = np.array([[0, 0]])\n",
        "X_1 = np.array([[-pi, 12.275], [pi, 2.275], [9.42478, 2.475]])\n",
        "X_2 = np.array([[0,0,0], [0,0,1], [0,0,2]])\n",
        "fun = analytical()\n",
        "y_0 = fun.fun_branin(X_0)\n",
        "y_1 = fun.fun_branin(X_1)\n",
        "y_2 = fun.fun_branin_factor(X_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "round(y_1[0], 2) == round(y_1[1],2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "round(y_1[0], 2) == round(y_1[2],2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y_2[0] == y_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y_2[1] == y_0 + 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y_2[2] == y_0 - 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy.random import multivariate_normal\n",
        "import numpy as np\n",
        "n = 100\n",
        "X = np.linspace(0, 10, n, endpoint=False).reshape(-1,1)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import array, zeros, power, ones, exp, multiply, eye, linspace, mat, spacing, sqrt, arange, append, ravel\n",
        "from numpy.linalg import cholesky, solve\n",
        "from numpy.random import multivariate_normal\n",
        "def build_Psi(X, theta):\n",
        "    n = X.shape[0]\n",
        "    k = X.shape[1]\n",
        "    D = zeros((k, n, n))\n",
        "    for l in range(k):\n",
        "        for i in range(n):\n",
        "            for j in range(i, n):\n",
        "                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n",
        "    D = sum(D)\n",
        "    D = D + D.T\n",
        "    return exp(-D)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "theta = np.array([1.0])\n",
        "Psi = build_Psi(X, theta)\n",
        "np.round(Psi[:3,:], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = multivariate_normal(zeros(Psi.shape[0]), Psi, size = (3, 1, 1), check_valid=\"raise\")\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert Y to a 3 x 100 array\n",
        "Y = np.squeeze(Y)\n",
        "Y.shape\n",
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot 3 samples from the GP as a function of X\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, Y.T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = multivariate_normal(zeros(Psi.shape[0]), Psi, size = 3, check_valid=\"raise\")\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot 3 samples from the GP as a function of X\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, Y.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size: 5\n",
            "Inputs Shape: torch.Size([5, 133])\n",
            "Targets Shape: torch.Size([5])\n",
            "---------------\n",
            "Inputs: tensor([[9.6160e+03, 1.8910e+03, 1.0000e+00, 3.9000e-01, 1.0000e+02, 2.0000e+00,\n",
            "         2.5120e+01, 2.1188e+04, 2.2000e+01, 7.7740e+03, 4.0000e+00, 1.4000e+01,\n",
            "         6.5245e+00, 8.1855e+00, 8.5495e+00, 7.8658e+03, 1.2825e+00, 1.2546e+00,\n",
            "         1.3104e+00, 2.1754e-02, 1.0000e+00, 3.6689e+00, 1.0382e+00, 1.5438e-03,\n",
            "         1.1253e-03, 9.0749e-04, 7.7623e+03, 7.7710e+03, 7.7796e+03, 8.0863e+00,\n",
            "         9.6301e-01, 6.0000e+00, 2.5200e+01, 2.1188e+04, 9.7140e-01, 3.7693e+00,\n",
            "         3.7098e+00, 3.7597e+00, 1.2018e-02, 4.2519e+00, 1.3915e-02, 1.4580e+00,\n",
            "         1.0388e+02, 2.1310e+04, 9.5966e+01, 1.9150e+01, 2.4188e+02, 4.7709e+02,\n",
            "         2.6922e+02, 2.2574e+02, 1.7324e+01, 2.8234e+01, 6.0624e+01, 8.2381e+01,\n",
            "         2.3560e+01, 2.4310e+01, 3.7574e+00, 3.7848e+00, 9.5966e+01, 2.1341e+04,\n",
            "         5.4976e+02, 1.5538e+01, 1.3392e+01, 1.7141e+05, 7.6138e-01, 7.5385e-01,\n",
            "         2.1310e+04, 5.4896e+02, 1.5414e+01, 1.3372e+01, 1.7092e+05, 1.6907e+05,\n",
            "         2.0578e+03, 9.7140e-01, 4.8070e+00, 9.7140e-01, 4.7407e+00, 4.9485e+00,\n",
            "         4.8803e+00, 4.8803e+00, 2.9230e+02, 5.1523e+02, 1.4012e+00, 1.1527e+00,\n",
            "         3.2040e+00, 8.0775e-01, 1.2813e-01, 1.1343e+00, 3.2567e-01, 2.8831e+00,\n",
            "         1.5990e+00, 7.4490e-01, 1.0773e-01, 1.5522e+01, 7.5039e+02, 5.4260e+02,\n",
            "         1.3649e+00, 2.8952e+02, 2.1590e+00, 6.2074e-01, 3.7321e+02, 7.7792e+02,\n",
            "         2.6099e-01, 1.0070e+00, 7.9601e-01, 8.1239e-01, 9.7983e-01, 6.0606e-01,\n",
            "         5.9952e-01, 6.0195e-01, 2.8005e+05, 1.6365e+03, 2.4374e+03, 4.7167e+00,\n",
            "         9.8620e-01, 4.6812e+00, 9.7099e-01, 4.7826e+00, 4.8576e+00, 4.8211e+00,\n",
            "         4.9162e-01, 7.4156e-01, 6.7543e+04, 1.7819e+05, 3.4601e+06, 1.4974e+00,\n",
            "         7.3615e-01, 1.1447e-01, 8.8202e+02, 4.9980e+02, 3.0411e-02, 1.4040e+03,\n",
            "         4.7000e+01],\n",
            "        [9.6100e+03, 1.8850e+03, 1.0000e+00, 3.9000e-01, 1.0000e+02, 2.0000e+00,\n",
            "         2.6720e+01, 2.1154e+04, 2.2000e+01, 7.7562e+03, 4.0000e+00, 1.3000e+01,\n",
            "         4.0326e+00, 8.5542e+00, 9.3465e+00, 7.6611e+03, 2.2195e+00, 2.1213e+00,\n",
            "         2.3177e+00, 4.4260e-02, 1.0000e+00, 6.1716e+00, 1.0783e+00, 1.5438e-03,\n",
            "         3.3387e-02, 2.7593e-02, 7.5374e+03, 7.8111e+03, 8.0576e+03, 8.7844e+00,\n",
            "         9.5178e-01, 9.0000e+00, 2.6800e+01, 2.1166e+04, 9.7140e-01, 3.7693e+00,\n",
            "         3.7098e+00, 3.7597e+00, 1.2018e-02, 4.2519e+00, 1.3915e-02, 1.4580e+00,\n",
            "         1.0388e+02, 2.1310e+04, 9.5966e+01, 1.9150e+01, 2.4188e+02, 4.7709e+02,\n",
            "         2.6922e+02, 2.2574e+02, 1.7324e+01, 2.8234e+01, 6.0624e+01, 8.2381e+01,\n",
            "         2.3560e+01, 2.4310e+01, 3.7574e+00, 3.7848e+00, 9.5966e+01, 2.1341e+04,\n",
            "         5.4976e+02, 1.5538e+01, 1.3392e+01, 1.7141e+05, 7.6138e-01, 7.5385e-01,\n",
            "         2.1310e+04, 5.4896e+02, 1.5414e+01, 1.3372e+01, 1.7092e+05, 1.6907e+05,\n",
            "         2.0578e+03, 9.7140e-01, 4.8070e+00, 9.7140e-01, 4.7407e+00, 4.9485e+00,\n",
            "         4.8803e+00, 4.8803e+00, 2.9230e+02, 5.1523e+02, 1.4012e+00, 1.1527e+00,\n",
            "         3.2040e+00, 8.0775e-01, 1.2813e-01, 1.1343e+00, 3.2567e-01, 2.8831e+00,\n",
            "         1.5990e+00, 7.4490e-01, 1.0773e-01, 1.5522e+01, 7.5039e+02, 5.4260e+02,\n",
            "         1.3649e+00, 2.8952e+02, 2.1590e+00, 6.2074e-01, 3.7321e+02, 7.7792e+02,\n",
            "         2.6099e-01, 1.0070e+00, 7.9601e-01, 8.1239e-01, 9.7983e-01, 6.0606e-01,\n",
            "         5.9952e-01, 6.0195e-01, 2.8005e+05, 1.6365e+03, 2.4374e+03, 4.7167e+00,\n",
            "         9.8620e-01, 4.6812e+00, 9.7099e-01, 4.7826e+00, 4.8576e+00, 4.8211e+00,\n",
            "         4.9162e-01, 7.4156e-01, 6.7543e+04, 1.7819e+05, 3.4601e+06, 1.4974e+00,\n",
            "         7.3615e-01, 1.1447e-01, 8.8202e+02, 4.9980e+02, 3.0411e-02, 1.3040e+03,\n",
            "         4.4000e+01],\n",
            "        [8.6160e+03, 1.7590e+03, 1.0000e+00, 3.9000e-01, 1.0000e+02, 1.0000e+00,\n",
            "         2.8000e+01, 2.1137e+04, 2.4000e+01, 8.4556e+03, 3.0000e+00, 1.7000e+01,\n",
            "         4.1870e+00, 8.4650e+00, 9.2105e+00, 8.5039e+03, 2.1108e+00, 2.0217e+00,\n",
            "         2.1998e+00, 4.2181e-02, 1.0000e+00, 2.7333e+00, 1.0018e+00, 9.1086e-04,\n",
            "         5.2291e-04, 5.0768e-04, 8.4525e+03, 8.4569e+03, 8.4613e+03, 8.9219e+00,\n",
            "         9.7819e-01, 7.0000e+00, 2.8000e+01, 2.1155e+04, 9.7140e-01, 3.7693e+00,\n",
            "         3.7098e+00, 3.7597e+00, 1.2018e-02, 4.2519e+00, 1.3915e-02, 1.4580e+00,\n",
            "         1.0388e+02, 2.1310e+04, 9.5966e+01, 1.9150e+01, 2.4188e+02, 4.7709e+02,\n",
            "         2.6922e+02, 2.2574e+02, 1.7324e+01, 2.8234e+01, 6.0624e+01, 8.2381e+01,\n",
            "         2.3560e+01, 2.4310e+01, 3.7574e+00, 3.7848e+00, 9.5966e+01, 2.1341e+04,\n",
            "         5.4976e+02, 1.5538e+01, 1.3392e+01, 1.7141e+05, 7.6138e-01, 7.5385e-01,\n",
            "         2.1310e+04, 5.4896e+02, 1.5414e+01, 1.3372e+01, 1.7092e+05, 1.6907e+05,\n",
            "         2.0578e+03, 9.7140e-01, 4.8070e+00, 9.7140e-01, 4.7407e+00, 4.9485e+00,\n",
            "         4.8803e+00, 4.8803e+00, 2.9230e+02, 5.1523e+02, 1.4012e+00, 1.1527e+00,\n",
            "         3.2040e+00, 8.0775e-01, 1.2813e-01, 1.1343e+00, 3.2567e-01, 2.8831e+00,\n",
            "         1.5990e+00, 7.4490e-01, 1.0773e-01, 1.5522e+01, 7.5039e+02, 5.4260e+02,\n",
            "         1.3649e+00, 2.8952e+02, 2.1590e+00, 6.2074e-01, 3.7321e+02, 7.7792e+02,\n",
            "         2.6099e-01, 1.0070e+00, 7.9601e-01, 8.1239e-01, 9.7983e-01, 6.0606e-01,\n",
            "         5.9952e-01, 6.0195e-01, 2.8005e+05, 1.6365e+03, 2.4374e+03, 4.7167e+00,\n",
            "         9.8620e-01, 4.6812e+00, 9.7099e-01, 4.7826e+00, 4.8576e+00, 4.8211e+00,\n",
            "         4.9162e-01, 7.4156e-01, 6.7543e+04, 1.7819e+05, 3.4601e+06, 1.4974e+00,\n",
            "         7.3615e-01, 1.1447e-01, 8.8202e+02, 4.9980e+02, 3.0411e-02, 1.7030e+03,\n",
            "         5.1000e+01],\n",
            "        [9.5910e+03, 1.3410e+03, 1.0000e+00, 3.9000e-01, 1.0000e+02, 0.0000e+00,\n",
            "         3.2160e+01, 2.1119e+04, 2.2000e+01, 7.7483e+03, 4.0000e+00, 1.3000e+01,\n",
            "         5.3501e+00, 1.1349e+01, 1.2400e+01, 7.6611e+03, 2.2195e+00, 2.1213e+00,\n",
            "         2.3177e+00, 4.4260e-02, 1.0000e+00, 6.1716e+00, 1.0783e+00, 1.5438e-03,\n",
            "         4.0283e-04, 3.0987e-04, 7.7442e+03, 7.7473e+03, 7.7504e+03, 1.0702e+01,\n",
            "         9.1062e-01, 8.0000e+00, 3.2200e+01, 2.1096e+04, 9.7139e-01, 3.7733e+00,\n",
            "         3.6837e+00, 3.7359e+00, 7.2989e-03, 4.2018e+00, 1.2804e-02, 1.4583e+00,\n",
            "         1.0341e+02, 2.1185e+04, 9.5964e+01, 1.8792e+01, 2.4039e+02, 4.7351e+02,\n",
            "         2.6540e+02, 2.2472e+02, 1.7321e+01, 2.8227e+01, 6.0638e+01, 8.2435e+01,\n",
            "         2.3543e+01, 2.4310e+01, 3.7362e+00, 3.7600e+00, 9.5964e+01, 2.1229e+04,\n",
            "         5.4687e+02, 1.2093e+01, 1.0423e+01, 1.7079e+05, 7.6182e-01, 7.5725e-01,\n",
            "         2.1185e+04, 5.4574e+02, 1.2003e+01, 1.0401e+01, 1.7009e+05, 1.6897e+05,\n",
            "         1.2422e+03, 9.7139e-01, 4.7847e+00, 9.7139e-01, 4.7447e+00, 4.9256e+00,\n",
            "         4.8844e+00, 4.8844e+00, 2.9194e+02, 5.1366e+02, 1.4012e+00, 1.1541e+00,\n",
            "         3.2114e+00, 8.0799e-01, 1.0025e-01, 1.1422e+00, 2.8657e-01, 3.2651e+00,\n",
            "         1.5906e+00, 7.4963e-01, 1.0286e-01, 1.2106e+01, 7.4675e+02, 5.3869e+02,\n",
            "         1.3654e+00, 2.8950e+02, 2.1559e+00, 6.2422e-01, 3.7150e+02, 7.7524e+02,\n",
            "         2.0479e-01, 1.0086e+00, 7.9795e-01, 8.1679e-01, 9.7694e-01, 6.0790e-01,\n",
            "         6.0391e-01, 6.0542e-01, 2.7742e+05, 9.9842e+02, 1.4663e+03, 4.6767e+00,\n",
            "         9.8014e-01, 4.6551e+00, 9.7096e-01, 4.7714e+00, 4.8165e+00, 4.7943e+00,\n",
            "         4.9105e-01, 7.4070e-01, 6.7362e+04, 1.8231e+05, 2.6799e+06, 1.4939e+00,\n",
            "         7.3359e-01, 8.9622e-02, 6.9218e+02, 4.9860e+02, 2.3760e-02, 1.3040e+03,\n",
            "         4.4000e+01],\n",
            "        [9.6240e+03, 2.7450e+03, 1.0000e+00, 3.9000e-01, 1.0000e+02, 7.0000e+00,\n",
            "         5.1040e+01, 2.0897e+04, 2.5000e+01, 8.7061e+03, 2.0000e+00, 1.9000e+01,\n",
            "         3.1848e+00, 7.0645e+00, 7.3190e+00, 8.7936e+03, 2.2581e+00, 2.2182e+00,\n",
            "         2.2981e+00, 1.7694e-02, 1.0000e+00, 8.6307e+00, 1.0984e+00, 2.7517e-03,\n",
            "         4.7616e-04, 4.1406e-04, 8.7017e+03, 8.7058e+03, 8.7099e+03, 7.4160e+00,\n",
            "         9.5300e-01, 7.0000e+00, 5.1000e+01, 2.0901e+04, 9.7139e-01, 3.7320e+00,\n",
            "         3.6140e+00, 3.6647e+00, 9.2129e-03, 4.0983e+00, 1.1915e-02, 1.4722e+00,\n",
            "         1.0307e+02, 2.0966e+04, 9.5963e+01, 1.9120e+01, 2.3685e+02, 4.6544e+02,\n",
            "         2.5984e+02, 2.2385e+02, 1.7368e+01, 2.8230e+01, 6.0792e+01, 8.2441e+01,\n",
            "         2.3571e+01, 2.4341e+01, 3.6774e+00, 3.7051e+00, 9.5963e+01, 2.0998e+04,\n",
            "         5.4092e+02, 1.3498e+01, 1.1633e+01, 1.6992e+05, 7.7214e-01, 7.6630e-01,\n",
            "         2.0966e+04, 5.4011e+02, 1.3390e+01, 1.1616e+01, 1.6940e+05, 1.6801e+05,\n",
            "         1.5496e+03, 9.7139e-01, 4.7533e+00, 9.7139e-01, 4.7034e+00, 4.8933e+00,\n",
            "         4.8419e+00, 4.8419e+00, 2.9227e+02, 5.1015e+02, 1.4012e+00, 1.1528e+00,\n",
            "         3.2074e+00, 8.1619e-01, 1.1312e-01, 1.1614e+00, 3.0062e-01, 3.0866e+00,\n",
            "         1.5733e+00, 7.5209e-01, 9.8263e-02, 1.3488e+01, 7.3870e+02, 5.3316e+02,\n",
            "         1.3662e+00, 2.8945e+02, 2.1478e+00, 6.3118e-01, 3.6868e+02, 7.7141e+02,\n",
            "         2.3007e-01, 1.0073e+00, 7.9972e-01, 8.2169e-01, 9.7326e-01, 6.1749e-01,\n",
            "         6.1240e-01, 6.1435e-01, 2.7234e+05, 1.2487e+03, 1.7802e+03, 4.6123e+00,\n",
            "         9.8226e-01, 4.5854e+00, 9.7098e-01, 4.6956e+00, 4.7501e+00, 4.7224e+00,\n",
            "         4.9049e-01, 7.3986e-01, 6.6694e+04, 1.8318e+05, 2.9377e+06, 1.4881e+00,\n",
            "         7.2991e-01, 1.0077e-01, 7.8129e+02, 4.9594e+02, 2.6505e-02, 1.9020e+03,\n",
            "         5.5000e+01]])\n",
            "Targets: tensor([ 8.3675,  8.9504,  8.8377, 11.8744,  7.1918])\n"
          ]
        }
      ],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "# dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True)\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(f\"Inputs Shape: {inputs.shape}\")\n",
        "    print(f\"Targets Shape: {targets.shape}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test HyperLight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 1234\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.hyperparameters.values import get_var_name\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                            fun_control=fun_control,\n",
        "                            hyper_dict=LightHyperDict)\n",
        "hyper_light = HyperLight(seed=126, log_level=50)\n",
        "n_hyperparams = len(get_var_name(fun_control))\n",
        "# generate a random np.array X with shape (2, n_hyperparams)\n",
        "X = np.random.rand(2, n_hyperparams)\n",
        "X == hyper_light.check_X_shape(X, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 1234\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory runs/lightning_logs/-2621019871347415348/checkpoints exists and is not empty.\n",
            "\n",
            "  | Name   | Type       | Params | In sizes | Out sizes\n",
            "-------------------------------------------------------------\n",
            "0 | layers | Sequential | 157    | [16, 10] | [16, 1]  \n",
            "-------------------------------------------------------------\n",
            "157       Trainable params\n",
            "0         Non-trainable params\n",
            "157       Total params\n",
            "0.001     Total estimated model params size (MB)\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train_model(): Test set size: 266\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">       27259.2421875       </span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">       27259.2421875       </span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m      27259.2421875      \u001b[0m\u001b[35m \u001b[0m\n",
              "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m      27259.2421875      \u001b[0m\u001b[35m \u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params | In sizes | Out sizes\n",
            "-------------------------------------------------------------\n",
            "0 | layers | Sequential | 157    | [16, 10] | [16, 1]  \n",
            "-------------------------------------------------------------\n",
            "157       Trainable params\n",
            "0         Non-trainable params\n",
            "157       Total params\n",
            "0.001     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 27259.2421875, 'hp_metric': 27259.2421875}\n",
            "Train_model(): Test set size: 266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">      24221.275390625      </span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">      24221.275390625      </span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m     24221.275390625     \u001b[0m\u001b[35m \u001b[0m\n",
              "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m     24221.275390625     \u001b[0m\u001b[35m \u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 24221.275390625, 'hp_metric': 24221.275390625}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([27259.2421875 , 24221.27539062])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import (add_core_model_to_fun_control,\n",
        "    get_default_hyperparameters_as_array)\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.hyperparameters.values import set_data_set\n",
        "import numpy as np\n",
        "fun_control = fun_control_init(\n",
        "    _L_in=10,\n",
        "    _L_out=1,)\n",
        "dataset = Diabetes()\n",
        "set_data_set(fun_control=fun_control,\n",
        "                data_set=dataset)\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                            fun_control=fun_control,\n",
        "                            hyper_dict=LightHyperDict)\n",
        "hyper_light = HyperLight(seed=126, log_level=50)\n",
        "X = get_default_hyperparameters_as_array(fun_control)\n",
        "# combine X and X to a np.array with shape (2, n_hyperparams)\n",
        "# so that two values are returned\n",
        "X = np.vstack((X, X))\n",
        "hyper_light.fun(X, fun_control)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
