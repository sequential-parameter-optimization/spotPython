{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "title: 'spotPython Tests'\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fun_control_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(_L_in=64, _L_out=11, num_workers=0, device=None)\n",
        "fun_control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def class_attributes_to_dataframe(class_obj):\n",
        "    # Get the attributes and their values of the class object\n",
        "    attributes = [attr for attr in dir(class_obj) if not callable(getattr(class_obj, attr)) and not attr.startswith(\"__\")]\n",
        "    values = [getattr(class_obj, attr) for attr in attributes]\n",
        "    \n",
        "    # Create a DataFrame from the attributes and values\n",
        "    df = pd.DataFrame({'Attribute Name': attributes, 'Attribute Value': values})\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        self.name = \"John\"\n",
        "        self.age = 30\n",
        "        self.salary = 50000\n",
        "\n",
        "my_instance = MyClass()\n",
        "df = class_attributes_to_dataframe(my_instance)\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import inf\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "# number of initial points:\n",
        "ni = 7\n",
        "# number of points\n",
        "n = 10\n",
        "\n",
        "fun = analytical().fun_sphere\n",
        "lower = np.array([-1])\n",
        "upper = np.array([1])\n",
        "design_control={\"init_size\": ni}\n",
        "\n",
        "spot_1 = spot.Spot(fun=fun,\n",
        "            lower = lower,\n",
        "            upper= upper,\n",
        "            fun_evals = n,\n",
        "            show_progress=True,\n",
        "            design_control=design_control,)\n",
        "spot_1.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sys import stdout\n",
        "df = spot_1.class_attributes_to_dataframe()\n",
        "stdout.write(df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from river import datasets\n",
        "from river import evaluate\n",
        "from river.linear_model import LogisticRegression\n",
        "from river import metrics\n",
        "from river import optim\n",
        "from river import preprocessing\n",
        "\n",
        "dataset = datasets.Phishing()\n",
        "\n",
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "metric = metrics.Accuracy()\n",
        "\n",
        "evaluate.progressive_val_score(dataset, model, metric)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.csvdataset import CSVDataset\n",
        "dataset = CSVDataset(csv_file='./data/spotPython/data.csv', target_column='prognosis')\n",
        "print(dataset.data.shape)\n",
        "print(dataset.targets.shape)            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.extra_repr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 3\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSV Data set Sensitive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from ./data/spotPython/data.csv\n",
            "Target column: prognosis\n",
            "Data shape: (11, 65)\n",
            "Data head:\n",
            "   sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain  \\\n",
            "0             1         0            0           0            1           1   \n",
            "1             1         0            0           0            1           1   \n",
            "2             1         1            1           1            0           1   \n",
            "3             1         1            0           1            1           0   \n",
            "4             0         0            1           0            0           1   \n",
            "\n",
            "   vomiting  rash  diarrhea  hypotension  ...  breathing_restriction  \\\n",
            "0         1     1         0            0  ...                      0   \n",
            "1         1     1         0            1  ...                      0   \n",
            "2         0     1         0            1  ...                      0   \n",
            "3         0     0         0            0  ...                      0   \n",
            "4         0     0         0            0  ...                      0   \n",
            "\n",
            "   toe_inflammation  finger_inflammation  lips_irritation  itchiness  ulcers  \\\n",
            "0                 0                    0                0          0       0   \n",
            "1                 0                    0                0          0       0   \n",
            "2                 1                    0                1          0       0   \n",
            "3                 0                    0                0          0       0   \n",
            "4                 0                    0                0          0       0   \n",
            "\n",
            "   toenail_loss  speech_problem  bullseye_rash          prognosis  \n",
            "0             0               0              0        Chikungunya  \n",
            "1             1               0              0             Dengue  \n",
            "2             0               0              0  Rift Valley fever  \n",
            "3             0               0              0       Yellow Fever  \n",
            "4             0               0              0               Zika  \n",
            "\n",
            "[5 rows x 65 columns]\n",
            "Data describe:\n",
            "       sudden_fever   headache  mouth_bleed  nose_bleed  muscle_pain  \\\n",
            "count     11.000000  11.000000    11.000000   11.000000    11.000000   \n",
            "mean       0.636364   0.636364     0.363636    0.454545     0.545455   \n",
            "std        0.504525   0.504525     0.504525    0.522233     0.522233   \n",
            "min        0.000000   0.000000     0.000000    0.000000     0.000000   \n",
            "25%        0.000000   0.000000     0.000000    0.000000     0.000000   \n",
            "50%        1.000000   1.000000     0.000000    0.000000     1.000000   \n",
            "75%        1.000000   1.000000     1.000000    1.000000     1.000000   \n",
            "max        1.000000   1.000000     1.000000    1.000000     1.000000   \n",
            "\n",
            "       joint_pain   vomiting       rash   diarrhea  hypotension  ...  \\\n",
            "count   11.000000  11.000000  11.000000  11.000000    11.000000  ...   \n",
            "mean     0.636364   0.545455   0.636364   0.181818     0.363636  ...   \n",
            "std      0.504525   0.522233   0.504525   0.404520     0.504525  ...   \n",
            "min      0.000000   0.000000   0.000000   0.000000     0.000000  ...   \n",
            "25%      0.000000   0.000000   0.000000   0.000000     0.000000  ...   \n",
            "50%      1.000000   1.000000   1.000000   0.000000     0.000000  ...   \n",
            "75%      1.000000   1.000000   1.000000   0.000000     1.000000  ...   \n",
            "max      1.000000   1.000000   1.000000   1.000000     1.000000  ...   \n",
            "\n",
            "       lymph_swells  breathing_restriction  toe_inflammation  \\\n",
            "count     11.000000              11.000000         11.000000   \n",
            "mean       0.363636               0.181818          0.272727   \n",
            "std        0.504525               0.404520          0.467099   \n",
            "min        0.000000               0.000000          0.000000   \n",
            "25%        0.000000               0.000000          0.000000   \n",
            "50%        0.000000               0.000000          0.000000   \n",
            "75%        1.000000               0.000000          0.500000   \n",
            "max        1.000000               1.000000          1.000000   \n",
            "\n",
            "       finger_inflammation  lips_irritation  itchiness     ulcers  \\\n",
            "count            11.000000        11.000000  11.000000  11.000000   \n",
            "mean              0.090909         0.181818   0.181818   0.181818   \n",
            "std               0.301511         0.404520   0.404520   0.404520   \n",
            "min               0.000000         0.000000   0.000000   0.000000   \n",
            "25%               0.000000         0.000000   0.000000   0.000000   \n",
            "50%               0.000000         0.000000   0.000000   0.000000   \n",
            "75%               0.000000         0.000000   0.000000   0.000000   \n",
            "max               1.000000         1.000000   1.000000   1.000000   \n",
            "\n",
            "       toenail_loss  speech_problem  bullseye_rash  \n",
            "count     11.000000       11.000000      11.000000  \n",
            "mean       0.181818        0.090909       0.090909  \n",
            "std        0.404520        0.301511       0.301511  \n",
            "min        0.000000        0.000000       0.000000  \n",
            "25%        0.000000        0.000000       0.000000  \n",
            "50%        0.000000        0.000000       0.000000  \n",
            "75%        0.000000        0.000000       0.000000  \n",
            "max        1.000000        1.000000       1.000000  \n",
            "\n",
            "[8 rows x 64 columns]\n"
          ]
        }
      ],
      "source": [
        "from spotPython.light.csvdataset import CSVDataset\n",
        "dataset = CSVDataset(csv_file='./data/spotPython/data.csv', target_column='prognosis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size: 11\n",
            "---------------\n",
            "Inputs: tensor([[1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "         0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
            "         1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
            "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
            "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
            "         1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
            "         1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
            "         1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
            "         0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
            "         1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
            "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
            "         0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
            "         1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
            "         0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
            "         0., 1., 1., 0., 0., 1., 1., 0., 1., 1.]])\n",
            "Targets: tensor([ 0,  1,  6,  9, 10,  4,  2,  8,  5,  7,  3])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 100\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
