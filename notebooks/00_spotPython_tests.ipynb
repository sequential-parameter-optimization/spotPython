{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  cache: false\n",
    "  eval: true\n",
    "  echo: true\n",
    "  warning: false\n",
    "title: 'spotpython Tests'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fun_control_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "fun_control = fun_control_init(_L_in=64, _L_out=11, num_workers=0, device=None)\n",
    "fun_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def class_attributes_to_dataframe(class_obj):\n",
    "    # Get the attributes and their values of the class object\n",
    "    attributes = [attr for attr in dir(class_obj) if not callable(getattr(class_obj, attr)) and not attr.startswith(\"__\")]\n",
    "    values = [getattr(class_obj, attr) for attr in attributes]\n",
    "    \n",
    "    # Create a DataFrame from the attributes and values\n",
    "    df = pd.DataFrame({'Attribute Name': attributes, 'Attribute Value': values})\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        self.name = \"John\"\n",
    "        self.age = 30\n",
    "        self.salary = 50000\n",
    "\n",
    "my_instance = MyClass()\n",
    "df = class_attributes_to_dataframe(my_instance)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import inf\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "# number of initial points:\n",
    "ni = 7\n",
    "# number of points\n",
    "n = 10\n",
    "\n",
    "fun = analytical().fun_sphere\n",
    "lower = np.array([-1])\n",
    "upper = np.array([1])\n",
    "design_control={\"init_size\": ni}\n",
    "\n",
    "spot_1 = spot.Spot(fun=fun,\n",
    "            lower = lower,\n",
    "            upper= upper,\n",
    "            fun_evals = n,\n",
    "            show_progress=True,\n",
    "            design_control=design_control,)\n",
    "spot_1.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "df = spot_1.class_attributes_to_dataframe()\n",
    "stdout.write(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "from river import evaluate\n",
    "from river.linear_model import LogisticRegression\n",
    "from river import metrics\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "\n",
    "dataset = datasets.Phishing()\n",
    "\n",
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.csvdataset import CSVDataset\n",
    "# dataset = CSVDataset(csv_file='./data/spotpython/data.csv', target_column='prognosis')\n",
    "dataset = CSVDataset(target_column='prognosis')\n",
    "print(dataset.data.shape)\n",
    "print(dataset.targets.shape)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.extra_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 3\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Data set VBDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv_file='./data/spotpython/data.csv' as a pandas df and save it as a pickle file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/spotpython/data.csv')\n",
    "df.to_pickle('./data/spotpython/data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.csvdataset import CSVDataset\n",
    "import torch\n",
    "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyHcf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhcf.data.daten_sensitive import DatenSensitive\n",
    "from pyhcf.utils.names import get_short_parameter_names\n",
    "daten = DatenSensitive()\n",
    "df = daten.load()\n",
    "names =  df.columns\n",
    "names = get_short_parameter_names(names)\n",
    "# rename columns with short names\n",
    "df.columns = names\n",
    "df.head()\n",
    "# save the df as a csv file\n",
    "df.to_csv('./data/spotpython/data_sensitive.csv', index=False)\n",
    "# save the df as a pickle file\n",
    "df.to_pickle('./data/spotpython/data_sensitive.pkl')\n",
    "# remove all rows with NaN values\n",
    "df = df.dropna()\n",
    "# save the df as a csv file\n",
    "df.to_csv('./data/spotpython/data_sensitive_rmNA.csv', index=False)\n",
    "# save the df as a pickle file\n",
    "df.to_pickle('./data/spotpython/data_sensitive_rmNA.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyHcf data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotpython.light.csvdataset import CSVDataset\n",
    "# import torch\n",
    "# dataset = CSVDataset(csv_file='./data/spotpython/data_sensitive.csv', target_column='N', feature_type=torch.float32, target_type=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# # Set batch size for DataLoader\n",
    "# batch_size = 5000\n",
    "# # Create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Iterate over the data in the DataLoader\n",
    "# for batch in dataloader:\n",
    "#     inputs, targets = batch\n",
    "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
    "#     print(\"---------------\")\n",
    "#     # print(f\"Inputs: {inputs}\")\n",
    "#     print(f\"Targets: {targets}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotpython.light.csvdataset import CSVDataset\n",
    "# import torch\n",
    "# dataset = CSVDataset(csv_file='./data/spotpython/data_sensitive.csv', target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# # Set batch size for DataLoader\n",
    "# batch_size = 5000\n",
    "# # Create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Iterate over the data in the DataLoader\n",
    "# for batch in dataloader:\n",
    "#     inputs, targets = batch\n",
    "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
    "#     print(\"---------------\")\n",
    "#     # print(f\"Inputs: {inputs}\")\n",
    "#     print(f\"Targets: {targets}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.pkldataset import PKLDataset\n",
    "import torch\n",
    "dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)\n",
    "dataset.feature_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.pkldataset import PKLDataset\n",
    "import torch\n",
    "dataset = PKLDataset(pkl_file='./data/spotpython/data_sensitive.pkl', target_column='A', feature_type=torch.long, rmNA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# # Set batch size for DataLoader\n",
    "# batch_size = 5\n",
    "# # Create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Iterate over the data in the DataLoader\n",
    "# for batch in dataloader:\n",
    "#     inputs, targets = batch\n",
    "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
    "#     print(\"---------------\")\n",
    "#     print(f\"Inputs: {inputs}\")\n",
    "#     print(f\"Targets: {targets}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.pkldataset import PKLDataset\n",
    "import torch\n",
    "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotpython/notebooks/data/spotpython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test lightdatamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "from spotpython.data.pkldataset import PKLDataset\n",
    "import torch\n",
    "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
    "# dataset = PKLDataset(directory=\"./data/spotpython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set size: {len(data_module.data_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation set size: {len(data_module.data_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test set size: {len(data_module.data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the DataModule in fun_control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "from spotpython.data.pkldataset import PKLDataset\n",
    "import torch\n",
    "fun_control = fun_control_init()\n",
    "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
    "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=7)\n",
    "dm.setup()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                key=\"data_module\",\n",
    "                value=dm, replace=True)\n",
    "data_module = fun_control[\"data_module\"]\n",
    "print(f\"Test set size: {len(data_module.data_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## same with the sensitive data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.pkldataset import PKLDataset\n",
    "import torch\n",
    "fun_control = fun_control_init()\n",
    "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotpython/notebooks/data/spotpython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)\n",
    "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=77)\n",
    "dm.setup()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                key=\"data_module\",\n",
    "                value=dm, replace=True)\n",
    "data_module = fun_control[\"data_module\"]\n",
    "print(f\"Test set size: {len(data_module.data_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## same, but VBDO data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "import torch\n",
    "fun_control = fun_control_init()\n",
    "dataset = CSVDataset(directory=\"/Users/bartz/workspace/spotpython/notebooks/data/VBDP/\", filename=\"train.csv\",target_column='prognosis', feature_type=torch.long)\n",
    "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=77)\n",
    "dm.setup()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                key=\"data_module\",\n",
    "                value=dm, replace=True)\n",
    "data_module = fun_control[\"data_module\"]\n",
    "print(f\"Test set size: {len(data_module.data_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Hyperdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "lhd = LightHyperDict()\n",
    "lhd.hyper_dict\n",
    "user_lhd = LightHyperDict(filename=\"user_hyper_dict.json\", directory=\"./hyperdict/\")\n",
    "user_lhd.hyper_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes  \n",
    "import torch\n",
    "\n",
    "# Load the diabetes dataset\n",
    "feature_df, target_df = load_diabetes(return_X_y=True, as_frame=True)\n",
    "feature_tensor = torch.tensor(feature_df.values, dtype=torch.float32)\n",
    "target_tensor = torch.tensor(target_df.values, dtype=torch.float32)\n",
    "feature_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.diabetes import Diabetes\n",
    "dataset = Diabetes()\n",
    "print(dataset.data.shape)\n",
    "print(dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add core model to fun control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.netlightregressione import NetLightRegression\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "fun_control = fun_control_init()\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=LightHyperDict)\n",
    "fun_control[\"core_model\"].__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the fun_control[\"core_model_hyper_dict\"] is a LightHyperDict\n",
    "isinstance(fun_control[\"core_model_hyper_dict\"], dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test check_X_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.light.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.hyperparameters.values import get_var_name\n",
    "fun_control = fun_control_init()\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=LightHyperDict)\n",
    "hyper_light = HyperLight(seed=126, log_level=50)\n",
    "n_hyperparams = len(get_var_name(fun_control))\n",
    "# generate a random np.array X with shape (2, n_hyperparams)\n",
    "X = np.random.rand(2, n_hyperparams)\n",
    "X == hyper_light.check_X_shape(X, fun_control)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test hyperlight fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.light.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "import numpy as np\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10,\n",
    "    _L_out=1,)\n",
    "\n",
    "dataset = Diabetes()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                    key=\"data_set\",\n",
    "                    value=dataset)\n",
    "\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=LightHyperDict)\n",
    "hyper_light = HyperLight(seed=126, log_level=50)\n",
    "X = get_default_hyperparameters_as_array(fun_control)\n",
    "# combine X and X to a np.array with shape (2, n_hyperparams)\n",
    "X = np.vstack((X, X))\n",
    "y = hyper_light.fun(X, fun_control)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test  NetLightRegression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.netlightregression import NetLightRegression\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "PATH_DATASETS = './data'\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "dataset = Diabetes()\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "batch_x, batch_y = next(iter(train_loader)) \n",
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "\n",
    "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
    "                                initialization='xavier', act_fn=nn.ReLU(),\n",
    "                                optimizer='Adam', dropout_prob=0.1, lr_mult=0.1,\n",
    "                                patience=5, _L_in=10, _L_out=1)\n",
    "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
    "trainer.fit(net_light_base, train_loader)\n",
    "trainer.validate(net_light_base, val_loader)\n",
    "trainer.test(net_light_base, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests optimizer_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.netlightregression import NetLightRegression\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "lr_mult=0.1\n",
    "\n",
    "dataset = Diabetes()\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
    "                                initialization='xavier', act_fn=nn.ReLU(),\n",
    "                                optimizer='Adam', dropout_prob=0.1, lr_mult=lr_mult,\n",
    "                                patience=5, _L_in=10, _L_out=1)\n",
    "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
    "trainer.fit(net_light_base, train_loader)\n",
    "# Adam uses a lr which is calculated as lr=lr_mult * 0.001, so this value\n",
    "# should be 0.1 * 0.001 = 0.0001 \n",
    "trainer.optimizers[0].param_groups[0][\"lr\"] == lr_mult*0.001\n",
    "\n",
    "\n",
    "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
    "                                initialization='xavier', act_fn=nn.ReLU(),\n",
    "                                optimizer='Adadelta', dropout_prob=0.1, lr_mult=lr_mult,\n",
    "                                patience=5, _L_in=10, _L_out=1)\n",
    "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
    "trainer.fit(net_light_base, train_loader)\n",
    "# Adadelta uses a lr which is calculated as lr=lr_mult * 1.0, so this value\n",
    "# should be 1.0 * 0.1 = 0.1 \n",
    "trainer.optimizers[0].param_groups[0][\"lr\"] == lr_mult*1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.light.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.hyperparameters.values import get_var_name, assign_values, generate_one_config_from_var_dict\n",
    "from spotpython.light.traintest import train_model, test_model\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10,\n",
    "    _L_out=1,)\n",
    "\n",
    "dataset = Diabetes()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset)\n",
    "\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=LightHyperDict)\n",
    "X = get_default_hyperparameters_as_array(fun_control)\n",
    "var_dict = assign_values(X, get_var_name(fun_control))\n",
    "for config in generate_one_config_from_var_dict(var_dict, fun_control):\n",
    "    y_train = train_model(config, fun_control)\n",
    "    y_test = test_model(config, fun_control)\n",
    "    break\n",
    "print(y_train)\n",
    "print(y_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.light.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.hyperparameters.values import get_var_name, assign_values, generate_one_config_from_var_dict\n",
    "from spotpython.light.traintest import test_model\n",
    "\n",
    "\n",
    "def test_traintest_test_model():\n",
    "    fun_control = fun_control_init(\n",
    "        _L_in=10,\n",
    "        _L_out=1,)\n",
    "\n",
    "    dataset = Diabetes()\n",
    "    set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset)\n",
    "\n",
    "    add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                                fun_control=fun_control,\n",
    "                                hyper_dict=LightHyperDict)\n",
    "    X = get_default_hyperparameters_as_array(fun_control)\n",
    "    var_dict = assign_values(X, get_var_name(fun_control))\n",
    "    for vals in generate_one_config_from_var_dict(var_dict, fun_control):\n",
    "        y_test = test_model(test_config=vals,\n",
    "                            fun_control=fun_control)\n",
    "        break\n",
    "    # check if y is a float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test getVarName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.hyperparameters.values import get_var_name\n",
    "fun_control = {\"core_model_hyper_dict\":{\n",
    "            \"leaf_prediction\": {\n",
    "                \"levels\": [\"mean\", \"model\", \"adaptive\"],\n",
    "                \"type\": \"factor\",\n",
    "                \"default\": \"mean\",\n",
    "                \"core_model_parameter_type\": \"str\"},\n",
    "            \"leaf_model\": {\n",
    "                \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n",
    "                \"type\": \"factor\",\n",
    "                \"default\": \"LinearRegression\",\n",
    "                \"core_model_parameter_type\": \"instance\"},\n",
    "            \"splitter\": {\n",
    "                \"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n",
    "                \"type\": \"factor\",\n",
    "                \"default\": \"EBSTSplitter\",\n",
    "                \"core_model_parameter_type\": \"instance()\"},\n",
    "            \"binary_split\": {\n",
    "                \"levels\": [0, 1],\n",
    "                \"type\": \"factor\",\n",
    "                \"default\": 0,\n",
    "                \"core_model_parameter_type\": \"bool\"},\n",
    "            \"stop_mem_management\": {\n",
    "                \"levels\": [0, 1],\n",
    "                \"type\": \"factor\",\n",
    "                \"default\": 0,\n",
    "                \"core_model_parameter_type\": \"bool\"}}}\n",
    "len(get_var_name(fun_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test netlightregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from spotpython.spot import spot\n",
    "from math import inf\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.utils.file import get_experiment_name, get_spot_tensorboard_path\n",
    "from spotpython.utils.device import getDevice\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.data.pkldataset import PKLDataset\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "from spotpython.hyperparameters.values import modify_hyper_parameter_bounds\n",
    "from spotpython.hyperparameters.values import modify_hyper_parameter_levels\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.hyperparameters.values import (get_bound_values,\n",
    "    get_var_name,\n",
    "    get_var_type,)\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "from spotpython.hyperparameters.values import get_tuned_architecture\n",
    "from spotpython.light.testmodel import test_model\n",
    "from spotpython.light.loadmodel import load_light_from_checkpoint\n",
    "\n",
    "MAX_TIME = 1\n",
    "INIT_SIZE = 5\n",
    "WORKERS = 0\n",
    "PREFIX=\"031\"\n",
    "\n",
    "experiment_name = get_experiment_name(prefix=PREFIX)\n",
    "fun_control = fun_control_init(\n",
    "    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name),\n",
    "    num_workers=WORKERS,\n",
    "    device=getDevice(),\n",
    "    _L_in=133,\n",
    "    _L_out=1,\n",
    "    TENSORBOARD_CLEAN=True)\n",
    "\n",
    "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotpython/notebooks/data/spotpython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True)\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset)\n",
    "\n",
    "\n",
    "\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=LightHyperDict)\n",
    "modify_hyper_parameter_bounds(fun_control, \"l1\", bounds=[5,8])\n",
    "modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[3,5])\n",
    "modify_hyper_parameter_bounds(fun_control, \"batch_size\", bounds=[2, 8])\n",
    "modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
    "\n",
    "print(gen_design_table(fun_control))\n",
    "\n",
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")\n",
    "fun = HyperLight(log_level=50).fun\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "                       log_level=50,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   max_time = MAX_TIME,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      })\n",
    "spot_tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.plot_progress(log_y=False, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.plot_importance(threshold=0.025, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_tuned_architecture(spot_tuner, fun_control)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = load_light_from_checkpoint(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.plot_important_hyperparameter_contour(filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.parallel_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.cvmodel import cv_model\n",
    "# set the number of folds to 10\n",
    "fun_control[\"k_folds\"] = 10\n",
    "cv_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.fun.objectivefunctions import analytical\n",
    "import numpy as np\n",
    "y = np.array([1, 2, 3, 4, 5])\n",
    "fun = analytical(sigma=1.0, seed=123)\n",
    "fun.add_noise(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.fun.objectivefunctions import analytical\n",
    "import numpy as np\n",
    "print(np.array([1, 2, 3, 4, 5]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import inf\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "from scipy.optimize import shgo\n",
    "from scipy.optimize import direct\n",
    "from scipy.optimize import differential_evolution\n",
    "import matplotlib.pyplot as plt\n",
    "from spotpython.utils.init import fun_control_init\n",
    "fun_control = fun_control_init(seed=4321, sigma=0.1)\n",
    "fun = analytical(seed=222, sigma=0.0).fun_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_1 = spot.Spot(fun=fun,\n",
    "                   lower = np.array([-10]),\n",
    "                   upper = np.array([100]),\n",
    "                   fun_evals = 100,\n",
    "                   fun_repeats = 3,\n",
    "                   max_time = inf,\n",
    "                   noise = True,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type=[\"num\"],\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=111,\n",
    "                   log_level = 10,\n",
    "                   show_models=False,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": 5,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": 1,\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 1000,\n",
    "                                      })\n",
    "spot_1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def squared_euclidean_distance(X_0, X, theta):\n",
    "    return np.sum(theta*(X_0 - X)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array, zeros, power, ones, exp, multiply, eye, linspace, mat, spacing, sqrt, arange, append, ravel\n",
    "from numpy.linalg import cholesky, solve\n",
    "from numpy.random import multivariate_normal\n",
    "def build_Psi(X, theta):\n",
    "    n = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    D = zeros((k, n, n))\n",
    "    for l in range(k):\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n",
    "    D = sum(D)\n",
    "    D = D + D.T\n",
    "    return exp(-D)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([1.0, 1.0])\n",
    "X = np.array([[1.0, 0.0], [1.0, 1.0], [0.0, 1.0]])\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_Psi(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.fun.objectivefunctions import analytical\n",
    "import numpy as np\n",
    "X = np.array([[0, 0, 0], [0, 0, 1], [0, 0, 2]])\n",
    "fun = analytical()\n",
    "fun.fun_branin_factor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pi = np.pi\n",
    "X = np.array([[0,0], [-pi, 12.275], [pi, 2.275], [9.42478, 2.475]])\n",
    "fun = analytical()\n",
    "fun.fun_branin(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.fun.objectivefunctions import analytical\n",
    "import numpy as np\n",
    "pi = np.pi\n",
    "X_0 = np.array([[0, 0]])\n",
    "X_1 = np.array([[-pi, 12.275], [pi, 2.275], [9.42478, 2.475]])\n",
    "X_2 = np.array([[0,0,0], [0,0,1], [0,0,2]])\n",
    "fun = analytical()\n",
    "y_0 = fun.fun_branin(X_0)\n",
    "y_1 = fun.fun_branin(X_1)\n",
    "y_2 = fun.fun_branin_factor(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(y_1[0], 2) == round(y_1[1],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "round(y_1[0], 2) == round(y_1[2],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_2[0] == y_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_2[1] == y_0 + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_2[2] == y_0 - 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import multivariate_normal\n",
    "import numpy as np\n",
    "n = 100\n",
    "X = np.linspace(0, 10, n, endpoint=False).reshape(-1,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array, zeros, power, ones, exp, multiply, eye, linspace, mat, spacing, sqrt, arange, append, ravel\n",
    "from numpy.linalg import cholesky, solve\n",
    "from numpy.random import multivariate_normal\n",
    "def build_Psi(X, theta):\n",
    "    n = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    D = zeros((k, n, n))\n",
    "    for l in range(k):\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n",
    "    D = sum(D)\n",
    "    D = D + D.T\n",
    "    return exp(-D)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([1.0])\n",
    "Psi = build_Psi(X, theta)\n",
    "np.round(Psi[:3,:], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = multivariate_normal(zeros(Psi.shape[0]), Psi, size = (3, 1, 1), check_valid=\"raise\")\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Y to a 3 x 100 array\n",
    "Y = np.squeeze(Y)\n",
    "Y.shape\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3 samples from the GP as a function of X\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, Y.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = multivariate_normal(zeros(Psi.shape[0]), Psi, size = 3, check_valid=\"raise\")\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3 samples from the GP as a function of X\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, Y.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.pkldataset import PKLDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)\n",
    "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotpython/notebooks/data/spotpython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True)\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test HyperLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.hyperparameters.values import get_var_name\n",
    "fun_control = fun_control_init()\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                            fun_control=fun_control,\n",
    "                            hyper_dict=LightHyperDict)\n",
    "hyper_light = HyperLight(seed=126, log_level=50)\n",
    "n_hyperparams = len(get_var_name(fun_control))\n",
    "# generate a random np.array X with shape (2, n_hyperparams)\n",
    "X = np.random.rand(2, n_hyperparams)\n",
    "X == hyper_light.check_X_shape(X, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import (add_core_model_to_fun_control,\n",
    "    get_default_hyperparameters_as_array)\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "import numpy as np\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10,\n",
    "    _L_out=1,)\n",
    "dataset = Diabetes()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset)\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                            fun_control=fun_control,\n",
    "                            hyper_dict=LightHyperDict)\n",
    "hyper_light = HyperLight(seed=126, log_level=50)\n",
    "X = get_default_hyperparameters_as_array(fun_control)\n",
    "# combine X and X to a np.array with shape (2, n_hyperparams)\n",
    "# so that two values are returned\n",
    "X = np.vstack((X, X))\n",
    "hyper_light.fun(X, fun_control)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test pkldataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.pkldataset import PKLDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)\n",
    "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotpython/notebooks/data/spotpython/\",\n",
    "                    filename=\"data_sensitive.pkl\",\n",
    "                    target_column='N',\n",
    "                    feature_type=torch.float32,\n",
    "                    target_type=torch.float32,\n",
    "                    rmNA=True)\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import get_bound_values\n",
    "from spotpython.hyperparameters.values import get_control_key_value, set_control_key_value\n",
    "from spotpython.hyperparameters.values import get_var_type_from_var_name\n",
    "\n",
    "fun_control = fun_control_init()\n",
    "set_control_key_value(control_dict=fun_control, key=\"var_type\", value=[\"int\", \"float\", \"str\"], replace=True)\n",
    "set_control_key_value(control_dict=fun_control, key=\"var_name\", value=[\"max_depth\", \"learning_rate\", \"model_type\"], replace=True)\n",
    "\n",
    "print(fun_control)\n",
    "\n",
    "# Test with existing var_name\n",
    "assert get_var_type_from_var_name(var_name=\"max_depth\", fun_control=fun_control) == \"int\"\n",
    "assert get_var_type_from_var_name(var_name=\"learning_rate\", fun_control=fun_control) == \"float\"\n",
    "assert get_var_type_from_var_name(var_name=\"model_type\", fun_control=fun_control) == \"str\"\n",
    "\n",
    "# Test with non-existing var_name\n",
    "with pytest.raises(ValueError):\n",
    "    get_var_type_from_var_name(var_name=\"non_existing\", fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import get_control_key_value\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "from spotpython.hyperparameters.values import get_var_type_from_var_name\n",
    "\n",
    "fun_control = fun_control_init()\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                    fun_control=fun_control,\n",
    "                    hyper_dict=LightHyperDict)\n",
    "var_type = get_control_key_value(control_dict=fun_control, key=\"var_type\")\n",
    "var_name = get_control_key_value(control_dict=fun_control, key=\"var_name\")\n",
    "print(var_type)\n",
    "print(var_name)\n",
    "vn = \"l1\"\n",
    "get_var_type_from_var_name(fun_control=fun_control, var_name=vn)\n",
    "\n",
    "assert var_type[var_name.index(vn)] == \"int\"\n",
    "assert get_var_type_from_var_name(fun_control, vn) == \"int\"\n",
    "vn = \"initialization\"\n",
    "assert var_type[var_name.index(vn)] == \"factor\"\n",
    "assert var_type[var_name.index(vn)] == \"factor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import get_control_key_value\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "from spotpython.hyperparameters.values import set_control_hyperparameter_value\n",
    "\n",
    "fun_control = fun_control_init()\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                    fun_control=fun_control,\n",
    "                    hyper_dict=LightHyperDict)\n",
    "set_control_hyperparameter_value(control_dict=fun_control, hyperparameter=\"l1\", value=[1,7])\n",
    "set_control_hyperparameter_value(control_dict=fun_control, hyperparameter=\"initialization\", value=[\"xavier2\", \"kaiming2\"])\n",
    "print(fun_control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entry(dictionary, key, i):\n",
    "    if key in dictionary:\n",
    "        if 'levels' in dictionary[key]:\n",
    "            if i < len(dictionary[key]['levels']):\n",
    "                return dictionary[key]['levels'][i]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from spotpython.data.pkldataset_intern import PKLDataset\n",
    "from spotpython.utils.device import getDevice\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.utils.file import get_experiment_name, get_spot_tensorboard_path\n",
    "import numpy as np\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "from math import inf\n",
    "\n",
    "MAX_TIME = 60\n",
    "FUN_EVALS = inf\n",
    "INIT_SIZE = 25\n",
    "WORKERS = 0\n",
    "PREFIX=\"031\"\n",
    "DEVICE = getDevice()\n",
    "\n",
    "\n",
    "experiment_name = get_experiment_name(prefix=PREFIX)\n",
    "fun_control = fun_control_init(\n",
    "    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name),\n",
    "    _L_in=10,\n",
    "    _L_out=1,\n",
    "    TENSORBOARD_CLEAN=True,\n",
    "    device=DEVICE,\n",
    "    enable_progress_bar=False,\n",
    "    fun_evals=FUN_EVALS,\n",
    "    log_level=10,\n",
    "    max_time=MAX_TIME,\n",
    "    num_workers=WORKERS,\n",
    "    show_progress=True,\n",
    "    tolerance_x=np.sqrt(np.spacing(1)),\n",
    "    )\n",
    "\n",
    "dataset = Diabetes()\n",
    "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotpython/notebooks/data/spotpython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True, rmMF=True)\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset,\n",
    "                        replace=True)\n",
    "\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"_L_in\",\n",
    "                        value=133,\n",
    "                        replace=True)\n",
    "\n",
    "\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=LightHyperDict)\n",
    "# from spotpython.hyperparameters.values import modify_hyper_parameter_bounds\n",
    "\n",
    "from spotpython.hyperparameters.values import set_control_hyperparameter_value\n",
    "set_control_hyperparameter_value(fun_control, \"l1\", [3,8])\n",
    "set_control_hyperparameter_value(fun_control, \"epochs\", [4,9])\n",
    "set_control_hyperparameter_value(fun_control, \"batch_size\", [1, 4])\n",
    "set_control_hyperparameter_value(fun_control, \"optimizer\", [\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entry(dictionary, key, i):\n",
    "    if 'core_model_hyper_dict' in dictionary:\n",
    "        if key in dictionary['core_model_hyper_dict']:\n",
    "            if 'levels' in dictionary['core_model_hyper_dict'][key]:\n",
    "                if i < len(dictionary['core_model_hyper_dict'][key]['levels']):\n",
    "                    return dictionary['core_model_hyper_dict'][key]['levels'][i]\n",
    "    return None\n",
    "print(get_entry(fun_control, \"optimizer\", 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.device import getDevice\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.utils.file import get_experiment_name, get_spot_tensorboard_path\n",
    "import numpy as np\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "from spotpython.hyperparameters.values import get_ith_hyperparameter_name_from_fun_control\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.hyperparameters.values import set_control_hyperparameter_value\n",
    "experiment_name = get_experiment_name(prefix=\"000\")\n",
    "fun_control = fun_control_init(\n",
    "    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name),\n",
    "    _L_in=10,\n",
    "    _L_out=1,\n",
    "    TENSORBOARD_CLEAN=True,\n",
    "    device=getDevice(),\n",
    "    enable_progress_bar=False,\n",
    "    fun_evals=15,\n",
    "    log_level=10,\n",
    "    max_time=1,\n",
    "    num_workers=0,\n",
    "    show_progress=True,\n",
    "    tolerance_x=np.sqrt(np.spacing(1)),\n",
    "    )\n",
    "dataset = Diabetes()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset,\n",
    "                        replace=True)\n",
    "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
    "                            fun_control=fun_control,\n",
    "                            hyper_dict=LightHyperDict)\n",
    "\n",
    "set_control_hyperparameter_value(fun_control, \"l1\", [3,8])\n",
    "set_control_hyperparameter_value(fun_control, \"optimizer\", [\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
    "assert get_ith_hyperparameter_name_from_fun_control(fun_control, key=\"optimizer\", i=0) == \"Adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_timestamp(only_int=True):\n",
    "    dt = datetime.datetime.now().isoformat(sep=\" \", timespec=\"microseconds\")\n",
    "    if only_int:\n",
    "        # remove - . : and space\n",
    "        dt = dt.replace(\"-\", \"\")\n",
    "        dt = dt.replace(\".\", \"\")\n",
    "        dt = dt.replace(\":\", \"\")\n",
    "        dt = dt.replace(\" \", \"\")\n",
    "    return dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init, surrogate_control_init, design_control_init\n",
    ")\n",
    "\n",
    "def test_plot_progress():\n",
    "    # number of initial points:\n",
    "    ni = 7\n",
    "    # number of points\n",
    "    fun_evals = 10\n",
    "    fun = analytical().fun_sphere\n",
    "    fun_control = fun_control_init(\n",
    "        lower = np.array([-1, -1]),\n",
    "        upper = np.array([1, 1]),\n",
    "        fun_evals=fun_evals,\n",
    "        tolerance_x = np.sqrt(np.spacing(1))\n",
    "    )\n",
    "    design_control=design_control_init(init_size=ni)\n",
    "    surrogate_control=surrogate_control_init(n_theta=3)\n",
    "    S = spot.Spot(fun=fun,\n",
    "                    fun_control=fun_control,\n",
    "                    design_control=design_control,\n",
    "                    surrogate_control=surrogate_control,)\n",
    "    S.run()\n",
    "\n",
    "    # Test plot_progress with different parameters\n",
    "    S.plot_progress(show=False)  # Test with show=False\n",
    "    S.plot_progress(log_x=True, show=False)  # Test with log_x=True\n",
    "    S.plot_progress(log_y=True, show=False)  # Test with log_y=True\n",
    "    S.plot_progress(filename=\"test_plot.png\", show=False)  # Test with a different filename\n",
    "    # add NaN to S.y at position 2\n",
    "    S.y[2] = np.nan\n",
    "    S.plot_progress(show=False)  # Test with show=False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init, surrogate_control_init, design_control_init\n",
    ")\n",
    "\n",
    "\n",
    "# number of initial points:\n",
    "ni = 7\n",
    "# number of points\n",
    "fun_evals = 10\n",
    "fun = analytical().fun_sphere\n",
    "fun_control = fun_control_init(\n",
    "    lower = np.array([-1, -1]),\n",
    "    upper = np.array([1, 1]),\n",
    "    fun_evals=fun_evals,\n",
    "    tolerance_x = np.sqrt(np.spacing(1))\n",
    ")\n",
    "design_control=design_control_init(init_size=ni)\n",
    "surrogate_control=surrogate_control_init(n_theta=3)\n",
    "S = spot.Spot(fun=fun,\n",
    "                fun_control=fun_control,\n",
    "                design_control=design_control,\n",
    "                surrogate_control=surrogate_control,)\n",
    "S.run()\n",
    "\n",
    "# remove points from S.y so that there are less than ni points\n",
    "S.y = S.y[:3]\n",
    "# Test plot_progress with different parameters\n",
    "S.plot_progress(show=False)  # Test with show=False\n",
    "S.plot_progress(log_x=True, show=False)  # Test with log_x=True\n",
    "S.plot_progress(log_y=True, show=False)  # Test with log_y=True\n",
    "S.plot_progress(filename=\"test_plot.png\", show=False)  # Test with a different filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import inf\n",
    "from spotpython.spot import spot\n",
    "from scipy.optimize import differential_evolution\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init,\n",
    "    design_control_init,\n",
    "    surrogate_control_init,\n",
    "    optimizer_control_init)\n",
    "def objective_function(X, fun_control=None):\n",
    "    if not isinstance(X, np.ndarray):\n",
    "        X = np.array(X)\n",
    "    if X.shape[1] != 2:\n",
    "        raise Exception\n",
    "    x0 = X[:, 0]\n",
    "    x1 = X[:, 1]\n",
    "    y = x0**2 + 10*x1**2\n",
    "    return y\n",
    "fun_control = fun_control_init(\n",
    "            lower = np.array([0, 0]),\n",
    "            upper = np.array([10, 10]),\n",
    "            fun_evals=8,\n",
    "            fun_repeats=1,\n",
    "            max_time=inf,\n",
    "            noise=True,\n",
    "            tolerance_x=0,\n",
    "            ocba_delta=0,\n",
    "            var_type=[\"num\", \"num\"],\n",
    "            infill_criterion=\"ei\",\n",
    "            n_points=1,\n",
    "            seed=123,\n",
    "            log_level=10,\n",
    "            show_models=False,\n",
    "            show_progress=True)\n",
    "design_control = design_control_init(\n",
    "            init_size=5,\n",
    "            repeats=1)\n",
    "surrogate_control = surrogate_control_init(\n",
    "            log_level=10,\n",
    "            model_optimizer=differential_evolution,\n",
    "            model_fun_evals=10000,\n",
    "            min_theta=-3,\n",
    "            max_theta=3,\n",
    "            n_theta=2,\n",
    "            theta_init_zero=True,\n",
    "            n_p=1,\n",
    "            optim_p=False,\n",
    "            noise=True,\n",
    "            var_type=[\"num\", \"num\"],\n",
    "            seed=124, \n",
    "            min_Lambda=1,\n",
    "            max_Lambda=10)\n",
    "optimizer_control = optimizer_control_init(\n",
    "            max_iter=1000,\n",
    "            seed=125)\n",
    "spot = spot.Spot(fun=objective_function,\n",
    "            fun_control=fun_control,\n",
    "            design_control=design_control,\n",
    "            surrogate_control=surrogate_control,\n",
    "            optimizer_control=optimizer_control\n",
    "            )\n",
    "spot.run()\n",
    "spot.plot_progress()\n",
    "spot.plot_contour(i=0, j=1)\n",
    "spot.plot_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotpython.spot import spot\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init\n",
    "\n",
    "fun = analytical().fun_branin\n",
    "fun_control = fun_control_init(lower = np.array([-5, 0]),\n",
    "                               upper = np.array([10, 15]),\n",
    "                               fun_evals=20)\n",
    "design_control = design_control_init(init_size=10)\n",
    "surrogate_control = surrogate_control_init(n_theta=2)\n",
    "S = spot.Spot(fun=fun, fun_control=fun_control, design_control=design_control)\n",
    "S.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.surrogate.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import inf\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "from scipy.optimize import shgo\n",
    "from scipy.optimize import direct\n",
    "from scipy.optimize import differential_evolution\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = analytical().fun_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,100).reshape(-1,1)\n",
    "y = fun(x)\n",
    "plt.figure()\n",
    "plt.plot(x,y, \"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\n",
    "spot_1 = spot.Spot(fun=fun,\n",
    "                   fun_control=fun_control_init(\n",
    "                        lower = np.array([-10]),\n",
    "                        upper = np.array([100]),\n",
    "                        fun_evals = 7,\n",
    "                        fun_repeats = 1,\n",
    "                        max_time = inf,\n",
    "                        noise = False,\n",
    "                        tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                        var_type=[\"num\"],\n",
    "                        infill_criterion = \"y\",\n",
    "                        n_points = 1,\n",
    "                        seed=123,\n",
    "                        log_level = 50),\n",
    "                   design_control=design_control_init(\n",
    "                        init_size=5,\n",
    "                        repeats=1),\n",
    "                   surrogate_control=surrogate_control_init(\n",
    "                        noise=False,\n",
    "                        min_theta=-4,\n",
    "                        max_theta=3,\n",
    "                        n_theta=1,\n",
    "                        model_optimizer=differential_evolution,\n",
    "                        model_fun_evals=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.fun.objectivefunctions import analytical\n",
    "fun = analytical().fun_sphere\n",
    "from spotpython.design.spacefilling import spacefilling\n",
    "design = spacefilling(2)\n",
    "from scipy.optimize import differential_evolution\n",
    "optimizer = differential_evolution\n",
    "from spotpython.build.kriging import Kriging\n",
    "surrogate = Kriging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init, design_control_init, optimizer_control_init, surrogate_control_init\n",
    "fun_control=fun_control_init(lower=np.array([-1, -1]),\n",
    "                            upper=np.array([1, 1]))\n",
    "design_control=design_control_init()\n",
    "optimizer_control=optimizer_control_init()\n",
    "surrogate_control=surrogate_control_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.spot import spot\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "                       fun_control=fun_control,\n",
    "                       design_control=design_control,\n",
    "                       optimizer_control=optimizer_control,\n",
    "                       surrogate_control=surrogate_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytest\n",
    "import torch\n",
    "from pyhcf.data.loadHcfData import build_df, load_hcf_data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list=[\"L\", \"AQ\", \"AS\"]\n",
    "dataset = load_hcf_data(param_list=p_list, target=\"T\",\n",
    "                        rmNA=True, rmMF=True,\n",
    "                        load_all_features=False,\n",
    "                        load_thermo_features=False,\n",
    "                        scale_data=True,\n",
    "                        return_X_y=False)\n",
    "assert isinstance(dataset, torch.utils.data.TensorDataset)\n",
    "assert len(dataset) > 0\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader    \n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    assert inputs.size(0) == batch_size\n",
    "    print(f\"Inputs Shape: {inputs.shape[1]}\")\n",
    "    print(f\"P List: {p_list}\")\n",
    "    print(f\"P List Length: {len(p_list)}\")\n",
    "    # input is p_list + 1 (for target)\n",
    "    # p_list = [\"L\", \"AQ\", \"AS\"] plus target \"N\"\n",
    "    assert inputs.shape[1] + 1 == len(p_list)\n",
    "    print(f\"Targets Shape: {targets.shape[0]}\")\n",
    "    assert targets.shape[0] == batch_size\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "import torch\n",
    "# data.csv is simple csv file with 11 samples\n",
    "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n",
    "data_module.setup()\n",
    "print(f\"Training set size: {len(data_module.data_train)}\")\n",
    "print(f\"Validation set size: {len(data_module.data_val)}\")\n",
    "print(f\"Test set size: {len(data_module.data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "import torch\n",
    "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n",
    "data_module.setup(stage=\"predict\")\n",
    "print(f\"Predict set size: {len(data_module.data_predict)}\")\n",
    "for batch in data_module.predict_dataloader():\n",
    "    inputs, targets = batch\n",
    "    print(f\"inputs: {inputs}\")\n",
    "    print(f\"targets: {targets}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_module.data_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_div2_list(n, n_min):\n",
    "    result = []\n",
    "    current = n\n",
    "    while current >= n_min:\n",
    "        result.extend([current] * (n // current))\n",
    "        current = current // 2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_L_in = 128\n",
    "l1 = \n",
    "\n",
    "n_low = _L_in // 4\n",
    "# ensure that n_high is larger than n_low\n",
    "n_high = max(l1, 2 * n_low)\n",
    "generate_div2_list(n_high, n_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.math import generate_div2_list\n",
    "generate_div2_list(64, 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.transformer.positionalEncoding import PositionalEncoding\n",
    "import torch\n",
    "# number of tensors\n",
    "n = 3\n",
    "# dimension of each tensor\n",
    "k = 32\n",
    "pe = PositionalEncoding(d_model=k, dropout_prob=0, verbose=False)\n",
    "input = torch.zeros(1, n, k)\n",
    "# Generate a tensor of size (1, 10, 4) with values from 1 to 10\n",
    "for i in range(n):\n",
    "    input[0, i, :] = i\n",
    "print(f\"Input shape: {input.shape}\")\n",
    "print(f\"Input: {input}\")\n",
    "output = pe(input)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.transformer.skiplinear import SkipLinear\n",
    "import torch\n",
    "n_in = 2\n",
    "n_out = 4\n",
    "sl = SkipLinear(n_in, n_out)\n",
    "input = torch.zeros(1, n_in)\n",
    "for i in range(n_in):\n",
    "    input[0, i] = i\n",
    "print(f\"Input shape: {input.shape}\")\n",
    "print(f\"Input: {input}\")\n",
    "output = sl(input)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output: {output}\")\n",
    "print(sl.lst_modules)\n",
    "for i in sl.lst_modules:\n",
    "    print(f\"weights: {i.weights}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Example from J. Caffrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people_income_transformer.py\n",
    "# predict income from sex, age, city, politics\n",
    "# PyTorch 2.0.0-CPU Anaconda3-2022.10  Python 3.9.13\n",
    "# Windows 10/11 \n",
    "\n",
    "# Transformer component for regression\n",
    "\n",
    "import numpy as np\n",
    "import torch as T\n",
    "\n",
    "device = T.device('cpu')  # apply to Tensor or Module\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class PeopleDataset(T.utils.data.Dataset):\n",
    "  def __init__(self, src_file):\n",
    "    # sex age   state   income   politics\n",
    "    # -1  0.27  0 1 0   0.7610   0 0 1\n",
    "    # +1  0.19  0 0 1   0.6550   1 0 0\n",
    "\n",
    "    tmp_x = np.loadtxt(src_file, usecols=[0,1,2,3,4,6,7,8],\n",
    "      delimiter=\",\", comments=\"#\", dtype=np.float32)\n",
    "    tmp_y = np.loadtxt(src_file, usecols=5, delimiter=\",\",\n",
    "      comments=\"#\", dtype=np.float32)\n",
    "    tmp_y = tmp_y.reshape(-1,1)  # 2D required\n",
    "\n",
    "    self.x_data = T.tensor(tmp_x, dtype=T.float32).to(device)\n",
    "    self.y_data = T.tensor(tmp_y, dtype=T.float32).to(device)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    preds = self.x_data[idx]\n",
    "    incom = self.y_data[idx] \n",
    "    return (preds, incom)  # as a tuple\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class SkipLinear(T.nn.Module):\n",
    "\n",
    "  # -----\n",
    "\n",
    "  class Core(T.nn.Module):\n",
    "    def __init__(self, n):\n",
    "      super().__init__()\n",
    "      # 1 node to n nodes, n gte 2\n",
    "      self.weights = T.nn.Parameter(T.zeros((n,1),\n",
    "        dtype=T.float32))\n",
    "      self.biases = T.nn.Parameter(T.tensor(n,\n",
    "        dtype=T.float32))\n",
    "      lim = 0.01\n",
    "      T.nn.init.uniform_(self.weights, -lim, lim)\n",
    "      T.nn.init.zeros_(self.biases)\n",
    "\n",
    "    def forward(self, x):\n",
    "      wx= T.mm(x, self.weights.t())\n",
    "      v = T.add(wx, self.biases)\n",
    "      return v\n",
    "\n",
    "  # -----\n",
    "\n",
    "  def __init__(self, n_in, n_out):\n",
    "    super().__init__()\n",
    "    self.n_in = n_in; self.n_out = n_out\n",
    "    if n_out  % n_in != 0:\n",
    "      print(\"FATAL: n_out must be divisible by n_in\")\n",
    "    n = n_out // n_in  # num nodes per input\n",
    "\n",
    "    self.lst_modules = \\\n",
    "      T.nn.ModuleList([SkipLinear.Core(n) for \\\n",
    "        i in range(n_in)])\n",
    "\n",
    "  def forward(self, x):\n",
    "    lst_nodes = []\n",
    "    for i in range(self.n_in):\n",
    "      xi = x[:,i].reshape(-1,1)\n",
    "      oupt = self.lst_modules[i](xi)\n",
    "      lst_nodes.append(oupt)\n",
    "    result = T.cat((lst_nodes[0], lst_nodes[1]), 1)\n",
    "    for i in range(2,self.n_in):\n",
    "      result = T.cat((result, lst_nodes[i]), 1)\n",
    "    result = result.reshape(-1, self.n_out)\n",
    "    return result\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class PositionalEncoding(T.nn.Module):  # documentation code\n",
    "  def __init__(self, d_model: int, dropout: float=0.1,\n",
    "   max_len: int=5000):\n",
    "    super(PositionalEncoding, self).__init__()  # old syntax\n",
    "    self.dropout = T.nn.Dropout(p=dropout)\n",
    "    pe = T.zeros(max_len, d_model)  # like 10x4\n",
    "    position = \\\n",
    "      T.arange(0, max_len, dtype=T.float).unsqueeze(1)\n",
    "    div_term = T.exp(T.arange(0, d_model, 2).float() * \\\n",
    "      (-np.log(10_000.0) / d_model))\n",
    "    pe[:, 0::2] = T.sin(position * div_term)\n",
    "    pe[:, 1::2] = T.cos(position * div_term)\n",
    "    pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "    self.register_buffer('pe', pe)  # allows state-save\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.pe[:x.size(0), :]\n",
    "    return self.dropout(x)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class TransformerNet(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(TransformerNet, self).__init__()\n",
    "    self.embed = SkipLinear(8, 32)  # 8 inputs, each goes to 4 \n",
    "    self.pos_enc = \\\n",
    "      PositionalEncoding(4, dropout=0.20)  # positional\n",
    "    self.enc_layer = T.nn.TransformerEncoderLayer(d_model=4,\n",
    "      nhead=2, dim_feedforward=10, \n",
    "      batch_first=True)  # d_model divisible by nhead\n",
    "    self.trans_enc = T.nn.TransformerEncoder(self.enc_layer,\n",
    "      num_layers=2)  # 6 layers default\n",
    "\n",
    "    self.fc1 = T.nn.Linear(32, 10)  # 8--32-T-10-1\n",
    "    self.fc2 = T.nn.Linear(10, 1)\n",
    "\n",
    "    # default weight and bias initialization\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = self.embed(x)  # 8 inpts to 32 embed\n",
    "    z = z.reshape(-1, 8, 4)  # bat seq embed\n",
    "    z = self.pos_enc(z) \n",
    "    z = self.trans_enc(z) \n",
    "    z = z.reshape(-1, 32)  # torch.Size([bs, xxx])\n",
    "    z = T.tanh(self.fc1(z))\n",
    "    z = self.fc2(z)  # regression: no activation\n",
    "    return z\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def accuracy(model, ds, pct_close):\n",
    "  # assumes model.eval()\n",
    "  # correct within pct of true income\n",
    "  n_correct = 0; n_wrong = 0\n",
    "\n",
    "  for i in range(len(ds)):\n",
    "    X = ds[i][0].reshape(1,-1)  # make it a batch\n",
    "    Y = ds[i][1].reshape(1)\n",
    "    with T.no_grad():\n",
    "      oupt = model(X)         # computed income\n",
    "\n",
    "    if T.abs(oupt - Y) <= T.abs(pct_close * Y):\n",
    "      n_correct += 1\n",
    "    else:\n",
    "      n_wrong += 1\n",
    "  acc = (n_correct * 1.0) / (n_correct + n_wrong)\n",
    "  return acc\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def accuracy_x(model, ds, pct_close):\n",
    "  # all-at-once (quick)\n",
    "  # assumes model.eval()\n",
    "  X = ds.x_data  # all inputs\n",
    "  Y = ds.y_data  # all targets\n",
    "  n_items = len(X)\n",
    "  with T.no_grad():\n",
    "    pred = model(X)  # all predicted incomes\n",
    " \n",
    "  n_correct = T.sum((T.abs(pred - Y) <= \\\n",
    "    T.abs(pct_close * Y)))\n",
    "  result = (n_correct.item() / n_items)  # scalar\n",
    "  return result  \n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def train(model, ds, bs, lr, me, le, test_ds):\n",
    "  # dataset, bat_size, lrn_rate, max_epochs, log interval\n",
    "  train_ldr = T.utils.data.DataLoader(ds, batch_size=bs,\n",
    "    shuffle=True)\n",
    "  loss_func = T.nn.MSELoss()\n",
    "  optimizer = T.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "  for epoch in range(0, me):\n",
    "    epoch_loss = 0.0  # for one full epoch\n",
    "    for (b_idx, batch) in enumerate(train_ldr):\n",
    "      X = batch[0]  # predictors\n",
    "      y = batch[1]  # target income\n",
    "      optimizer.zero_grad()\n",
    "      oupt = model(X)\n",
    "      loss_val = loss_func(oupt, y)  # a tensor\n",
    "      epoch_loss += loss_val.item()  # accumulate\n",
    "      loss_val.backward()  # compute gradients\n",
    "      optimizer.step()     # update weights\n",
    "\n",
    "    if epoch % le == 0:\n",
    "      print(\"epoch = %4d  |  loss = %0.4f\" % \\\n",
    "        (epoch, epoch_loss))\n",
    "      # model.eval()\n",
    "      # print(\"-------------\")\n",
    "      # acc_train = accuracy(model, ds, 0.10)\n",
    "      # print(\"Accuracy on train data = %0.4f\" % acc_train)\n",
    "      # acc_test = accuracy(model, test_ds, 0.10) \n",
    "      # print(\"Accuracy on test data = %0.4f\" % acc_test)\n",
    "      # model.train()\n",
    "      # print(\"-------------\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "  # 0. get started\n",
    "  print(\"\\nBegin People predict income using Transformer \")\n",
    "  T.manual_seed(0)\n",
    "  np.random.seed(0)\n",
    "  \n",
    "\n",
    "\n",
    "  # 1. create Dataset objects\n",
    "  print(\"\\nCreating People Dataset objects \")\n",
    "  train_file = \"../src/spotpython/data/people_train.csv\"\n",
    "  train_ds = PeopleDataset(train_file)  # 200 rows\n",
    "\n",
    "  test_file = \"../src/spotpython/data/people_test.csv\"\n",
    "  test_ds = PeopleDataset(test_file)  # 40 rows\n",
    "\n",
    "  # 2. create network\n",
    "  print(\"\\nCreating (8--32)-T-10-1 neural network \")\n",
    "  net = TransformerNet().to(device)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "  # 3. train model\n",
    "  print(\"\\nbat_size = 10 \")\n",
    "  print(\"loss = MSELoss() \")\n",
    "  print(\"optimizer = Adam \")\n",
    "  print(\"lrn_rate = 0.01 \")\n",
    "\n",
    "  print(\"\\nStarting training\")\n",
    "  net.train()\n",
    "  train(net, train_ds, bs=10, lr=0.01, me=300,\n",
    "    le=50, test_ds=test_ds)\n",
    "  print(\"Done \")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "  # 4. evaluate model accuracy\n",
    "  print(\"\\nComputing model accuracy (within 0.10 of true) \")\n",
    "  net.eval()\n",
    "  acc_train = accuracy(net, train_ds, 0.10)  # item-by-item\n",
    "  print(\"Accuracy on train data = %0.4f\" % acc_train)\n",
    "\n",
    "  acc_test = accuracy_x(net, test_ds, 0.10)  # all-at-once\n",
    "  print(\"Accuracy on test data = %0.4f\" % acc_test)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "  # 5. make a prediction\n",
    "  print(\"\\nPredicting income for M 34 Oklahoma moderate: \")\n",
    "  x = np.array([[-1, 0.34, 0,0,1,  0,1,0]],\n",
    "    dtype=np.float32)\n",
    "  x = T.tensor(x, dtype=T.float32).to(device) \n",
    "\n",
    "  with T.no_grad():\n",
    "    pred_inc = net(x)\n",
    "  pred_inc = pred_inc.item()  # scalar\n",
    "  print(\"$%0.2f\" % (pred_inc * 100_000))  # un-normalized\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "  # 6. save model (state_dict approach)\n",
    "  print(\"\\nSaving trained model state\")\n",
    "  fn = \".\\\\Models\\\\people_income_model.pt\"\n",
    "  T.save(net.state_dict(), fn)\n",
    "\n",
    "  # model = Net()\n",
    "  # model.load_state_dict(T.load(fn))\n",
    "  # use model to make prediction(s)\n",
    "\n",
    "  print(\"\\nEnd People income demo \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SkipLinear(torch.nn.Module):\n",
    "    class Core(torch.nn.Module):\n",
    "        \"\"\"A simple linear layer with n outputs.\"\"\"\n",
    "\n",
    "        def __init__(self, n):\n",
    "            \"\"\"\n",
    "            Initialize the layer.\n",
    "\n",
    "            Args:\n",
    "                n (int): The number of output nodes.\n",
    "            \"\"\"\n",
    "            super().__init__()\n",
    "            self.weights = torch.nn.Parameter(torch.zeros((n, 1), dtype=torch.float32))\n",
    "            self.biases = torch.nn.Parameter(torch.zeros(n, dtype=torch.float32))\n",
    "            lim = 0.01\n",
    "            torch.nn.init.uniform_(self.weights, -lim, lim)\n",
    "\n",
    "        def forward(self, x)->torch.Tensor:\n",
    "            \"\"\"\n",
    "            Forward pass through the layer.\n",
    "\n",
    "            Args:\n",
    "                x (torch.Tensor): The input tensor.\n",
    "\n",
    "            Returns:\n",
    "                torch.Tensor: The output of the layer.\n",
    "            \"\"\"\n",
    "            return x @ self.weights.t() + self.biases\n",
    "\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        if n_out % n_in != 0:\n",
    "            raise ValueError(\"n_out % n_in != 0\")\n",
    "        n = n_out // n_in  # num nodes per input\n",
    "\n",
    "        self.lst_modules = torch.nn.ModuleList([SkipLinear.Core(n) for i in range(n_in)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        lst_nodes = []\n",
    "        for i in range(self.n_in):\n",
    "            xi = x[:, i].reshape(-1, 1)\n",
    "            oupt = self.lst_modules[i](xi)\n",
    "            lst_nodes.append(oupt)\n",
    "        result = torch.cat((lst_nodes[0], lst_nodes[1]), 1)\n",
    "        for i in range(2, self.n_in):\n",
    "            result = torch.cat((result, lst_nodes[i]), 1)\n",
    "        result = result.reshape(-1, self.n_out)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipLinear(torch.nn.Module):\n",
    "\n",
    "    class Core(torch.nn.Module):\n",
    "        \"\"\"A simple linear layer with n outputs.\"\"\"\n",
    "\n",
    "        def __init__(self, n):\n",
    "            \"\"\"\n",
    "            Initialize the layer.\n",
    "\n",
    "            Args:\n",
    "                n (int): The number of output nodes.\n",
    "            \"\"\"\n",
    "            super().__init__()\n",
    "            self.weights = torch.nn.Parameter(torch.zeros((n, 1), dtype=torch.float32))\n",
    "            self.biases = torch.nn.Parameter(torch.zeros(n, dtype=torch.float32))\n",
    "            lim = 0.01\n",
    "            torch.nn.init.uniform_(self.weights, -lim, lim)\n",
    "\n",
    "        def forward(self, x) -> torch.Tensor:\n",
    "            \"\"\"\n",
    "            Forward pass through the layer.\n",
    "\n",
    "            Args:\n",
    "                x (torch.Tensor): The input tensor.\n",
    "\n",
    "            Returns:\n",
    "                torch.Tensor: The output of the layer.\n",
    "            \"\"\"\n",
    "            return x @ self.weights.t() + self.biases\n",
    "\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        if n_out % n_in != 0:\n",
    "            raise ValueError(\"n_out % n_in != 0\")\n",
    "        n = n_out // n_in  # num nodes per input\n",
    "\n",
    "        self.lst_modules = torch.nn.ModuleList([SkipLinear.Core(n) for i in range(n_in)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        lst_nodes = []\n",
    "        for i in range(self.n_in):\n",
    "            xi = x[:, i].reshape(-1, 1)\n",
    "            oupt = self.lst_modules[i](xi)\n",
    "            lst_nodes.append(oupt)\n",
    "        result = torch.cat((lst_nodes[0], lst_nodes[1]), 1)\n",
    "        for i in range(2, self.n_in):\n",
    "            result = torch.cat((result, lst_nodes[i]), 1)\n",
    "        result = result.reshape(-1, self.n_out)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spotGUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import get_default_values, get_bound_values\n",
    "lhd = LightHyperDict()\n",
    "# generate a dictionary fun_control with the key \"core_model_hyper_dict\" and the value lhd.hyper_dict['NetLightRegression']\n",
    "fun_control = {\"core_model_hyper_dict\": lhd.hyper_dict['NetLightRegression']}\n",
    "get_default_values(fun_control)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import json\n",
    "from spotpython.hyperparameters.values import get_default_values, get_bound_values\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "\n",
    "\n",
    "def create_gui(model):\n",
    "    lhd = LightHyperDict()\n",
    "    # generate a dictionary fun_control with the key \"core_model_hyper_dict\" and the value lhd.hyper_dict['NetLightRegression']\n",
    "    fun_control = {\"core_model_hyper_dict\": lhd.hyper_dict['NetLightRegression']}\n",
    "\n",
    "    # Apply the functions to the dictionary\n",
    "    default_values = get_default_values(fun_control)\n",
    "    lower_bound_values = get_bound_values(fun_control, \"lower\")\n",
    "    upper_bound_values = get_bound_values(fun_control, \"upper\")\n",
    "\n",
    "    # Create a tkinter window\n",
    "    root = tk.Tk()\n",
    "\n",
    "    # Loop over the dictionary and create labels and entries for each key-value pair\n",
    "    for i, (key, value) in enumerate(lhd.hyper_dict['NetLightRegression'].items()):\n",
    "            # Create a label with the key as text\n",
    "            label = tk.Label(root, text=key)\n",
    "            label.grid(row=i, column=0, sticky=\"W\")\n",
    "\n",
    "            # Create an entry with the default value as the default text\n",
    "            default_entry = tk.Entry(root)\n",
    "            default_entry.insert(0, value)\n",
    "            default_entry.grid(row=i, column=1, sticky=\"W\")\n",
    "        # add the lower bound values in column 2\n",
    "            lower_bound_entry = tk.Entry(root)\n",
    "            lower_bound_entry.insert(0, lower_bound_values[i])\n",
    "            lower_bound_entry.grid(row=i, column=2, sticky=\"W\")\n",
    "        # add the upper bound values in column 3\n",
    "            upper_bound_entry = tk.Entry(root)\n",
    "            upper_bound_entry.insert(0, upper_bound_values[i])\n",
    "            upper_bound_entry.grid(row=i, column=3, sticky=\"W\")\n",
    "\n",
    "    # Run the tkinter main loop\n",
    "    root.mainloop()\n",
    "\n",
    "# Call the function to create the GUI\n",
    "create_gui(model = 'NetLightRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "\n",
    "\n",
    "def create_gui(model):\n",
    "    lhd = LightHyperDict()\n",
    "    dict =  lhd.hyper_dict[model]\n",
    "\n",
    "    \n",
    "    # Create a tkinter window\n",
    "    root = tk.Tk()\n",
    "\n",
    "    # Loop over the dictionary and create labels and entries for each key-value pair\n",
    "    # TODO: Add labels to the column headers\n",
    "    for i, (key, value) in enumerate(dict.items()):            \n",
    "            if dict[key][\"type\"] == \"int\" or dict[key][\"type\"] == \"float\":\n",
    "                # Create a label with the key as text\n",
    "                label = tk.Label(root, text=key)\n",
    "                label.grid(row=i, column=0, sticky=\"W\")\n",
    "                # Create an entry with the default value as the default text\n",
    "                default_entry = tk.Entry(root)\n",
    "                default_entry.insert(0, dict[key][\"default\"])\n",
    "                default_entry.grid(row=i, column=1, sticky=\"W\")\n",
    "                # add the lower bound values in column 2\n",
    "                lower_bound_entry = tk.Entry(root)                \n",
    "                lower_bound_entry.insert(0, dict[key][\"lower\"])\n",
    "                lower_bound_entry.grid(row=i, column=2, sticky=\"W\")\n",
    "                # add the upper bound values in column 3\n",
    "                upper_bound_entry = tk.Entry(root)\n",
    "                upper_bound_entry.insert(0, dict[key][\"upper\"])\n",
    "                upper_bound_entry.grid(row=i, column=3, sticky=\"W\")\n",
    "            if dict[key][\"type\"] == \"factor\":        \n",
    "                # Create a label with the key as text\n",
    "                label = tk.Label(root, text=key)\n",
    "                label.grid(row=i, column=0, sticky=\"W\")\n",
    "                # Create an entry with the default value as the default text\n",
    "                default_entry = tk.Entry(root)\n",
    "                default_entry.insert(0, dict[key][\"default\"])\n",
    "                default_entry.grid(row=i, column=1, sticky=\"W\")\n",
    "                # add the lower bound values in column 2\n",
    "                factor_level_entry = tk.Entry(root)\n",
    "                # add a comma to each level\n",
    "                dict[key][\"levels\"] = \", \".join(dict[key][\"levels\"])                                \n",
    "                factor_level_entry.insert(0, dict[key][\"levels\"])\n",
    "                # TODO: Fix columnspan\n",
    "                factor_level_entry.grid(row=i, column=2, columnspan=2, sticky=\"W\")\n",
    "\n",
    "    # Run the tkinter main loop\n",
    "    root.mainloop()\n",
    "\n",
    "# Call the function to create the GUI\n",
    "create_gui(model = 'NetLightRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gui(model = 'TransformerLightRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save Load Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from spotpython.utils.file import save_experiment, load_experiment\n",
    "import numpy as np\n",
    "from math import inf\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init,\n",
    "    design_control_init,\n",
    "    surrogate_control_init,\n",
    "    optimizer_control_init)\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "\n",
    "def test_file_save_load():\n",
    "    fun = analytical().fun_branin\n",
    "\n",
    "    fun_control = fun_control_init(\n",
    "                PREFIX=\"branin\",\n",
    "                SUMMARY_WRITER=False,\n",
    "                lower = np.array([0, 0]),\n",
    "                upper = np.array([10, 10]),\n",
    "                fun_evals=8,\n",
    "                fun_repeats=1,\n",
    "                max_time=inf,\n",
    "                noise=False,\n",
    "                tolerance_x=0,\n",
    "                ocba_delta=0,\n",
    "                var_type=[\"num\", \"num\"],\n",
    "                infill_criterion=\"ei\",\n",
    "                n_points=1,\n",
    "                seed=123,\n",
    "                log_level=20,\n",
    "                show_models=False,\n",
    "                show_progress=True)\n",
    "    design_control = design_control_init(\n",
    "                init_size=5,\n",
    "                repeats=1)\n",
    "    surrogate_control = surrogate_control_init(\n",
    "                model_fun_evals=10000,\n",
    "                min_theta=-3,\n",
    "                max_theta=3,\n",
    "                n_theta=2,\n",
    "                theta_init_zero=True,\n",
    "                n_p=1,\n",
    "                optim_p=False,\n",
    "                var_type=[\"num\", \"num\"],\n",
    "                seed=124)\n",
    "    optimizer_control = optimizer_control_init(\n",
    "                max_iter=1000,\n",
    "                seed=125)\n",
    "    spot_tuner = spot.Spot(fun=fun,\n",
    "                fun_control=fun_control,\n",
    "                design_control=design_control,\n",
    "                surrogate_control=surrogate_control,\n",
    "                optimizer_control=optimizer_control)\n",
    "    # Call the save_experiment function\n",
    "    pkl_name = save_experiment(\n",
    "        spot_tuner=spot_tuner,\n",
    "        fun_control=fun_control,\n",
    "        design_control=None,\n",
    "        surrogate_control=None,\n",
    "        optimizer_control=None\n",
    "    )\n",
    "\n",
    "    # Verify that the pickle file is created\n",
    "    assert os.path.exists(pkl_name)\n",
    "\n",
    "    # Call the load_experiment function\n",
    "    spot_tuner_1, fun_control_1, design_control_1, surrogate_control_1, optimizer_control_1 = load_experiment(pkl_name)\n",
    "\n",
    "    # Verify the name of the pickle file\n",
    "    assert pkl_name == f\"spot_{fun_control['PREFIX']}experiment.pickle\"\n",
    "\n",
    "    # Clean up the temporary directory\n",
    "    os.remove(pkl_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_save_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netlightregression2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.netlightregression2 import NetLightRegression2\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import torch\n",
    "BATCH_SIZE = 8\n",
    "dataset = Diabetes()\n",
    "train1_set, test_set = torch.utils.data.random_split(dataset, [0.6, 0.4])\n",
    "train_set, val_set = torch.utils.data.random_split(train1_set, [0.6, 0.4])\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(f\"batch_x.shape: {batch_x.shape}\")\n",
    "print(f\"batch_y.shape: {batch_y.shape}\")\n",
    "net_light_base = NetLightRegression2(l1=128,\n",
    "                                    epochs=10,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    initialization='Default',\n",
    "                                    act_fn=nn.ReLU(),\n",
    "                                    optimizer='Adam',\n",
    "                                    dropout_prob=0.1,\n",
    "                                    lr_mult=0.1,\n",
    "                                    patience=5,\n",
    "                                    _L_in=10,\n",
    "                                    _L_out=1,\n",
    "                                    _torchmetric=\"mean_squared_error\",)\n",
    "trainer = L.Trainer(max_epochs=10,  enable_progress_bar=False)\n",
    "trainer.fit(net_light_base, train_loader)\n",
    "trainer.validate(net_light_base, val_loader)\n",
    "trainer.test(net_light_base, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "import torch\n",
    "# data.csv is simple csv file with 11 samples\n",
    "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n",
    "data_module.setup()\n",
    "print(f\"Training set size: {len(data_module.data_train)}\")\n",
    "print(f\"Validation set size: {len(data_module.data_val)}\")\n",
    "print(f\"Test set size: {len(data_module.data_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tuned Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "from spotpython.utils.file import save_experiment, load_experiment\n",
    "import numpy as np\n",
    "from math import inf\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init,\n",
    "    design_control_init,\n",
    "    surrogate_control_init,\n",
    "    optimizer_control_init)\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "fun = analytical().fun_branin\n",
    "fun_control = fun_control_init(\n",
    "            PREFIX=\"branin\",\n",
    "            SUMMARY_WRITER=False,\n",
    "            lower = np.array([0, 0]),\n",
    "            upper = np.array([10, 10]),\n",
    "            fun_evals=8,\n",
    "            fun_repeats=1,\n",
    "            max_time=inf,\n",
    "            noise=False,\n",
    "            tolerance_x=0,\n",
    "            ocba_delta=0,\n",
    "            var_type=[\"num\", \"num\"],\n",
    "            infill_criterion=\"ei\",\n",
    "            n_points=1,\n",
    "            seed=123,\n",
    "            log_level=20,\n",
    "            show_models=False,\n",
    "            show_progress=True)\n",
    "design_control = design_control_init(\n",
    "            init_size=5,\n",
    "            repeats=1)\n",
    "surrogate_control = surrogate_control_init(\n",
    "            model_fun_evals=10000,\n",
    "            min_theta=-3,\n",
    "            max_theta=3,\n",
    "            n_theta=2,\n",
    "            theta_init_zero=True,\n",
    "            n_p=1,\n",
    "            optim_p=False,\n",
    "            var_type=[\"num\", \"num\"],\n",
    "            seed=124)\n",
    "optimizer_control = optimizer_control_init(\n",
    "            max_iter=1000,\n",
    "            seed=125)\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "            fun_control=fun_control,\n",
    "            design_control=design_control,\n",
    "            surrogate_control=surrogate_control,\n",
    "            optimizer_control=optimizer_control)\n",
    "spot_tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.get_tuned_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.get_tuned_hyperparameters(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tuned Hyperparameters from a Machine/Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.device import getDevice\n",
    "from math import inf\n",
    "from spotpython.utils.init import fun_control_init\n",
    "import numpy as np\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "\n",
    "MAX_TIME = 1\n",
    "FUN_EVALS = 10\n",
    "INIT_SIZE = 5\n",
    "WORKERS = 0\n",
    "PREFIX=\"037\"\n",
    "DEVICE = getDevice()\n",
    "DEVICES = 1\n",
    "TEST_SIZE = 0.4\n",
    "TORCH_METRIC = \"mean_squared_error\"\n",
    "dataset = Diabetes()\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10,\n",
    "    _L_out=1,\n",
    "    _torchmetric=TORCH_METRIC,\n",
    "    PREFIX=PREFIX,\n",
    "    TENSORBOARD_CLEAN=True,\n",
    "    data_set=dataset,\n",
    "    device=DEVICE,\n",
    "    enable_progress_bar=False,\n",
    "    fun_evals=FUN_EVALS,\n",
    "    log_level=50,\n",
    "    max_time=MAX_TIME,\n",
    "    num_workers=WORKERS,\n",
    "    show_progress=True,\n",
    "    test_size=TEST_SIZE,\n",
    "    tolerance_x=np.sqrt(np.spacing(1)),\n",
    "    )\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
    "add_core_model_to_fun_control(fun_control=fun_control,\n",
    "                              core_model=NetLightRegression,\n",
    "                              hyper_dict=LightHyperDict)\n",
    "from spotpython.hyperparameters.values import set_control_hyperparameter_value\n",
    "\n",
    "set_control_hyperparameter_value(fun_control, \"l1\", [7, 8])\n",
    "set_control_hyperparameter_value(fun_control, \"epochs\", [3, 5])\n",
    "set_control_hyperparameter_value(fun_control, \"batch_size\", [4, 5])\n",
    "set_control_hyperparameter_value(fun_control, \"optimizer\", [\n",
    "                \"Adam\",\n",
    "                \"RAdam\",\n",
    "            ])\n",
    "set_control_hyperparameter_value(fun_control, \"dropout_prob\", [0.01, 0.1])\n",
    "set_control_hyperparameter_value(fun_control, \"lr_mult\", [0.5, 5.0])\n",
    "set_control_hyperparameter_value(fun_control, \"patience\", [2, 3])\n",
    "set_control_hyperparameter_value(fun_control, \"act_fn\",[\n",
    "                \"ReLU\",\n",
    "                \"LeakyReLU\"\n",
    "            ] )\n",
    "from spotpython.utils.init import design_control_init, surrogate_control_init\n",
    "design_control = design_control_init(init_size=INIT_SIZE)\n",
    "\n",
    "surrogate_control = surrogate_control_init(noise=True,\n",
    "                                            n_theta=2)\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "fun = HyperLight(log_level=50).fun\n",
    "from spotpython.spot import spot\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "                       fun_control=fun_control,\n",
    "                       design_control=design_control,\n",
    "                       surrogate_control=surrogate_control)\n",
    "spot_tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.get_tuned_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factors\n",
    "\n",
    "* Example from https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/012_num_spot_ei.html#factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.design.spacefilling import spacefilling\n",
    "from spotpython.build.kriging import Kriging\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = spacefilling(2)\n",
    "n = 30\n",
    "rng = np.random.RandomState(1)\n",
    "lower = np.array([-5,-0])\n",
    "upper = np.array([10,15])\n",
    "fun = analytical().fun_branin_factor\n",
    "#fun = analytical(sigma=0).fun_sphere\n",
    "\n",
    "X0 = gen.scipy_lhd(n, lower=lower, upper = upper)\n",
    "X1 = np.random.randint(low=0, high=3, size=(n,))\n",
    "X = np.c_[X0, X1]\n",
    "y = fun(X)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "S = Kriging(name='kriging',  seed=123, log_level=10, n_theta=3, noise=False, var_type=[\"num\", \"num\", \"num\"])\n",
    "S.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Sf = Kriging(name='kriging',  seed=123, log_level=10, n_theta=3, noise=False, var_type=[\"num\", \"num\", \"factor\"])\n",
    "# Sf = Kriging(name='kriging',  seed=123, log_level=50, n_theta=3, noise=False, var_type=[\"num\", \"num\", \"num\"])\n",
    "Sf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0\n",
    "for _ in range(100):\n",
    "    n = 100\n",
    "    X0 = gen.scipy_lhd(n, lower=lower, upper = upper)\n",
    "    X1 = np.random.randint(low=0, high=3, size=(n,))\n",
    "    X = np.c_[X0, X1]\n",
    "    y = fun(X)\n",
    "    s=np.sum(np.abs(S.predict(X) - y))\n",
    "    sf=np.sum(np.abs(Sf.predict(X) - y))\n",
    "    res = res + (sf - s)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def select_distant_points(X, y, k):\n",
    "    \"\"\"\n",
    "    Selects k points that are distant from each other using a clustering approach.\n",
    "    \n",
    "    :param X: np.array of shape (n, k), with n points in k-dimensional space.\n",
    "    :param y: np.array of length n, with values corresponding to each point in X.\n",
    "    :param k: The number of distant points to select.\n",
    "    :return: Selected k points from X and their corresponding y values.\n",
    "    \"\"\"\n",
    "    # Perform k-means clustering to find k clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\").fit(X)\n",
    "    \n",
    "    # Find the closest point in X to each cluster center\n",
    "    selected_points = np.array([X[np.argmin(np.linalg.norm(X - center, axis=1))] for center in kmeans.cluster_centers_])\n",
    "    \n",
    "    # Find indices of the selected points in the original X array\n",
    "    indices = np.array([np.where(np.all(X==point, axis=1))[0][0] for point in selected_points])\n",
    "    \n",
    "    # Select the corresponding y values\n",
    "    selected_y = y[indices]\n",
    "    \n",
    "    return selected_points, selected_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100, 2)  # Generate some random points\n",
    "y = np.random.rand(100)     # Random corresponding y values\n",
    "k = 5\n",
    "\n",
    "selected_points, selected_y = select_distant_points(X, y, k)\n",
    "print(\"Selected Points:\", selected_points)\n",
    "print(\"Corresponding y values:\", selected_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init, optimizer_control_init, surrogate_control_init, design_control_init\n",
    "    )\n",
    "# number of initial points:\n",
    "ni = 5\n",
    "# number of points\n",
    "fun_evals = 10\n",
    "fun = analytical().fun_sphere\n",
    "fun_control = fun_control_init(\n",
    "    lower = np.array([-1, -1, -1]),\n",
    "    upper = np.array([1, 1, 1]),\n",
    "    fun_evals=fun_evals,\n",
    "    tolerance_x = np.sqrt(np.spacing(1))\n",
    "    )\n",
    "design_control=design_control_init(init_size=ni)\n",
    "surrogate_control=surrogate_control_init(n_theta=3)\n",
    "S = spot.Spot(fun=fun,\n",
    "            fun_control=fun_control,\n",
    "            design_control=design_control,\n",
    "            surrogate_control=surrogate_control,)\n",
    "S.run()\n",
    "S.plot_important_hyperparameter_contour(max_imp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [['x0', 85.50983192204619], ['x1', 100.0], ['x2', 81.35712613549178]]\n",
    "\n",
    "# Sorting the array in descending order by the second element of each sub-list\n",
    "sorted_array = sorted(array, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(sorted_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_second_and_return_indices(array):\n",
    "    \"\"\"\n",
    "    Sorts an array of arrays based on the second values in descending order and returns\n",
    "    the indices of the original array entries.\n",
    "\n",
    "    :param array: List of lists, where each inner list has at least two elements.\n",
    "    :return: Indices of the original array entries after sorting by the second value.\n",
    "             Returns an empty list if the input is empty or None.\n",
    "    :raises ValueError: If any sub-array is improperly structured.\n",
    "    \"\"\"\n",
    "    if not array:\n",
    "        return []\n",
    "\n",
    "    # Check for improperly structured sub-arrays\n",
    "    for item in array:\n",
    "        if not isinstance(item, list) or len(item) < 2:\n",
    "            raise ValueError(\"All sub-arrays must be lists with at least two elements.\")\n",
    "\n",
    "    # Enumerate the array to keep track of original indices, then sort by the second item\n",
    "    sorted_indices = [index for index, value in sorted(enumerate(array), key=lambda x: x[1][1], reverse=True)]\n",
    "\n",
    "    return sorted_indices\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    array = [['x0', 85.50983192204619], ['x1', 100.0], ['x2', 81.35712613549178]]\n",
    "    indices = sort_by_second_and_return_indices(array)\n",
    "    print(\"Indices of the sorted elements:\", indices)\n",
    "except ValueError as error:\n",
    "    print(f\"Error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Core Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.tree import HoeffdingAdaptiveTreeRegressor\n",
    "from spotriver.data.river_hyper_dict import RiverHyperDict\n",
    "from spotpython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_for_core_model, get_default_values\n",
    "fun_control = {}\n",
    "add_core_model_to_fun_control(core_model=HoeffdingAdaptiveTreeRegressor,\n",
    "    fun_control=fun_control,\n",
    "    hyper_dict=RiverHyperDict,\n",
    "    filename=None)\n",
    "values = get_default_values(fun_control)\n",
    "print(values)\n",
    "# get_default_hyperparameters_for_core_model(fun_control)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytest\n",
    "import pprint\n",
    "from spotpython.plot.xai import (get_activations, get_gradients, get_weights, plot_nn_values_hist, plot_nn_values_scatter, visualize_weights, visualize_gradients, visualize_activations, visualize_activations_distributions, visualize_gradient_distributions, visualize_weights_distributions)\n",
    "\n",
    "def test_plot_nn_values_scatter_reshaped_values():\n",
    "    # Mock data for testing\n",
    "    nn_values = {\n",
    "        'layer0': np.random.rand(10),  # 10 values suggesting padding for a 4x4\n",
    "        'layer1': np.random.rand(64),  # 64 values suggesting a perfect square (8x8)\n",
    "        'layer2': np.random.rand(32),  # 32 values suggesting  padding for a 6x6\n",
    "        'layer3': np.random.rand(16),  # 16 values suggesting a perfect square (4x4)\n",
    "    }\n",
    "\n",
    "    # Use the modified function that returns reshaped_values for testing\n",
    "    reshaped_values = plot_nn_values_scatter(nn_values, 'Test NN', return_reshaped=True)    \n",
    "\n",
    "    pprint.pprint(nn_values)\n",
    "    pprint.pprint(reshaped_values)\n",
    "    \n",
    "\n",
    "    # Assert for layer0: Checks if reshaping is correct for perfect square\n",
    "    assert reshaped_values['layer0'].shape == (4, 4)\n",
    "    # Assert for layer1: Checks if reshaping is correct for non-square\n",
    "    assert reshaped_values['layer1'].shape == (8, 8)\n",
    "    assert reshaped_values['layer2'].shape == (6, 6)\n",
    "    assert reshaped_values['layer3'].shape == (4, 4)\n",
    "\n",
    "\n",
    "\n",
    "test_plot_nn_values_scatter_reshaped_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.convert import set_dataset_target_type\n",
    "import pandas as pd\n",
    "dataset = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9], \"y\": [True, False, True]})\n",
    "print(dataset)\n",
    "dataset = set_dataset_target_type(dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import river.tree\n",
    "core_model_name = \"tree.HoeffdingTreeRegressor\"\n",
    "core_model_module = core_model_name.split(\".\")[0]\n",
    "coremodel = core_model_name.split(\".\")[1]\n",
    "core_model_instance = getattr(getattr(river, core_model_module), coremodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.friedman import FriedmanDriftDataset\n",
    "import matplotlib.pyplot as plt\n",
    "data_generator = FriedmanDriftDataset(n_samples=100, seed=42, change_point1=50, change_point2=75, constant=False)\n",
    "data = [data for data in data_generator]\n",
    "indices = [i for _, _, i in data]\n",
    "values = {f\"x{i}\": [] for i in range(5)}\n",
    "values[\"y\"] = []\n",
    "for x, y, _ in data:\n",
    "    for i in range(5):\n",
    "        values[f\"x{i}\"].append(x[i])\n",
    "    values[\"y\"].append(y)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for label, series in values.items():\n",
    "    plt.plot(indices, series, label=label)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('')\n",
    "plt.axvline(x=50, color='k', linestyle='--', label='Drift Point 1')\n",
    "plt.axvline(x=75, color='r', linestyle='--', label='Drift Point 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Scaler for Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "from spotpython.data.pkldataset import PKLDataset\n",
    "from spotpython.utils.scaler import TorchStandardScaler\n",
    "import torch\n",
    "\n",
    "scaler=TorchStandardScaler()\n",
    "\n",
    "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.float64)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5, scaler=scaler)\n",
    "data_module.setup()\n",
    "print(f\"Training set size: {len(data_module.data_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "import numpy as np\n",
    "np.max(diabetes.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "from spotpython.data.pkldataset import PKLDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "dataset = Diabetes()\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 1\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.california_housing import CaliforniaHousing\n",
    "dataset = CaliforniaHousing()\n",
    "print(dataset.get_names())\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.california_housing import CaliforniaHousing\n",
    "dataset = CaliforniaHousing()\n",
    "print(dataset.data.shape)\n",
    "print(dataset.targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from spotpython.data.california_housing import CaliforniaHousing\n",
    "import torch\n",
    "dataset = CaliforniaHousing(feature_type=torch.float32, target_type=torch.float32)\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.california_housing import CaliforniaHousing\n",
    "import torch\n",
    "dataset = CaliforniaHousing(feature_type=torch.float32, target_type=torch.float32)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=2, test_size=0.5, scaler=scaler)\n",
    "data_module.setup()\n",
    "print(f\"Training set size: {len(data_module.data_train)}\")\n",
    "print(f\"Validation set size: {len(data_module.data_val)}\")\n",
    "print(f\"Test set size: {len(data_module.data_test)}\")\n",
    "# print the first batch of the training set from data_module.data_train\n",
    "print(next(iter(data_module.train_dataloader())))\n",
    "# print the first batch of the training set from data_module.data_train as a numpy array\n",
    "print(next(iter(data_module.train_dataloader()))[0].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init, optimizer_control_init, surrogate_control_init, design_control_init\n",
    "    )\n",
    "# number of initial points:\n",
    "ni = 7\n",
    "# start point X_0\n",
    "X_start = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "fun = analytical().fun_sphere\n",
    "fun_control = fun_control_init(\n",
    "    lower = np.array([-1, -1]),\n",
    "    upper = np.array([1, 1]))\n",
    "design_control=design_control_init(init_size=ni)\n",
    "S = spot.Spot(fun=fun,\n",
    "            fun_control=fun_control,\n",
    "            design_control=design_control,)\n",
    "S.run(X_start=X_start)\n",
    "print(f\"S.X: {S.X}\")\n",
    "print(f\"S.y: {S.y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.csvdataset import CSVDataset\n",
    "from spotpython.utils.scaler import TorchStandardScaler, TorchMinMaxScaler\n",
    "from spotpython.data.california_housing import CaliforniaHousing\n",
    "\n",
    "\n",
    "dataset = CaliforniaHousing(feature_type=torch.float32, target_type=torch.float32)\n",
    "scaler = TorchMinMaxScaler()\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5, scaler=scaler)\n",
    "data_module.setup()\n",
    "\n",
    "loader = data_module.train_dataloader\n",
    "\n",
    "total_sum = None\n",
    "total_count = 0\n",
    "\n",
    "# Iterate over batches in the DataLoader\n",
    "for batch in loader():\n",
    "    inputs, targets = batch\n",
    "    \n",
    "\n",
    "total_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "\n",
    "\n",
    "def test_net_light_regression_class():\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "    dataset = Diabetes()\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "    val_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    net_light_regression = NetLightRegression(\n",
    "        l1=128,\n",
    "        epochs=10,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        initialization=\"Default\",\n",
    "        act_fn=nn.ReLU(),\n",
    "        optimizer=\"Adam\",\n",
    "        dropout_prob=0.1,\n",
    "        lr_mult=0.1,\n",
    "        patience=5,\n",
    "        _L_in=10,\n",
    "        _L_out=1,\n",
    "        _torchmetric=\"mean_squared_error\",\n",
    "    )\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=2,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.fit(net_light_regression, train_loader, val_loader)\n",
    "    res = trainer.test(net_light_regression, test_loader)\n",
    "    # test if the entry 'hp_metric' is in the res dict\n",
    "    assert \"hp_metric\" in res[0].keys()\n",
    "\n",
    "test_net_light_regression_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set_int_hyperparameter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotriver.hyperdict.river_hyper_dict import RiverHyperDict\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import set_int_hyperparameter_values\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "fun_control = fun_control_init(\n",
    "    core_model_name=\"forest.AMFRegressor\",\n",
    "    hyperdict=RiverHyperDict,\n",
    ")\n",
    "print(\"Before modification:\")\n",
    "print(gen_design_table(fun_control))\n",
    "set_int_hyperparameter_values(fun_control, \"n_estimators\", 2, 5)\n",
    "print(\"After modification:\")\n",
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from spotriver.hyperdict.river_hyper_dict import RiverHyperDict\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import set_factor_hyperparameter_values\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "fun_control = fun_control_init(\n",
    "    core_model_name=\"tree.HoeffdingTreeRegressor\",\n",
    "    hyperdict=RiverHyperDict,\n",
    ")\n",
    "print(\"Before modification:\")\n",
    "print(gen_design_table(fun_control))\n",
    "set_factor_hyperparameter_values(fun_control, \"leaf_model\", ['LinearRegression',\n",
    "                                                     'Perceptron'])\n",
    "print(\"After modification:\")\n",
    "print(gen_design_table(fun_control))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = fun_control_init(\n",
    "    core_model_name=\"tree.HoeffdingTreeRegressor\",\n",
    "    hyperdict=RiverHyperDict,\n",
    ")\n",
    "\n",
    "set_factor_hyperparameter_values(fun_control, \"leaf_model\", [\"LinearRegression\",\n",
    "                                                                \"Perceptron\"])\n",
    "\n",
    "# Access updated hyperparameters\n",
    "updated_hyperparameters = fun_control[\"core_model_hyper_dict\"]\n",
    "print(updated_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotriver.hyperdict.river_hyper_dict import RiverHyperDict\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.hyperparameters.values import set_boolean_hyperparameter_values\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "fun_control = fun_control_init(\n",
    "    core_model_name=\"forest.AMFRegressor\",\n",
    "    hyperdict=RiverHyperDict,\n",
    ")\n",
    "print(\"Before modification:\")\n",
    "print(gen_design_table(fun_control))\n",
    "set_boolean_hyperparameter_values(fun_control, \"use_aggregation\", 0, 0)\n",
    "print(\"After modification:\")\n",
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, full_dataset, train_size=0.8, batch_size=32, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.dataset = full_dataset\n",
    "        self.train_size = train_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Split the dataset\n",
    "        train_len = int(len(self.dataset) * self.train_size)\n",
    "        val_len = len(self.dataset) - train_len\n",
    "        self.train_set, self.val_set = random_split(self.dataset, [train_len, val_len])\n",
    "        \n",
    "        # Fit scaler on training data\n",
    "        train_data = torch.stack([item[0] for item in self.train_set])\n",
    "        print(f\"train_data before scaling\\n: {train_data}\")  \n",
    "        self.scaler.fit(train_data)\n",
    "       \n",
    "        # Transform training data\n",
    "        scaled_train_data = self.scaler.transform(train_data)\n",
    "        self.train_set = self._update_dataset(self.train_set, scaled_train_data)\n",
    "        print(f\"train_data after scaling\\n: {self.train_set}\")  \n",
    "        \n",
    "        # Transform validation data\n",
    "        val_data = torch.stack([item[0] for item in self.val_set])\n",
    "        scaled_val_data = self.scaler.transform(val_data)\n",
    "        self.val_set = self._update_dataset(self.val_set, scaled_val_data)\n",
    "\n",
    "    def _update_dataset(self, original_dataset, scaled_data):\n",
    "        updated_dataset = []\n",
    "        for i, (data, label) in enumerate(original_dataset):\n",
    "            updated_dataset.append((torch.tensor(scaled_data[i]), label))\n",
    "        return updated_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_data = torch.stack([item[0] for item in self.test_set])\n",
    "        scaled_test_data = self.scaler.transform(test_data)\n",
    "        self.test_set = self._update_dataset(self.test_set, scaled_test_data)\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Here you can download datasets if needed\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a 3-dimensional tensor with 1000 samples\n",
    "n = 10\n",
    "data = torch.rand((n, 3))\n",
    "print(f\"data: {data}\")\n",
    "labels = torch.tensor([i % 2 for i in range(n)], dtype=torch.float32)\n",
    "print(f\"labels: {labels}\")\n",
    "full_dataset = MyDataset(data, labels)\n",
    "\n",
    "# Creating DataModule instance\n",
    "data_module = MyDataModule(full_dataset)\n",
    "\n",
    "# Setup the data module\n",
    "data_module.setup()\n",
    "\n",
    "# Example of fetching a single batch\n",
    "train_loader = data_module.train_dataloader()\n",
    "for batch in train_loader:\n",
    "    print(f\"Batch data shape: {batch[0].shape}\")\n",
    "    x, y = batch\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Model Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, do not delete the following imports, they are needed for the function add_core_model_to_fun_control\n",
    "import river\n",
    "from river import forest, tree, linear_model, rules\n",
    "from river import preprocessing\n",
    "import sklearn.metrics\n",
    "import spotpython\n",
    "from spotpython.light import regression\n",
    "\n",
    "def get_core_model_from_name(core_model_name: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns the river core model name and instance from a core model name.\n",
    "\n",
    "    Args:\n",
    "        core_model_name (str): The full name of the core model in the format 'module.Model'.\n",
    "\n",
    "    Returns:\n",
    "        (str, object): A tuple containing the core model name and an instance of the core model.\n",
    "    \"\"\"\n",
    "    # Split the model name into its components\n",
    "    name_parts = core_model_name.split(\".\")\n",
    "    \n",
    "    if len(name_parts) < 2:\n",
    "        raise ValueError(f\"Invalid core model name: {core_model_name}. Expected format: 'module.ModelName'.\")\n",
    "\n",
    "    module_name = name_parts[0]\n",
    "    model_name = name_parts[1]\n",
    "    \n",
    "    try:\n",
    "        # Try to get the model from the river library\n",
    "        core_model_instance = getattr(getattr(river, module_name), model_name)\n",
    "        return model_name, core_model_instance\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Try to get the model from the spotpython library\n",
    "            submodule_name = name_parts[1]\n",
    "            model_name = name_parts[2] if len(name_parts) == 3 else model_name\n",
    "            print(f\"module_name: {module_name}\")\n",
    "            print(f\"submodule_name: {submodule_name}\")\n",
    "            print(f\"model_name: {model_name}\")\n",
    "            core_model_instance = getattr(getattr(getattr(spotpython, module_name), submodule_name), model_name)\n",
    "            return model_name, core_model_instance\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Model '{core_model_name}' not found in either 'river' or 'spotpython' libraries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example of usage\n",
    "model_name, model_instance = get_core_model_from_name('tree.HoeffdingTreeRegressor')\n",
    "print(f\"Model Name: {model_name}, Model Instance: {model_instance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, model_instance = get_core_model_from_name(\"light.regression.NNLinearRegressor\")\n",
    "print(f\"Model Name: {model_name}, Model Instance: {model_instance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression import NNLinearRegressor\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "PATH_DATASETS = './data'\n",
    "BATCH_SIZE = 8\n",
    "dataset = Diabetes()\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "net_light_base = NNLinearRegressor(l1=128,\n",
    "                                    epochs=10,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    initialization='xavier',\n",
    "                                    act_fn=nn.ReLU(),\n",
    "                                    optimizer='Adam',\n",
    "                                    dropout_prob=0.1,\n",
    "                                    lr_mult=0.1,\n",
    "                                    patience=5,\n",
    "                                    _L_in=10,\n",
    "                                    _L_out=1,\n",
    "                                    _torchmetric=\"mean_squared_error\",)\n",
    "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=True)\n",
    "trainer.fit(net_light_base, train_loader)\n",
    "trainer.validate(net_light_base, val_loader)\n",
    "trainer.test(net_light_base, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes(return_X_y=False, as_frame=True)\n",
    "# svaing the data to a csv file\n",
    "data.frame.to_csv('~/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moons Data Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "n_features = 2\n",
    "n_samples = 500\n",
    "target_column = \"y\"\n",
    "ds =  make_moons(n_samples, noise=0.5, random_state=0)\n",
    "X, y = ds\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "train.head()\n",
    "# combine the training and test data and save to a csv file\n",
    "data = pd.concat([train, test])\n",
    "data.to_csv('moon.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "X, y = make_classification(n_samples=1000, n_features=20,  n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "# combine the training and test data and save to a csv file\n",
    "data = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))))\n",
    "data.columns = [f\"x{i}\" for i in range(1, 21)] + [\"y\"]\n",
    "data.to_csv('binary_classification.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "X, y = make_classification(n_samples=1000, n_features=20,  n_informative=9, n_redundant=2, n_repeated=0, n_classes=10, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "# combine the training and test data and save to a csv file\n",
    "data = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))))\n",
    "data.columns = [f\"x{i}\" for i in range(1, 21)] + [\"y\"]\n",
    "data.to_csv('multiple_classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=10, n_targets=1, bias=0.0, effective_rank=None, tail_strength=0.5, noise=0.0, shuffle=True, coef=False, random_state=None)\n",
    "# combine the training and test data and save to a csv file\n",
    "data = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))))\n",
    "data.columns = [f\"x{i}\" for i in range(1, 21)] + [\"y\"]\n",
    "data.to_csv('regression.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "data = load_iris(as_frame=True)\n",
    "data.frame.to_csv('iris.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotGUI.tuner.spotRun import get_report_file_name\n",
    "from spotpython.utils.init import fun_control_init\n",
    "fun_control = fun_control_init(PREFIX=\"test\")\n",
    "get_report_file_name(fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotGUI.tuner.spotRun import get_scenario_dict\n",
    "import pprint\n",
    "dic = get_scenario_dict(\"sklearn\")\n",
    "pprint.pprint(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhcf.utils.io import load_hcf_dataframe, hcf_df2tensor\n",
    "from pyhcf.utils.names import load_all_features_N_regression_list\n",
    "from torch.utils.data import DataLoader\n",
    "df = load_hcf_dataframe(A=True,\n",
    "    H=True,\n",
    "    param_list=load_all_features_N_regression_list(),\n",
    "    target='N',\n",
    "    rmNA=True,\n",
    "    rmMF=True,\n",
    "    rmV=4,\n",
    "    min_freq=1000,\n",
    "    incl_drossel=False)\n",
    "dataset = hcf_df2tensor(df, target='N', return_X_y=False)\n",
    "print(type(dataset))\n",
    "print(len(dataset))\n",
    "# save the 'TensorDataset' object to a pkl file\n",
    "# import pickle\n",
    "# with open('hcf_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataset, f)\n",
    "# load the 'TensorDataset' object from the pkl file\n",
    "# with open('hcf_dataset.pkl', 'rb') as f:\n",
    "#     dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__getitem__(0)\n",
    "# get the dimensions of the first sample\n",
    "dataset.__getitem__(0)[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import fun_control_init\n",
    "fun = analytical().fun_sphere\n",
    "fun_control = fun_control_init(\n",
    "    lower = np.array([-1, -1]),\n",
    "    upper = np.array([1, 1])\n",
    "    )\n",
    "S = spot.Spot(fun=fun,\n",
    "            fun_control=fun_control,\n",
    "            )\n",
    "X0, y0 = S.generate_random_point()\n",
    "print(f\"X0: {X0}\")\n",
    "print(f\"y0: {y0}\")\n",
    "assert X0.size == 2\n",
    "assert y0.size == 1\n",
    "assert np.all(X0 >= S.lower)\n",
    "assert np.all(X0 <= S.upper)\n",
    "assert y0 >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import get_spot_tensorboard_path\n",
    "get_spot_tensorboard_path(\"00_ubuntu_2021-08-31_14-30-00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import get_experiment_name\n",
    "get_experiment_name(prefix=\"00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init, optimizer_control_init, surrogate_control_init, design_control_init\n",
    "    )\n",
    "# number of initial points:\n",
    "ni = 5\n",
    "# number of points\n",
    "fun_evals = 10\n",
    "fun = analytical().fun_sphere\n",
    "fun_control = fun_control_init(\n",
    "    lower = np.array([-1, -1, -1]),\n",
    "    upper = np.array([1, 1, 1]),\n",
    "    fun_evals=fun_evals,\n",
    "    tolerance_x = np.sqrt(np.spacing(1))\n",
    "    )\n",
    "design_control=design_control_init(init_size=ni)\n",
    "surrogate_control=surrogate_control_init(n_theta=3)\n",
    "S = spot.Spot(fun=fun,\n",
    "            fun_control=fun_control,\n",
    "            design_control=design_control,\n",
    "            surrogate_control=surrogate_control,)\n",
    "S.run()\n",
    "S.plot_important_hyperparameter_contour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import design_control_init\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "design_control = design_control_init(init_size=3)\n",
    "fun_control = fun_control_init(\n",
    "    lower = np.array([-1, -1]),\n",
    "    upper = np.array([1, 1]),\n",
    "    fun_evals=fun_evals,\n",
    "    tolerance_x = np.sqrt(np.spacing(1))\n",
    "    )\n",
    "S = spot.Spot(fun = analytical().fun_sphere,\n",
    "              fun_control = fun_control,\n",
    "              design_control = design_control)\n",
    "X = S.generate_design(size=3, repeats=1, lower=np.array([0, 0]), upper=np.array([100, 1]))\n",
    "assert X.shape[0] == 3\n",
    "assert X.shape[1] == 2\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import inf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from spotriver.utils.data_conversion import convert_to_df\n",
    "from river.datasets import synth\n",
    "import warnings\n",
    "if not os.path.exists('./figures'):\n",
    "    os.makedirs('./figures')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "PREFIX=\"TEST_SAVE\"\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from river.datasets import synth\n",
    "from spotriver.utils.data_conversion import convert_to_df\n",
    "from math import inf\n",
    "import numpy as np\n",
    "from spotriver.fun.hyperriver import HyperRiver\n",
    "from spotriver.hyperdict.river_hyper_dict import RiverHyperDict\n",
    "from spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\n",
    "\n",
    "\n",
    "target_column = \"y\"\n",
    "metric = mean_absolute_error\n",
    "horizon = 7*24\n",
    "n_train = horizon\n",
    "p_1 = int(n_train/4)\n",
    "p_2 = int(n_train/2)\n",
    "position=(p_1, p_2)\n",
    "dataset_train = synth.FriedmanDrift(\n",
    "   drift_type='gra',\n",
    "   position=position,\n",
    "   seed=123\n",
    ")\n",
    "\n",
    "train = convert_to_df(dataset_train, n_total=n_train)\n",
    "train.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\n",
    "\n",
    "\n",
    "n_val = 10_000\n",
    "p_1 = int(n_val/4)\n",
    "p_2 = int(n_val/2)\n",
    "position=(p_1, p_2)\n",
    "dataset_val = synth.FriedmanDrift(\n",
    "   drift_type='gra',\n",
    "   position=position,\n",
    "   seed=124\n",
    ")\n",
    "val = convert_to_df(dataset_val, n_total=n_val)\n",
    "val.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\n",
    "\n",
    "from math import inf\n",
    "import numpy as np\n",
    "from spotriver.fun.hyperriver import HyperRiver\n",
    "from spotriver.hyperdict.river_hyper_dict import RiverHyperDict\n",
    "from spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\n",
    "\n",
    "fun = HyperRiver().fun_oml_horizon\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    PREFIX=PREFIX,\n",
    "    TENSORBOARD_CLEAN=False,\n",
    "    tensorboard_start=False,\n",
    "    tensorboard_stop=False,\n",
    "    fun_evals=inf,\n",
    "    max_time=0.1,\n",
    "\n",
    "    prep_model_name=\"StandardScaler\",\n",
    "    test=val, # tuner uses the validation set as test set\n",
    "    train=train,\n",
    "    target_column=target_column,\n",
    "\n",
    "    metric_sklearn_name=\"mean_absolute_error\",\n",
    "    horizon=7*24,\n",
    "    oml_grace_period=7*24,\n",
    "    weight_coeff=0.0,\n",
    "    weights=np.array([100, 0.1, 0.1]),\n",
    "\n",
    "    core_model_name=\"tree.HoeffdingTreeRegressor\",\n",
    "    hyperdict=RiverHyperDict,\n",
    "   )\n",
    "\n",
    "\n",
    "design_control = design_control_init(\n",
    "    init_size=3,\n",
    ")\n",
    "\n",
    "surrogate_control = surrogate_control_init(\n",
    "    noise=True,\n",
    "    n_theta=2,\n",
    "    min_Lambda=0.001,\n",
    "    max_Lambda=100,\n",
    ")\n",
    "\n",
    "optimizer_control = optimizer_control_init()\n",
    "\n",
    "from spotpython.spot import spot\n",
    "spot_tuner = spot.Spot(\n",
    "    fun=fun,\n",
    "    fun_control=fun_control,\n",
    "    design_control=design_control,\n",
    "    surrogate_control=surrogate_control,\n",
    "    optimizer_control=optimizer_control,\n",
    ")\n",
    "res = spot_tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.file import load_and_run_spot_python_experiment\n",
    "spot_tuner = load_and_run_spot_python_experiment(\"spot_000_experiment.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_div2_list(n, n_min) -> list:\n",
    "    \"\"\"\n",
    "    Generate a list of numbers from n to n_min (inclusive) by dividing n by 2\n",
    "    until the result is less than n_min.\n",
    "    This function starts with n and keeps dividing it by 2 until n_min is reached.\n",
    "    The number of times each value is added to the list is determined by n // current.\n",
    "\n",
    "    Args:\n",
    "        n (int): The number to start with.\n",
    "        n_min (int): The minimum number to stop at.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of numbers from n to n_min (inclusive).\n",
    "\n",
    "    Examples:\n",
    "        _generate_div2_list(10, 1)\n",
    "        [10, 5, 5, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        _generate_div2_list(10, 2)\n",
    "        [10, 5, 5, 2, 2, 2, 2, 2]\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    current = n\n",
    "    repeats = 1\n",
    "    max_repeats = 4\n",
    "    while current >= n_min:\n",
    "        result.extend([current] * min(repeats, max_repeats))\n",
    "        current = current // 2\n",
    "        repeats = repeats + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_generate_div2_list(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_generate_div2_list(128, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_hidden_sizes(_L_in = 80, l1=2**9):\n",
    "    n_low = _L_in // 4\n",
    "    n_high = max(l1, 2 * n_low)\n",
    "    hidden_sizes = _generate_div2_list(n_high, n_low)\n",
    "    return hidden_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_hidden_sizes(l1=2**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhcf.data.daten_lightv2 import DatenLightV2\n",
    "from pyhcf.utils.io import hcf_df2tensor\n",
    "df = DatenLightV2().load()\n",
    "print(f\"Datensatz der Gre {df.shape} erfolgreich geladen.\")\n",
    "print(df.columns.to_list())\n",
    "dataset = hcf_df2tensor(df, target='N', return_X_y=False)\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Network Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, we generate an 80-dim dataframe with 10000 samples, where the first two columns are random integers and the rest are random floats.\n",
    "* Then, we generate a target variable as the sum of the squared values.\n",
    "* The dataframe is converted to a tensor and split into a training, validation, and testing set. The corresponding data loaders are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "np.random.seed(42)\n",
    "n_samples = 10_000\n",
    "n_int = 2\n",
    "n_float = 76\n",
    "input_dim = n_int + n_float\n",
    "output_dim = 1\n",
    "data = np.random.rand(n_samples, n_float)\n",
    "data = np.hstack((np.random.randint(0, 10, (n_samples, n_int)), data))\n",
    "df = pd.DataFrame(data)\n",
    "df['y'] = np.sum(df.iloc[:, 2:]**2, axis=1)\n",
    "df.head()\n",
    "X = torch.tensor(df.iloc[:, :-1].values, dtype=torch.float32)\n",
    "y = torch.tensor(df.iloc[:, -1].values, dtype=torch.float32)\n",
    "dataset = TensorDataset(X, y)\n",
    "print(f\"Dataset with input tensor shape: {dataset.tensors[0].shape}\")\n",
    "print(f\"Dataset with target tensor shape: {dataset.tensors[1].shape}\")\n",
    "# print(dataset[0][0])\n",
    "# print(dataset[0][1])\n",
    "train_size_0 = int(0.8 * len(dataset))\n",
    "train_size = int(0.8 * train_size_0)\n",
    "val_size = train_size_0 - train_size\n",
    "test_size = len(dataset) - train_size_0\n",
    "train_dataset_0, test_dataset = random_split(dataset, [train_size_0, test_size])\n",
    "train_dataset, val_dataset = random_split(train_dataset_0, [train_size, val_size])\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test NNLinearRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.regression import NNLinearRegressor\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "net_light_base = NNLinearRegressor(l1=128,\n",
    "                                    batch_norm=True,\n",
    "                                    epochs=10,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    initialization='xavier',\n",
    "                                    act_fn=nn.ReLU(),\n",
    "                                    optimizer='Adam',\n",
    "                                    dropout_prob=0.1,\n",
    "                                    lr_mult=0.1,\n",
    "                                    patience=5,\n",
    "                                    _L_in=input_dim,\n",
    "                                    _L_out=output_dim,\n",
    "                                    _torchmetric=\"mean_squared_error\",)\n",
    "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=True)\n",
    "trainer.fit(net_light_base, train_loader)\n",
    "trainer.validate(net_light_base, val_loader)\n",
    "trainer.test(net_light_base, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn\n",
    "from spotpython.hyperparameters.optimizer import optimizer_handler\n",
    "import torchmetrics.functional.regression\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from spotpython.light.regression import NNLinearRegressor\n",
    "\n",
    "class SettingsDataset(Dataset):\n",
    "    \"\"\"Custom Dataset to handle settings-based data.\"\"\"\n",
    "    def __init__(self, dataframe, settings_columns, target_column):\n",
    "        self.dataframe = dataframe\n",
    "        self.settings_columns = settings_columns\n",
    "        self.target_column = target_column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        settings = tuple(self.dataframe.iloc[idx][self.settings_columns])\n",
    "        features = self.dataframe.iloc[idx].drop(self.settings_columns + [self.target_column]).values\n",
    "        target = self.dataframe.iloc[idx][self.target_column]\n",
    "        return settings, torch.tensor(features, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "class FilteredNNLinearRegressor:\n",
    "    def __init__(self, settings_columns, data, target_column='target', **nn_kwargs):\n",
    "        self.settings_columns = settings_columns\n",
    "        self.models = {}\n",
    "        self.nn_kwargs = nn_kwargs\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.prepare_networks()\n",
    "\n",
    "    def prepare_networks(self):\n",
    "        settings_combinations = self.data[self.settings_columns].drop_duplicates().to_records(index=False)\n",
    "        i = 0\n",
    "        for combination in settings_combinations:\n",
    "            print(f\"Combination {i}: {combination}\")\n",
    "            i += 1\n",
    "            self.models[combination] = NNLinearRegressor(**self.nn_kwargs)\n",
    "\n",
    "    def feature_filter(self, settings):\n",
    "        \"\"\"Filter the data based on given settings tuple.\"\"\"\n",
    "        df_filtered = self.data[(self.data[self.settings_columns] == pd.Series(settings)).all(axis=1)]\n",
    "        print(f\"df_filtered: {df_filtered}\")\n",
    "        return df_filtered\n",
    "\n",
    "    def train(self, trainer_kwargs):\n",
    "        # Split data and train each model separately\n",
    "        for settings, model in self.models.items():\n",
    "            filtered_data = self.feature_filter(settings)\n",
    "            dataset = SettingsDataset(filtered_data, self.settings_columns, self.target_column)\n",
    "            train_loader = DataLoader(dataset, batch_size=self.nn_kwargs['batch_size'])\n",
    "            trainer = L.Trainer(**trainer_kwargs)\n",
    "            trainer.fit(model, train_loader)\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        predictions = {}\n",
    "        for settings, model in self.models.items():\n",
    "            filtered_data = self.feature_filter(settings)\n",
    "            if not filtered_data.empty:\n",
    "                dataset = SettingsDataset(filtered_data, self.settings_columns, self.target_column)\n",
    "                test_loader = DataLoader(dataset, batch_size=self.nn_kwargs['batch_size'])\n",
    "                trainer = L.Trainer()\n",
    "                preds = trainer.predict(model, test_loader)\n",
    "                predictions[settings] = preds\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'setting1': [-1, -1, 1, 1],\n",
    "    'setting2': ['A', 'B', 'A', 'B'],\n",
    "    'feature1': [0.1, 0.2, 0.3, 0.4],\n",
    "    'feature2': [0.5, 0.6, 0.7, 0.8],\n",
    "    'target': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "settings_columns = ['setting1', 'setting2']\n",
    "target_column = 'target'\n",
    "nn_kwargs = {\n",
    "    'l1': 16,\n",
    "    'epochs': 5,\n",
    "    'batch_size': 2,\n",
    "    'initialization': 'xavier',\n",
    "    'act_fn': nn.ReLU(),\n",
    "    'optimizer': 'Adam',\n",
    "    'dropout_prob': 0.1,\n",
    "    'lr_mult': 0.1,\n",
    "    'patience': 2,\n",
    "    'batch_norm': True,\n",
    "    '_L_in': 2,  # For this example, 2 features besides settings\n",
    "    '_L_out': 1,\n",
    "    '_torchmetric': \"mean_squared_error\",\n",
    "}\n",
    "\n",
    "multi_network = FilteredNNLinearRegressor(settings_columns, data, target_column, **nn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_kwargs = {'max_epochs': 2,  'enable_progress_bar': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_network.train(trainer_kwargs)\n",
    "predictions = multi_network.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Explanation:\n",
    "1. SettingsDataset: A custom dataset class that includes settings as part of the data. Each row has a tuple of settings, feature values, and the target value.\n",
    "\n",
    "2. FilteredNNLinearRegressor: An umbrella class that handles setting combinations and assigns each its own `NNLinearRegressor` model instance. It trains these models using only relevant data filtered by the `feature_filter()` function.\n",
    "\n",
    "3. Feature Filtering: The `feature_filter()` function uses Pandas to filter rows based on their relevant setting information before creating dataset and loader instances for each unique settings combination.\n",
    "\n",
    "4. Training and Prediction: We generate and train separate models for each settings combination and then predict using test data filtered similarly using the defined `feature_filter()`.\n",
    "\n",
    "This approach provides modularity as each model is logically separated based on settings, while utilizing your existing class structure to individually specify training processes and handle data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.nn_linear_regressor import NNLinearRegressor\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import (\n",
    "        get_default_hyperparameters_as_array, get_one_config_from_X)\n",
    "from spotpython.plot.xai import get_gradients\n",
    "import numpy as np\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10, # 10: diabetes\n",
    "    _L_out=1,\n",
    "    _torchmetric=\"mean_squared_error\",\n",
    "    data_set=Diabetes(),\n",
    "    core_model=NNLinearRegressor,\n",
    "    hyperdict=LightHyperDict)\n",
    "X = get_default_hyperparameters_as_array(fun_control)\n",
    "config = get_one_config_from_X(X, fun_control)\n",
    "_L_in = fun_control[\"_L_in\"]\n",
    "_L_out = fun_control[\"_L_out\"]\n",
    "_torchmetric = fun_control[\"_torchmetric\"]\n",
    "batch_size = 16\n",
    "model = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _torchmetric=_torchmetric)\n",
    "gradients = get_gradients(model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\")\n",
    "# assert that the gradients are a dictionary with keys that contain the string 'layers' and values that are arrays\n",
    "assert all([key in gradients.keys() for key in gradients.keys()])\n",
    "assert all([isinstance(value, np.ndarray) for value in gradients.values()])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.nn_linear_regressor import NNLinearRegressor\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import (\n",
    "        get_default_hyperparameters_as_array, get_one_config_from_X)\n",
    "from spotpython.plot.xai import get_gradients\n",
    "import numpy as np\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10, # 10: diabetes\n",
    "    _L_out=1,\n",
    "    _torchmetric=\"mean_squared_error\",\n",
    "    data_set=Diabetes(),\n",
    "    core_model=NNLinearRegressor,\n",
    "    hyperdict=LightHyperDict)\n",
    "X = get_default_hyperparameters_as_array(fun_control)\n",
    "config = get_one_config_from_X(X, fun_control)\n",
    "_L_in = fun_control[\"_L_in\"]\n",
    "_L_out = fun_control[\"_L_out\"]\n",
    "_torchmetric = fun_control[\"_torchmetric\"]\n",
    "batch_size = 16\n",
    "model = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _torchmetric=_torchmetric)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CondNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConditionalLayer(nn.Module):\n",
    "    def __init__(self, input_dim, condition_dim, output_dim):\n",
    "        super(ConditionalLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.condition_fc = nn.Linear(condition_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        # Basic linear transformation\n",
    "        base_output = self.fc(x)\n",
    "        # Compute a condition-dependent transformation\n",
    "        condition_output = self.condition_fc(condition)\n",
    "        # Modulate the output by adding the condition-dependent transformation\n",
    "        output = base_output + condition_output\n",
    "        return F.relu(output)\n",
    "\n",
    "class ConditionalNet(nn.Module):\n",
    "    def __init__(self, input_dim, condition_dim, hidden_dim, output_dim):\n",
    "        super(ConditionalNet, self).__init__()\n",
    "        self.cond_layer1 = ConditionalLayer(input_dim, condition_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        x = self.cond_layer1(x, condition)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_dim = 10\n",
    "condition_dim = 2  # For instance, if you have two conditional features like region and season\n",
    "hidden_dim = 20\n",
    "output_dim = 1\n",
    "\n",
    "model = ConditionalNet(input_dim, condition_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Example data\n",
    "x = torch.randn(5, input_dim)\n",
    "condition = torch.randn(5, condition_dim)\n",
    "\n",
    "output = model(x, condition)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from spotpython.light.regression import NNCondNetRegressor\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "PATH_DATASETS = './data'\n",
    "BATCH_SIZE = 64\n",
    "# generate data\n",
    "num_samples = 1_000\n",
    "input_dim = 10\n",
    "cond_dim = 2\n",
    "X = torch.randn(num_samples, input_dim)  # random data for example\n",
    "Y = torch.randn(num_samples, 1)  # random target for example\n",
    "data_set = TensorDataset(X, Y)\n",
    "train_loader = DataLoader(dataset=data_set, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=data_set, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=data_set, batch_size=BATCH_SIZE)\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "net_light_base = NNCondNetRegressor(l1=128,\n",
    "                                batch_norm=True,\n",
    "                                    epochs=10,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    initialization='xavier',\n",
    "                                    act_fn=nn.ReLU(),\n",
    "                                    optimizer='Adam',\n",
    "                                    dropout_prob=0.1,\n",
    "                                    lr_mult=0.1,\n",
    "                                    patience=5,\n",
    "                                    _L_cond=cond_dim,\n",
    "                                    _L_in=input_dim - cond_dim,\n",
    "                                    _L_out=1,\n",
    "                                    _torchmetric=\"mean_squared_error\",)\n",
    "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=True)\n",
    "trainer.fit(net_light_base, train_loader)\n",
    "# validation and test should give the same result, because the data is the same\n",
    "trainer.validate(net_light_base, val_loader)\n",
    "trainer.test(net_light_base, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CondNet Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.file import get_experiment_filename\n",
    "from math import inf\n",
    "from spotpython.hyperparameters.values import set_hyperparameter\n",
    "\n",
    "PREFIX=\"4000\"\n",
    "\n",
    "data_set = Diabetes()\n",
    "input_dim = 10\n",
    "output_dim = 1\n",
    "cond_dim = 2\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    PREFIX=PREFIX,\n",
    "    fun_evals=inf,\n",
    "    max_time=1,\n",
    "    data_set = data_set,\n",
    "    core_model_name=\"light.regression.NNCondNetRegressor\",\n",
    "    hyperdict=LightHyperDict,\n",
    "    _L_in=input_dim - cond_dim,\n",
    "    _L_out=1,\n",
    "    _L_cond=cond_dim,)\n",
    "\n",
    "fun = HyperLight().fun\n",
    "\n",
    "\n",
    "set_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\n",
    "set_hyperparameter(fun_control, \"l1\", [3,4])\n",
    "set_hyperparameter(fun_control, \"epochs\", [3,7])\n",
    "set_hyperparameter(fun_control, \"batch_size\", [4,5])\n",
    "set_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\n",
    "set_hyperparameter(fun_control, \"patience\", [2,3])\n",
    "set_hyperparameter(fun_control, \"lr_mult\", [0.1, 20.0])\n",
    "\n",
    "design_control = design_control_init(init_size=10)\n",
    "\n",
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control)\n",
    "res = spot_tuner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_weights(net, return_index=False) -> tuple:\n",
    "    \"\"\"\n",
    "    Get the weights of a neural network and the size of each layer.\n",
    "\n",
    "    Args:\n",
    "        net (object):\n",
    "            A neural network.\n",
    "        return_index (bool, optional):\n",
    "            Whether to return the index. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            A tuple containing:\n",
    "            - weights: A dictionary with the weights of the neural network.\n",
    "            - index: The layer index list (only if return_index is True).\n",
    "            - layer_sizes: A dictionary with layer names as keys and their sizes as entries in NumPy array format.\n",
    "\n",
    "    Examples:\n",
    "        >>> # Example usage (as described in the original function's docstring)\n",
    "    \"\"\"\n",
    "    weights = {}\n",
    "    index = []\n",
    "    layer_sizes = {}\n",
    "    \n",
    "    for name, param in net.named_parameters():\n",
    "        if name.endswith(\".bias\"):\n",
    "            continue\n",
    "        \n",
    "        # Extract layer number\n",
    "        layer_number = int(name.split(\".\")[1])\n",
    "        index.append(layer_number)\n",
    "        \n",
    "        # Create dictionary key for this layer\n",
    "        key_name = f\"Layer {layer_number}\"\n",
    "        \n",
    "        # Store weight information\n",
    "        weights[key_name] = param.detach().view(-1).cpu().numpy()\n",
    "        \n",
    "        # Store layer size as a NumPy array\n",
    "        layer_sizes[key_name] = np.array(param.size())\n",
    "    \n",
    "    if return_index:\n",
    "        return weights, index, layer_sizes\n",
    "    else:\n",
    "        return weights, layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n",
      "/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Layer 0': array([0.87303966, 0.46751958, 0.11630094, 0.493778  , 0.59376913,\n",
       "         0.15941548, 0.21318042, 0.02062678, 0.32472628, 0.93553424,\n",
       "         0.58549803, 0.46945995, 0.520079  , 0.8117728 , 0.05846822,\n",
       "         0.11420518, 0.3337648 , 0.21224093, 0.75789255, 0.85329175,\n",
       "         0.01488709, 0.07566017, 0.01309109, 0.68862724, 0.90242726,\n",
       "         0.11232996, 0.2685218 , 0.6591103 , 0.17350733, 0.9247398 ,\n",
       "         0.6165806 , 0.3608082 , 0.5324753 , 0.65588427, 0.32319343,\n",
       "         0.11257207, 0.5033608 , 0.5091075 , 0.5100826 , 0.42703485,\n",
       "         0.82103676, 0.3604704 , 0.45160365, 0.7055938 , 0.18528134,\n",
       "         0.6338793 , 0.38944215, 0.73983675, 0.22876781, 0.51847917,\n",
       "         0.5489147 , 0.09770173, 0.1364289 , 0.69175667, 0.35447174,\n",
       "         0.7969483 , 0.00606871, 0.2528357 , 0.08816904, 0.6997357 ,\n",
       "         0.48550433, 0.4067393 , 0.41681433, 0.10917556, 0.6417975 ,\n",
       "         0.5124629 , 0.15494353, 0.68814385, 0.48995048, 0.01642621,\n",
       "         0.7689601 , 0.76744354, 0.40579492, 0.15478092, 0.520075  ,\n",
       "         0.8772899 , 0.9576699 , 0.12259948, 0.2741655 , 0.8893122 ],\n",
       "        dtype=float32),\n",
       "  'Layer 3': array([0.7443891 , 0.8095065 , 0.25113285, 0.93076724, 0.08896703,\n",
       "         0.47591555, 0.51038146, 0.5839839 , 0.12270802, 0.9587332 ,\n",
       "         0.9913866 , 0.15469629, 0.5184704 , 0.23366892, 0.9794423 ,\n",
       "         0.77883285, 0.79445034, 0.66130227, 0.4502216 , 0.7815312 ,\n",
       "         0.5085141 , 0.3176424 , 0.7581541 , 0.65690315, 0.3704427 ,\n",
       "         0.36297196, 0.05783021, 0.3629408 , 0.2974429 , 0.22747558,\n",
       "         0.04839081, 0.89163804], dtype=float32),\n",
       "  'Layer 6': array([0.05315423, 0.99635726, 0.23773861, 0.46156645, 0.907871  ,\n",
       "         0.6649557 , 0.35725033, 0.09747154, 0.29557234, 0.90265304,\n",
       "         0.31119514, 0.91671044, 0.41389173, 0.43623322, 0.6995561 ,\n",
       "         0.42653286], dtype=float32),\n",
       "  'Layer 9': array([0.49578917, 0.84629655, 0.6670992 , 0.48009777, 0.6904146 ,\n",
       "         0.93547195, 0.62602013, 0.35337394], dtype=float32),\n",
       "  'Layer 12': array([0.66383564, 0.45625526, 0.109088  , 0.30693573], dtype=float32),\n",
       "  'Layer 15': array([0.7274068 , 0.51639706, 0.68447214, 0.20734751], dtype=float32),\n",
       "  'Layer 18': array([0.9726678 , 0.29133874], dtype=float32)},\n",
       " {'Layer 0': array([ 8, 10]),\n",
       "  'Layer 3': array([4, 8]),\n",
       "  'Layer 6': array([4, 4]),\n",
       "  'Layer 9': array([2, 4]),\n",
       "  'Layer 12': array([2, 2]),\n",
       "  'Layer 15': array([2, 2]),\n",
       "  'Layer 18': array([1, 2])})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# from spotpython.plot.xai import get_weights\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.nn_linear_regressor import NNLinearRegressor\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import (\n",
    "        get_default_hyperparameters_as_array, get_one_config_from_X)\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "# from spotpython.plot.xai import get_gradients\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10, # 10: diabetes\n",
    "    _L_out=1,\n",
    "    _torchmetric=\"mean_squared_error\",\n",
    "    data_set=Diabetes(),\n",
    "    core_model=NNLinearRegressor,\n",
    "    hyperdict=LightHyperDict)\n",
    "X = get_default_hyperparameters_as_array(fun_control)\n",
    "config = get_one_config_from_X(X, fun_control)\n",
    "_L_in = fun_control[\"_L_in\"]\n",
    "_L_out = fun_control[\"_L_out\"]\n",
    "_torchmetric = fun_control[\"_torchmetric\"]\n",
    "batch_size = 16\n",
    "model = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _torchmetric=_torchmetric)\n",
    "weights, layer_sizes = get_weights(net=model)\n",
    "weights, layer_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import math\n",
    "\n",
    "def plot_nn_values_scatter(\n",
    "    nn_values,\n",
    "    layer_sizes,\n",
    "    nn_values_names=\"\",\n",
    "    absolute=True,\n",
    "    cmap=\"gray\",\n",
    "    figsize=(6, 6),\n",
    "    return_reshaped=False,\n",
    "    show=True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Plot the values of a neural network including a marker for padding values.\n",
    "    For simplicity, this example will annotate 'P' directly on the plot for padding values\n",
    "    using a unique marker value approach.\n",
    "\n",
    "    Args:\n",
    "        nn_values (dict):\n",
    "            A dictionary with the values of the neural network. For example,\n",
    "            the weights, gradients, or activations.\n",
    "        layer_sizes (dict):\n",
    "            A dictionary with layer names as keys and their sizes as entries in NumPy array format.\n",
    "        nn_values_names (str, optional):\n",
    "            The name of the values. Defaults to \"\".\n",
    "        absolute (bool, optional):\n",
    "            Whether to use the absolute values. Defaults to True.\n",
    "        cmap (str, optional):\n",
    "            The colormap to use. Defaults to \"gray\".\n",
    "        figsize (tuple, optional):\n",
    "            The figure size. Defaults to (6, 6).\n",
    "        return_reshaped (bool, optional):\n",
    "            Whether to return the reshaped values. Defaults to False.\n",
    "        show (bool, optional):\n",
    "            Whether to show the plot. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the reshaped values.\n",
    "    \"\"\"\n",
    "    if cmap == \"gray\":\n",
    "        cmap = \"gray\"\n",
    "    elif cmap == \"BlueWhiteRed\":\n",
    "        cmap = colors.LinearSegmentedColormap.from_list(\"\", [\"blue\", \"white\", \"red\"])\n",
    "    elif cmap == \"GreenYellowRed\":\n",
    "        cmap = colors.LinearSegmentedColormap.from_list(\"\", [\"green\", \"yellow\", \"red\"])\n",
    "    else:\n",
    "        cmap = \"viridis\"\n",
    "\n",
    "    res = {}\n",
    "    padding_marker = np.nan  # Use NaN as a special marker for padding\n",
    "    for layer, values in nn_values.items():\n",
    "        if layer not in layer_sizes:\n",
    "            print(f\"Layer {layer} size not defined, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        layer_shape = layer_sizes[layer]\n",
    "        height, width = layer_shape if len(layer_shape) == 2 else (layer_shape[0], 1)  # Support linear layers\n",
    "        \n",
    "        print(f\"{len(values)} values in Layer {layer}. Geometry: ({height}, {width})\")\n",
    "        \n",
    "        total_size = height * width\n",
    "        if len(values) < total_size:\n",
    "            padding_needed = total_size - len(values)\n",
    "            print(f\"{padding_needed} padding values added to Layer {layer}.\")\n",
    "            values = np.append(values, [padding_marker] * padding_needed)  # Append padding values\n",
    "\n",
    "        if absolute:\n",
    "            reshaped_values = np.abs(values).reshape((height, width))\n",
    "            # Mark padding values distinctly by setting them back to NaN\n",
    "            reshaped_values[reshaped_values == np.abs(padding_marker)] = np.nan\n",
    "        else:\n",
    "            reshaped_values = values.reshape((height, width))\n",
    "\n",
    "        _, ax = plt.subplots(figsize=figsize)\n",
    "        cax = ax.imshow(reshaped_values, cmap=cmap, interpolation=\"nearest\")\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if np.isnan(reshaped_values[i, j]):\n",
    "                    ax.text(j, i, \"P\", ha=\"center\", va=\"center\", color=\"red\")\n",
    "        \n",
    "        plt.colorbar(cax, label=\"Value\")\n",
    "        plt.title(f\"{nn_values_names} Plot for {layer}\")\n",
    "        if show:\n",
    "            plt.show()\n",
    "        \n",
    "        # Add reshaped_values to the dictionary res\n",
    "        res[layer] = reshaped_values\n",
    "    if return_reshaped:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, layer_sizes = get_weights(net=model)\n",
    "plot_nn_values_scatter(nn_values=weights, layer_sizes=layer_sizes, nn_values_names=\"Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "\n",
    "def get_gradients(net, fun_control, batch_size, device=\"cpu\", normalize=False) -> tuple:\n",
    "    \"\"\"\n",
    "    Get the gradients of a neural network and the size of each layer.\n",
    "\n",
    "    Args:\n",
    "        net (object):\n",
    "            A neural network.\n",
    "        fun_control (dict):\n",
    "            A dictionary with the function control.\n",
    "        batch_size (int, optional):\n",
    "            The batch size.\n",
    "        device (str, optional):\n",
    "            The device to use. Defaults to \"cpu\".\n",
    "        normalize (bool, optional):\n",
    "            Whether to normalize the input data. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - grads: A dictionary with the gradients of the neural network.\n",
    "            - layer_sizes: A dictionary with layer names as keys and their sizes as entries in NumPy array format.\n",
    "\n",
    "    Examples:\n",
    "        >>> # Example usage to compute gradients\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    dataset = fun_control[\"data_set\"]\n",
    "    data_module = LightDataModule(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        test_size=fun_control[\"test_size\"],\n",
    "        scaler=fun_control[\"scaler\"],\n",
    "        verbosity=10,\n",
    "    )\n",
    "    data_module.setup(stage=\"fit\")\n",
    "    train_loader = data_module.train_dataloader()\n",
    "    inputs, targets = next(iter(train_loader))\n",
    "    if normalize:\n",
    "        inputs = (inputs - inputs.mean(dim=0, keepdim=True)) / inputs.std(dim=0, keepdim=True)\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    # Pass one batch through the network, and calculate the gradients for the weights\n",
    "    net.zero_grad()\n",
    "    preds = net(inputs)\n",
    "    preds = preds.squeeze(-1)  # Remove the last dimension if it's 1\n",
    "    loss = F.mse_loss(preds, targets)\n",
    "    loss.backward()\n",
    "\n",
    "    grads = {}\n",
    "    layer_sizes = {}\n",
    "    for name, params in net.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            # Collect gradient information\n",
    "            grads[name] = params.grad.view(-1).cpu().clone().numpy()\n",
    "            # Collect size information\n",
    "            layer_sizes[name] = np.array(params.size())\n",
    "\n",
    "    net.zero_grad()\n",
    "    return grads, layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.nn_linear_regressor import NNLinearRegressor\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import (\n",
    "        get_default_hyperparameters_as_array, get_one_config_from_X)\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "# from spotpython.plot.xai import get_gradients\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10, # 10: diabetes\n",
    "    _L_out=1,\n",
    "    _torchmetric=\"mean_squared_error\",\n",
    "    data_set=Diabetes(),\n",
    "    core_model=NNLinearRegressor,\n",
    "    hyperdict=LightHyperDict)\n",
    "X = get_default_hyperparameters_as_array(fun_control)\n",
    "config = get_one_config_from_X(X, fun_control)\n",
    "_L_in = fun_control[\"_L_in\"]\n",
    "_L_out = fun_control[\"_L_out\"]\n",
    "_torchmetric = fun_control[\"_torchmetric\"]\n",
    "batch_size = 16\n",
    "model = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _torchmetric=_torchmetric)\n",
    "get_gradients(model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients, layer_sizes = get_gradients(model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\")\n",
    "plot_nn_values_scatter(nn_values=gradients, layer_sizes=layer_sizes, nn_values_names=\"Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n",
      "/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from spotpython.utils.init import fun_control_init\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.nn_linear_regressor import NNLinearRegressor\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.hyperparameters.values import (\n",
    "        get_default_hyperparameters_as_array, get_one_config_from_X)\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "# from spotpython.plot.xai import get_gradients\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10, # 10: diabetes\n",
    "    _L_out=1,\n",
    "    _torchmetric=\"mean_squared_error\",\n",
    "    data_set=Diabetes(),\n",
    "    core_model=NNLinearRegressor,\n",
    "    hyperdict=LightHyperDict)\n",
    "X = get_default_hyperparameters_as_array(fun_control)\n",
    "config = get_one_config_from_X(X, fun_control)\n",
    "_L_in = fun_control[\"_L_in\"]\n",
    "_L_out = fun_control[\"_L_out\"]\n",
    "_torchmetric = fun_control[\"_torchmetric\"]\n",
    "batch_size = 16\n",
    "model = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _torchmetric=_torchmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nans(data, layer_index) -> bool:\n",
    "    \"\"\"Checks for NaN values in the tensor data.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): The tensor to check for NaN values.\n",
    "        layer_index (int): The index of the layer for logging purposes.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if NaNs are found, False otherwise.\n",
    "    \"\"\"\n",
    "    if torch.isnan(data).any():\n",
    "        print(f\"NaN detected after layer {layer_index}\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(net, fun_control, batch_size, device=\"cpu\", normalize=False) -> tuple:\n",
    "    \"\"\"\n",
    "    Computes the activations for each layer of the network, the mean activations,\n",
    "    and the sizes of the activations for each layer.\n",
    "\n",
    "    Args:\n",
    "        net (nn.Module): The neural network model.\n",
    "        fun_control (dict): A dictionary containing the dataset.\n",
    "        batch_size (int): The batch size for the data loader.\n",
    "        device (str): The device to run the model on. Defaults to \"cpu\".\n",
    "        normalize (bool): Whether to normalize the input data. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the activations, mean activations, and layer sizes for each layer.\n",
    "\n",
    "    Examples:\n",
    "        >>> from spotpython.plot.xai import get_activations\n",
    "            activations, mean_activations, layer_sizes = get_activations(net, fun_control)\n",
    "    \"\"\"\n",
    "    activations = {}\n",
    "    mean_activations = {}\n",
    "    layer_sizes = {}\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    dataset = fun_control[\"data_set\"]\n",
    "    data_module = LightDataModule(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        test_size=fun_control[\"test_size\"],\n",
    "        scaler=fun_control[\"scaler\"],\n",
    "        verbosity=10,\n",
    "    )\n",
    "    data_module.setup(stage=\"fit\")\n",
    "    train_loader = data_module.train_dataloader()\n",
    "    inputs, _ = next(iter(train_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    if normalize:\n",
    "        inputs = (inputs - inputs.mean(dim=0, keepdim=True)) / inputs.std(dim=0, keepdim=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        # Loop through all layers\n",
    "        for layer_index, layer in enumerate(net.layers[:-1]):\n",
    "            inputs = layer(inputs)  # Forward pass through the layer\n",
    "\n",
    "            # Check for NaNs\n",
    "            if check_for_nans(inputs, layer_index):\n",
    "                break\n",
    "\n",
    "            # Collect activations for Linear layers\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                activations[layer_index] = inputs.view(-1).cpu().numpy()\n",
    "                mean_activations[layer_index] = inputs.mean(dim=0).cpu().numpy()\n",
    "                # Record the size of the activations\n",
    "                layer_sizes[layer_index] = np.array(inputs.size())\n",
    "\n",
    "    return activations, mean_activations, layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage: fit\n",
      "full_sizefull_train_size: 0.6\n",
      "full_sizeval_size: 0.24\n",
      "full_sizetrain_size: 0.36\n",
      "full_sizetest_size: 0.4\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n",
      "128 values in Layer 0. Geometry: (16, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAIQCAYAAACISblhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/3ElEQVR4nO3de1xUdf4/8NdwmeEiIIhyURTwhqSCgrLetSaRzLK8fyuRSr9bsmn07WIl4KXQUpdSkqw1ybW0LTW7LGYoWSt5gcw1V1MXBUVuJiCoDDLn98f+mHVkMMAznzlyXs/H4zwezZnD5/05Q/Ke1zlnzmgkSZJARESqY2frCRARkW2wARARqRQbABGRSrEBEBGpFBsAEZFKsQEQEakUGwARkUqxARARqRQbABGRSrEB2NCsWbMQGBhok9rJycnQaDQ2qS2XM2fOQKPRYMOGDULqbdy4ESEhIXB0dET79u2F1CSyJjaAW3jnnXeg0WgQFRXV6jGKioqQnJyMw4cPyzexZrpy5QqSk5ORnZ0tvPbtyM7OhkajMS2Ojo4IDg7GzJkz8e9//1uWGvv27UNycjIqKiqatf3x48cxa9YsdO/eHe+99x7WrVsnyzxupaKiAnPmzEHHjh3h6uqKMWPGIC8vz+p1SUUkatLQoUOlwMBACYB08uTJVo1x8OBBCYD0wQcfNHrOYDBI165du81ZNq2srEwCICUlJTV6rq6uTrp69arVat+OPXv2SACkZ555Rtq4caO0fv16KT4+XtJqtZKXl5d0/vx5SZIkKT8/v8nX9ve8+eabEgApPz+/WduvXbv2tv4/aKn6+npp6NChkqurq5ScnCytWbNGCg0Nldzc3KRff/1VyByo7WMCaEJ+fj727duHVatWoWPHjti0aZPsNRwdHaHT6WQftzkcHBzg5ORkk9rNNWLECDz66KOIi4vD6tWrsWLFCvz222/IyMgQPpfS0lIAkPXQz5UrV5p87tNPP8W+ffuwYcMGJCUlYe7cucjOzoa9vT2SkpJkmwOpnK07kFItWbJE8vT0lGpra6WnnnpK6tmzp8XtLl26JM2fP1/q1q2bpNVqpc6dO0uPPfaYVFZWZnone/PS8I41NjZW6tatmyRJ/0kDnp6e0qxZsxrVqKyslHQ6nfTcc89JkiRJtbW10sKFC6WBAwdK7u7ukouLizR8+HBp9+7dpp9peHd889KQBpKSkqSbf/11dXXS4sWLpeDgYEmr1UrdunWTFixY0CildOvWTRo/frz0/fffS4MGDZJ0Op0UFBQkZWRkmG1nMBik5ORkqUePHpJOp5O8vLykYcOGSd98880tX/uG1+1vf/ub2fqjR49KAKTZs2eb7ePNCSArK0saPny45OLiInl4eEgPPPCAdOzYMdPzDft+89JUGujWrVuTr6MkSVJaWpoUGhoqabVayc/PT3r66aelS5cumY0xatQo6a677pIOHTokjRgxQnJ2dpbmzZvX5GswZcoUycfHR6qvrzdbP2fOHMnFxcWqyZHUgwmgCZs2bcLDDz8MrVaLGTNm4OTJkzh48KDZNtXV1RgxYgRWr16NsWPH4q233sIf//hHHD9+HOfOnUOfPn2wePFiAMCcOXOwceNGbNy4ESNHjmxUz9HREQ899BC2b98Og8Fg9tz27dtRW1uL6dOnAwCqqqrw/vvvY/To0Vi+fDmSk5NRVlaG6Oho07mGjh07Yu3atQCAhx56yFT74YcfbnKfn3zySSQmJmLgwIH485//jFGjRiElJcVU90anTp3C5MmTce+992LlypXw9PTErFmz8Msvv5i2SU5OxqJFizBmzBisWbMGr7zyCrp27drq49inT58GAHTo0KHJbb799ltER0ejtLQUycnJSEhIwL59+zBs2DCcOXMGAPDwww9jxowZAIA///nPptemY8eOFsdMTU3FQw89BABYu3at2euYnJyMuXPnwt/fHytXrsSkSZPw7rvvYuzYsairqzMb5+LFi4iJiUF4eDhSU1MxZsyYJvfjp59+wsCBA2FnZ/5PdPDgwbhy5Qp+/fXXW7xSRM1k6w6kRIcOHZIASLt27ZIkSZKMRqPUpUuXRu/YEhMTJQDS1q1bG41hNBolSbr1OYAbE4AkSdLOnTslANIXX3xhtt19990nBQcHmx5fv35dqq2tNdvm0qVLko+Pj/T444+b1t3qHMDNCeDw4cMSAOnJJ5802+7//u//JABm6aLhHfHevXtN60pLS81SiiRJUlhYmDR+/PhGtX9PQwJYv369VFZWJhUVFUlfffWVFBgYKGk0GungwYOSJFlOAOHh4VKnTp2kixcvmtb9/PPPkp2dnTRz5kzTupaeA2h4vcrKysz2WavVSmPHjjV7p75mzRrT/BuMGjVKAiClp6c3q56rq6vZ77LBV199JQGQMjMzmzUO0a0wAViwadMm+Pj4mN6haTQaTJs2DZs3b0Z9fb1pu88++wxhYWGmd4c3as0llnfffTe8vb2xZcsW07pLly5h165dmDZtmmmdvb09tFotAMBoNOK3337D9evXERkZ2ep3119//TUAICEhwWz9c889BwD46quvzNaHhoZixIgRpscdO3ZE7969za7Sad++PX755RecPHmyVXN6/PHH0bFjR/j7+2P8+PGoqalBRkYGIiMjLW5/4cIFHD58GLNmzYKXl5dpff/+/XHvvfea9lEu3377LQwGA+bPn2/2Tn327Nlwd3dv9JrpdDrExcU1a+yrV69aPD/UcN7m6tWrtzFzov9gA7hJfX09Nm/ejDFjxiA/Px+nTp3CqVOnEBUVhZKSEmRlZZm2PX36NPr27StbbQcHB0yaNAmff/45amtrAQBbt25FXV2dWQMAgIyMDPTv3x9OTk7o0KEDOnbsiK+++gqVlZWtqn327FnY2dmhR48eZut9fX3Rvn17nD171mx9165dG43h6emJS5cumR4vXrwYFRUV6NWrF/r164fnn38eR44cafacEhMTsWvXLuzevRtHjhxBUVERHnvssVvuAwD07t270XN9+vRBeXk5ampqml3/9zRVT6vVIjg4uNFr1rlzZ1Pj/j3Ozs6m/wdudO3aNdPzRLeLDeAmu3fvxoULF7B582b07NnTtEydOhUArHI10I2mT5+Oy5cv4+9//zsA4JNPPkFISAjCwsJM2/z1r381XZP+l7/8BZmZmdi1axfuvvtuGI3G26rf3ORib29vcb10wzeMjhw5EqdPn8b69evRt29fvP/++xg4cCDef//9ZtXo168f9Ho9xowZg379+sHBwaFZP6dULfmj7efnhwsXLjRa37DO399ftnmRet3Z/6KsYNOmTejUqRPS0tIaPbd161Zs27YN6enpcHZ2Rvfu3XH06NFbjtfSQ0EjR46En58ftmzZguHDh2P37t145ZVXzLb59NNPERwcjK1bt5qNf/PlgS2p3a1bNxiNRpw8eRJ9+vQxrS8pKUFFRQW6devWov1o4OXlhbi4OMTFxaG6uhojR45EcnIynnzyyVaNdysNczxx4kSj544fPw5vb2+4uroCaN0hulvVCw4ONq03GAzIz8+HXq9v9djh4eH4/vvvYTQazQ4v7d+/Hy4uLujVq1frJ070/zEB3ODq1avYunUr7r//fkyePLnREh8fj8uXL2PHjh0AgEmTJuHnn3/Gtm3bGo3V8E644Q9Ocz9xamdnh8mTJ+OLL77Axo0bcf369UaHfxrefd/4bnv//v3Iyckx287FxaXZte+77z4A/7ni5UarVq0CAIwfP75Z87/RxYsXzR63a9cOPXr0sHhoQw5+fn4IDw9HRkaG2T4fPXoU33zzjWkfgZb/XizR6/XQarV4++23zX4Xf/nLX1BZWdmq16zB5MmTUVJSgq1bt5rWlZeX429/+xsmTJhgs8+PUNvCBHCDHTt24PLly3jggQcsPv+HP/zB9KGwadOm4fnnn8enn36KKVOm4PHHH0dERAR+++037NixA+np6QgLC0P37t3Rvn17pKenw83NDa6uroiKikJQUFCT85g2bRpWr16NpKQk9OvXz+wdOQDcf//92Lp1Kx566CGMHz8e+fn5SE9PR2hoKKqrq03bOTs7IzQ0FFu2bEGvXr3g5eWFvn37WjxvERYWhtjYWKxbtw4VFRUYNWoUDhw4gIyMDEycOPGWlyw2JTQ0FKNHj0ZERAS8vLxw6NAhfPrpp4iPj2/xWM315ptvIiYmBkOGDMETTzyBq1evYvXq1fDw8EBycrJpu4iICADAK6+8gunTp8PR0RETJkwwNYbm6NixIxYsWIBFixZh3LhxeOCBB3DixAm88847GDRoEB599NFW78fkyZPxhz/8AXFxcTh27Bi8vb3xzjvvoL6+HosWLWr1uERmbHsRkrJMmDBBcnJykmpqaprcZtasWZKjo6NUXl4uSZIkXbx4UYqPj5c6d+4sabVaqUuXLlJsbKzpeUmSpM8//1wKDQ2VHBwcmvwg2I2MRqMUEBAgAZCWLl1q8fnXX39d6tatm6TT6aQBAwZIX375pcXx9u3bJ0VEREharbZZHwRbtGiRFBQUJDk6OkoBAQG3/CDYzUaNGiWNGjXK9Hjp0qXS4MGDpfbt20vOzs5SSEiI9Nprr0kGg6Gpl1eSpKY/CHazpj4I9u2330rDhg2TnJ2dJXd3d2nChAlmHwRrsGTJEqlz586SnZ3d714Sauky0AZr1qyRQkJCJEdHR8nHx0d66qmnmvwgWEv89ttv0hNPPCF16NBBcnFxkUaNGmW6BJZIDhpJuiG7EhGRavAcABGRSrEBEBGpFBsAEZFKsQEQEakUGwARkUqxARARqZTiPghmNBpRVFQENze3O/5Ly4naEkmScPnyZfj7+zf6ngK5XLt2rdH3YchFq9Uq/lvwRFNcAygqKkJAQICtp0FETSgsLESXLl1kH/fatWsICgpCcXGx7GMD/7mzbX5+PpvADRTXANzc3AAA99xzj9C7P+7du1dYrQY33uFTFNHfJOXn5ye0HvCff+ii5ebmCq95q293swaDwYC//vWvpn+j1hi/uLgYhYWFcHd3l3XsqqoqBAQEwGAwsAHcQHENoOGwj4ODAxwdHYXXFckWtze2VnRvSlO3jbYmW7yutvj/p7nfLSA3a++rm5ub7E2GNzywjCeBiYhUSnEJgIjUTZIk2d+xMwFYxgRARKRSTABEpChMAOKwARCRorABiMNDQEREKsUEQESKwgQgjtUSQFpaGgIDA+Hk5ISoqCgcOHDAWqWIiKgVrNIAtmzZgoSEBCQlJSEvLw9hYWGIjo5GaWmpNcoRURvSkADkXqgxqzSAVatWYfbs2YiLi0NoaCjS09Ph4uKC9evXW6McERG1guwNwGAwIDc3F3q9/r9F7Oyg1+uRk5MjdzkiamOYAMSR/SRweXk56uvr4ePjY7bex8cHx48fb7R9bW0tamtrTY+rqqrknhIREVlg88tAU1JS4OHhYVp4K2gidWMCEEf2BuDt7Q17e3uUlJSYrS8pKbF4m94FCxagsrLStBQWFso9JSIiskD2BqDVahEREYGsrCzTOqPRiKysLAwZMqTR9jqdDu7u7mYLEakXE4A4VvkgWEJCAmJjYxEZGYnBgwcjNTUVNTU1iIuLs0Y5ImpD+EEwcazSAKZNm4aysjIkJiaiuLgY4eHhyMzMbHRimIiIbMdqt4KIj49HfHy8tYYnojaKCUAcm18FREREtsGbwRGRojABiMMEQESkUkwARKQoTADiMAEQEakUEwARKQoTgDhsAESkKGwA4vAQEBGRSik2ARw5cgR2duL6U1RUlLBaDU6ePCm85l133SW8pmi//PKL8JphYWHCa37zzTdC6xmNRiF1mADEYQIgIlIpxSYAIlInJgBxmACIiFSKCYCIFIUJQBwmACIilWICICLF4Tt2MdgAiEhReAhIHB4CIiJSKSYAIlIUJgBxmACIiFSKCYCIFIUJQBwmACIilWICICJFYQIQhwmAiEil2ACISFEaEoDcS0ulpaUhMDAQTk5OiIqKwoEDB5rcduvWrYiMjET79u3h6uqK8PBwbNy4sdF+JSYmws/PD87OztDr9Ta5JfyN2ACISFGU0AC2bNmChIQEJCUlIS8vD2FhYYiOjkZpaanF7b28vPDKK68gJycHR44cQVxcHOLi4rBz507TNm+88QbefvttpKenY//+/XB1dUV0dDSuXbt2W6/X7WADICK6yapVqzB79mzExcUhNDQU6enpcHFxwfr16y1uP3r0aDz00EPo06cPunfvjnnz5qF///744YcfAPynqaWmpuLVV1/Fgw8+iP79++PDDz9EUVERtm/fLnDPzLEBEJGi2DoBGAwG5ObmQq/Xm9bZ2dlBr9cjJyenWfPPysrCiRMnMHLkSABAfn4+iouLzcb08PBAVFRUs8a0Fl4FRESqUVVVZfZYp9NBp9OZrSsvL0d9fT18fHzM1vv4+OD48eNNjl1ZWYnOnTujtrYW9vb2eOedd3DvvfcCAIqLi01j3Dxmw3O2wARARIpizQQQEBAADw8P05KSkiLbvN3c3HD48GEcPHgQr732GhISEpCdnS3b+NbABEBEqlFYWAh3d3fT45vf/QOAt7c37O3tUVJSYra+pKQEvr6+TY5tZ2eHHj16AADCw8Pxr3/9CykpKRg9erTp50pKSuDn52c2Znh4+O3s0m1hAiAiRbFmAnB3dzdbLDUArVaLiIgIZGVlmdYZjUZkZWVhyJAhzd4Po9GI2tpaAEBQUBB8fX3NxqyqqsL+/ftbNKbcmACIiG6SkJCA2NhYREZGYvDgwUhNTUVNTQ3i4uIAADNnzkTnzp1Nh5BSUlIQGRmJ7t27o7a2Fl9//TU2btyItWvXAgA0Gg3mz5+PpUuXomfPnggKCsLChQvh7++PiRMn2mo32QCISFmUcCuIadOmoaysDImJiSguLkZ4eDgyMzNNJ3ELCgpgZ/ffAyg1NTV4+umnce7cOTg7OyMkJAR//etfMW3aNNM2L7zwAmpqajBnzhxUVFRg+PDhyMzMhJOTkzw72QoaSWE3yaiqqoKHhwf8/PzMXmBr69Wrl7BaDWzxKcDu3bsLryna6dOnhddsOPYrUkFBgdB6RqMRZ86cQWVlpdlxdLk0/Ns/evQo3NzcZB378uXL6Nu3r9XmfqfiOQAiIpXiISAiUhQlHAJSCyYAIiKVUmwCePbZZ+Hs7CysXkVFhbBaDe6++27hNX/77Teh9WxxvHXgwIHCa16/fl14zccee0xovatXryI+Pt7qdZgAxGECICJSKcUmACJSJyYAcZgAiIhUigmAiBSFCUAcNgAiUhQ2AHF4CIiISKWYAIhIUZgAxGECICJSKSYAIlIcvmMXQ/YEkJKSgkGDBsHNzQ2dOnXCxIkTceLECbnLEBHRbZK9AXz33XeYO3cufvzxR+zatQt1dXUYO3Ysampq5C5FRG2QNb8RjMzJfggoMzPT7PGGDRvQqVMn5ObmYuTIkXKXIyKiVrL6OYDKykoAgJeXl8Xna2trTd+bCfznSyGISL14FZA4Vr0KyGg0Yv78+Rg2bBj69u1rcZuUlBR4eHiYloCAAGtOiYgUjoeAxLFqA5g7dy6OHj2KzZs3N7nNggULUFlZaVoKCwutOSUiIvr/rHYIKD4+Hl9++SX27t2LLl26NLmdTqeDTqez1jSI6A7DQ0DiyN4AJEnCn/70J2zbtg3Z2dkICgqSuwQREclA9gYwd+5cfPTRR/j888/h5uaG4uJiAICHh4fQb/giojsTE4A4sp8DWLt2LSorKzF69Gj4+fmZli1btshdioiIboNVDgEREbUWE4A4vBkcEZFK8WZwRKQoTADisAEQkaKwAYjDQ0BERCrFBEBEisIEIA4TABGRSjEBEJGiMAGIwwRARKRSik0AX3zxBRwcxE0vODhYWK0Gp0+fFl5To9EIrafVaoXWA4DLly8Lr+no6Ci85r59+4TWq6+vF1KHCUAcJgAiIpVSbAIgInViAhCHCYCISKWYAIhIUZgAxGEDICJFYQMQh4eAiIhUigmAiBSFCUAcJgAiIpViAiAiRWECEIcJgIhIpZgAiEhRmADEYQIgIlIpJgAiUhy+YxeDDYCIFIWHgMThISAiIpViAiAiRWECEIcJgIhIpZgAiEhRmADEYQIgIlIpJgAiUhQmAHGYAIiIVIoJgIgUhQlAHDYAIlIUNgBxeAiIiEilmACISFGYAMRhAiAisiAtLQ2BgYFwcnJCVFQUDhw40OS27733HkaMGAFPT094enpCr9c32n7WrFnQaDRmy7hx46y9G7fEBkBEitKQAOReWmLLli1ISEhAUlIS8vLyEBYWhujoaJSWllrcPjs7GzNmzMCePXuQk5ODgIAAjB07FufPnzfbbty4cbhw4YJp+fjjj1v9OslBsYeAiouLYW9vL6ze5cuXhdVqcOrUKeE127dvL7SewWAQWg8AioqKhNd0cBD/T0l0TTUdRlm1ahVmz56NuLg4AEB6ejq++uorrF+/Hi+99FKj7Tdt2mT2+P3338dnn32GrKwszJw507Rep9PB19fXupNvASYAIlIUWycAg8GA3Nxc6PV60zo7Ozvo9Xrk5OQ0a4wrV66grq4OXl5eZuuzs7PRqVMn9O7dG0899RQuXrzY7HlZg2ITABGR3Kqqqswe63Q66HQ6s3Xl5eWor6+Hj4+P2XofHx8cP368WXVefPFF+Pv7mzWRcePG4eGHH0ZQUBBOnz6Nl19+GTExMcjJyRF6tONGbABEpCjWvAooICDAbH1SUhKSk5NlrbVs2TJs3rwZ2dnZcHJyMq2fPn266b/79euH/v37o3v37sjOzsY999wj6xyaiw2AiBTFmg2gsLAQ7u7upvU3v/sHAG9vb9jb26OkpMRsfUlJye8ev1+xYgWWLVuGb7/9Fv3797/ltsHBwfD29sapU6ds1gB4DoCIVMPd3d1ssdQAtFotIiIikJWVZVpnNBqRlZWFIUOGNDn2G2+8gSVLliAzMxORkZG/O5dz587h4sWL8PPza93OyIAJgIgURQkfBEtISEBsbCwiIyMxePBgpKamoqamxnRV0MyZM9G5c2ekpKQAAJYvX47ExER89NFHCAwMRHFxMQCgXbt2aNeuHaqrq7Fo0SJMmjQJvr6+OH36NF544QX06NED0dHRsu5rS7ABEBHdZNq0aSgrK0NiYiKKi4sRHh6OzMxM04nhgoIC2Nn99wDK2rVrYTAYMHnyZLNxGs4x2Nvb48iRI8jIyEBFRQX8/f0xduxYLFmyxGIKEYUNgIgURQkJAADi4+MRHx9v8bns7Gyzx2fOnLnlWM7Ozti5c2eL52BtPAdARKRSTABEpChKSQBqYPUEsGzZMmg0GsyfP9/apYiIqAWsmgAOHjyId99993evhyUiasAEII7VEkB1dTUeeeQRvPfee/D09LRWGSJqY2x9LyA1sVoDmDt3LsaPH292LwxLamtrUVVVZbYQEZH1WeUQ0ObNm5GXl4eDBw/+7rYpKSlYtGiRNaZBRHcgHgISR/YEUFhYiHnz5mHTpk1mN0JqyoIFC1BZWWlaCgsL5Z4SERFZIHsCyM3NRWlpKQYOHGhaV19fj71792LNmjWora01u/WppduxEpG68R27GLI3gHvuuQf//Oc/zdbFxcUhJCQEL774os3ue01EROZkbwBubm7o27ev2TpXV1d06NCh0XoiopvxHIA4vBUEEZFKCbkVxM03TiIiagoTgDi8FxARKQobgDg8BEREpFJMAESkKEwA4jABEBGpFBMAESkKE4A4TABERCrFBEBEisIEII5iG8Bzzz0HZ2dnYfV8fHyE1Wpw9epV4TWvX78utJ4tvgvi/Pnzwmva4jbmor9oqaamBvfdd5/QmmRdim0ARKROTADisAEQkaKwAYjDk8BERCrFBEBEisIEIA4TABGRSjEBEJGiMAGIwwRARKRSTABEpChMAOIwARARqRQTABEpChOAOGwARKQobADi8BAQEZFKMQEQkaIwAYjDBEBEpFJMAESkKEwA4jABEBGpFBMAESkKE4A4TABERCrFBEBEisIEIA4TABGRSjEBEJGiMAGIwwZARIrDP9hi8BAQEZFKMQEQkaLwEJA4TABERCrFBEBEisIEIA4TABGRSjEBEJGiMAGIo9gGsHLlStjb2wurd+rUKWG1GvTu3Vt4zQsXLgit5+7uLrQeAJSXlwuv+eijjwqv+cILLwitxz+ibY9iGwARqRMTgDhsAESkKGwA4vAkMBGRSjEBEJGiMAGIwwRARKRSTABEpChMAOIwARARqRQTABEpChOAOEwAREQWpKWlITAwEE5OToiKisKBAwea3Pa9997DiBEj4OnpCU9PT+j1+kbbS5KExMRE+Pn5wdnZGXq9HidPnrT2btwSGwARKUpDApB7aYktW7YgISEBSUlJyMvLQ1hYGKKjo1FaWmpx++zsbMyYMQN79uxBTk4OAgICMHbsWJw/f960zRtvvIG3334b6enp2L9/P1xdXREdHY1r167d1ut1O6zSAM6fP49HH30UHTp0gLOzM/r164dDhw5ZoxQRtTFKaACrVq3C7NmzERcXh9DQUKSnp8PFxQXr16+3uP2mTZvw9NNPIzw8HCEhIXj//fdhNBqRlZVl2qfU1FS8+uqrePDBB9G/f398+OGHKCoqwvbt22/3JWs12RvApUuXMGzYMDg6OuLvf/87jh07hpUrV8LT01PuUkREsjMYDMjNzYVerzets7Ozg16vR05OTrPGuHLlCurq6uDl5QUAyM/PR3FxsdmYHh4eiIqKavaY1iD7SeDly5cjICAAH3zwgWldUFCQ3GWIqI2y5kngqqoqs/U6nQ46nc5sXXl5Oerr6+Hj42O23sfHB8ePH29WvRdffBH+/v6mP/jFxcWmMW4es+E5W5A9AezYsQORkZGYMmUKOnXqhAEDBuC9995rcvva2lpUVVWZLURE1hAQEAAPDw/TkpKSInuNZcuWYfPmzdi2bRucnJxkH19OsjeAf//731i7di169uyJnTt34qmnnsIzzzyDjIwMi9unpKSY/UICAgLknhIR3UGseQ6gsLAQlZWVpmXBggWN6nt7e8Pe3h4lJSVm60tKSuDr63vLua9YsQLLli3DN998g/79+5vWN/xca8a0JtkbgNFoxMCBA/H6669jwIABmDNnDmbPno309HSL2y9YsMDsF1JYWCj3lIiIAPzn+yluXG4+/AMAWq0WERERphO4AEwndIcMGdLk2G+88QaWLFmCzMxMREZGmj0XFBQEX19fszGrqqqwf//+W45pbbKfA/Dz80NoaKjZuj59+uCzzz6zuL2lY3BEpF5K+CBYQkICYmNjERkZicGDByM1NRU1NTWIi4sDAMycOROdO3c2HUJavnw5EhMT8dFHHyEwMNB0XL9du3Zo164dNBoN5s+fj6VLl6Jnz54ICgrCwoUL4e/vj4kTJ8q6ry0hewMYNmwYTpw4Ybbu119/Rbdu3eQuRURkFdOmTUNZWRkSExNRXFyM8PBwZGZmmk7iFhQUwM7uvwdQ1q5dC4PBgMmTJ5uNk5SUhOTkZAD/+Qa3mpoazJkzBxUVFRg+fDgyMzNtep5A9gbw7LPPYujQoXj99dcxdepUHDhwAOvWrcO6devkLkVEbZASEgAAxMfHIz4+3uJz2dnZZo/PnDnzu+NpNBosXrwYixcvbvFcrEX2cwCDBg3Ctm3b8PHHH6Nv375YsmQJUlNT8cgjj8hdiojaICV8EEwtrHIzuPvvvx/333+/NYYmIiKZ8G6gRKQoSjkEpAa8GRwRkUoxARCRojABiMMEQESkUkwARKQ4fMcuBhMAEZFKMQEQkaLwHIA4im0AERER0Gq1wuqFhIQIq9Vg+PDhwmv+4x//EFovMDBQaD1bcXR0FF7ziSeeEFrPYDAI+UQ/G4A4PARERKRSik0ARKROTADiMAEQEakUEwARKQoTgDhMAEREKsUEQESKwgQgDhMAEZFKMQEQkaIwAYjDBkBEisIGIA4PARERqRQTABEpChOAOEwARER3iOvXr+Pbb7/Fu+++i8uXLwMAioqKUF1d3arxmACISFGYACw7e/Ysxo0bh4KCAtTW1uLee++Fm5sbli9fjtraWqSnp7d4TCYAIqI7wLx58xAZGYlLly7B2dnZtP6hhx5CVlZWq8ZkAiAiRWECsOz777/Hvn37Gt0mPzAwEOfPn2/VmEwARER3AKPRiPr6+kbrz507Bzc3t1aNyQZARIrSkADkXu50Y8eORWpqqumxRqNBdXU1kpKScN9997VqTB4CIiJF4SEgy1auXIno6GiEhobi2rVr+J//+R+cPHkS3t7e+Pjjj1s1JhsAEdEdoEuXLvj555+xefNmHDlyBNXV1XjiiSfwyCOPmJ0Ubgk2ACJSFCaApjk4OODRRx+VbzzZRiIiIqv58MMPb/n8zJkzWzwmGwARKQoTgGXz5s0ze1xXV4crV65Aq9XCxcWlVQ2AVwEREd0BLl26ZLZUV1fjxIkTGD58eKtPArMBEJGi8DLQ5uvZsyeWLVvWKB00FxsAEdEdzMHBAUVFRa37WZnnQkR0W3gOwLIdO3aYPZYkCRcuXMCaNWswbNiwVo3JBkBEisIGYNnEiRPNHms0GnTs2BF33303Vq5c2aox2QCIiO4ARqNR9jEV2wB27twJOztxpygiIiKE1Wqwbds24TVbe9fA1iosLBRaDwBcXFyE17S3txdes6ysTGg9Szcis5a28I79TqDYBkBEpHYJCQnN3nbVqlUtHp8NgIgUhecA/uunn35q1nYajaZV47MBEBEp1J49e6w6PhsAESkKE4A4bABERHeIQ4cO4ZNPPkFBQQEMBoPZc1u3bm3xePwkMBEpCm8FYdnmzZsxdOhQ/Otf/8K2bdtQV1eHX375Bbt374aHh0erxmQDICJFYQOw7PXXX8ef//xnfPHFF9BqtXjrrbdw/PhxTJ06FV27dm3VmGwARER3gNOnT2P8+PEAAK1Wi5qaGmg0Gjz77LNYt25dq8ZkAyAiRWECsMzT0xOXL18GAHTu3BlHjx4FAFRUVODKlSutGlP2BlBfX4+FCxciKCgIzs7O6N69O5YsWdImfgFERKI1/KEfOXIkdu3aBQCYMmUK5s2bh9mzZ2PGjBm45557WjW27FcBLV++HGvXrkVGRgbuuusuHDp0CHFxcfDw8MAzzzwjdzkiamN4Gai5/v37Y9CgQZg4cSKmTJkCAHjllVfg6OiIffv2YdKkSXj11VdbNbbsDWDfvn148MEHTceqAgMD8fHHH+PAgQNylyIiavO+++47fPDBB0hJScFrr72GSZMm4cknn8RLL71022PLfgho6NChyMrKwq+//goA+Pnnn/HDDz8gJiZG7lJE1AbxHIC5ESNGYP369bhw4QJWr16NM2fOYNSoUejVqxeWL1+O4uLiVo8tewN46aWXMH36dISEhMDR0REDBgzA/Pnz8cgjj1jcvra2FlVVVWYLERGZc3V1RVxcHL777jv8+uuvmDJlCtLS0tC1a1c88MADrRpT9gbwySefYNOmTfjoo4+Ql5eHjIwMrFixAhkZGRa3T0lJgYeHh2kJCAiQe0pEdAdhAvh9PXr0wMsvv4xXX30Vbm5u+Oqrr1o1juznAJ5//nlTCgCAfv364ezZs0hJSUFsbGyj7RcsWGB2y9Oqqio2ASKiJuzduxfr16/HZ599Bjs7O0ydOhVPPPFEq8aSvQFcuXKl0Re52NvbN/ltNjqdDjqdTu5pENEdilcBNVZUVIQNGzZgw4YNOHXqFIYOHYq3334bU6dOhaura6vHlb0BTJgwAa+99hq6du2Ku+66Cz/99BNWrVqFxx9/XO5SRNQGsQGYi4mJwbfffgtvb2/MnDkTjz/+OHr37i3L2LI3gNWrV2PhwoV4+umnUVpaCn9/f/zv//4vEhMT5S5FRNTmOTo64tNPP8X9998v+1ePyn4S2M3NDampqTh79iyuXr2K06dPY+nSpdBqtXKXIqI2SCkngdPS0hAYGAgnJydERUXd8rNMv/zyCyZNmoTAwEBoNBqkpqY22iY5ORkajcZsCQkJ+d157NixAw8++KBVvnea9wIiIrrJli1bkJCQgKSkJOTl5SEsLAzR0dEoLS21uP2VK1cQHByMZcuWwdfXt8lx77rrLly4cMG0/PDDD9bahWZhAyAiRVFCAli1ahVmz56NuLg4hIaGIj09HS4uLli/fr3F7QcNGoQ333wT06dPv+VFLQ4ODvD19TUt3t7eLZqX3NgAiIhuYDAYkJubC71eb1pnZ2cHvV6PnJyc2xr75MmT8Pf3R3BwMB555BEUFBTc7nRvC78SkogUxZpXAd18pwFLl6GXl5ejvr4ePj4+Zut9fHxw/PjxVs8hKioKGzZsQO/evXHhwgUsWrQII0aMwNGjR+Hm5tbqcW8HEwARqUZAQIDZnQdSUlKE1Y6JicGUKVPQv39/REdH4+uvv0ZFRQU++eQTYXO4GRMAESmKNRNAYWEh3N3dTestHa/39vaGvb09SkpKzNaXlJTc8gRvS7Vv3x69evXCqVOnZBuzpZgAiEhRrHkS2N3d3Wyx1AC0Wi0iIiKQlZVlWmc0GpGVlYUhQ4bItp/V1dU4ffo0/Pz8ZBuzpZgAiIhukpCQgNjYWERGRmLw4MFITU1FTU0N4uLiAAAzZ85E586dTYeQDAYDjh07Zvrv8+fP4/Dhw2jXrh169OgBAPi///s/TJgwAd26dUNRURGSkpJgb2+PGTNm2GYnoeAGcP36dWg0GmH1Dh48KKxWg5vvmSSC6Ntt3xyjRfDw8BBes7XfyXo7RN9Dq6n7eclNCbeCmDZtGsrKypCYmIji4mKEh4cjMzPTdGK4oKDA7N9vUVERBgwYYHq8YsUKrFixAqNGjUJ2djYA4Ny5c5gxYwYuXryIjh07Yvjw4fjxxx/RsWPH29/BVlJsAyAisqX4+HjEx8dbfK7hj3qDwMDA320ymzdvlmtqsmEDICJFUUICUAueBCYiUikmACJSHL5jF4MJgIhIpZgAiEhReA5AHDYAIlIUNgBxeAiIiEilmACISFGYAMRhAiAiUikmACJSFCYAcZgAiIhUigmAiBSFCUAcJgAiIpViAiAiRWECEIcNgIgUhQ1AHB4CIiJSKSYAIlIUJgBxmACIiFSKCYCIFIUJQBwmACIilWICICJFYQIQhwmAiEilmACISFGYAMRhAyAiRWEDEIeHgIiIVIoJgIgUhQlAHCYAIiKVUmwCyM7ORrt27YTV69Wrl7BaDfbs2SO8prOzs9B67u7uQusBQEFBgfCaP//8s/Ca48ePF1qvuroaQ4YMsXodJgBxmACIiFRKsQmAiNSJCUAcJgAiIpViAiAiRWECEIcNgIgUhQ1AHB4CIiJSKSYAIlIcvmMXgwmAiEilmACISFF4DkCcFieAvXv3YsKECfD394dGo8H27dvNnpckCYmJifDz84OzszP0ej1Onjwp13yJiEgmLW4ANTU1CAsLQ1pamsXn33jjDbz99ttIT0/H/v374erqiujoaFy7du22J0tEbV9DApB7ocZafAgoJiYGMTExFp+TJAmpqal49dVX8eCDDwIAPvzwQ/j4+GD79u2YPn367c2WiIhkI+tJ4Pz8fBQXF0Ov15vWeXh4ICoqCjk5ORZ/pra2FlVVVWYLEakXE4A4sjaA4uJiAICPj4/Zeh8fH9NzN0tJSYGHh4dpCQgIkHNKRHSHYQMQx+aXgS5YsACVlZWmpbCw0NZTIiJSBVkvA/X19QUAlJSUwM/Pz7S+pKQE4eHhFn9Gp9NBp9PJOQ0iuoPxMlBxZE0AQUFB8PX1RVZWlmldVVUV9u/fL+SLJIiIqPlanACqq6tx6tQp0+P8/HwcPnwYXl5e6Nq1K+bPn4+lS5eiZ8+eCAoKwsKFC+Hv74+JEyfKOW8iaqOYAMRpcQM4dOgQxowZY3qckJAAAIiNjcWGDRvwwgsvoKamBnPmzEFFRQWGDx+OzMxMODk5yTdrIiK6bS1uAKNHj75lN9VoNFi8eDEWL158WxMjInViAhDH5lcBERGRbfBmcESkKEwA4rABEJGisAGIw0NAREQqxQRARIrCBCAOEwARkUoxARCRojABiMMEQESkUopNAM888wwcHMRN79KlS8JqNaisrBReMzg4WGi9kJAQofUANHnrcWvq0qWL8JorV64UWs9gMAipwwQgDhMAEZFKsQEQkaIo5Qth0tLSEBgYCCcnJ0RFReHAgQNNbvvLL79g0qRJCAwMhEajQWpq6m2PKQIbABHRTbZs2YKEhAQkJSUhLy8PYWFhiI6ORmlpqcXtr1y5guDgYCxbtsz0vSi3O6YIbABEpChKSACrVq3C7NmzERcXh9DQUKSnp8PFxQXr16+3uP2gQYPw5ptvYvr06U1+wVVLxxSBDYCIFMXWDcBgMCA3Nxd6vd60zs7ODnq9Hjk5Oa3aJ2uMKQfFXgVERCS3qqoqs8eWvpK2vLwc9fX18PHxMVvv4+OD48ePt6quNcaUAxMAESmKNRNAQEAAPDw8TEtKSoqN99a2mACISDUKCwvh7u5uemzpeL23tzfs7e1RUlJitr6kpKTJE7y/xxpjyoEJgIgUxZoJwN3d3Wyx1AC0Wi0iIiKQlZVlWmc0GpGVlYUhQ4a0ap+sMaYcmACIiG6SkJCA2NhYREZGYvDgwUhNTUVNTQ3i4uIAADNnzkTnzp1Nh5AMBgOOHTtm+u/z58/j8OHDaNeuHXr06NGsMW2BDYCIFEUJt4KYNm0aysrKkJiYiOLiYoSHhyMzM9N0EregoAB2dv89gFJUVIQBAwaYHq9YsQIrVqzAqFGjkJ2d3awxbYENgIjIgvj4eMTHx1t8ruGPeoPAwMBmNZlbjWkLbABEpDi8eZsYbABEpChKOASkFrwKiIhIpZgAiEhRmADEYQIgIlIpJgAiUhQmAHGYAIiIVIoJgIgUhQlAHCYAIiKVYgIgIkVhAhCHDYCIFIUNQBweAiIiUikmACJSFCYAcZgAiIhUigmAiBSFCUAcxTaAXr16QavVCqtnMBiE1Wpw/vx54TVFf/nE9evXhdYDAEdHR+E1q6urhdcMCAgQWq+2tlZoPbI+xTYAIlInJgBxeA6AiEilmACISFGYAMRhAyAiRWEDEIeHgIiIVIoJgIgUhQlAHCYAIiKVYgIgIkVhAhCHCYCISKWYAIhIUZgAxGlxAti7dy8mTJgAf39/aDQabN++3fRcXV0dXnzxRfTr1w+urq7w9/fHzJkzUVRUJOeciYhIBi1uADU1NQgLC0NaWlqj565cuYK8vDwsXLgQeXl52Lp1K06cOIEHHnhAlskSUdvXkADkXqixFh8CiomJQUxMjMXnPDw8sGvXLrN1a9asweDBg1FQUICuXbu2bpZEpBo8BCSO1c8BVFZWQqPRoH379hafr62tNbvLYFVVlbWnREREsPJVQNeuXcOLL76IGTNmwN3d3eI2KSkp8PDwMC2ib3FLRMrCQ0DiWK0B1NXVYerUqZAkCWvXrm1yuwULFqCystK0FBYWWmtKRER0A6scAmr443/27Fns3r27yXf/AKDT6aDT6awxDSK6Q/EduxiyN4CGP/4nT57Enj170KFDB7lLEBGRDFrcAKqrq3Hq1CnT4/z8fBw+fBheXl7w8/PD5MmTkZeXhy+//BL19fUoLi4GAHh5eQn9ikciujPxKiBxWtwADh06hDFjxpgeJyQkAABiY2ORnJyMHTt2AADCw8PNfm7Pnj0YPXp062dKRESyanEDGD169C27KTstEd0OJgBxeC8gIlIUNgBxeDdQIiKVYgIgIkVhAhCHCYCISKWYAIhIUZgAxGECICJSKSYAIlIUJgBxFNsAjh07BgcHcdM7c+aMsFoN+vbtK7xmbm6u0HrBwcFC6wEwu724KCEhIcJr/vbbb0LrGQwGofXI+hTbAIhInZgAxGEDICJFYQMQhyeBiYhUigmAiBSFCUAcJgAiIpViAiAiRWECEIcJgIhIpZgAiEhRmADEYQIgIlIpJgAiUhQmAHHYAIhIUdgAxOEhICIilWICICJFYQIQhwmAiMiCtLQ0BAYGwsnJCVFRUThw4MAtt//b3/6GkJAQODk5oV+/fvj666/Nnp81axY0Go3ZMm7cOGvuwu9iAyAiRWlIAHIvLbFlyxYkJCQgKSkJeXl5CAsLQ3R0NEpLSy1uv2/fPsyYMQNPPPEEfvrpJ0ycOBETJ07E0aNHzbYbN24cLly4YFo+/vjjVr9OcmADICK6yapVqzB79mzExcUhNDQU6enpcHFxwfr16y1u/9Zbb2HcuHF4/vnn0adPHyxZsgQDBw7EmjVrzLbT6XTw9fU1LZ6eniJ2p0lsAESkKLZOAAaDAbm5udDr9aZ1dnZ20Ov1yMnJsfgzOTk5ZtsDQHR0dKPts7Oz0alTJ/Tu3RtPPfUULl682IJXRn48CUxEqlFVVWX2WKfTQafTma0rLy9HfX09fHx8zNb7+Pjg+PHjFsctLi62uH1xcbHp8bhx4/Dwww8jKCgIp0+fxssvv4yYmBjk5OTA3t7+dnar1dgAiEhRrHkVUEBAgNn6pKQkJCcny1qrKdOnTzf9d79+/dC/f390794d2dnZuOeee4TM4WZsAESkGoWFhXB3dzc9vvndPwB4e3vD3t4eJSUlZutLSkrg6+trcVxfX98WbQ/85/uyvb29cerUKZs1AJ4DICLFsdbxf3d3d7PFUgPQarWIiIhAVlaWaZ3RaERWVhaGDBlicb5Dhgwx2x4Adu3a1eT2AHDu3DlcvHgRfn5+LX15ZMMEQESKooQPgiUkJCA2NhaRkZEYPHgwUlNTUVNTg7i4OADAzJkz0blzZ6SkpAAA5s2bh1GjRmHlypUYP348Nm/ejEOHDmHdunUAgOrqaixatAiTJk2Cr68vTp8+jRdeeAE9evRAdHS0rPvaEmwAREQ3mTZtGsrKypCYmIji4mKEh4cjMzPTdKK3oKAAdnb/PYAydOhQfPTRR3j11Vfx8ssvo2fPnti+fTv69u0LALC3t8eRI0eQkZGBiooK+Pv7Y+zYsViyZInFFCIKGwARKYoSEgAAxMfHIz4+3uJz2dnZjdZNmTIFU6ZMsbi9s7Mzdu7c2eI5WBvPARARqRQTABEpilISgBowARARqRQTABEpChOAOIptAF26dIGjo6Owev7+/sJqNSgvLxdes1u3bkLrifwdNrh69arwmjff+lcEBwex/3yvX78utB5Zn2IbABGpExOAOGwARKQobADi8CQwEZFKMQEQkaIwAYjDBEBEpFJMAESkKEwA4jABEBGpFBMAESkKE4A4TABERCrFBEBEisIEIE6LE8DevXsxYcIE+Pv7Q6PRYPv27U1u+8c//hEajQapqam3MUUiUhO5vw7SGg2lrWhxA6ipqUFYWBjS0tJuud22bdvw448/2uQeO0RE9PtafAgoJiYGMTExt9zm/Pnz+NOf/oSdO3di/PjxrZ4cEakPDwGJI/s5AKPRiMceewzPP/887rrrrt/dvra2FrW1tabHVVVVck+JiIgskP0qoOXLl8PBwQHPPPNMs7ZPSUmBh4eHaQkICJB7SkR0B+E5AHFkbQC5ubl46623sGHDBmg0mmb9zIIFC1BZWWlaCgsL5ZwSERE1QdYG8P3336O0tBRdu3aFg4MDHBwccPbsWTz33HMIDAy0+DM6nQ7u7u5mCxGpFxOAOLKeA3jssceg1+vN1kVHR+Oxxx5DXFycnKWIiOg2tbgBVFdX49SpU6bH+fn5OHz4MLy8vNC1a1d06NDBbHtHR0f4+vqid+/etz9bImrzeBWQOC1uAIcOHcKYMWNMjxMSEgAAsbGx2LBhg2wTIyJ1YgMQp8UNYPTo0S16Mc+cOdPSEkREJADvBUREisIEIA7vBkpEpFJMAESkOHzHLgYTABGRSjEBEJGiWOPdPxOFZUwAREQqxQRARIrCBCCOYhvA9evXm31DOTnY4iZ0169fF17zwoULQuv5+PgIrQcAdnbig21JSYnwmg888IDQegaDAYcOHbJ6HTYAcXgIiIhIpRSbAIhInZgAxGECICJSKSYAIlIUJgBxmACIiFSKCYCIFIUJQBwmACIilWICICJFYQIQhw2AiBSFDUAcHgIiIlIpJgAiUhQmAHGYAIiIVIoJgIgUhQlAHCYAIiKVYgIgIkVhAhCHCYCISKWYAIhIUZgAxGEDICJFYQMQh4eAiIhUigmAiBSFCUAcJgAiIpViAiAiRWECEIcJgIhIpZgAiEhRmADEYQIgIlIpJgAiUhQmAHHYAIhIcfgHWwzFNYCGX3xdXZ3QutevXxdaDwDq6+vbfE1bvK52duKPbBqNRuE1DQaDTerxj3PboZEU9ts8d+4cAgICbD0NImpCYWEhunTpIvu4165dQ1BQEIqLi2UfGwB8fX2Rn58PJycnq4x/J1JcAzAajSgqKoKbmxs0Gk2LfraqqgoBAQEoLCyEu7u7lWZoe2rYTzXsI3Bn7ackSbh8+TL8/f2tlrKuXbtmtWSj1Wr5x/8mijsEZGdnd9vvLtzd3RX/j0kOathPNewjcOfsp4eHh1XHd3Jy4h9pgXgZKBGRSrEBEBGpVJtqADqdDklJSdDpdLaeilWpYT/VsI+AevaTlElxJ4GJiEiMNpUAiIio+dgAiIhUig2AiEil2ACIiFSqzTSAtLQ0BAYGwsnJCVFRUThw4ICtpySrlJQUDBo0CG5ubujUqRMmTpyIEydO2HpaVrds2TJoNBrMnz/f1lOR3fnz5/Hoo4+iQ4cOcHZ2Rr9+/XDo0CFbT4tUpE00gC1btiAhIQFJSUnIy8tDWFgYoqOjUVpaauupyea7777D3Llz8eOPP2LXrl2oq6vD2LFjUVNTY+upWc3Bgwfx7rvvon///raeiuwuXbqEYcOGwdHREX//+99x7NgxrFy5Ep6enraeGqlIm7gMNCoqCoMGDcKaNWsA/Od+QgEBAfjTn/6El156ycazs46ysjJ06tQJ3333HUaOHGnr6ciuuroaAwcOxDvvvIOlS5ciPDwcqamptp6WbF566SX84x//wPfff2/rqZCK3fEJwGAwIDc3F3q93rTOzs4Oer0eOTk5NpyZdVVWVgIAvLy8bDwT65g7dy7Gjx9v9nttS3bs2IHIyEhMmTIFnTp1woABA/Dee+/ZelqkMnd8AygvL0d9fT18fHzM1vv4+FjttrK2ZjQaMX/+fAwbNgx9+/a19XRkt3nzZuTl5SElJcXWU7Gaf//731i7di169uyJnTt34qmnnsIzzzyDjIwMW0+NVERxdwOl3zd37lwcPXoUP/zwg62nIrvCwkLMmzcPu3btatN3hTQajYiMjMTrr78OABgwYACOHj2K9PR0xMbG2nh2pBZ3fALw9vaGvb09SkpKzNaXlJTA19fXRrOynvj4eHz55ZfYs2ePVb6Uw9Zyc3NRWlqKgQMHwsHBAQ4ODvjuu+/w9ttvw8HBwSbfomYNfn5+CA0NNVvXp08fFBQU2GhGpEZ3fAPQarWIiIhAVlaWaZ3RaERWVhaGDBliw5nJS5IkxMfHY9u2bdi9ezeCgoJsPSWruOeee/DPf/4Thw8fNi2RkZF45JFHcPjwYdjb29t6irIYNmxYo8t4f/31V3Tr1s1GMyI1ahOHgBISEhAbG4vIyEgMHjwYqampqKmpQVxcnK2nJpu5c+fio48+wueffw43NzfT+Q0PDw84OzvbeHbycXNza3Rew9XVFR06dGhT5zueffZZDB06FK+//jqmTp2KAwcOYN26dVi3bp2tp0ZqIrURq1evlrp27SpptVpp8ODB0o8//mjrKckKgMXlgw8+sPXUrG7UqFHSvHnzbD0N2X3xxRdS3759JZ1OJ4WEhEjr1q2z9ZRIZdrE5wCIiKjl7vhzAERE1DpsAEREKsUGQESkUmwAREQqxQZARKRSbABERCrFBkBEpFJsAEREKsUGQESkUmwAREQqxQZARKRSbABERCr1/wAzuMLLQY3H5wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 values in Layer 3. Geometry: (16, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 values in Layer 6. Geometry: (16, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 values in Layer 9. Geometry: (16, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 values in Layer 12. Geometry: (16, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 values in Layer 15. Geometry: (16, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activations, mean_activations, layer_sizes = get_activations(net=model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\")\n",
    "plot_nn_values_scatter(nn_values=activations, layer_sizes=layer_sizes, nn_values_names=\"Activations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spot312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
