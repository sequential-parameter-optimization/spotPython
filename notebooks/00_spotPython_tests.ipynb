{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "title: 'spotPython Tests'\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fun_control_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(_L_in=64, _L_out=11, num_workers=0, device=None)\n",
        "fun_control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def class_attributes_to_dataframe(class_obj):\n",
        "    # Get the attributes and their values of the class object\n",
        "    attributes = [attr for attr in dir(class_obj) if not callable(getattr(class_obj, attr)) and not attr.startswith(\"__\")]\n",
        "    values = [getattr(class_obj, attr) for attr in attributes]\n",
        "    \n",
        "    # Create a DataFrame from the attributes and values\n",
        "    df = pd.DataFrame({'Attribute Name': attributes, 'Attribute Value': values})\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        self.name = \"John\"\n",
        "        self.age = 30\n",
        "        self.salary = 50000\n",
        "\n",
        "my_instance = MyClass()\n",
        "df = class_attributes_to_dataframe(my_instance)\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import inf\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "# number of initial points:\n",
        "ni = 7\n",
        "# number of points\n",
        "n = 10\n",
        "\n",
        "fun = analytical().fun_sphere\n",
        "lower = np.array([-1])\n",
        "upper = np.array([1])\n",
        "design_control={\"init_size\": ni}\n",
        "\n",
        "spot_1 = spot.Spot(fun=fun,\n",
        "            lower = lower,\n",
        "            upper= upper,\n",
        "            fun_evals = n,\n",
        "            show_progress=True,\n",
        "            design_control=design_control,)\n",
        "spot_1.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sys import stdout\n",
        "df = spot_1.class_attributes_to_dataframe()\n",
        "stdout.write(df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from river import datasets\n",
        "from river import evaluate\n",
        "from river.linear_model import LogisticRegression\n",
        "from river import metrics\n",
        "from river import optim\n",
        "from river import preprocessing\n",
        "\n",
        "dataset = datasets.Phishing()\n",
        "\n",
        "model = (\n",
        "    preprocessing.StandardScaler() |\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "metric = metrics.Accuracy()\n",
        "\n",
        "evaluate.progressive_val_score(dataset, model, metric)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.csvdataset import CSVDataset\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data.csv', target_column='prognosis')\n",
        "dataset = CSVDataset(target_column='prognosis')\n",
        "print(dataset.data.shape)\n",
        "print(dataset.targets.shape)            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.extra_repr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 3\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSV Data set VBDP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the csv_file='./data/spotPython/data.csv' as a pandas df and save it as a pickle file\n",
        "import pandas as pd\n",
        "df = pd.read_csv('./data/spotPython/data.csv')\n",
        "df.to_pickle('./data/spotPython/data.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyHcf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyhcf.data.daten_sensitive import DatenSensitive\n",
        "from pyhcf.utils.names import get_short_parameter_names\n",
        "daten = DatenSensitive()\n",
        "df = daten.load()\n",
        "names =  df.columns\n",
        "names = get_short_parameter_names(names)\n",
        "# rename columns with short names\n",
        "df.columns = names\n",
        "df.head()\n",
        "# save the df as a csv file\n",
        "df.to_csv('./data/spotPython/data_sensitive.csv', index=False)\n",
        "# save the df as a pickle file\n",
        "df.to_pickle('./data/spotPython/data_sensitive.pkl')\n",
        "# remove all rows with NaN values\n",
        "df = df.dropna()\n",
        "# save the df as a csv file\n",
        "df.to_csv('./data/spotPython/data_sensitive_rmNA.csv', index=False)\n",
        "# save the df as a pickle file\n",
        "df.to_pickle('./data/spotPython/data_sensitive_rmNA.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyHcf data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.light.csvdataset import CSVDataset\n",
        "# import torch\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data_sensitive.csv', target_column='N', feature_type=torch.float32, target_type=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5000\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     # print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.light.csvdataset import CSVDataset\n",
        "# import torch\n",
        "# dataset = CSVDataset(csv_file='./data/spotPython/data_sensitive.csv', target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5000\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     # print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pickle data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)\n",
        "dataset.feature_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Sensitive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(pkl_file='./data/spotPython/data_sensitive.pkl', target_column='A', feature_type=torch.long, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # Set batch size for DataLoader\n",
        "# batch_size = 5\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Iterate over the data in the DataLoader\n",
        "# for batch in dataloader:\n",
        "#     inputs, targets = batch\n",
        "#     print(f\"Batch Size: {inputs.size(0)}\")\n",
        "#     print(\"---------------\")\n",
        "#     print(f\"Inputs: {inputs}\")\n",
        "#     print(f\"Targets: {targets}\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test lightdatamodule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
        "# dataset = PKLDataset(directory=\"./data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_module.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Training set size: {len(data_module.data_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Validation set size: {len(data_module.data_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Test set size: {len(data_module.data_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set the DataModule in fun_control "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=7)\n",
        "dm.setup()\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                key=\"data_module\",\n",
        "                value=dm, replace=True)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## same with the sensitive data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float64, rmNA=False)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=77)\n",
        "dm.setup()\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                key=\"data_module\",\n",
        "                value=dm, replace=True)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## same, but VBDO data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "fun_control = fun_control_init()\n",
        "dataset = CSVDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/VBDP/\", filename=\"train.csv\",target_column='prognosis', feature_type=torch.long)\n",
        "dm = LightDataModule(dataset=dataset, batch_size=5, test_size=77)\n",
        "dm.setup()\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                key=\"data_module\",\n",
        "                value=dm, replace=True)\n",
        "data_module = fun_control[\"data_module\"]\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# load Hyperdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "lhd = LightHyperDict()\n",
        "lhd.hyper_dict\n",
        "user_lhd = LightHyperDict(filename=\"user_hyper_dict.json\", directory=\"./hyperdict/\")\n",
        "user_lhd.hyper_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diabetes data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes  \n",
        "import torch\n",
        "\n",
        "# Load the diabetes dataset\n",
        "feature_df, target_df = load_diabetes(return_X_y=True, as_frame=True)\n",
        "feature_tensor = torch.tensor(feature_df.values, dtype=torch.float32)\n",
        "target_tensor = torch.tensor(target_df.values, dtype=torch.float32)\n",
        "feature_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.diabetes import Diabetes\n",
        "dataset = Diabetes()\n",
        "print(dataset.data.shape)\n",
        "print(dataset.targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# add core model to fun control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.netlightregressione import NetLightRegression\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "fun_control[\"core_model\"].__name__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the fun_control[\"core_model_hyper_dict\"] is a LightHyperDict\n",
        "isinstance(fun_control[\"core_model_hyper_dict\"], dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test check_X_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.hyperparameters.values import get_var_name\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "hyper_light = HyperLight(seed=126, log_level=50)\n",
        "n_hyperparams = len(get_var_name(fun_control))\n",
        "# generate a random np.array X with shape (2, n_hyperparams)\n",
        "X = np.random.rand(2, n_hyperparams)\n",
        "X == hyper_light.check_X_shape(X, fun_control)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test hyperlight fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "import numpy as np\n",
        "fun_control = fun_control_init(\n",
        "    _L_in=10,\n",
        "    _L_out=1,)\n",
        "\n",
        "dataset = Diabetes()\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                    key=\"data_set\",\n",
        "                    value=dataset)\n",
        "\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "hyper_light = HyperLight(seed=126, log_level=50)\n",
        "X = get_default_hyperparameters_as_array(fun_control)\n",
        "# combine X and X to a np.array with shape (2, n_hyperparams)\n",
        "X = np.vstack((X, X))\n",
        "y = hyper_light.fun(X, fun_control)\n",
        "y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test  NetLightRegression Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from torch import nn\n",
        "import lightning as L\n",
        "PATH_DATASETS = './data'\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "dataset = Diabetes()\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "batch_x, batch_y = next(iter(train_loader)) \n",
        "print(batch_x.shape)\n",
        "print(batch_y.shape)\n",
        "\n",
        "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
        "                                initialization='xavier', act_fn=nn.ReLU(),\n",
        "                                optimizer='Adam', dropout_prob=0.1, lr_mult=0.1,\n",
        "                                patience=5, _L_in=10, _L_out=1)\n",
        "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
        "trainer.fit(net_light_base, train_loader)\n",
        "trainer.validate(net_light_base, val_loader)\n",
        "trainer.test(net_light_base, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# tests optimizer_handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from torch import nn\n",
        "import lightning as L\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "lr_mult=0.1\n",
        "\n",
        "dataset = Diabetes()\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
        "                                initialization='xavier', act_fn=nn.ReLU(),\n",
        "                                optimizer='Adam', dropout_prob=0.1, lr_mult=lr_mult,\n",
        "                                patience=5, _L_in=10, _L_out=1)\n",
        "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
        "trainer.fit(net_light_base, train_loader)\n",
        "# Adam uses a lr which is calculated as lr=lr_mult * 0.001, so this value\n",
        "# should be 0.1 * 0.001 = 0.0001 \n",
        "trainer.optimizers[0].param_groups[0][\"lr\"] == lr_mult*0.001\n",
        "\n",
        "\n",
        "net_light_base = NetLightRegression(l1=128, epochs=10, batch_size=BATCH_SIZE,\n",
        "                                initialization='xavier', act_fn=nn.ReLU(),\n",
        "                                optimizer='Adadelta', dropout_prob=0.1, lr_mult=lr_mult,\n",
        "                                patience=5, _L_in=10, _L_out=1)\n",
        "trainer = L.Trainer(max_epochs=2,  enable_progress_bar=False)\n",
        "trainer.fit(net_light_base, train_loader)\n",
        "# Adadelta uses a lr which is calculated as lr=lr_mult * 1.0, so this value\n",
        "# should be 1.0 * 0.1 = 0.1 \n",
        "trainer.optimizers[0].param_groups[0][\"lr\"] == lr_mult*1.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "from spotPython.hyperparameters.values import get_var_name, assign_values, generate_one_config_from_var_dict\n",
        "from spotPython.light.traintest import train_model, test_model\n",
        "fun_control = fun_control_init(\n",
        "    _L_in=10,\n",
        "    _L_out=1,)\n",
        "\n",
        "dataset = Diabetes()\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                        key=\"data_set\",\n",
        "                        value=dataset)\n",
        "\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "X = get_default_hyperparameters_as_array(fun_control)\n",
        "var_dict = assign_values(X, get_var_name(fun_control))\n",
        "for config in generate_one_config_from_var_dict(var_dict, fun_control):\n",
        "    y_train = train_model(config, fun_control)\n",
        "    y_test = test_model(config, fun_control)\n",
        "    break\n",
        "print(y_train)\n",
        "print(y_test[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control, get_default_hyperparameters_as_array\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "from spotPython.hyperparameters.values import get_var_name, assign_values, generate_one_config_from_var_dict\n",
        "from spotPython.light.traintest import test_model\n",
        "\n",
        "\n",
        "def test_traintest_test_model():\n",
        "    fun_control = fun_control_init(\n",
        "        _L_in=10,\n",
        "        _L_out=1,)\n",
        "\n",
        "    dataset = Diabetes()\n",
        "    set_control_key_value(control_dict=fun_control,\n",
        "                        key=\"data_set\",\n",
        "                        value=dataset)\n",
        "\n",
        "    add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                                fun_control=fun_control,\n",
        "                                hyper_dict=LightHyperDict)\n",
        "    X = get_default_hyperparameters_as_array(fun_control)\n",
        "    var_dict = assign_values(X, get_var_name(fun_control))\n",
        "    for vals in generate_one_config_from_var_dict(var_dict, fun_control):\n",
        "        y_test = test_model(test_config=vals,\n",
        "                            fun_control=fun_control)\n",
        "        break\n",
        "    # check if y is a float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test getVarName()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import get_var_name\n",
        "fun_control = {\"core_model_hyper_dict\":{\n",
        "            \"leaf_prediction\": {\n",
        "                \"levels\": [\"mean\", \"model\", \"adaptive\"],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": \"mean\",\n",
        "                \"core_model_parameter_type\": \"str\"},\n",
        "            \"leaf_model\": {\n",
        "                \"levels\": [\"linear_model.LinearRegression\", \"linear_model.PARegressor\", \"linear_model.Perceptron\"],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": \"LinearRegression\",\n",
        "                \"core_model_parameter_type\": \"instance\"},\n",
        "            \"splitter\": {\n",
        "                \"levels\": [\"EBSTSplitter\", \"TEBSTSplitter\", \"QOSplitter\"],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": \"EBSTSplitter\",\n",
        "                \"core_model_parameter_type\": \"instance()\"},\n",
        "            \"binary_split\": {\n",
        "                \"levels\": [0, 1],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": 0,\n",
        "                \"core_model_parameter_type\": \"bool\"},\n",
        "            \"stop_mem_management\": {\n",
        "                \"levels\": [0, 1],\n",
        "                \"type\": \"factor\",\n",
        "                \"default\": 0,\n",
        "                \"core_model_parameter_type\": \"bool\"}}}\n",
        "len(get_var_name(fun_control))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test netlightregression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from spotPython.spot import spot\n",
        "from math import inf\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.utils.file import get_experiment_name, get_spot_tensorboard_path\n",
        "from spotPython.utils.device import getDevice\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "from spotPython.data.pkldataset import PKLDataset\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "from spotPython.hyperparameters.values import modify_hyper_parameter_levels\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.hyperparameters.values import (get_bound_values,\n",
        "    get_var_name,\n",
        "    get_var_type,)\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "from spotPython.hyperparameters.values import get_tuned_architecture\n",
        "from spotPython.light.testmodel import test_model\n",
        "from spotPython.light.loadmodel import load_light_from_checkpoint\n",
        "\n",
        "MAX_TIME = 1\n",
        "INIT_SIZE = 5\n",
        "WORKERS = 0\n",
        "PREFIX=\"031\"\n",
        "\n",
        "experiment_name = get_experiment_name(prefix=PREFIX)\n",
        "fun_control = fun_control_init(\n",
        "    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name),\n",
        "    num_workers=WORKERS,\n",
        "    device=getDevice(),\n",
        "    _L_in=133,\n",
        "    _L_out=1,\n",
        "    TENSORBOARD_CLEAN=True)\n",
        "\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True)\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                        key=\"data_set\",\n",
        "                        value=dataset)\n",
        "\n",
        "\n",
        "\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "modify_hyper_parameter_bounds(fun_control, \"l1\", bounds=[5,8])\n",
        "modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[3,5])\n",
        "modify_hyper_parameter_bounds(fun_control, \"batch_size\", bounds=[2, 8])\n",
        "modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
        "\n",
        "print(gen_design_table(fun_control))\n",
        "\n",
        "var_type = get_var_type(fun_control)\n",
        "var_name = get_var_name(fun_control)\n",
        "lower = get_bound_values(fun_control, \"lower\")\n",
        "upper = get_bound_values(fun_control, \"upper\")\n",
        "fun = HyperLight(log_level=50).fun\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                       log_level=50,\n",
        "                   lower = lower,\n",
        "                   upper = upper,\n",
        "                   fun_evals = inf,\n",
        "                   max_time = MAX_TIME,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type = var_type,\n",
        "                   var_name = var_name,\n",
        "                   show_progress= True,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": INIT_SIZE},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": len(var_name),\n",
        "                                      \"model_fun_evals\": 10_000,\n",
        "                                      })\n",
        "spot_tuner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.plot_progress(log_y=False, filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.plot_importance(threshold=0.025, filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = get_tuned_architecture(spot_tuner, fun_control)\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model(config, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_loaded = load_light_from_checkpoint(config, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.plot_important_hyperparameter_contour(filename=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.parallel_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.cvmodel import cv_model\n",
        "# set the number of folds to 10\n",
        "fun_control[\"k_folds\"] = 10\n",
        "cv_model(config, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "import numpy as np\n",
        "y = np.array([1, 2, 3, 4, 5])\n",
        "fun = analytical(sigma=1.0, seed=123)\n",
        "fun.add_noise(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "import numpy as np\n",
        "print(np.array([1, 2, 3, 4, 5]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import inf\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "from scipy.optimize import shgo\n",
        "from scipy.optimize import direct\n",
        "from scipy.optimize import differential_evolution\n",
        "import matplotlib.pyplot as plt\n",
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(seed=4321, sigma=0.1)\n",
        "fun = analytical(seed=222, sigma=0.0).fun_sphere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_1 = spot.Spot(fun=fun,\n",
        "                   lower = np.array([-10]),\n",
        "                   upper = np.array([100]),\n",
        "                   fun_evals = 100,\n",
        "                   fun_repeats = 3,\n",
        "                   max_time = inf,\n",
        "                   noise = True,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type=[\"num\"],\n",
        "                   infill_criterion = \"y\",\n",
        "                   n_points = 1,\n",
        "                   seed=111,\n",
        "                   log_level = 10,\n",
        "                   show_models=False,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": 5,\n",
        "                                   \"repeats\": 1},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"cod_type\": \"norm\",\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": 1,\n",
        "                                      \"model_optimizer\": differential_evolution,\n",
        "                                      \"model_fun_evals\": 1000,\n",
        "                                      })\n",
        "spot_1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def squared_euclidean_distance(X_0, X, theta):\n",
        "    return np.sum(theta*(X_0 - X)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import array, zeros, power, ones, exp, multiply, eye, linspace, mat, spacing, sqrt, arange, append, ravel\n",
        "from numpy.linalg import cholesky, solve\n",
        "from numpy.random import multivariate_normal\n",
        "def build_Psi(X, theta):\n",
        "    n = X.shape[0]\n",
        "    k = X.shape[1]\n",
        "    D = zeros((k, n, n))\n",
        "    for l in range(k):\n",
        "        for i in range(n):\n",
        "            for j in range(i, n):\n",
        "                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n",
        "    D = sum(D)\n",
        "    D = D + D.T\n",
        "    return exp(-D)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "theta = np.array([1.0, 1.0])\n",
        "X = np.array([[1.0, 0.0], [1.0, 1.0], [0.0, 1.0]])\n",
        "print(X.shape)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "build_Psi(X, theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "import numpy as np\n",
        "X = np.array([[0, 0, 0], [0, 0, 1], [0, 0, 2]])\n",
        "fun = analytical()\n",
        "fun.fun_branin_factor(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "pi = np.pi\n",
        "X = np.array([[0,0], [-pi, 12.275], [pi, 2.275], [9.42478, 2.475]])\n",
        "fun = analytical()\n",
        "fun.fun_branin(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "import numpy as np\n",
        "pi = np.pi\n",
        "X_0 = np.array([[0, 0]])\n",
        "X_1 = np.array([[-pi, 12.275], [pi, 2.275], [9.42478, 2.475]])\n",
        "X_2 = np.array([[0,0,0], [0,0,1], [0,0,2]])\n",
        "fun = analytical()\n",
        "y_0 = fun.fun_branin(X_0)\n",
        "y_1 = fun.fun_branin(X_1)\n",
        "y_2 = fun.fun_branin_factor(X_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "round(y_1[0], 2) == round(y_1[1],2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "round(y_1[0], 2) == round(y_1[2],2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y_2[0] == y_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y_2[1] == y_0 + 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y_2[2] == y_0 - 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy.random import multivariate_normal\n",
        "import numpy as np\n",
        "n = 100\n",
        "X = np.linspace(0, 10, n, endpoint=False).reshape(-1,1)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import array, zeros, power, ones, exp, multiply, eye, linspace, mat, spacing, sqrt, arange, append, ravel\n",
        "from numpy.linalg import cholesky, solve\n",
        "from numpy.random import multivariate_normal\n",
        "def build_Psi(X, theta):\n",
        "    n = X.shape[0]\n",
        "    k = X.shape[1]\n",
        "    D = zeros((k, n, n))\n",
        "    for l in range(k):\n",
        "        for i in range(n):\n",
        "            for j in range(i, n):\n",
        "                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n",
        "    D = sum(D)\n",
        "    D = D + D.T\n",
        "    return exp(-D)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "theta = np.array([1.0])\n",
        "Psi = build_Psi(X, theta)\n",
        "np.round(Psi[:3,:], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = multivariate_normal(zeros(Psi.shape[0]), Psi, size = (3, 1, 1), check_valid=\"raise\")\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert Y to a 3 x 100 array\n",
        "Y = np.squeeze(Y)\n",
        "Y.shape\n",
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot 3 samples from the GP as a function of X\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, Y.T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = multivariate_normal(zeros(Psi.shape[0]), Psi, size = 3, check_valid=\"raise\")\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot 3 samples from the GP as a function of X\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, Y.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "# dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True)\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(f\"Inputs Shape: {inputs.shape}\")\n",
        "    print(f\"Targets Shape: {targets.shape}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test HyperLight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.hyperparameters.values import get_var_name\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                            fun_control=fun_control,\n",
        "                            hyper_dict=LightHyperDict)\n",
        "hyper_light = HyperLight(seed=126, log_level=50)\n",
        "n_hyperparams = len(get_var_name(fun_control))\n",
        "# generate a random np.array X with shape (2, n_hyperparams)\n",
        "X = np.random.rand(2, n_hyperparams)\n",
        "X == hyper_light.check_X_shape(X, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import (add_core_model_to_fun_control,\n",
        "    get_default_hyperparameters_as_array)\n",
        "from spotPython.fun.hyperlight import HyperLight\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "import numpy as np\n",
        "fun_control = fun_control_init(\n",
        "    _L_in=10,\n",
        "    _L_out=1,)\n",
        "dataset = Diabetes()\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                        key=\"data_set\",\n",
        "                        value=dataset)\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                            fun_control=fun_control,\n",
        "                            hyper_dict=LightHyperDict)\n",
        "hyper_light = HyperLight(seed=126, log_level=50)\n",
        "X = get_default_hyperparameters_as_array(fun_control)\n",
        "# combine X and X to a np.array with shape (2, n_hyperparams)\n",
        "# so that two values are returned\n",
        "X = np.vstack((X, X))\n",
        "hyper_light.fun(X, fun_control)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## test pkldataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.pkldataset import PKLDataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "# dataset = PKLDataset(target_column='prognosis', feature_type=torch.long)\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\",\n",
        "                    filename=\"data_sensitive.pkl\",\n",
        "                    target_column='N',\n",
        "                    feature_type=torch.float32,\n",
        "                    target_type=torch.float32,\n",
        "                    rmNA=True)\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytest\n",
        "import numpy as np\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import get_bound_values\n",
        "from spotPython.hyperparameters.values import get_control_key_value, set_control_key_value\n",
        "from spotPython.hyperparameters.values import get_var_type_from_var_name\n",
        "\n",
        "fun_control = fun_control_init()\n",
        "set_control_key_value(control_dict=fun_control, key=\"var_type\", value=[\"int\", \"float\", \"str\"], replace=True)\n",
        "set_control_key_value(control_dict=fun_control, key=\"var_name\", value=[\"max_depth\", \"learning_rate\", \"model_type\"], replace=True)\n",
        "\n",
        "print(fun_control)\n",
        "\n",
        "# Test with existing var_name\n",
        "assert get_var_type_from_var_name(var_name=\"max_depth\", fun_control=fun_control) == \"int\"\n",
        "assert get_var_type_from_var_name(var_name=\"learning_rate\", fun_control=fun_control) == \"float\"\n",
        "assert get_var_type_from_var_name(var_name=\"model_type\", fun_control=fun_control) == \"str\"\n",
        "\n",
        "# Test with non-existing var_name\n",
        "with pytest.raises(ValueError):\n",
        "    get_var_type_from_var_name(var_name=\"non_existing\", fun_control=fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import get_control_key_value\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.hyperparameters.values import get_var_type_from_var_name\n",
        "\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                    fun_control=fun_control,\n",
        "                    hyper_dict=LightHyperDict)\n",
        "var_type = get_control_key_value(control_dict=fun_control, key=\"var_type\")\n",
        "var_name = get_control_key_value(control_dict=fun_control, key=\"var_name\")\n",
        "print(var_type)\n",
        "print(var_name)\n",
        "vn = \"l1\"\n",
        "get_var_type_from_var_name(fun_control=fun_control, var_name=vn)\n",
        "\n",
        "assert var_type[var_name.index(vn)] == \"int\"\n",
        "assert get_var_type_from_var_name(fun_control, vn) == \"int\"\n",
        "vn = \"initialization\"\n",
        "assert var_type[var_name.index(vn)] == \"factor\"\n",
        "assert var_type[var_name.index(vn)] == \"factor\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.hyperparameters.values import get_control_key_value\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.hyperparameters.values import set_control_hyperparameter_value\n",
        "\n",
        "fun_control = fun_control_init()\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                    fun_control=fun_control,\n",
        "                    hyper_dict=LightHyperDict)\n",
        "set_control_hyperparameter_value(control_dict=fun_control, hyperparameter=\"l1\", value=[1,7])\n",
        "set_control_hyperparameter_value(control_dict=fun_control, hyperparameter=\"initialization\", value=[\"xavier2\", \"kaiming2\"])\n",
        "print(fun_control)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## get names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_entry(dictionary, key, i):\n",
        "    if key in dictionary:\n",
        "        if 'levels' in dictionary[key]:\n",
        "            if i < len(dictionary[key]['levels']):\n",
        "                return dictionary[key]['levels'][i]\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from spotPython.data.pkldataset_intern import PKLDataset\n",
        "from spotPython.utils.device import getDevice\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.utils.file import get_experiment_name, get_spot_tensorboard_path\n",
        "import numpy as np\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "from math import inf\n",
        "\n",
        "MAX_TIME = 60\n",
        "FUN_EVALS = inf\n",
        "INIT_SIZE = 25\n",
        "WORKERS = 0\n",
        "PREFIX=\"031\"\n",
        "DEVICE = getDevice()\n",
        "\n",
        "\n",
        "experiment_name = get_experiment_name(prefix=PREFIX)\n",
        "fun_control = fun_control_init(\n",
        "    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name),\n",
        "    _L_in=10,\n",
        "    _L_out=1,\n",
        "    TENSORBOARD_CLEAN=True,\n",
        "    device=DEVICE,\n",
        "    enable_progress_bar=False,\n",
        "    fun_evals=FUN_EVALS,\n",
        "    log_level=10,\n",
        "    max_time=MAX_TIME,\n",
        "    num_workers=WORKERS,\n",
        "    show_progress=True,\n",
        "    tolerance_x=np.sqrt(np.spacing(1)),\n",
        "    )\n",
        "\n",
        "dataset = Diabetes()\n",
        "dataset = PKLDataset(directory=\"/Users/bartz/workspace/spotPython/notebooks/data/spotPython/\", filename=\"data_sensitive.pkl\", target_column='N', feature_type=torch.float32, target_type=torch.float32, rmNA=True, rmMF=True)\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                        key=\"data_set\",\n",
        "                        value=dataset,\n",
        "                        replace=True)\n",
        "\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                        key=\"_L_in\",\n",
        "                        value=133,\n",
        "                        replace=True)\n",
        "\n",
        "\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=LightHyperDict)\n",
        "# from spotPython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "\n",
        "from spotPython.hyperparameters.values import set_control_hyperparameter_value\n",
        "set_control_hyperparameter_value(fun_control, \"l1\", [3,8])\n",
        "set_control_hyperparameter_value(fun_control, \"epochs\", [4,9])\n",
        "set_control_hyperparameter_value(fun_control, \"batch_size\", [1, 4])\n",
        "set_control_hyperparameter_value(fun_control, \"optimizer\", [\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fun_control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_entry(dictionary, key, i):\n",
        "    if 'core_model_hyper_dict' in dictionary:\n",
        "        if key in dictionary['core_model_hyper_dict']:\n",
        "            if 'levels' in dictionary['core_model_hyper_dict'][key]:\n",
        "                if i < len(dictionary['core_model_hyper_dict'][key]['levels']):\n",
        "                    return dictionary['core_model_hyper_dict'][key]['levels'][i]\n",
        "    return None\n",
        "print(get_entry(fun_control, \"optimizer\", 0)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.device import getDevice\n",
        "from spotPython.utils.init import fun_control_init\n",
        "from spotPython.utils.file import get_experiment_name, get_spot_tensorboard_path\n",
        "import numpy as np\n",
        "from spotPython.data.diabetes import Diabetes\n",
        "from spotPython.light.regression.netlightregression import NetLightRegression\n",
        "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotPython.hyperparameters.values import get_ith_hyperparameter_name_from_fun_control\n",
        "from spotPython.hyperparameters.values import set_control_key_value\n",
        "from spotPython.hyperparameters.values import set_control_hyperparameter_value\n",
        "experiment_name = get_experiment_name(prefix=\"000\")\n",
        "fun_control = fun_control_init(\n",
        "    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name),\n",
        "    _L_in=10,\n",
        "    _L_out=1,\n",
        "    TENSORBOARD_CLEAN=True,\n",
        "    device=getDevice(),\n",
        "    enable_progress_bar=False,\n",
        "    fun_evals=15,\n",
        "    log_level=10,\n",
        "    max_time=1,\n",
        "    num_workers=0,\n",
        "    show_progress=True,\n",
        "    tolerance_x=np.sqrt(np.spacing(1)),\n",
        "    )\n",
        "dataset = Diabetes()\n",
        "set_control_key_value(control_dict=fun_control,\n",
        "                        key=\"data_set\",\n",
        "                        value=dataset,\n",
        "                        replace=True)\n",
        "add_core_model_to_fun_control(core_model=NetLightRegression,\n",
        "                            fun_control=fun_control,\n",
        "                            hyper_dict=LightHyperDict)\n",
        "\n",
        "set_control_hyperparameter_value(fun_control, \"l1\", [3,8])\n",
        "set_control_hyperparameter_value(fun_control, \"optimizer\", [\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
        "assert get_ith_hyperparameter_name_from_fun_control(fun_control, key=\"optimizer\", i=0) == \"Adam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "def get_timestamp(only_int=True):\n",
        "    dt = datetime.datetime.now().isoformat(sep=\" \", timespec=\"microseconds\")\n",
        "    if only_int:\n",
        "        # remove - . : and space\n",
        "        dt = dt.replace(\"-\", \"\")\n",
        "        dt = dt.replace(\".\", \"\")\n",
        "        dt = dt.replace(\":\", \"\")\n",
        "        dt = dt.replace(\" \", \"\")\n",
        "    return dt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytest\n",
        "import numpy as np\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "from spotPython.utils.init import (\n",
        "    fun_control_init, surrogate_control_init, design_control_init\n",
        ")\n",
        "\n",
        "def test_plot_progress():\n",
        "    # number of initial points:\n",
        "    ni = 7\n",
        "    # number of points\n",
        "    fun_evals = 10\n",
        "    fun = analytical().fun_sphere\n",
        "    fun_control = fun_control_init(\n",
        "        lower = np.array([-1, -1]),\n",
        "        upper = np.array([1, 1]),\n",
        "        fun_evals=fun_evals,\n",
        "        tolerance_x = np.sqrt(np.spacing(1))\n",
        "    )\n",
        "    design_control=design_control_init(init_size=ni)\n",
        "    surrogate_control=surrogate_control_init(n_theta=3)\n",
        "    S = spot.Spot(fun=fun,\n",
        "                    fun_control=fun_control,\n",
        "                    design_control=design_control,\n",
        "                    surrogate_control=surrogate_control,)\n",
        "    S.run()\n",
        "\n",
        "    # Test plot_progress with different parameters\n",
        "    S.plot_progress(show=False)  # Test with show=False\n",
        "    S.plot_progress(log_x=True, show=False)  # Test with log_x=True\n",
        "    S.plot_progress(log_y=True, show=False)  # Test with log_y=True\n",
        "    S.plot_progress(filename=\"test_plot.png\", show=False)  # Test with a different filename\n",
        "    # add NaN to S.y at position 2\n",
        "    S.y[2] = np.nan\n",
        "    S.plot_progress(show=False)  # Test with show=False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytest\n",
        "import numpy as np\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "from spotPython.utils.init import (\n",
        "    fun_control_init, surrogate_control_init, design_control_init\n",
        ")\n",
        "\n",
        "\n",
        "# number of initial points:\n",
        "ni = 7\n",
        "# number of points\n",
        "fun_evals = 10\n",
        "fun = analytical().fun_sphere\n",
        "fun_control = fun_control_init(\n",
        "    lower = np.array([-1, -1]),\n",
        "    upper = np.array([1, 1]),\n",
        "    fun_evals=fun_evals,\n",
        "    tolerance_x = np.sqrt(np.spacing(1))\n",
        ")\n",
        "design_control=design_control_init(init_size=ni)\n",
        "surrogate_control=surrogate_control_init(n_theta=3)\n",
        "S = spot.Spot(fun=fun,\n",
        "                fun_control=fun_control,\n",
        "                design_control=design_control,\n",
        "                surrogate_control=surrogate_control,)\n",
        "S.run()\n",
        "\n",
        "# remove points from S.y so that there are less than ni points\n",
        "S.y = S.y[:3]\n",
        "# Test plot_progress with different parameters\n",
        "S.plot_progress(show=False)  # Test with show=False\n",
        "S.plot_progress(log_x=True, show=False)  # Test with log_x=True\n",
        "S.plot_progress(log_y=True, show=False)  # Test with log_y=True\n",
        "S.plot_progress(filename=\"test_plot.png\", show=False)  # Test with a different filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import inf\n",
        "from spotPython.spot import spot\n",
        "from scipy.optimize import differential_evolution\n",
        "from spotPython.utils.init import (\n",
        "    fun_control_init,\n",
        "    design_control_init,\n",
        "    surrogate_control_init,\n",
        "    optimizer_control_init)\n",
        "def objective_function(X, fun_control=None):\n",
        "    if not isinstance(X, np.ndarray):\n",
        "        X = np.array(X)\n",
        "    if X.shape[1] != 2:\n",
        "        raise Exception\n",
        "    x0 = X[:, 0]\n",
        "    x1 = X[:, 1]\n",
        "    y = x0**2 + 10*x1**2\n",
        "    return y\n",
        "fun_control = fun_control_init(\n",
        "            lower = np.array([0, 0]),\n",
        "            upper = np.array([10, 10]),\n",
        "            fun_evals=8,\n",
        "            fun_repeats=1,\n",
        "            max_time=inf,\n",
        "            noise=True,\n",
        "            tolerance_x=0,\n",
        "            ocba_delta=0,\n",
        "            var_type=[\"num\", \"num\"],\n",
        "            infill_criterion=\"ei\",\n",
        "            n_points=1,\n",
        "            seed=123,\n",
        "            log_level=10,\n",
        "            show_models=False,\n",
        "            show_progress=True)\n",
        "design_control = design_control_init(\n",
        "            init_size=5,\n",
        "            repeats=1)\n",
        "surrogate_control = surrogate_control_init(\n",
        "            log_level=10,\n",
        "            model_optimizer=differential_evolution,\n",
        "            model_fun_evals=10000,\n",
        "            min_theta=-3,\n",
        "            max_theta=3,\n",
        "            n_theta=2,\n",
        "            theta_init_zero=True,\n",
        "            n_p=1,\n",
        "            optim_p=False,\n",
        "            noise=True,\n",
        "            var_type=[\"num\", \"num\"],\n",
        "            seed=124, \n",
        "            min_Lambda=1,\n",
        "            max_Lambda=10)\n",
        "optimizer_control = optimizer_control_init(\n",
        "            max_iter=1000,\n",
        "            seed=125)\n",
        "spot = spot.Spot(fun=objective_function,\n",
        "            fun_control=fun_control,\n",
        "            design_control=design_control,\n",
        "            surrogate_control=surrogate_control,\n",
        "            optimizer_control=optimizer_control\n",
        "            )\n",
        "spot.run()\n",
        "spot.plot_progress()\n",
        "spot.plot_contour(i=0, j=1)\n",
        "spot.plot_importance()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from spotPython.spot import spot\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.utils.init import fun_control_init, design_control_init, surrogate_control_init\n",
        "\n",
        "fun = analytical().fun_branin\n",
        "fun_control = fun_control_init(lower = np.array([-5, 0]),\n",
        "                               upper = np.array([10, 15]),\n",
        "                               fun_evals=20)\n",
        "design_control = design_control_init(init_size=10)\n",
        "surrogate_control = surrogate_control_init(n_theta=2)\n",
        "S = spot.Spot(fun=fun, fun_control=fun_control, design_control=design_control)\n",
        "S.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "S.print_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "S.plot_progress(log_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "S.surrogate.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import inf\n",
        "from spotPython.fun.objectivefunctions import analytical\n",
        "from spotPython.spot import spot\n",
        "from scipy.optimize import shgo\n",
        "from scipy.optimize import direct\n",
        "from scipy.optimize import differential_evolution\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fun = analytical().fun_sphere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.linspace(-1,1,100).reshape(-1,1)\n",
        "y = fun(x)\n",
        "plt.figure()\n",
        "plt.plot(x,y, \"k\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\n",
        "spot_1 = spot.Spot(fun=fun,\n",
        "                   fun_control=fun_control_init(\n",
        "                        lower = np.array([-10]),\n",
        "                        upper = np.array([100]),\n",
        "                        fun_evals = 7,\n",
        "                        fun_repeats = 1,\n",
        "                        max_time = inf,\n",
        "                        noise = False,\n",
        "                        tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                        var_type=[\"num\"],\n",
        "                        infill_criterion = \"y\",\n",
        "                        n_points = 1,\n",
        "                        seed=123,\n",
        "                        log_level = 50),\n",
        "                   design_control=design_control_init(\n",
        "                        init_size=5,\n",
        "                        repeats=1),\n",
        "                   surrogate_control=surrogate_control_init(\n",
        "                        noise=False,\n",
        "                        min_theta=-4,\n",
        "                        max_theta=3,\n",
        "                        n_theta=1,\n",
        "                        model_optimizer=differential_evolution,\n",
        "                        model_fun_evals=10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.objectivefunctions import analytical\n",
        "fun = analytical().fun_sphere\n",
        "from spotPython.design.spacefilling import spacefilling\n",
        "design = spacefilling(2)\n",
        "from scipy.optimize import differential_evolution\n",
        "optimizer = differential_evolution\n",
        "from spotPython.build.kriging import Kriging\n",
        "surrogate = Kriging()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init, design_control_init, optimizer_control_init, surrogate_control_init\n",
        "fun_control=fun_control_init(lower=np.array([-1, -1]),\n",
        "                            upper=np.array([1, 1]))\n",
        "design_control=design_control_init()\n",
        "optimizer_control=optimizer_control_init()\n",
        "surrogate_control=surrogate_control_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.spot import spot\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                       fun_control=fun_control,\n",
        "                       design_control=design_control,\n",
        "                       optimizer_control=optimizer_control,\n",
        "                       surrogate_control=surrogate_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pytest\n",
        "import torch\n",
        "from pyhcf.data.loadHcfData import build_df, load_hcf_data\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_list=[\"L\", \"AQ\", \"AS\"]\n",
        "dataset = load_hcf_data(param_list=p_list, target=\"T\",\n",
        "                        rmNA=True, rmMF=True,\n",
        "                        load_all_features=False,\n",
        "                        load_thermo_features=False,\n",
        "                        scale_data=True,\n",
        "                        return_X_y=False)\n",
        "assert isinstance(dataset, torch.utils.data.TensorDataset)\n",
        "assert len(dataset) > 0\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader    \n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    assert inputs.size(0) == batch_size\n",
        "    print(f\"Inputs Shape: {inputs.shape[1]}\")\n",
        "    print(f\"P List: {p_list}\")\n",
        "    print(f\"P List Length: {len(p_list)}\")\n",
        "    # input is p_list + 1 (for target)\n",
        "    # p_list = [\"L\", \"AQ\", \"AS\"] plus target \"N\"\n",
        "    assert inputs.shape[1] + 1 == len(p_list)\n",
        "    print(f\"Targets Shape: {targets.shape[0]}\")\n",
        "    assert targets.shape[0] == batch_size\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "# data.csv is simple csv file with 11 samples\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
        "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n",
        "data_module.setup()\n",
        "print(f\"Training set size: {len(data_module.data_train)}\")\n",
        "print(f\"Validation set size: {len(data_module.data_val)}\")\n",
        "print(f\"Test set size: {len(data_module.data_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.data.lightdatamodule import LightDataModule\n",
        "from spotPython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n",
        "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n",
        "data_module.setup(stage=\"predict\")\n",
        "print(f\"Predict set size: {len(data_module.data_predict)}\")\n",
        "for batch in data_module.predict_dataloader():\n",
        "    inputs, targets = batch\n",
        "    print(f\"inputs: {inputs}\")\n",
        "    print(f\"targets: {targets}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(data_module.data_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_div2_list(n, n_min):\n",
        "    result = []\n",
        "    current = n\n",
        "    while current >= n_min:\n",
        "        result.extend([current] * (n // current))\n",
        "        current = current // 2\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_L_in = 128\n",
        "l1 = \n",
        "\n",
        "n_low = _L_in // 4\n",
        "# ensure that n_high is larger than n_low\n",
        "n_high = max(l1, 2 * n_low)\n",
        "generate_div2_list(n_high, n_low)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.math import generate_div2_list\n",
        "generate_div2_list(64, 63)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([1, 5, 2])\n",
            "Input: tensor([[[0., 0.],\n",
            "         [1., 1.],\n",
            "         [2., 2.],\n",
            "         [3., 3.],\n",
            "         [4., 4.]]])\n",
            "Output shape: torch.Size([1, 5, 2])\n",
            "Output: tensor([[[0., 1.],\n",
            "         [1., 2.],\n",
            "         [2., 3.],\n",
            "         [3., 4.],\n",
            "         [4., 5.]]])\n"
          ]
        }
      ],
      "source": [
        "from spotPython.light.transformer.positionalEncoding import PositionalEncoding\n",
        "import torch\n",
        "# number of tensors\n",
        "n = 5\n",
        "# dimension of each tensor\n",
        "k = 2\n",
        "pe = PositionalEncoding(emb_dim=k, dropout_prob=0)\n",
        "input = torch.zeros(1, n, k)\n",
        "# Generate a tensor of size (1, 10, 4) with values from 1 to 10\n",
        "for i in range(n):\n",
        "    input[0, i, :] = i\n",
        "\n",
        "print(f\"Input shape: {input.shape}\")\n",
        "print(f\"Input: {input}\")\n",
        "output = pe(input)\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Output: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
