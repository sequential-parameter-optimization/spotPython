{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HPT: PyTorch With VBDP {#sec-vbdp}\n",
        "\n",
        "In this tutorial, we will show how `spotPython` can be integrated into the `PyTorch`\n",
        "training workflow for a classifiaction task.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Data must be downloaded manually\n",
        "\n",
        "* Ensure that the correspondiing data is available as `./data/VBDP/train.csv`.\n",
        "\n",
        ":::\n",
        "\n",
        "This document refers to the following software versions:\n",
        "\n",
        "- ``python``: 3.10.10\n",
        "- ``torch``: 2.0.1\n",
        "- ``torchvision``: 0.15.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spotPython                                0.2.41\n",
            "spotRiver                                 0.0.94\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip list | grep  \"spot[RiverPython]\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`spotPython` can be installed via pip. Alternatively, the source code can be downloaded from gitHub: [https://github.com/sequential-parameter-optimization/spotPython](https://github.com/sequential-parameter-optimization/spotPython).\n",
        "\n",
        "```{raw}\n",
        "!pip install spotPython\n",
        "```\n",
        "\n",
        "* Uncomment the following lines if you want to for (re-)installation the latest version of `spotPython` from gitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install --upgrade build\n",
        "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup {#sec-setup-25}\n",
        "\n",
        "Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Run time and initial design size should be increased for real experiments\n",
        "\n",
        "* MAX_TIME is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\n",
        "* INIT_SIZE is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-note}\n",
        "### Note: Device selection\n",
        "\n",
        "* The device can be selected by setting the variable `DEVICE`.\n",
        "* Since we are using a simple neural net, the setting `\"cpu\"` is preferred (on Mac).\n",
        "* If you have a GPU, you can use `\"cuda:0\"` instead.\n",
        "* If DEVICE is set to `None`, `spotPython` will automatically select the device.\n",
        "  * This might result in `\"mps\"` on Macs, which is not the best choice for simple neural nets.\n",
        "\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_TIME = 1\n",
        "INIT_SIZE = 5\n",
        "DEVICE = None # \"cpu\" # \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "from spotPython.utils.device import getDevice\n",
        "DEVICE = getDevice(DEVICE)\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29-torch_bartz08-2_1min_5init_2023-06-25_10-42-10\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "import socket\n",
        "from datetime import datetime\n",
        "from dateutil.tz import tzlocal\n",
        "start_time = datetime.now(tzlocal())\n",
        "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
        "experiment_name = '29-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
        "experiment_name = experiment_name.replace(':', '-')\n",
        "print(experiment_name)\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialization of the `fun_control` Dictionary\n",
        "\n",
        ":::{.callout-caution}\n",
        "### Caution: Tensorboard does not work under Windows\n",
        "* Since tensorboard does not work under Windows, we recommend setting the parameter `tensorboard_path` to `None` if you are working under Windows.\n",
        ":::\n",
        "\n",
        "`spotPython` uses a Python dictionary for storing the information required for the hyperparameter tuning process, which was described in @sec-initialization-fun-control-14, see [Initialization of the fun_control Dictionary](https://sequential-parameter-optimization.github.io/spotPython/14_spot_ray_hpt_torch_cifar10.html#sec-initialization-fun-control-14) in the documentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(task=\"classification\",\n",
        "    tensorboard_path=\"./runs/29\",\n",
        "    num_workers=10,\n",
        "    device=DEVICE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: PyTorch Data Loading {#sec-data-loading-25}\n",
        "\n",
        "### 1. Load VBDP Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import OrdinalEncoder\n",
        "# train_df = pd.read_csv('./data/VBDP/train.csv')\n",
        "# # remove the id column\n",
        "# train_df = train_df.drop(columns=['id'])\n",
        "# n_samples = train_df.shape[0]\n",
        "# n_features = train_df.shape[1] - 1\n",
        "# target_column = \"prognosis\"\n",
        "# # # Encoder our prognosis labels as integers for easier decoding later\n",
        "# enc = OrdinalEncoder()\n",
        "# train_df[target_column] = enc.fit_transform(train_df[[target_column]])\n",
        "# train_df.head()\n",
        "\n",
        "# # convert all entries to int for faster processing\n",
        "# train_df = train_df.astype(int)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Add logical combinations (AND, OR, XOR) of the features to the data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.utils.convert import add_logical_columns\n",
        "# df_new = train_df.copy()\n",
        "# # save the target column using \"target_column\" as the column name\n",
        "# target = train_df[target_column]\n",
        "# # remove the target column\n",
        "# df_new = df_new.drop(columns=[target_column])\n",
        "# train_df = add_logical_columns(df_new)\n",
        "# # add the target column back\n",
        "# train_df[target_column] = target\n",
        "# train_df = train_df.astype(int)\n",
        "# train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import numpy as np\n",
        "\n",
        "# n_samples = train_df.shape[0]\n",
        "# n_features = train_df.shape[1] - 1\n",
        "# train_df.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "# train_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check content of the target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(train_df.drop(target_column, axis=1), train_df[target_column],\n",
        "#                                                     random_state=42,\n",
        "#                                                     test_size=0.25,\n",
        "#                                                     stratify=train_df[target_column])\n",
        "# trainset = pd.DataFrame(np.hstack((X_train, np.array(y_train).reshape(-1, 1))))\n",
        "# testset = pd.DataFrame(np.hstack((X_test, np.array(y_test).reshape(-1, 1))))\n",
        "# trainset.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "# testset.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "# print(train_df.shape)\n",
        "# print(trainset.shape)\n",
        "# print(testset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from spotPython.torch.dataframedataset import DataFrameDataset\n",
        "# dtype_x = torch.float32\n",
        "# dtype_y = torch.long\n",
        "# train_df = DataFrameDataset(train_df, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "# train = DataFrameDataset(trainset, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "# test = DataFrameDataset(testset, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "# n_samples = len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # add the dataset to the fun_control\n",
        "# fun_control.update({\"data\": train_df, # full dataset,\n",
        "#                \"train\": trainset,\n",
        "#                \"test\": testset,\n",
        "#                \"n_samples\": n_samples,\n",
        "#                \"target_column\": target_column})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Specification of the Preprocessing Model {#sec-specification-of-preprocessing-model-25}\n",
        "\n",
        "After the training and test data are specified and added to the `fun_control` dictionary, `spotPython` allows the specification of a data preprocessing pipeline, e.g., for the scaling of the data or for the one-hot encoding of categorical variables, see @sec-specification-of-preprocessing-model-14. This feature is not used here, so we do not change the default value (which is `None`).\n",
        "\n",
        "## Step 5: Select `algorithm` and `core_model_hyper_dict` {#sec-selection-of-the-algorithm-25}\n",
        "\n",
        "### Implementing a Configurable Neural Network With spotPython \n",
        "\n",
        "`spotPython` includes the `Net_vbdp` class which is implemented in the file `netvbdp.py`.\n",
        "The class is imported here.\n",
        "\n",
        "This class  inherits from the class `Net_Core` which is implemented in the file `netcore.py`, see @sec-the-netcore-class-14.\n",
        "\n",
        "### Add the NN Model to the fun_control Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.litmodel import LitModel \n",
        "from spotPython.data.light_hyper_dict import LightHyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "fun_control = add_core_model_to_fun_control(core_model=LitModel,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict= LightHyperDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spotPython.light.litmodel.LitModel"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fun_control[\"core_model\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The corresponding entries for the `core_model` class are shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'l1': {'type': 'int',\n",
              "  'default': 3,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 3,\n",
              "  'upper': 8},\n",
              " 'epochs': {'type': 'int',\n",
              "  'default': 4,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 4,\n",
              "  'upper': 9},\n",
              " 'batch_size': {'type': 'int',\n",
              "  'default': 4,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 1,\n",
              "  'upper': 4},\n",
              " 'act_fn': {'levels': ['ReLU'],\n",
              "  'type': 'factor',\n",
              "  'default': 'ReLU',\n",
              "  'transform': 'None',\n",
              "  'class_name': 'torch.nn',\n",
              "  'core_model_parameter_type': 'instance()',\n",
              "  'lower': 0,\n",
              "  'upper': 0},\n",
              " 'optimizer': {'levels': ['Adadelta',\n",
              "   'Adagrad',\n",
              "   'Adam',\n",
              "   'AdamW',\n",
              "   'SparseAdam',\n",
              "   'Adamax',\n",
              "   'ASGD',\n",
              "   'NAdam',\n",
              "   'RAdam',\n",
              "   'RMSprop',\n",
              "   'Rprop',\n",
              "   'SGD'],\n",
              "  'type': 'factor',\n",
              "  'default': 'SGD',\n",
              "  'transform': 'None',\n",
              "  'class_name': 'torch.optim',\n",
              "  'core_model_parameter_type': 'str',\n",
              "  'lower': 0,\n",
              "  'upper': 12}}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fun_control['core_model_hyper_dict']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model` {#sec-modification-of-hyperparameters-25}\n",
        "\n",
        " `spotPython` provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions were described in @sec-modification-of-hyperparameters-14.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Small number of epochs for demonstration purposes\n",
        "\n",
        "* `epochs` and `patience` are set to small values for demonstration purposes. These values are too small for a real application.\n",
        "* More resonable values are, e.g.:\n",
        "  * `fun_control = modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[7, 9])` and\n",
        "  * `fun_control = modify_hyper_parameter_bounds(fun_control, \"patience\", bounds=[2, 7])`\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"l1\", bounds=[2, 3])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[2, 3])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"batch_size\", bounds=[7, 8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import modify_hyper_parameter_levels\n",
        "fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
        "# fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\", [\"Adam\"])\n",
        "# fun_control[\"core_model_hyper_dict\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Selection of the Objective (Loss) Function\n",
        "\n",
        "### Evaluation  {#sec-selection-of-target-function-25}\n",
        "\n",
        "The evaluation procedure requires the specification of two elements:\n",
        "\n",
        "1. the way how the data is split into a train and a test set (see @sec-data-splitting-14)\n",
        "2. the loss function (and a metric).\n",
        "\n",
        "\n",
        "### Loss Functions and Metrics {#sec-loss-functions-and-metrics-25}\n",
        "\n",
        "The loss function is specified by the key `\"loss_function\"`.\n",
        "We will use CrossEntropy loss for the multiclass-classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.nn import CrossEntropyLoss\n",
        "# loss_function = CrossEntropyLoss()\n",
        "# fun_control.update({\"loss_function\": loss_function})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metric {#sec-metric-25}\n",
        "\n",
        "* We will use the MAP@k metric for the evaluation of the model. Here is an example how this metric is calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6250)\n"
          ]
        }
      ],
      "source": [
        "from spotPython.torch.mapk import MAPK\n",
        "import torch\n",
        "mapk = MAPK(k=2)\n",
        "target = torch.tensor([0, 1, 2, 2])\n",
        "preds = torch.tensor(\n",
        "    [\n",
        "        [0.5, 0.2, 0.2],  # 0 is in top 2\n",
        "        [0.3, 0.4, 0.2],  # 1 is in top 2\n",
        "        [0.2, 0.4, 0.3],  # 2 is in top 2\n",
        "        [0.7, 0.2, 0.1],  # 2 isn't in top 2\n",
        "    ]\n",
        ")\n",
        "mapk.update(preds, target)\n",
        "print(mapk.compute()) # tensor(0.6250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.torch.mapk import MAPK\n",
        "# import torchmetrics\n",
        "# metric_torch = MAPK(k=3)\n",
        "# fun_control.update({\"metric_torch\": metric_torch})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Calling the SPOT Function\n",
        "\n",
        "### Preparing the SPOT Call {#sec-prepare-spot-call-25}\n",
        "\n",
        "The following code passes the information about the parameter ranges and bounds to `spot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract the variable types, names, and bounds\n",
        "from spotPython.hyperparameters.values import (get_bound_values,\n",
        "    get_var_name,\n",
        "    get_var_type,)\n",
        "var_type = get_var_type(fun_control)\n",
        "var_name = get_var_name(fun_control)\n",
        "fun_control.update({\"var_type\": var_type,\n",
        "                    \"var_name\": var_name})\n",
        "lower = get_bound_values(fun_control, \"lower\")\n",
        "upper = get_bound_values(fun_control, \"upper\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the dictionary `fun_control` contains all information needed for the hyperparameter tuning. Before the hyperparameter tuning is started, it is recommended to take a look at the experimental design. The method `gen_design_table` generates a design table as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "fig-label": "tbl-design-25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| name       | type   | default   |   lower |   upper | transform             |\n",
            "|------------|--------|-----------|---------|---------|-----------------------|\n",
            "| l1         | int    | 3         |       2 |       3 | transform_power_2_int |\n",
            "| epochs     | int    | 4         |       2 |       3 | transform_power_2_int |\n",
            "| batch_size | int    | 4         |       7 |       8 | transform_power_2_int |\n",
            "| act_fn     | factor | ReLU      |       0 |       0 | None                  |\n",
            "| optimizer  | factor | SGD       |       0 |       3 | None                  |\n"
          ]
        }
      ],
      "source": [
        "#| fig-cap: Experimental design for the hyperparameter tuning.\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows to check if all information is available and if the information is correct.\n",
        "\n",
        "### The Objective Function `fun_torch` {#sec-the-objective-function-25}\n",
        "\n",
        "The objective function `fun_torch` is selected next. It implements an interface from `PyTorch`'s training, validation, and  testing methods to `spotPython`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.light.hyperlight import HyperLight\n",
        "fun = HyperLight().fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3,  4,  4,  0, 11]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from spotPython.hyperparameters.values import get_default_hyperparameters_as_array\n",
        "hyper_dict=LightHyperDict().load()\n",
        "X_start = get_default_hyperparameters_as_array(fun_control, hyper_dict)\n",
        "X_start"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Starting the Hyperparameter Tuning {#sec-call-the-hyperparameter-tuner-25}\n",
        "\n",
        "The `spotPython` hyperparameter tuning is started by calling the `Spot` function as described in @sec-call-the-hyperparameter-tuner-14.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | act_fn | ReLU       | 0     \n",
            "1 | model  | Sequential | 3.2 K \n",
            "--------------------------------------\n",
            "3.2 K     Trainable params\n",
            "0         Non-trainable params\n",
            "3.2 K     Total params\n",
            "0.013     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "config: {'l1': 4, 'epochs': 4, 'batch_size': 256, 'act_fn': ReLU(), 'optimizer': 'Adamax'}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8954dbade8934aeda30acea33633d342",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b041b20f86214bac83d90ddf0014bc59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b051300d46e5442ab8588e336f55ba13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea50039477224954aa7f557fa8cf92b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1690546e078a4056b38c3847a232b94a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d7a8a8f5dc340aa8fe59bff7622830f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:189: UserWarning: .validate(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c016f2d78fb94b6398842e3f737a161d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.41280001401901245    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.6904031038284302     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.41280001401901245   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.6904031038284302    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | act_fn | ReLU       | 0     \n",
            "1 | model  | Sequential | 3.2 K \n",
            "--------------------------------------\n",
            "3.2 K     Trainable params\n",
            "0         Non-trainable params\n",
            "3.2 K     Total params\n",
            "0.013     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 1.6904031038284302, 'val_acc': 0.41280001401901245}\n",
            "\n",
            "config: {'l1': 4, 'epochs': 8, 'batch_size': 128, 'act_fn': ReLU(), 'optimizer': 'Adam'}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8bf334a3d414dceac9ea4efafbef119",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b039a41bfc147758b997660808825b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d39324bf35d14e8ea48cbf110b3e5f6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c5f78e8fbe647b8a51f5ac37356ef3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8f5f247bb3c4f7a9db818935432a2f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8a3b820302944319aacec7778d8bb2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "badc405c54d34d748278480c96ae0597",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3590d7ed5fd4f5e9a8e7ed67256db3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb5b0adf84d94b99ba2cc996b0119c20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdf2772cd46d4b37b29860f8b8a645af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9588703a91514960a849f74e94126089",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6611999869346619     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0870628356933594     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6611999869346619    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0870628356933594    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | act_fn | ReLU       | 0     \n",
            "1 | model  | Sequential | 3.2 K \n",
            "--------------------------------------\n",
            "3.2 K     Trainable params\n",
            "0         Non-trainable params\n",
            "3.2 K     Total params\n",
            "0.013     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 1.0870628356933594, 'val_acc': 0.6611999869346619}\n",
            "\n",
            "config: {'l1': 4, 'epochs': 4, 'batch_size': 128, 'act_fn': ReLU(), 'optimizer': 'NAdam'}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "988cb8d642474b28993ad2ab4f21aac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abd457448cab4a0b97f51fcd5117aa1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d0cb82e46374aca8baa7077310a006c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8dd3ac619424de0902561dbfb66554b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e0d23f671e844b080efe27409a46146",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a9b35d0e58640e5b0d1ed0e6a0c1276",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d938654e140493f99308de43005b3c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6111999750137329     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.3066868782043457     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6111999750137329    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3066868782043457    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type       | Params\n",
            "--------------------------------------\n",
            "0 | act_fn | ReLU       | 0     \n",
            "1 | model  | Sequential | 6.4 K \n",
            "--------------------------------------\n",
            "6.4 K     Trainable params\n",
            "0         Non-trainable params\n",
            "6.4 K     Total params\n",
            "0.026     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 1.3066868782043457, 'val_acc': 0.6111999750137329}\n",
            "\n",
            "config: {'l1': 8, 'epochs': 4, 'batch_size': 128, 'act_fn': ReLU(), 'optimizer': 'AdamW'}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce643e83de444cdbb30237e5d5afa348",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1c533c108034c788720de12bea0ecdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ddeac7b4e824028af38be828908d2e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from spotPython.spot import spot\n",
        "from math import inf\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                   lower = lower,\n",
        "                   upper = upper,\n",
        "                   fun_evals = inf,\n",
        "                   fun_repeats = 1,\n",
        "                   max_time = MAX_TIME,\n",
        "                   noise = False,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type = var_type,\n",
        "                   var_name = var_name,\n",
        "                   infill_criterion = \"y\",\n",
        "                   n_points = 1,\n",
        "                   seed=123,\n",
        "                   log_level = 50,\n",
        "                   show_models= False,\n",
        "                   show_progress= True,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": INIT_SIZE,\n",
        "                                   \"repeats\": 1},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"cod_type\": \"norm\",\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": len(var_name),\n",
        "                                      \"model_fun_evals\": 10_000,\n",
        "                                      \"log_level\": 50\n",
        "                                      })\n",
        "spot_tuner.run(X_start=X_start)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Tensorboard {#sec-tensorboard-25}\n",
        "\n",
        "The textual output shown in the console (or code cell) can be visualized with Tensorboard as described in @sec-tensorboard-14, see also the description in the documentation: [Tensorboard.](https://sequential-parameter-optimization.github.io/spotPython/14_spot_ray_hpt_torch_cifar10.html#sec-tensorboard-14)\n",
        "\n",
        "## Step 10: Results {#sec-results-25}\n",
        "\n",
        "After the hyperparameter tuning run is finished, the results can be analyzed as described in @sec-results-14."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-progress-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Progress plot. *Black* dots denote results from the initial design. *Red* dots  illustrate the improvement found by the surrogate model based optimization.\n",
        "spot_tuner.plot_progress(log_y=False, \n",
        "    filename=\"./figures/\" + experiment_name+\"_progress.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "tbl-results-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Results of the hyperparameter tuning.\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-importance-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: 'Variable importance plot, threshold 0.025.'\n",
        "spot_tuner.plot_importance(threshold=0.025,\n",
        "    filename=\"./figures/\" + experiment_name+\"_importance.png\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the Tuned Architecture {#sec-get-spot-results-25}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import get_one_core_model_from_X\n",
        "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
        "model_spot = get_one_core_model_from_X(X, fun_control)\n",
        "model_spot"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of the Tuned Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.torch.traintest import (\n",
        "    train_tuned,\n",
        "    test_tuned,\n",
        "    )\n",
        "train_tuned(net=model_spot, train_dataset=train,\n",
        "        loss_function=fun_control[\"loss_function\"],\n",
        "        metric=fun_control[\"metric_torch\"],\n",
        "        shuffle=True,\n",
        "        device = fun_control[\"device\"],\n",
        "        path=None,\n",
        "        task=fun_control[\"task\"],)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If `path` is set to a filename, e.g., `path = \"model_spot_trained.pt\"`, the weights of the trained model will be loaded from this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_tuned(net=model_spot, test_dataset=test,\n",
        "            shuffle=False,\n",
        "            loss_function=fun_control[\"loss_function\"],\n",
        "            metric=fun_control[\"metric_torch\"],\n",
        "            device = fun_control[\"device\"],\n",
        "            task=fun_control[\"task\"],)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-validated Evaluations\n",
        "\n",
        "* This is the evaluation that will be used in the comparison.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Cross-validated Evaluations\n",
        "\n",
        "* The number of folds is set to 1 by default.\n",
        "* Here it was changed to 3 for demonstration purposes.\n",
        "* Set the number of folds to a reasonable value, e.g., 10.\n",
        "* This can be done by setting the `k_folds` attribute of the model as follows:\n",
        "* `setattr(model_spot, \"k_folds\",  10)`\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.torch.traintest import evaluate_cv\n",
        "# modify k-kolds:\n",
        "setattr(model_spot, \"k_folds\",  3)\n",
        "df_eval, df_preds, df_metrics = evaluate_cv(net=model_spot,\n",
        "    dataset=fun_control[\"data\"],\n",
        "    loss_function=fun_control[\"loss_function\"],\n",
        "    metric=fun_control[\"metric_torch\"],\n",
        "    task=fun_control[\"task\"],\n",
        "    writer=fun_control[\"writer\"],\n",
        "    writerId=\"model_spot_cv\",\n",
        "    device = fun_control[\"device\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric_name = type(fun_control[\"metric_torch\"]).__name__\n",
        "print(f\"loss: {df_eval}, Cross-validated {metric_name}: {df_metrics}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Detailed Hyperparameter Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-contour-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Contour plots.\n",
        "filename = \"./figures/\" + experiment_name\n",
        "spot_tuner.plot_important_hyperparameter_contour(filename=filename)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallel Coordinates Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-parallel-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Parallel coordinates plots\n",
        "spot_tuner.parallel_plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot all Combinations of Hyperparameters\n",
        "\n",
        "* Warning: this may take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PLOT_ALL = False\n",
        "if PLOT_ALL:\n",
        "    n = spot_tuner.k\n",
        "    for i in range(n-1):\n",
        "        for j in range(i+1, n):\n",
        "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
