{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: PyTorch Hyperparameter Tuning --- A Tutorial for spotPython\n",
        "subtitle: Version 0.1.3\n",
        "format:\n",
        "  pdf:\n",
        "    template: bart23e_template.tex\n",
        "    fig-width: 7\n",
        "    fig-height: 5\n",
        "    keep-tex: true\n",
        "    linenumbers: false\n",
        "    doublespacing: false\n",
        "    number-sections: true\n",
        "    runninghead: PyTorch Hyperparameter Tuning With spotPython\n",
        "  html:\n",
        "    fig-width: 7\n",
        "    fig-height: 5\n",
        "author:\n",
        "  - name: Thomas Bartz-Beielstein\n",
        "    affiliations:\n",
        "      - name: SpotSeven Lab\n",
        "      - city: Gummersbach\n",
        "        country: Germany\n",
        "        postal-code: 51643\n",
        "    orcid: 0000-0002-5938-5158\n",
        "    email: bartzbeielstein@gmail.com\n",
        "    url: 'https://www.spotseven.de'\n",
        "abstract: |\n",
        "  The goal of hyperparameter tuning (or hyperparameter optimization) is to optimize the hyperparameters to improve the performance of the machine or deep learning model. spotPython (\"Sequential Parameter Optimization Toolbox in Python\") is the Python version of the well-known hyperparameter tuner SPOT, which has been developed in the R programming environment for statistical analysis for over a decade. PyTorch is an optimized tensor library for deep learning using GPUs and CPUs. This document shows how to integrate the spotPython hyperparameter tuner into the PyTorch training workflow.  As an example, the results of the CIFAR10 image classifier are used. In addition to an introduction to spotPython, this tutorial also includes a brief comparison with Ray Tune, a Python library for running experiments and tuning hyperparameters. This comparison is based on the PyTorch hyperparameter tuning tutorial. The advantages and disadvantages of both approaches are discussed. We show that spotPython achieves similar or even better results while being more flexible and transparent than Ray Tune.\n",
        "keywords:\n",
        "  - hyperparameter tuning\n",
        "  - hyperparameter optimization\n",
        "  - spotPython\n",
        "  - PyTorch\n",
        "  - CIFAR10\n",
        "  - optimization\n",
        "  - deep learning\n",
        "  - machine learning\n",
        "bibliography: bart23e.bib\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: false\n",
        "  echo: true\n",
        "  warning: false\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter Tuning {#sec-hyperparameter-tuning}\n",
        "\n",
        "Hyperparameter tuning is an important, but often difficult and computationally intensive task.\n",
        "Changing the architecture of a neural network or the learning rate of an optimizer can have a significant impact on the performance .\n",
        "\n",
        "The goal of hyperparameter tuning is to optimize the hyperparameters in a way that improves the performance of the machine learning or deep learning model.\n",
        "The simplest, but also most computationally expensive, approach uses manual search (or trial-and-error [@Meignan:2015vp]).\n",
        "Commonly encountered is simple random search, i.e., random and repeated selection of hyperparameters for evaluation, and lattice search (\"grid search\").\n",
        "In addition, methods that perform directed search  and other model-free algorithms, i.e., algorithms that do not explicitly rely on a model, e.g., evolution strategies [@Bart13j] or pattern search [@Torczon00] play an important role.\n",
        "Also, \"hyperband\", i.e., a multi-armed bandit strategy that dynamically allocates resources to a set of random configurations and uses successive bisections to stop configurations with poor performance [@Li16a], is very common in hyperparameter tuning.\n",
        "The most sophisticated and efficient approaches are the Bayesian optimization and surrogate model based optimization methods, which are based on the optimization of cost functions determined by simulations or experiments.\n",
        "\n",
        "We consider below a surrogate model based optimization-based hyperparameter tuning approach based on the Python version of the SPOT (\"Sequential Parameter Optimization Toolbox\") [@BLP05], which is suitable for situations where only limited resources are available. This may be due to limited availability and cost of hardware, or due to the fact that confidential data may only be processed locally, e.g., due to legal requirements.\n",
        "Furthermore, in our approach, the understanding of algorithms is seen as a key tool for enabling transparency and explainability. This can be enabled, for example, by quantifying the contribution of machine learning and deep learning components (nodes, layers, split decisions, activation functions, etc.).\n",
        "Understanding the importance of hyperparameters and the interactions between multiple hyperparameters plays a major role in the interpretability and explainability of machine learning models.\n",
        "SPOT provides statistical tools for understanding hyperparameters and their interactions. Last but not least, it should be noted that the SPOT software code is available in the open source `spotPython` package on github^[[https://github.com/sequential-parameter-optimization](https://github.com/sequential-parameter-optimization)], allowing replicability of the results.\n",
        "This tutorial descries the Python variant of SPOT, which is called `spotPython`. The R implementation is described in @bart21i.\n",
        "SPOT is an established open source software that has been maintained for more than 15 years [@BLP05] [@bart21i].\n",
        "\n",
        "This tutorial is structured as follows. The concept of the hyperparameter tuning software `spotPython` is described in @sec-spot. @sec-hyperparameter-tuning-for-pytorch describes the integration of `spotPython` into the ``PyTorch`` training workflow and presents the results. Finally, @sec-summary presents a summary and an outlook.\n",
        "\n",
        "::: {.callout-note}\n",
        "The corresponding ` .ipynb` notebook [@bart23e] is updated regularly and reflects updates and changes in the `spotPython` package.\n",
        "It can be downloaded from [https://github.com/sequential-parameter-optimization/spotPython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb](https://github.com/sequential-parameter-optimization/spotPython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb).\n",
        ":::\n",
        "\n",
        "\n",
        "# The Hyperparameter Tuning Software SPOT {#sec-spot}\n",
        "\n",
        "Surrogate model based optimization methods are common approaches in simulation and optimization. SPOT was developed because there is a great need for sound statistical analysis of simulation and optimization algorithms. SPOT includes methods for tuning based on classical regression and analysis of variance techniques.\n",
        "It presents tree-based models such as classification and regression trees and random forests as well as Bayesian optimization (Gaussian process models, also known as Kriging). Combinations of different meta-modeling approaches are possible. SPOT comes with a sophisticated surrogate model based optimization method, that can handle discrete and continuous inputs. Furthermore, any model implemented in `scikit-learn` can be used out-of-the-box as a surrogate in `spotPython`.\n",
        "\n",
        "SPOT implements key techniques such as exploratory fitness landscape analysis and sensitivity analysis. It can be used to understand the performance of various algorithms, while simultaneously giving insights into their algorithmic behavior.\n",
        "In addition, SPOT can be used as an optimizer and for automatic and interactive tuning. Details on SPOT and its use in practice are given by @bart21i.\n",
        "\n",
        "A typical hyperparameter tuning process with `spotPython` consists of the following steps:\n",
        "\n",
        "1. Loading the data (training and test datasets), see @sec-data-loading.\n",
        "2. Specification of the preprocessing model, see @sec-specification-of-preprocessing-model. This model is called `prep_model` (\"preparation\" or pre-processing).\n",
        "The information required for the hyperparameter tuning is stored in the dictionary `fun_control`. Thus, the information needed for the execution of the hyperparameter tuning is available in a readable form.\n",
        "3. Selection of the machine learning or deep learning model to be tuned, see @sec-selection-of-the-algorithm. This is called the `core_model`. Once the `core_model` is defined, then the associated hyperparameters are stored in the `fun_control` dictionary. First, the hyperparameters of the `core_model` are initialized with the default values of the `core_model`.\n",
        "As default values we use the default values contained in the `spotPython` package for the algorithms of the `torch` package.\n",
        "4. Modification of the default values for the hyperparameters used in `core_model`, see @sec-modification-of-default-values. This step is optional.\n",
        "   1. numeric parameters are modified by changing the bounds.\n",
        "   2. categorical parameters are modified by changing the categories (\"levels\").\n",
        "5. Selection of target function (loss function) for the optimizer, see @sec-selection-of-target-function.\n",
        "6. Calling SPOT with the corresponding parameters, see @sec-call-the-hyperparameter-tuner. The results are stored in a dictionary and are available for further analysis.\n",
        "7. Presentation, visualization and interpretation of the results, see @sec-results-tuning.\n",
        "\n",
        "# Hyperparameter Tuning for PyTorch With `spotPython` {#sec-hyperparameter-tuning-for-pytorch}\n",
        "\n",
        "In this tutorial, we will show how `spotPython` can be integrated into the `PyTorch`\n",
        "training workflow. It is based on the tutorial \"Hyperparameter Tuning with Ray Tune\" from the `PyTorch` documentation [@pyto23a], which is an extension of the tutorial \"Training a Classifier\" [@pyto23b] for training a CIFAR10 image classifier.\n",
        "\n",
        "This document refers to the following software versions:\n",
        "\n",
        "- ``python``: 3.10.10\n",
        "- ``torch``: 2.0.1\n",
        "- ``torchvision``: 0.15.0\n",
        "- ``spotPython``: 0.1.3\n",
        "\n",
        "`spotPython` can be installed via pip^[Alternatively, the source code can be downloaded from gitHub: [https://github.com/sequential-parameter-optimization/spotPython](https://github.com/sequential-parameter-optimization/spotPython).].\n",
        "\n",
        "```{raw}\n",
        "!pip install spotPython\n",
        "```\n",
        "\n",
        "Results that refer to the `Ray Tune` package are taken from [https://PyTorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html](https://PyTorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)^[We were not able to install `Ray Tune` on our system. Therefore, we used the results from the `PyTorch` tutorial.].\n",
        "\n",
        "## Setup {#sec-setup}\n",
        "\n",
        "Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_TIME = 2880\n",
        "INIT_SIZE = 20\n",
        "DEVICE = \"cpu\" # \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14-torch_maans03_1440min_20init_2023-05-19_22-36-49\n"
          ]
        }
      ],
      "source": [
        "#| echo: false\n",
        "import os\n",
        "import copy\n",
        "import pickle\n",
        "import socket\n",
        "from datetime import datetime\n",
        "from dateutil.tz import tzlocal\n",
        "start_time = datetime.now(tzlocal())\n",
        "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
        "experiment_name = '14-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
        "experiment_name = experiment_name.replace(':', '-')\n",
        "print(experiment_name)\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "from tabulate import tabulate\n",
        "import warnings\n",
        "import json\n",
        "import numpy as np\n",
        "from math import inf\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.optimize import differential_evolution\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from spotPython.spot import spot\n",
        "from spotPython.hyperparameters.values import (\n",
        "    add_core_model_to_fun_control,\n",
        "    assign_values,\n",
        "    get_bound_values,\n",
        "    get_default_values,\n",
        "    get_default_hyperparameters_as_array,\n",
        "    get_var_name,\n",
        "    get_var_type,\n",
        "    modify_hyper_parameter_levels,\n",
        "    modify_hyper_parameter_bounds,\n",
        "    return_conf_list_from_var_dict,\n",
        "    get_one_core_model_from_X,\n",
        ")\n",
        "from spotPython.torch.traintest import (\n",
        "    evaluate_cv,\n",
        "    evaluate_hold_out,\n",
        "    train_save,\n",
        "    test_saved,\n",
        "    )\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "from spotPython.utils.transform import transform_hyper_parameter_values\n",
        "from spotPython.utils.init import fun_control_init\n",
        "\n",
        "from spotPython.data.torch_hyper_dict import TorchHyperDict\n",
        "from spotPython.fun.hypertorch import HyperTorch\n",
        "from spotPython.torch.netcifar10 import Net_CIFAR10\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialization of the `fun_control` Dictionary\n",
        "\n",
        "`spotPython` uses a Python dictionary for storing the information required for the hyperparameter tuning process. This dictionary is called `fun_control` and is initialized with the function `fun_control_init`. The function `fun_control_init` returns a skeleton  dictionary. The dictionary is filled with the required information for the hyperparameter tuning process. It stores the hyperparameter tuning settings, e.g., the deep learning network architecture that should be tuned, the classification (or regression) problem, and the data that is used for the tuning.\n",
        "The dictionary is used as an input for the SPOT function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "fun_control = fun_control_init()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading {#sec-data-loading}\n",
        "\n",
        "The data loading process is implemented in the same manner as described in the Section \"Data loaders\" in @pyto23a.\n",
        "The data loaders are wrapped into the function `load_data`. A global data directory is used, which allows sharing the data directory between different trials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "def load_data(data_dir=\"./data\"):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    return trainset, testset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The test and train data are added to the dictionary `fun_control`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#| echo: true\n",
        "train, test = load_data()\n",
        "n_samples = len(train)\n",
        "# add the dataset to the fun_control\n",
        "fun_control.update({\n",
        "    \"train\": train,\n",
        "    \"test\": test,\n",
        "    \"n_samples\": n_samples})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specification of the Preprocessing Model {#sec-specification-of-preprocessing-model}\n",
        "\n",
        "After the training and test data are specified and added to the `fun_control` dictionary, `spotPython` allows the specification of a data preprocessing pipeline, e.g., for the scaling of the data or for the one-hot encoding of categorical variables. The preprocessing model is called `prep_model` (\"preparation\" or pre-processing) and includes steps that are not subject to the hyperparameter tuning process. The preprocessing model is specified in the `fun_control` dictionary. The preprocessing model can be implemented as a `sklearn` pipeline. The following code shows a typical preprocessing pipeline:\n",
        "\n",
        "```{raw}\n",
        "categorical_columns = [\"cities\", \"colors\"]\n",
        "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\",\n",
        "                                    sparse_output=False)\n",
        "prep_model = ColumnTransformer(\n",
        "        transformers=[\n",
        "             (\"categorical\", one_hot_encoder, categorical_columns),\n",
        "         ],\n",
        "         remainder=StandardScaler(),\n",
        "     )\n",
        "```\n",
        "\n",
        "Because the Ray Tune (`ray[tune]`) hyperparameter tuning as described in @pyto23a does not use a preprocessing model, the preprocessing model is set to `None` here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "prep_model = None\n",
        "fun_control.update({\"prep_model\": prep_model})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select `algorithm` and `core_model_hyper_dict` {#sec-selection-of-the-algorithm}\n",
        "\n",
        "The same neural network model as implemented in the section \"Configurable neural network\" of the `PyTorch` tutorial [@pyto23a] is used here.\n",
        "We will show the implementation from @pyto23a in @sec-implementation-with-raytune first, before the extended implementation with `spotPython` is shown in @sec-implementation-with-spotpython.\n",
        "\n",
        "\n",
        "### Implementing a Configurable Neural Network With Ray Tune{#sec-implementation-with-raytune}\n",
        "\n",
        "We used the same hyperparameters that are implemented as configurable in the `PyTorch` tutorial. We specify the layer sizes, namely `l1` and `l2`, of the fully connected layers:\n",
        "\n",
        "```{raw}\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, l1=120, l2=84):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
        "        self.fc2 = nn.Linear(l1, l2)\n",
        "        self.fc3 = nn.Linear(l2, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "```\n",
        "\n",
        "The learning rate, i.e., `lr`,  of the optimizer is made configurable, too:\n",
        "\n",
        "```{raw}\n",
        "optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
        "```\n",
        "\n",
        "### Implementing a Configurable Neural Network With spotPython {#sec-implementation-with-spotpython}\n",
        "\n",
        "`spotPython` implements a class which is similar to the class described in the `PyTorch` tutorial. The class is called `Net_CIFAR10` and is implemented in the file `netcifar10.py`.\n",
        "\n",
        "```{raw}\n",
        "import spotPython.torch.netcore as netcore\n",
        "class Net_CIFAR10(netcore.Net_Core):\n",
        "    def __init__(self, l1, l2, lr, batch_size, epochs, k_folds, patience):\n",
        "        super(Net_CIFAR10, self).__init__(\n",
        "            lr=lr, batch_size=batch_size, epochs=epochs, k_folds=k_folds,\n",
        "            patience=patience\n",
        "        )\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
        "        self.fc2 = nn.Linear(l1, l2)\n",
        "        self.fc3 = nn.Linear(l2, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "```\n",
        "\n",
        "`Net_CIFAR10` inherits from the class `Net_Core` which is implemented in the file `netcore.py`.  It implements the additional attributes that are common to all neural network models. The attributes are the learning rate `lr`, the batch size `batch_size`, the number of epochs `epochs`, the number of folds `k_folds` for the cross validation, and the patience `patience` for the early stopping. The class `Net_Core` is shown below.\n",
        "\n",
        "```{raw}\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class Net_Core(nn.Module):\n",
        "    def __init__(self, lr, batch_size, epochs, k_folds, patience):\n",
        "        super(Net_Core, self).__init__()\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.k_folds = k_folds\n",
        "        self.patience = patience\n",
        "```\n",
        "\n",
        "### Comparison of the Approach Described in the PyTorch Tutorial With spotPython {#sec-comparison}\n",
        "\n",
        "Comparing the class `Net` from the `PyTorch` tutorial and the class `Net_CIFAR10` from `spotPython`, we see that the class `Net_CIFAR10` has additional attributes and does not inherit from `nn` directly. It adds an additional class, `Net_core`, that takes care of additional attributes that are common to all neural network models, e.g., the learning rate `lr` or the batch size `batch_size`.\n",
        "\n",
        "`spotPython`'s `core_model` implements an instance of the `Net_CIFAR10` class. In addition to the basic neural network model, the `core_model` can use these additional attributes.\n",
        "`spotPython` provides methods for handling these additional attributes to guarantee 100% compatibility with the `PyTorch` classes. The method `add_core_model_to_fun_control` adds the hyperparameters and additional attributes to the `fun_control` dictionary. The method is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "core_model = Net_CIFAR10\n",
        "fun_control = add_core_model_to_fun_control(core_model=core_model,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=TorchHyperDict,\n",
        "                              filename=None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-note}\n",
        "In addition to the class Net from the `PyTorch` tutorial, the class Net_CIFAR10 has additional attributes, e.g.:\n",
        "\n",
        "* learning rate (`lr`),\n",
        "* batch size (`batch_size`),\n",
        "* epochs (`epochs`),\n",
        "* k_folds (`k_folds`), and\n",
        "* early stopping criterion \"patience\" (`patience`)\n",
        "\n",
        "Further attributes can be easily added to the class, e.g., `optimizer` or `loss_function`.\n",
        ":::\n",
        "\n",
        "## The Search Space {#sec-search-space}\n",
        "\n",
        "In @sec-configuring-the-search-space-with-ray-tune, we first describe how to configure the search space with `ray[tune]`  (as shown in @pyto23a) \n",
        "and then how to configure the search space with `spotPython` in @sec-configuring-the-search-space-with-spotpython.\n",
        "\n",
        "### Configuring the Search Space With Ray Tune {#sec-configuring-the-search-space-with-ray-tune}\n",
        "\n",
        " Ray Tune's search space can be configured as follows [@pyto23a]:\n",
        "\n",
        "```{raw}\n",
        "config = {\n",
        "    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
        "    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
        "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "    \"batch_size\": tune.choice([2, 4, 8, 16])\n",
        "}\n",
        "```\n",
        "The ``tune.sample_from()`` function enables the user to define sample\n",
        "methods to obtain hyperparameters. In this example, the ``l1`` and ``l2`` parameters\n",
        "should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.\n",
        "The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,\n",
        "the batch size is a choice between 2, 4, 8, and 16.\n",
        "\n",
        "At each trial, `ray[tune]` will randomly sample a combination of parameters from these\n",
        "search spaces. It will then train a number of models in parallel and find the best\n",
        "performing one among these. `ray[tune]` uses the ``ASHAScheduler`` which will terminate bad\n",
        "performing trials early.\n",
        "\n",
        "### Configuring the Search Space With spotPython {#sec-configuring-the-search-space-with-spotpython}\n",
        "\n",
        "#### The `hyper_dict` Hyperparameters for the Selected Algorithm\n",
        "\n",
        "`spotPython` uses simple `JSON` files for the specification of the hyperparameters.\n",
        "Users can specify their individual  `JSON` files, or they can use the `JSON` files provided by `spotPython`.\n",
        "The `JSON` file for the `core_model` is called `torch_hyper_dict.json`.\n",
        "\n",
        "Each entry in the `JSON` file represents one hyperparameter with the following structure:\n",
        "`type`, `default`, `transform`, `lower`, and `upper`.\n",
        "The corresponding entries for the `Net_CIFAR10` class are shown below.\n",
        "\n",
        "```json\n",
        "{\"Net_CIFAR10\":\n",
        "    {\n",
        "        \"l1\": {\n",
        "            \"type\": \"int\",\n",
        "            \"default\": 5,\n",
        "            \"transform\": \"transform_power_2_int\",\n",
        "            \"lower\": 2,\n",
        "            \"upper\": 9},\n",
        "        \"l2\": {\n",
        "            \"type\": \"int\",\n",
        "            \"default\": 5,\n",
        "            \"transform\": \"transform_power_2_int\",\n",
        "            \"lower\": 2,\n",
        "            \"upper\": 9},\n",
        "        \"lr\": {\n",
        "            \"type\": \"float\",\n",
        "            \"default\": 1e-03,\n",
        "            \"transform\": \"None\",\n",
        "            \"lower\": 1e-05,\n",
        "            \"upper\": 1e-02},\n",
        "        \"batch_size\": {\n",
        "            \"type\": \"int\",\n",
        "            \"default\": 4,\n",
        "            \"transform\": \"transform_power_2_int\",\n",
        "            \"lower\": 1,\n",
        "            \"upper\": 4},\n",
        "        \"epochs\": {\n",
        "            \"type\": \"int\",\n",
        "            \"default\": 3,\n",
        "            \"transform\": \"transform_power_2_int\",\n",
        "            \"lower\": 1,\n",
        "            \"upper\": 4},\n",
        "        \"k_folds\": {\n",
        "            \"type\": \"int\",\n",
        "            \"default\": 2,\n",
        "            \"transform\": \"None\",\n",
        "            \"lower\": 2,\n",
        "            \"upper\": 3},\n",
        "        \"patience\": {\n",
        "            \"type\": \"int\",\n",
        "            \"default\": 5,\n",
        "            \"transform\": \"None\",\n",
        "            \"lower\": 2,\n",
        "            \"upper\": 10},\n",
        "        \"optimizer\": {\n",
        "            \"levels\": [\"Adadelta\",\n",
        "                       \"Adagrad\",\n",
        "                       \"Adam\",\n",
        "                       \"AdamW\",\n",
        "                       \"SparseAdam\",\n",
        "                       \"Adamax\",\n",
        "                       \"ASGD\",\n",
        "                       \"LBFGS\",\n",
        "                       \"NAdam\",\n",
        "                       \"RAdam\",\n",
        "                       \"RMSprop\",\n",
        "                       \"Rprop\",\n",
        "                       \"SGD\"],\n",
        "            \"type\": \"factor\",\n",
        "            \"default\": \"SGD\",\n",
        "            \"transform\": \"None\",\n",
        "            \"class_name\": \"torch.optim\",\n",
        "            \"core_model_parameter_type\": \"str\",\n",
        "            \"lower\": 0,\n",
        "            \"upper\": 12},\n",
        "        \"criterion\": {\n",
        "            \"levels\": [\"L1Loss\",\n",
        "                       \"MSELoss\",\n",
        "                       \"CrossEntropyLoss\",\n",
        "                       \"CTCLoss\",\n",
        "                       \"NLLLoss\",\n",
        "                       \"PoissonNLLLoss\",\n",
        "                       \"GaussianNLLLoss\",\n",
        "                       \"KLDivLoss\",\n",
        "                       \"BCELoss\",\n",
        "                       \"BCEWithLogitsLoss\",\n",
        "                       \"MarginRankingLoss\",\n",
        "                       \"HingeEmbeddingLoss\",\n",
        "                       \"MultiLabelMarginLoss\",\n",
        "                       \"HuberLoss\",\n",
        "                       \"SmoothL1Loss\",\n",
        "                       \"SoftMarginLoss\",\n",
        "                       \"MultiLabelSoftMarginLoss\",\n",
        "                       \"CosineEmbeddingLoss\",\n",
        "                       \"MultiMarginLoss\",\n",
        "                       \"TripletMarginLoss\",\n",
        "                       \"TripletMarginWithDistanceLoss\"],\n",
        "            \"type\": \"factor\",\n",
        "            \"default\": \"CrossEntropyLoss\",\n",
        "            \"transform\": \"None\",\n",
        "            \"class_name\": \"torch.nn\",\n",
        "            \"core_model_parameter_type\": \"instance()\",\n",
        "            \"lower\": 0,\n",
        "            \"upper\": 20}\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "#### Categorical Hyperparameters\n",
        "\n",
        "In contrast to `ray[tune]`, `spotPython` can handle numerical, boolean, and categorical hyperparameters. Since `ray[tune]` does not tune categorical hyperparameters, they are not used here. However, they can be specified in the `JSON` file in a similar way as the numerical hyperparameters as shown below:\n",
        "\n",
        "```json\n",
        "\"factor_hyperparameter\": {\n",
        "    \"levels\": [\"A\", \"B\", \"C\"],\n",
        "    \"type\": \"factor\",\n",
        "    \"default\": \"B\",\n",
        "    \"transform\": \"None\",\n",
        "    \"core_model_parameter_type\": \"str\",\n",
        "    \"lower\": 0,\n",
        "    \"upper\": 2},\n",
        "```\n",
        "\n",
        "## Modifying the Hyperparameters {#sec-modification-of-hyperparameters}\n",
        "\n",
        "Ray tune [@pyto23a] does not provide a way to change the specified hyperparameters without re-compilation. However, `spotPython` provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions are described in the following.\n",
        "\n",
        "### Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model` {#sec-modification-of-default-values}\n",
        "\n",
        "After specifying the model, the corresponding hyperparameters, their types and bounds are loaded from the `JSON` file `torch_hyper_dict.json`. After loading, the user can modify the hyperparameters, e.g., the bounds.\n",
        "`spotPython` provides a simple rule for de-activating hyperparameters: If the lower and the upper bound are set to identical values, the hyperparameter is de-activated. This is useful for the hyperparameter tuning, because it allows to specify a hyperparameter in the `JSON` file, but to de-activate it in the `fun_control` dictionary. This is done in the next step.\n",
        "\n",
        "\n",
        "### Modify Hyperparameters of Type numeric and integer (boolean)\n",
        "\n",
        "Since the hyperparameter `k_folds` is not used in the `PyTorch` tutorial, it is de-activated here by setting the lower and upper bound to the same value. Note, `k_folds` is of type \"integer\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'l1': {'type': 'int',\n",
              "  'default': 5,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 2,\n",
              "  'upper': 9},\n",
              " 'l2': {'type': 'int',\n",
              "  'default': 5,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 2,\n",
              "  'upper': 9},\n",
              " 'lr': {'type': 'float',\n",
              "  'default': 0.001,\n",
              "  'transform': 'None',\n",
              "  'lower': 1e-05,\n",
              "  'upper': 0.01},\n",
              " 'batch_size': {'type': 'int',\n",
              "  'default': 4,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 1,\n",
              "  'upper': 5},\n",
              " 'epochs': {'type': 'int',\n",
              "  'default': 3,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 3,\n",
              "  'upper': 4},\n",
              " 'k_folds': {'type': 'int',\n",
              "  'default': 2,\n",
              "  'transform': 'None',\n",
              "  'lower': 0,\n",
              "  'upper': 0},\n",
              " 'patience': {'type': 'int',\n",
              "  'default': 5,\n",
              "  'transform': 'None',\n",
              "  'lower': 3,\n",
              "  'upper': 3},\n",
              " 'optimizer': {'levels': ['Adadelta',\n",
              "   'Adagrad',\n",
              "   'Adam',\n",
              "   'AdamW',\n",
              "   'SparseAdam',\n",
              "   'Adamax',\n",
              "   'ASGD',\n",
              "   'LBFGS',\n",
              "   'NAdam',\n",
              "   'RAdam',\n",
              "   'RMSprop',\n",
              "   'Rprop',\n",
              "   'SGD'],\n",
              "  'type': 'factor',\n",
              "  'default': 'SGD',\n",
              "  'transform': 'None',\n",
              "  'class_name': 'torch.optim',\n",
              "  'core_model_parameter_type': 'str',\n",
              "  'lower': 0,\n",
              "  'upper': 12},\n",
              " 'criterion': {'levels': ['L1Loss',\n",
              "   'MSELoss',\n",
              "   'CrossEntropyLoss',\n",
              "   'CTCLoss',\n",
              "   'NLLLoss',\n",
              "   'PoissonNLLLoss',\n",
              "   'GaussianNLLLoss',\n",
              "   'KLDivLoss',\n",
              "   'BCELoss',\n",
              "   'BCEWithLogitsLoss',\n",
              "   'MarginRankingLoss',\n",
              "   'HingeEmbeddingLoss',\n",
              "   'MultiLabelMarginLoss',\n",
              "   'HuberLoss',\n",
              "   'SmoothL1Loss',\n",
              "   'SoftMarginLoss',\n",
              "   'MultiLabelSoftMarginLoss',\n",
              "   'CosineEmbeddingLoss',\n",
              "   'MultiMarginLoss',\n",
              "   'TripletMarginLoss',\n",
              "   'TripletMarginWithDistanceLoss'],\n",
              "  'type': 'factor',\n",
              "  'default': 'CrossEntropyLoss',\n",
              "  'transform': 'None',\n",
              "  'class_name': 'torch.nn',\n",
              "  'core_model_parameter_type': 'instance()',\n",
              "  'lower': 0,\n",
              "  'upper': 20}}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#| echo: true\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"batch_size\", bounds=[2, 6])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"k_folds\", bounds=[0, 0])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"patience\", bounds=[3, 3])\n",
        "fun_control[\"core_model_hyper_dict\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modify Hyperparameter of Type factor\n",
        "\n",
        "In a similar manner as for the numerical hyperparameters, the categorical hyperparameters can be modified.\n",
        "New configurations can be chosen by adding or deleting levels. For example, the hyperparameter `optimizer` can be re-configured as follows:\n",
        "\n",
        "In the following setting, two optimizers (`\"SGD\"` and `\"Adam\"`) will be compared during the `spotPython` hyperparameter tuning. The hyperparameter `optimizer` is active."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\", [\"SGD\", \"Adam\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The hyperparameter `optimizer` can be de-activated by choosing only one value (level), here: `\"SGD\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\", [\"SGD\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* As discussed in @sec-optimizers, there are some issues with the LBFGS optimizer. Therefore, the usage of the LBFGS optimizer is not  deactivated in `spotPython` by default. However, the LBFGS optimizer can be activated by adding it to the list of optimizers.\n",
        "* Rprop  was remmoved, because it does perform very poorly (as some pre-tests have shown). However, it can also be activated by adding it to the list of optimizers.\n",
        "* Therefore, there are elevendefault optimizers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "# fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adadelta\",\n",
        "#      \"Adagrad\", \"Adam\", \"AdamW\", \"Adamax\", \"ASGD\", \"NAdam\", \"RAdam\",\n",
        "#       \"RMSprop\", \"SGD\"])\n",
        "fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"AdamW\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizers {#sec-optimizers}\n",
        "\n",
        "@tbl-optimizers shows some of the optimizers available in `PyTorch`:\n",
        "\n",
        "| Optimizer | lr  | mom | weight | damp | nest | rho | lr_sc | lr_decay | betas |\n",
        "| :----- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :---| :---- |\n",
        "| SGD | required | float: 0 | float: 0 | float: 0 | bool: False | - | -| -| -|\n",
        "| Adadelta | - | - | float: 0 | - | - | float: 0.9 | float: 1.0| - | -|\n",
        "| Adagrad | float: 1e-2 | - | float: 0 | - | - | - | - | float: 0  | -|\n",
        "| Adam | float: 1e-3 | - | float: 0 | - | - | - | - | -| Tuple[float, float]: (0.9, 0.999) |\n",
        "| AdamW | float: 1e-3 | - | float: 1e-2 | - | - | - | - | -| Tuple[float, float]: (0.9, 0.999) |\n",
        "| SparseAdam | float: 1e-3 | - | - | - | - | - | - | -| Tuple[float, float]: (0.9, 0.999) |\n",
        "\n",
        ": Optimizers available in PyTorch (selection). \"mom\" denotes `momentum`, \"weight\" `weight_decay`, \"damp\" `dampening`, \"nest\" `nesterov`, and  \"lr_sc\" `learning rate for scaling delta`.  The default values are shown in the table. {#tbl-optimizers}\n",
        "\n",
        "`spotPython` implements an `optimization` handler that maps the optimizer names to the corresponding `PyTorch` optimizers.\n",
        "\n",
        "::: {.callout-note}\n",
        "### A note on LBFGS\n",
        "\n",
        "`PyTorch`'s LBFGS optimizer is deactivated in `spotPython` by default, because it does not perform very well. The  `PyTorch` documentation, see [https://pytorch.org/docs/stable/generated/torch.optim.LBFGS.html#torch.optim.LBFGS](https://pytorch.org/docs/stable/generated/torch.optim.LBFGS.html#torch.optim.LBFGS), states:\n",
        "\n",
        "> This is a very memory intensive optimizer (it requires additional `param_bytes * (history_size + 1)` bytes). If it doesn’t fit in memory try reducing the history size, or use a different algorithm.\n",
        "\n",
        "\n",
        "Furthermore, the LBFGS optimizer is not compatible with the `PyTorch` tutorial. The reason is that the LBFGS optimizer requires the `closure` function, which is not implemented in the `PyTorch` tutorial. Therefore, the `LBFGS` optimizer is recommended here.\n",
        ":::\n",
        "\n",
        "Since there are 10 optimizers in the portfolio, it is not recommended tuning the hyperparameters that effect one single optimizer only.\n",
        "Thus, the learning rate, which affects only the `SGD` optimizer, will be set to a fixed value. We choose the default value of `1e-3` for the learning rate, because this value can befound in `PyTorch` examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"lr\", bounds=[1e-3, 1e-3])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation  {#sec-selection-of-target-function}\n",
        "\n",
        "The evaluation procedure requires the specification of two elements:\n",
        "\n",
        "1. the way how the data is split into a train and a test set and\n",
        "2. the loss function (and a metric).\n",
        "\n",
        "### Hold-out Data Split and Cross-Validation\n",
        "\n",
        "As a default, `spotPython` provides a standard hold-out data split and cross validation.\n",
        "\n",
        "#### Hold-out Data Split\n",
        "\n",
        "If a hold-out data split is used, the data will be partitioned into a training, a validation, and a test data set.\n",
        "The split depends on the setting of the `eval` parameter. If `eval` is set to `train_hold_out`, one data set, usually the original training data set, is split into a new training and a validation data set. The training data set is used for training the model. The validation data set is used for the evaluation of the hyperparameter configuration and early stopping to prevent overfitting. In this case, the original test data set is not used.\n",
        "The following splits are performed in the hold-out setting:\n",
        "$\\{\\text{train}_0, \\text{test}\\} \\rightarrow \\{\\text{train}_1, \\text{validation}_1, \\text{test}\\}$, where $\\text{train}_1 \\cup \\text{validation}_1 = \\text{train}_0$.\n",
        "\n",
        "\n",
        "::: {.callout-note}\n",
        "`spotPython` returns the hyperparameters of the machine learning and deep learning models, e.g., number of layers, learning rate, or optimizer, but not the model weights. Therefore, after the SPOT run is finished, the corresponding model has to be trained again with the best hyperparameter configuration. The training is performed on the training data set. The test data set is used for the final evaluation of the model.\n",
        "\n",
        "Summarizing, the following splits are performed in the hold-out setting:\n",
        "\n",
        "1. Run `spotPython` with `eval` set to `train_hold_out` to determine the best hyperparameter configuration.\n",
        "2. Train the model with the best hyperparameter configuration on the training data set:\n",
        "   * `train_save(model_spot, train, \"model_spot.pt\")`.\n",
        "3. Test the model on the test data:\n",
        "   * `test_saved(model_spot, test, \"model_spot.pt\")`\n",
        "\n",
        "These steps will be exemplified in the following sections.\n",
        ":::\n",
        "\n",
        "In addition to this `hold-out` setting, `spotPython` provides another hold-out setting, where an explicit test data is specified by the user that will be used as the validation set. To choose this option, the `eval` parameter is set to `test_hold_out`. In this case, the training data set is used for the model training. Then, the explicitly defined test data set is used for the evaluation of the hyperparameter configuration (the validation).\n",
        "\n",
        "#### Cross-Validation\n",
        "\n",
        "The cross validation setting is used by setting the `eval` parameter to `train_cv` or `test_cv`. In both  cases, the data set is split into $k$ folds. The model is trained on $k-1$ folds and evaluated on the remaining fold. This is repeated $k$ times, so that each fold is used exactly once for evaluation. The final evaluation is performed on the test data set. The cross validation setting is useful for small data sets, because it allows to use all data for training and evaluation. However, it is computationally expensive, because the model has to be trained $k$ times.\n",
        "\n",
        "::: {.callout-note}\n",
        "Combinations of the above settings are possible, e.g., cross validation can be used for training and hold-out for evaluation or \\emph{vice versa}. Also, cross validation can be used for training and testing. Because cross validation is not used in the `PyTorch` tutorial [@pyto23a], it is not considered further here.\n",
        ":::\n",
        "\n",
        "### Loss Functions and Metrics\n",
        "\n",
        "The key `\"criterion\"` specifies the loss function which is used during the optimization. There are several different loss functions under `PyTorch`'s nn package. For example, a simple loss is `MSELoss`, which computes the mean-squared error between the output and the target. In this tutorial we will use `CrossEntropyLoss`, because it is also used in the `PyTorch` tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "fun_control = modify_hyper_parameter_levels(fun_control, \"criterion\", [\"CrossEntropyLoss\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition to the loss function, `spotPython` provides access to a large number of metrics. The key `\"metric_sklearn\"` is used for metrics that follow the `scikit-learn` conventions^[The key `\"metric\"` is used for the river based evaluation [@mont20a] via `eval_oml_iter_progressive`.].\n",
        "Because the `PyTorch` tutorial uses the accuracy as metric, we use the same metric here. Currently, accuracy is computed in the tutorial's example code. Therefore, we will use the same implementation here and set the key `\"metric_sklearn\"` to `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "weights = 1.0\n",
        "criterion = CrossEntropyLoss\n",
        "shuffle = True\n",
        "eval = \"train_hold_out\"\n",
        "device = DEVICE\n",
        "show_batch_interval = 100_000\n",
        "save_model = True\n",
        "path=\"torch_model.pt\"\n",
        "\n",
        "fun_control.update({\n",
        "               \"data_dir\": None,\n",
        "               \"checkpoint_dir\": None,\n",
        "               \"horizon\": None,\n",
        "               \"oml_grace_period\": None,\n",
        "               \"weights\": weights,\n",
        "               \"step\": None,\n",
        "               \"log_level\": 50,\n",
        "               \"weight_coeff\": None,\n",
        "               \"metric\": None,\n",
        "               \"metric_sklearn\": None,\n",
        "               \"criterion\": criterion,\n",
        "               \"shuffle\": shuffle,\n",
        "               \"eval\": eval,\n",
        "               \"device\": device,\n",
        "               \"show_batch_interval\": show_batch_interval,\n",
        "               \"save_model\": save_model,\n",
        "               \"path\": path,\n",
        "               })"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling the SPOT Function {#sec-call-the-hyperparameter-tuner}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "var_type = get_var_type(fun_control)\n",
        "var_name = get_var_name(fun_control)\n",
        "fun_control.update({\"var_type\": var_type,\n",
        "                    \"var_name\": var_name})\n",
        "\n",
        "lower = get_bound_values(fun_control, \"lower\")\n",
        "upper = get_bound_values(fun_control, \"upper\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the dictionary `fun_control` contains all information needed for the hyperparameter tuning. Before the hyperparameter tuning is started, it is recommended to take a look at the experimental design. The method `gen_design_table` generates a design table as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| name       | type   | default          |   lower |   upper | transform             |\n",
            "|------------|--------|------------------|---------|---------|-----------------------|\n",
            "| l1         | int    | 5                |   2     |   9     | transform_power_2_int |\n",
            "| l2         | int    | 5                |   2     |   9     | transform_power_2_int |\n",
            "| lr         | float  | 0.001            |   0.001 |   0.001 | None                  |\n",
            "| batch_size | int    | 4                |   1     |   5     | transform_power_2_int |\n",
            "| epochs     | int    | 3                |   3     |   4     | transform_power_2_int |\n",
            "| k_folds    | int    | 2                |   0     |   0     | None                  |\n",
            "| patience   | int    | 5                |   3     |   3     | None                  |\n",
            "| optimizer  | factor | SGD              |   0     |   9     | None                  |\n",
            "| criterion  | factor | CrossEntropyLoss |   0     |   0     | None                  |\n"
          ]
        }
      ],
      "source": [
        "#| echo: true\n",
        "print(gen_design_table(fun_control))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows to check if all information is available and if the information is correct.  @tbl-design shows the experimental design for the hyperparameter tuning. Hyperparameter transformations are shown in the column \"transform\", e.g., the `l1` default is `5`, which results in the value $2^5 = 32$ for the network, because the transformation ` transform_power_2_int` was selected in the `JSON` file. The default value of the `batch_size` is set to `4`, which results in a batch size of $2^4 = 16$. \n",
        "\n",
        "\n",
        "| name       | type   |   default |   lower |   upper | transform             |\n",
        "|------------|--------|-----------|---------|---------|-----------------------|\n",
        "| l1         | int    |     5     |   2     |    9    | transform_power_2_int |\n",
        "| l2         | int    |     5     |   2     |    9    | transform_power_2_int |\n",
        "| lr         | float  |     0.001 |   1e-05 |    0.01 | None                  |\n",
        "| batch_size | int    |     4     |   1     |    4    | transform_power_2_int |\n",
        "| epochs     | int    |     3     |   3     |    4    | transform_power_2_int |\n",
        "| k_folds    | int    |     2     |   0     |    0    | None                  |\n",
        ": Experimental design for the hyperparameter tuning. The table shows the hyperparameters, their types, default values, lower and upper bounds, and the transformation function. The transformation function is used to transform the hyperparameter values from the unit hypercube to the original domain. The transformation function is applied to the hyperparameter values before the evaluation of the objective function. {#tbl-design}\n",
        "\n",
        "The objective function `fun_torch` is selected next. It implements an interface from `PyTorch`'s training, validation, and  testing methods to `spotPython`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "fun = HyperTorch().fun_torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "hyper_dict=TorchHyperDict().load()\n",
        "X_start = get_default_hyperparameters_as_array(fun_control, hyper_dict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `spotPython` hyperparameter tuning is started by calling the `Spot` function. Here, we will run the tuner for  approx. 30 minutes (`max_time`). Note: the initial design is always evaluated in the `spotPython` run. As a consequence, the run may take longer than specified by `max_time`, because the evaluation time of initial design (here: `init_size`, 10 points) is performed independently of `max_time`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config: {'l1': 64, 'l2': 4, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.2983577991485595\n",
            "Accuracy on hold-out set: 0.10405\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.1567685312271117\n",
            "Accuracy on hold-out set: 0.21615\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.9299195732116698\n",
            "Accuracy on hold-out set: 0.28525\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.8131203311920165\n",
            "Accuracy on hold-out set: 0.31745\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.7423552231788635\n",
            "Accuracy on hold-out set: 0.34525\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.7086950478553773\n",
            "Accuracy on hold-out set: 0.3586\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6748702821731567\n",
            "Accuracy on hold-out set: 0.3674\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.671311504173279\n",
            "Accuracy on hold-out set: 0.367\n",
            "Returned to Spot: Validation loss: 1.671311504173279\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8832208382606506\n",
            "Accuracy on hold-out set: 0.32545\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.717071324300766\n",
            "Accuracy on hold-out set: 0.38095\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6282705089330674\n",
            "Accuracy on hold-out set: 0.40735\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5887550284147263\n",
            "Accuracy on hold-out set: 0.42315\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5455750832557678\n",
            "Accuracy on hold-out set: 0.44065\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.499717956495285\n",
            "Accuracy on hold-out set: 0.4605\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4784291104316711\n",
            "Accuracy on hold-out set: 0.4679\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.466477780151367\n",
            "Accuracy on hold-out set: 0.4712\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4337593653678895\n",
            "Accuracy on hold-out set: 0.48175\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4132916261553765\n",
            "Accuracy on hold-out set: 0.4884\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4088016750335692\n",
            "Accuracy on hold-out set: 0.49155\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3750838848471643\n",
            "Accuracy on hold-out set: 0.5026\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3565564108848571\n",
            "Accuracy on hold-out set: 0.5093\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.354980772435665\n",
            "Accuracy on hold-out set: 0.51015\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3254225546956062\n",
            "Accuracy on hold-out set: 0.5238\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3226806262373925\n",
            "Accuracy on hold-out set: 0.5248\n",
            "Returned to Spot: Validation loss: 1.3226806262373925\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.669948266506195\n",
            "Accuracy on hold-out set: 0.39135\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.571463303899765\n",
            "Accuracy on hold-out set: 0.42225\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.53710410656929\n",
            "Accuracy on hold-out set: 0.44055\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4869047020077706\n",
            "Accuracy on hold-out set: 0.45525\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4761373908758164\n",
            "Accuracy on hold-out set: 0.46385\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.454692794215679\n",
            "Accuracy on hold-out set: 0.46795\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4443676631093025\n",
            "Accuracy on hold-out set: 0.47665\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4172692937374114\n",
            "Accuracy on hold-out set: 0.4871\n",
            "Returned to Spot: Validation loss: 1.4172692937374114\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 512, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.2990729619503023\n",
            "Accuracy on hold-out set: 0.147\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.1699638729810715\n",
            "Accuracy on hold-out set: 0.20255\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.062737582349777\n",
            "Accuracy on hold-out set: 0.23975\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.024315212368965\n",
            "Accuracy on hold-out set: 0.25755\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.9975606794476508\n",
            "Accuracy on hold-out set: 0.2622\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.9791268317818642\n",
            "Accuracy on hold-out set: 0.27075\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.954011361193657\n",
            "Accuracy on hold-out set: 0.2827\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.9340372748017312\n",
            "Accuracy on hold-out set: 0.29235\n",
            "Returned to Spot: Validation loss: 1.9340372748017312\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 256, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.437789361000061\n",
            "Accuracy on hold-out set: 0.47305\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4048106864690781\n",
            "Accuracy on hold-out set: 0.50575\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.278214559841156\n",
            "Accuracy on hold-out set: 0.5551\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1818874956250192\n",
            "Accuracy on hold-out set: 0.591\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.221595850163698\n",
            "Accuracy on hold-out set: 0.5884\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2470656012535095\n",
            "Accuracy on hold-out set: 0.59465\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3040651526749134\n",
            "Accuracy on hold-out set: 0.59365\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.3040651526749134\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5626877600193023\n",
            "Accuracy on hold-out set: 0.4281\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3953992209911346\n",
            "Accuracy on hold-out set: 0.4833\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.315219264793396\n",
            "Accuracy on hold-out set: 0.52315\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.30589350566864\n",
            "Accuracy on hold-out set: 0.52665\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2717465675354005\n",
            "Accuracy on hold-out set: 0.5455\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2484766639232636\n",
            "Accuracy on hold-out set: 0.5503\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2436718111038207\n",
            "Accuracy on hold-out set: 0.55245\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2322412220478058\n",
            "Accuracy on hold-out set: 0.5648\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2437351568698882\n",
            "Accuracy on hold-out set: 0.55985\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2302148260831833\n",
            "Accuracy on hold-out set: 0.56285\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.225363118338585\n",
            "Accuracy on hold-out set: 0.56615\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.200543662261963\n",
            "Accuracy on hold-out set: 0.577\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.213534329366684\n",
            "Accuracy on hold-out set: 0.5746\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.196524969792366\n",
            "Accuracy on hold-out set: 0.5807\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.238475696325302\n",
            "Accuracy on hold-out set: 0.57515\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2026273607492446\n",
            "Accuracy on hold-out set: 0.5771\n",
            "Returned to Spot: Validation loss: 1.2026273607492446\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9668772798538208\n",
            "Accuracy on hold-out set: 0.28525\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8577896158218383\n",
            "Accuracy on hold-out set: 0.313\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7630833374023438\n",
            "Accuracy on hold-out set: 0.34075\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6855943316459656\n",
            "Accuracy on hold-out set: 0.36245\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6551119511604309\n",
            "Accuracy on hold-out set: 0.38\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6046305515766144\n",
            "Accuracy on hold-out set: 0.40245\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.563162168931961\n",
            "Accuracy on hold-out set: 0.42065\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5287309916496277\n",
            "Accuracy on hold-out set: 0.43245\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.532503964996338\n",
            "Accuracy on hold-out set: 0.4386\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4791584878444672\n",
            "Accuracy on hold-out set: 0.45655\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4619411540985108\n",
            "Accuracy on hold-out set: 0.472\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4356756623268128\n",
            "Accuracy on hold-out set: 0.4776\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4215805006027222\n",
            "Accuracy on hold-out set: 0.48515\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.4075729373931885\n",
            "Accuracy on hold-out set: 0.49345\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3894636637687683\n",
            "Accuracy on hold-out set: 0.49525\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.371904292154312\n",
            "Accuracy on hold-out set: 0.50285\n",
            "Returned to Spot: Validation loss: 1.371904292154312\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5094759210109712\n",
            "Accuracy on hold-out set: 0.44495\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4850806858778\n",
            "Accuracy on hold-out set: 0.49165\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2310760144233703\n",
            "Accuracy on hold-out set: 0.5598\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.184697996377945\n",
            "Accuracy on hold-out set: 0.58695\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1568939247131347\n",
            "Accuracy on hold-out set: 0.6036\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1416924013018608\n",
            "Accuracy on hold-out set: 0.60905\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1872494555950164\n",
            "Accuracy on hold-out set: 0.6145\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3103908315896988\n",
            "Accuracy on hold-out set: 0.5981\n",
            "Returned to Spot: Validation loss: 1.3103908315896988\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5419036787986755\n",
            "Accuracy on hold-out set: 0.43595\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3864810990810394\n",
            "Accuracy on hold-out set: 0.50255\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3126890885829925\n",
            "Accuracy on hold-out set: 0.53095\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2971822461605071\n",
            "Accuracy on hold-out set: 0.53645\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.214594244146347\n",
            "Accuracy on hold-out set: 0.57175\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1987267726421356\n",
            "Accuracy on hold-out set: 0.57835\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2095292830228805\n",
            "Accuracy on hold-out set: 0.57565\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.181831344819069\n",
            "Accuracy on hold-out set: 0.5878\n",
            "Returned to Spot: Validation loss: 1.181831344819069\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6494682323455812\n",
            "Accuracy on hold-out set: 0.39705\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.738130860569328\n",
            "Accuracy on hold-out set: 0.4625\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.52015931212008\n",
            "Accuracy on hold-out set: 0.487\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4816793703131377\n",
            "Accuracy on hold-out set: 0.5046\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.679849727286538\n",
            "Accuracy on hold-out set: 0.50165\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.7815948612845502\n",
            "Accuracy on hold-out set: 0.5082\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6336544196530827\n",
            "Accuracy on hold-out set: 0.51665\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.6336544196530827\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6717370664596558\n",
            "Accuracy on hold-out set: 0.36415\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4866238701343537\n",
            "Accuracy on hold-out set: 0.4499\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4135481592655181\n",
            "Accuracy on hold-out set: 0.48475\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3779676593899728\n",
            "Accuracy on hold-out set: 0.50235\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3759283873796464\n",
            "Accuracy on hold-out set: 0.49755\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3205174425959587\n",
            "Accuracy on hold-out set: 0.5264\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3249424063682556\n",
            "Accuracy on hold-out set: 0.5313\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.290414464557171\n",
            "Accuracy on hold-out set: 0.543\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2455240445017814\n",
            "Accuracy on hold-out set: 0.55515\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2417927728056908\n",
            "Accuracy on hold-out set: 0.566\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2515501942098142\n",
            "Accuracy on hold-out set: 0.56615\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2326483524441718\n",
            "Accuracy on hold-out set: 0.56815\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2115571711421014\n",
            "Accuracy on hold-out set: 0.5779\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2064474373757839\n",
            "Accuracy on hold-out set: 0.57935\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.189885093986988\n",
            "Accuracy on hold-out set: 0.58875\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2144700831830502\n",
            "Accuracy on hold-out set: 0.5817\n",
            "Returned to Spot: Validation loss: 1.2144700831830502\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4137623273074627\n",
            "Accuracy on hold-out set: 0.4926\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3781363287344575\n",
            "Accuracy on hold-out set: 0.5257\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2862425641976296\n",
            "Accuracy on hold-out set: 0.55455\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3064324400284328\n",
            "Accuracy on hold-out set: 0.565\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.274086302588787\n",
            "Accuracy on hold-out set: 0.5899\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2897798860762268\n",
            "Accuracy on hold-out set: 0.5758\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2974679424433504\n",
            "Accuracy on hold-out set: 0.5919\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3405632294198964\n",
            "Accuracy on hold-out set: 0.5857\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.3405632294198964\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3060291149139402\n",
            "Accuracy on hold-out set: 0.0987\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.304549039697647\n",
            "Accuracy on hold-out set: 0.1014\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3049653764724733\n",
            "Accuracy on hold-out set: 0.1\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.306854474925995\n",
            "Accuracy on hold-out set: 0.10065\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.306141357088089\n",
            "Accuracy on hold-out set: 0.09865\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 2.306141357088089\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6919753141403198\n",
            "Accuracy on hold-out set: 0.3746\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.548011100769043\n",
            "Accuracy on hold-out set: 0.43715\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.404309432029724\n",
            "Accuracy on hold-out set: 0.4858\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3538773962020874\n",
            "Accuracy on hold-out set: 0.50815\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2871802872657776\n",
            "Accuracy on hold-out set: 0.5331\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2414953103065491\n",
            "Accuracy on hold-out set: 0.5554\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2196207654953002\n",
            "Accuracy on hold-out set: 0.5694\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1899475155830384\n",
            "Accuracy on hold-out set: 0.5777\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1838695593833923\n",
            "Accuracy on hold-out set: 0.57895\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1511762293815613\n",
            "Accuracy on hold-out set: 0.59365\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2003632186889648\n",
            "Accuracy on hold-out set: 0.58215\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1616100023269653\n",
            "Accuracy on hold-out set: 0.5947\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1557198293685913\n",
            "Accuracy on hold-out set: 0.59715\n",
            "Early stopping at epoch 12\n",
            "Returned to Spot: Validation loss: 1.1557198293685913\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6224788418528624\n",
            "Accuracy on hold-out set: 0.4411\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5478726285333206\n",
            "Accuracy on hold-out set: 0.4992\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3202436261489885\n",
            "Accuracy on hold-out set: 0.5642\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5251931627253448\n",
            "Accuracy on hold-out set: 0.55775\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3939179296471425\n",
            "Accuracy on hold-out set: 0.57565\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3815186695398056\n",
            "Accuracy on hold-out set: 0.58905\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.3815186695398056\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5104104339033366\n",
            "Accuracy on hold-out set: 0.4586\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4117543895989657\n",
            "Accuracy on hold-out set: 0.4961\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3565442236155272\n",
            "Accuracy on hold-out set: 0.52185\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.31768243188709\n",
            "Accuracy on hold-out set: 0.5387\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3091985312387346\n",
            "Accuracy on hold-out set: 0.54125\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2555522933579981\n",
            "Accuracy on hold-out set: 0.56075\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2454604442477226\n",
            "Accuracy on hold-out set: 0.56595\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2362945124603808\n",
            "Accuracy on hold-out set: 0.5709\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2286202590212225\n",
            "Accuracy on hold-out set: 0.5786\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.220121693086624\n",
            "Accuracy on hold-out set: 0.5804\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2143816263586282\n",
            "Accuracy on hold-out set: 0.5835\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2173574209161102\n",
            "Accuracy on hold-out set: 0.58215\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2013658104836942\n",
            "Accuracy on hold-out set: 0.59205\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1950496380642057\n",
            "Accuracy on hold-out set: 0.5953\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2103713767776265\n",
            "Accuracy on hold-out set: 0.5907\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2000089558571576\n",
            "Accuracy on hold-out set: 0.59415\n",
            "Returned to Spot: Validation loss: 1.2000089558571576\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6365089490794578\n",
            "Accuracy on hold-out set: 0.40405\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6079792756872484\n",
            "Accuracy on hold-out set: 0.4731\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.608817174527538\n",
            "Accuracy on hold-out set: 0.4675\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5384178499158587\n",
            "Accuracy on hold-out set: 0.46385\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5147430880743544\n",
            "Accuracy on hold-out set: 0.5042\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4646843495629087\n",
            "Accuracy on hold-out set: 0.51205\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.557576138274937\n",
            "Accuracy on hold-out set: 0.51425\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5105888501133118\n",
            "Accuracy on hold-out set: 0.512\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4569266566186347\n",
            "Accuracy on hold-out set: 0.5269\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4872719574756734\n",
            "Accuracy on hold-out set: 0.529\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.5162926299819004\n",
            "Accuracy on hold-out set: 0.5202\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.5078460736438923\n",
            "Accuracy on hold-out set: 0.52615\n",
            "Early stopping at epoch 11\n",
            "Returned to Spot: Validation loss: 1.5078460736438923\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.30470849609375\n",
            "Accuracy on hold-out set: 0.1001\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.304693450164795\n",
            "Accuracy on hold-out set: 0.0955\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.305372445297241\n",
            "Accuracy on hold-out set: 0.0955\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.304584057998657\n",
            "Accuracy on hold-out set: 0.0995\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.304323984527588\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.303558890914917\n",
            "Accuracy on hold-out set: 0.1013\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.303919938659668\n",
            "Accuracy on hold-out set: 0.1001\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.304766309738159\n",
            "Accuracy on hold-out set: 0.1038\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.30634944190979\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 2.30634944190979\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 256, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6240149542570115\n",
            "Accuracy on hold-out set: 0.3869\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4628592076659201\n",
            "Accuracy on hold-out set: 0.4651\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3703558236718179\n",
            "Accuracy on hold-out set: 0.50035\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4024884194374085\n",
            "Accuracy on hold-out set: 0.4883\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2907560227870942\n",
            "Accuracy on hold-out set: 0.52535\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3010814958930015\n",
            "Accuracy on hold-out set: 0.53025\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3130836503386498\n",
            "Accuracy on hold-out set: 0.52205\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2699353729605676\n",
            "Accuracy on hold-out set: 0.53835\n",
            "Returned to Spot: Validation loss: 1.2699353729605676\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5796976751327514\n",
            "Accuracy on hold-out set: 0.41705\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4668410574913024\n",
            "Accuracy on hold-out set: 0.46615\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3911244917869567\n",
            "Accuracy on hold-out set: 0.50295\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3239515108466149\n",
            "Accuracy on hold-out set: 0.53255\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.394291822808981\n",
            "Accuracy on hold-out set: 0.51345\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.271552777093649\n",
            "Accuracy on hold-out set: 0.55375\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3624063754975795\n",
            "Accuracy on hold-out set: 0.5252\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.249595324808359\n",
            "Accuracy on hold-out set: 0.56045\n",
            "Returned to Spot: Validation loss: 1.249595324808359\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 4, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9834689756393433\n",
            "Accuracy on hold-out set: 0.2045\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.9082238470077515\n",
            "Accuracy on hold-out set: 0.21625\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.9591743143081666\n",
            "Accuracy on hold-out set: 0.2365\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.8559566041946411\n",
            "Accuracy on hold-out set: 0.25865\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.863761748123169\n",
            "Accuracy on hold-out set: 0.26915\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.8167344873428344\n",
            "Accuracy on hold-out set: 0.2617\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.8903365486145018\n",
            "Accuracy on hold-out set: 0.27835\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.8067121061325073\n",
            "Accuracy on hold-out set: 0.27445\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.8122457649230956\n",
            "Accuracy on hold-out set: 0.2687\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.8055205463409423\n",
            "Accuracy on hold-out set: 0.2673\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.7911878765106202\n",
            "Accuracy on hold-out set: 0.28\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.8298316034317017\n",
            "Accuracy on hold-out set: 0.2728\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.8623815210342407\n",
            "Accuracy on hold-out set: 0.28835\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.9696523330688476\n",
            "Accuracy on hold-out set: 0.29045\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.9696523330688476\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6037509200930595\n",
            "Accuracy on hold-out set: 0.39985\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5823026972651482\n",
            "Accuracy on hold-out set: 0.4241\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6274579430192708\n",
            "Accuracy on hold-out set: 0.4251\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4990676991522311\n",
            "Accuracy on hold-out set: 0.462\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5112783027641474\n",
            "Accuracy on hold-out set: 0.4564\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.498915891867876\n",
            "Accuracy on hold-out set: 0.46285\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4543943379640578\n",
            "Accuracy on hold-out set: 0.47145\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4658673120856285\n",
            "Accuracy on hold-out set: 0.4701\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4663085672408342\n",
            "Accuracy on hold-out set: 0.4784\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4362680657923221\n",
            "Accuracy on hold-out set: 0.48195\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4844671124938875\n",
            "Accuracy on hold-out set: 0.4727\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4190989673137664\n",
            "Accuracy on hold-out set: 0.49525\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.453333559253812\n",
            "Accuracy on hold-out set: 0.47575\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.423093760752678\n",
            "Accuracy on hold-out set: 0.4893\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4446669766560196\n",
            "Accuracy on hold-out set: 0.483\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.4446669766560196\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 256, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.304219289922714\n",
            "Accuracy on hold-out set: 0.1005\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3035491749048234\n",
            "Accuracy on hold-out set: 0.0978\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.303657049894333\n",
            "Accuracy on hold-out set: 0.0961\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3035239976882935\n",
            "Accuracy on hold-out set: 0.10115\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.304786906671524\n",
            "Accuracy on hold-out set: 0.0978\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3041044722795485\n",
            "Accuracy on hold-out set: 0.0978\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.303952686548233\n",
            "Accuracy on hold-out set: 0.1005\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 2.303952686548233\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5777467250347137\n",
            "Accuracy on hold-out set: 0.4197\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4286758798360824\n",
            "Accuracy on hold-out set: 0.4841\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3611546521782876\n",
            "Accuracy on hold-out set: 0.5121\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2483751401901244\n",
            "Accuracy on hold-out set: 0.55455\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2658642804443836\n",
            "Accuracy on hold-out set: 0.55945\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1966796129345894\n",
            "Accuracy on hold-out set: 0.57685\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1925843390643596\n",
            "Accuracy on hold-out set: 0.5839\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.185748322880268\n",
            "Accuracy on hold-out set: 0.5874\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1890746057093144\n",
            "Accuracy on hold-out set: 0.5893\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2200595129460097\n",
            "Accuracy on hold-out set: 0.5905\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.167569660744071\n",
            "Accuracy on hold-out set: 0.6076\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.158205179923773\n",
            "Accuracy on hold-out set: 0.61275\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1720467123687268\n",
            "Accuracy on hold-out set: 0.60985\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2052995375409723\n",
            "Accuracy on hold-out set: 0.6105\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2213374953597784\n",
            "Accuracy on hold-out set: 0.60445\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.2213374953597784\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7603817351341247\n",
            "Accuracy on hold-out set: 0.3158\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6130752403259276\n",
            "Accuracy on hold-out set: 0.37885\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5044930577278137\n",
            "Accuracy on hold-out set: 0.42845\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5393029041290283\n",
            "Accuracy on hold-out set: 0.42105\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4309648826599122\n",
            "Accuracy on hold-out set: 0.4597\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4083364534378051\n",
            "Accuracy on hold-out set: 0.4701\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4244347223281861\n",
            "Accuracy on hold-out set: 0.46485\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3841810475349425\n",
            "Accuracy on hold-out set: 0.4858\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4269291404247284\n",
            "Accuracy on hold-out set: 0.47165\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.378581427526474\n",
            "Accuracy on hold-out set: 0.48335\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.371817201566696\n",
            "Accuracy on hold-out set: 0.49215\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.37400062520504\n",
            "Accuracy on hold-out set: 0.4935\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3731372466087342\n",
            "Accuracy on hold-out set: 0.4959\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3306679658412934\n",
            "Accuracy on hold-out set: 0.51055\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3398271076202393\n",
            "Accuracy on hold-out set: 0.5103\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3456002076625824\n",
            "Accuracy on hold-out set: 0.50995\n",
            "Returned to Spot: Validation loss: 1.3456002076625824\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 512, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.513610099220276\n",
            "Accuracy on hold-out set: 0.44465\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.361282147026062\n",
            "Accuracy on hold-out set: 0.5047\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2592652069091796\n",
            "Accuracy on hold-out set: 0.545\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.223524308204651\n",
            "Accuracy on hold-out set: 0.56205\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1701137433052062\n",
            "Accuracy on hold-out set: 0.5872\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1716740451812744\n",
            "Accuracy on hold-out set: 0.59705\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2331298560142516\n",
            "Accuracy on hold-out set: 0.58915\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2571344835281373\n",
            "Accuracy on hold-out set: 0.5899\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.2571344835281373\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4727176284313201\n",
            "Accuracy on hold-out set: 0.46975\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3429568144798278\n",
            "Accuracy on hold-out set: 0.521\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2790918376922606\n",
            "Accuracy on hold-out set: 0.5435\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.184072265291214\n",
            "Accuracy on hold-out set: 0.57855\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1412959112167358\n",
            "Accuracy on hold-out set: 0.5972\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.137831463599205\n",
            "Accuracy on hold-out set: 0.60065\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1293547482728958\n",
            "Accuracy on hold-out set: 0.618\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1911875847578048\n",
            "Accuracy on hold-out set: 0.6078\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1937486982107162\n",
            "Accuracy on hold-out set: 0.61025\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2325668345451355\n",
            "Accuracy on hold-out set: 0.61805\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.2325668345451355\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.599949062728882\n",
            "Accuracy on hold-out set: 0.4072\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4483030137062072\n",
            "Accuracy on hold-out set: 0.4775\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.369408943080902\n",
            "Accuracy on hold-out set: 0.5158\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.241152059841156\n",
            "Accuracy on hold-out set: 0.5573\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1858395695686341\n",
            "Accuracy on hold-out set: 0.58295\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1493666481018066\n",
            "Accuracy on hold-out set: 0.59325\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1374492247581482\n",
            "Accuracy on hold-out set: 0.6072\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1287466134548187\n",
            "Accuracy on hold-out set: 0.61495\n",
            "Returned to Spot: Validation loss: 1.1287466134548187\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.672489295196533\n",
            "Accuracy on hold-out set: 0.397\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6341284866333008\n",
            "Accuracy on hold-out set: 0.41195\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4223642559051515\n",
            "Accuracy on hold-out set: 0.4915\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3109709425926208\n",
            "Accuracy on hold-out set: 0.5294\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.229776201057434\n",
            "Accuracy on hold-out set: 0.5579\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2136690031051636\n",
            "Accuracy on hold-out set: 0.57005\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2049011090278625\n",
            "Accuracy on hold-out set: 0.58025\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.231221194076538\n",
            "Accuracy on hold-out set: 0.57395\n",
            "Returned to Spot: Validation loss: 1.231221194076538\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6129768016815185\n",
            "Accuracy on hold-out set: 0.4083\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4378123532295226\n",
            "Accuracy on hold-out set: 0.4775\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3302195306777953\n",
            "Accuracy on hold-out set: 0.52045\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.237846824359894\n",
            "Accuracy on hold-out set: 0.55215\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2226078037261963\n",
            "Accuracy on hold-out set: 0.56975\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.231623141670227\n",
            "Accuracy on hold-out set: 0.57665\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.189291260433197\n",
            "Accuracy on hold-out set: 0.5903\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1766207193374634\n",
            "Accuracy on hold-out set: 0.60165\n",
            "Returned to Spot: Validation loss: 1.1766207193374634\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6180849931716919\n",
            "Accuracy on hold-out set: 0.392\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5704155838012694\n",
            "Accuracy on hold-out set: 0.42015\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4332725571632385\n",
            "Accuracy on hold-out set: 0.4634\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4370449863433838\n",
            "Accuracy on hold-out set: 0.4708\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3728269375801085\n",
            "Accuracy on hold-out set: 0.5024\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.353914930343628\n",
            "Accuracy on hold-out set: 0.50655\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3592876117706298\n",
            "Accuracy on hold-out set: 0.50595\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3354455207824707\n",
            "Accuracy on hold-out set: 0.519\n",
            "Returned to Spot: Validation loss: 1.3354455207824707\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7578232028007508\n",
            "Accuracy on hold-out set: 0.35235\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6638817100524903\n",
            "Accuracy on hold-out set: 0.3832\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6153913969039917\n",
            "Accuracy on hold-out set: 0.4045\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.582008626794815\n",
            "Accuracy on hold-out set: 0.4203\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5514868453502655\n",
            "Accuracy on hold-out set: 0.42855\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5279722206115722\n",
            "Accuracy on hold-out set: 0.4368\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5215554185390472\n",
            "Accuracy on hold-out set: 0.44165\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.493603274154663\n",
            "Accuracy on hold-out set: 0.4519\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4783373267173767\n",
            "Accuracy on hold-out set: 0.45855\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4680213376522064\n",
            "Accuracy on hold-out set: 0.46395\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.453281369447708\n",
            "Accuracy on hold-out set: 0.4688\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4528551629543305\n",
            "Accuracy on hold-out set: 0.47\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4347148640155791\n",
            "Accuracy on hold-out set: 0.47585\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.4271896163463593\n",
            "Accuracy on hold-out set: 0.4798\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4232662843227386\n",
            "Accuracy on hold-out set: 0.4815\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.417950362443924\n",
            "Accuracy on hold-out set: 0.48325\n",
            "Returned to Spot: Validation loss: 1.417950362443924\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 512, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4470600390553474\n",
            "Accuracy on hold-out set: 0.4759\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3407636000961065\n",
            "Accuracy on hold-out set: 0.5203\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2867921794690191\n",
            "Accuracy on hold-out set: 0.5424\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2572155697159468\n",
            "Accuracy on hold-out set: 0.56135\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2268291517995298\n",
            "Accuracy on hold-out set: 0.5724\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2288043085489422\n",
            "Accuracy on hold-out set: 0.57655\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.198594166252017\n",
            "Accuracy on hold-out set: 0.5884\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1842356679145247\n",
            "Accuracy on hold-out set: 0.59495\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1859593171093612\n",
            "Accuracy on hold-out set: 0.5939\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.193182976399362\n",
            "Accuracy on hold-out set: 0.6014\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1948002507174387\n",
            "Accuracy on hold-out set: 0.60335\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.1948002507174387\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 512, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5320117099761963\n",
            "Accuracy on hold-out set: 0.44175\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4154226238250733\n",
            "Accuracy on hold-out set: 0.48615\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2870242268562317\n",
            "Accuracy on hold-out set: 0.53325\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2089677166938781\n",
            "Accuracy on hold-out set: 0.571\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2031648762702942\n",
            "Accuracy on hold-out set: 0.5787\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1636597331047058\n",
            "Accuracy on hold-out set: 0.59215\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.196725885772705\n",
            "Accuracy on hold-out set: 0.5968\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1444670308589935\n",
            "Accuracy on hold-out set: 0.61285\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2198833209991455\n",
            "Accuracy on hold-out set: 0.60435\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2337491441249848\n",
            "Accuracy on hold-out set: 0.6137\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3385845083236694\n",
            "Accuracy on hold-out set: 0.61\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.3385845083236694\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7470374183654784\n",
            "Accuracy on hold-out set: 0.30815\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5325006196260453\n",
            "Accuracy on hold-out set: 0.4275\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4309990761518478\n",
            "Accuracy on hold-out set: 0.47255\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.43415360404253\n",
            "Accuracy on hold-out set: 0.4867\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3985947360277176\n",
            "Accuracy on hold-out set: 0.5216\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3927261057287454\n",
            "Accuracy on hold-out set: 0.51575\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.328351272559166\n",
            "Accuracy on hold-out set: 0.53415\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3442856170475483\n",
            "Accuracy on hold-out set: 0.53645\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4017517436534166\n",
            "Accuracy on hold-out set: 0.5448\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.418431627011299\n",
            "Accuracy on hold-out set: 0.5478\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.418431627011299\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6478148504972459\n",
            "Accuracy on hold-out set: 0.3679\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5669721976995468\n",
            "Accuracy on hold-out set: 0.40845\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4852627381563186\n",
            "Accuracy on hold-out set: 0.44105\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4702387354373931\n",
            "Accuracy on hold-out set: 0.44865\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.460210997414589\n",
            "Accuracy on hold-out set: 0.4478\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4553222195625306\n",
            "Accuracy on hold-out set: 0.4601\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4227116029858589\n",
            "Accuracy on hold-out set: 0.47005\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4500638333022595\n",
            "Accuracy on hold-out set: 0.4694\n",
            "Returned to Spot: Validation loss: 1.4500638333022595\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.434823174583912\n",
            "Accuracy on hold-out set: 0.48045\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.313873872423172\n",
            "Accuracy on hold-out set: 0.5353\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2908391315639018\n",
            "Accuracy on hold-out set: 0.5503\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1769749801635743\n",
            "Accuracy on hold-out set: 0.5912\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2020273064494134\n",
            "Accuracy on hold-out set: 0.5936\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2374350636690854\n",
            "Accuracy on hold-out set: 0.6012\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2286950948894024\n",
            "Accuracy on hold-out set: 0.6099\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.2286950948894024\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7491417137145997\n",
            "Accuracy on hold-out set: 0.3707\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5421396507263183\n",
            "Accuracy on hold-out set: 0.4348\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4083139134407043\n",
            "Accuracy on hold-out set: 0.49575\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3179229066848754\n",
            "Accuracy on hold-out set: 0.5289\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2541311786651612\n",
            "Accuracy on hold-out set: 0.56085\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2038648367881775\n",
            "Accuracy on hold-out set: 0.57715\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1694745182037354\n",
            "Accuracy on hold-out set: 0.58915\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1329933928489686\n",
            "Accuracy on hold-out set: 0.6065\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1411339616775513\n",
            "Accuracy on hold-out set: 0.61\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.153916619348526\n",
            "Accuracy on hold-out set: 0.61265\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1753483397483826\n",
            "Accuracy on hold-out set: 0.6142\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.1753483397483826\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6479183609485626\n",
            "Accuracy on hold-out set: 0.4003\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.478791021490097\n",
            "Accuracy on hold-out set: 0.461\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.414913390302658\n",
            "Accuracy on hold-out set: 0.4891\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3378733622550965\n",
            "Accuracy on hold-out set: 0.52655\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.290378661441803\n",
            "Accuracy on hold-out set: 0.544\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2606716016769408\n",
            "Accuracy on hold-out set: 0.55755\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2324365382432938\n",
            "Accuracy on hold-out set: 0.56535\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2111673447608948\n",
            "Accuracy on hold-out set: 0.5764\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1977302599430084\n",
            "Accuracy on hold-out set: 0.5829\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1920155447483063\n",
            "Accuracy on hold-out set: 0.5909\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2072670530080796\n",
            "Accuracy on hold-out set: 0.589\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1881844915866853\n",
            "Accuracy on hold-out set: 0.59535\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.194968029475212\n",
            "Accuracy on hold-out set: 0.5891\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1976103113412857\n",
            "Accuracy on hold-out set: 0.5913\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1762465452194213\n",
            "Accuracy on hold-out set: 0.60275\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.200515614581108\n",
            "Accuracy on hold-out set: 0.596\n",
            "Returned to Spot: Validation loss: 1.200515614581108\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.2204484820842745\n",
            "Accuracy on hold-out set: 0.22285\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.115823156046867\n",
            "Accuracy on hold-out set: 0.2599\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.0846186564445497\n",
            "Accuracy on hold-out set: 0.2691\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.0553683511734007\n",
            "Accuracy on hold-out set: 0.27575\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.029175527584553\n",
            "Accuracy on hold-out set: 0.2809\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.998937062084675\n",
            "Accuracy on hold-out set: 0.2887\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.9711098997831344\n",
            "Accuracy on hold-out set: 0.29495\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.957746341884136\n",
            "Accuracy on hold-out set: 0.2992\n",
            "Returned to Spot: Validation loss: 1.957746341884136\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 4, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.911205020713806\n",
            "Accuracy on hold-out set: 0.2536\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6874714237213135\n",
            "Accuracy on hold-out set: 0.33275\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.599903504371643\n",
            "Accuracy on hold-out set: 0.40985\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4941927630424499\n",
            "Accuracy on hold-out set: 0.45825\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5262340107917787\n",
            "Accuracy on hold-out set: 0.47\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4166932756423951\n",
            "Accuracy on hold-out set: 0.49835\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.410959508895874\n",
            "Accuracy on hold-out set: 0.5045\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3693450499534607\n",
            "Accuracy on hold-out set: 0.5299\n",
            "Returned to Spot: Validation loss: 1.3693450499534607\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4688095481395722\n",
            "Accuracy on hold-out set: 0.46385\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3226159152507782\n",
            "Accuracy on hold-out set: 0.5306\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.253410577607155\n",
            "Accuracy on hold-out set: 0.55955\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.171629820561409\n",
            "Accuracy on hold-out set: 0.5905\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1511450712919236\n",
            "Accuracy on hold-out set: 0.60105\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1248308233827353\n",
            "Accuracy on hold-out set: 0.6196\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.113475837224722\n",
            "Accuracy on hold-out set: 0.6225\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1905308248668909\n",
            "Accuracy on hold-out set: 0.62075\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2235409754067659\n",
            "Accuracy on hold-out set: 0.6267\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3013626571379602\n",
            "Accuracy on hold-out set: 0.63065\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.3013626571379602\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6101728715896606\n",
            "Accuracy on hold-out set: 0.4197\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4398054242134095\n",
            "Accuracy on hold-out set: 0.4816\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3728755548477174\n",
            "Accuracy on hold-out set: 0.5156\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2739362642288208\n",
            "Accuracy on hold-out set: 0.5441\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2512388591766357\n",
            "Accuracy on hold-out set: 0.56585\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2224288930892944\n",
            "Accuracy on hold-out set: 0.5799\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1920992990493775\n",
            "Accuracy on hold-out set: 0.5908\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.210657642364502\n",
            "Accuracy on hold-out set: 0.59665\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2148802117347717\n",
            "Accuracy on hold-out set: 0.5992\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3381314596176148\n",
            "Accuracy on hold-out set: 0.5941\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.3381314596176148\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.575252042913437\n",
            "Accuracy on hold-out set: 0.42275\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4880130951583386\n",
            "Accuracy on hold-out set: 0.45925\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4300078520059585\n",
            "Accuracy on hold-out set: 0.48595\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.400904261907935\n",
            "Accuracy on hold-out set: 0.4996\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3761117346048355\n",
            "Accuracy on hold-out set: 0.50955\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3557646763637663\n",
            "Accuracy on hold-out set: 0.52065\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.342306512722373\n",
            "Accuracy on hold-out set: 0.52285\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3291717589482666\n",
            "Accuracy on hold-out set: 0.53105\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3156175670459866\n",
            "Accuracy on hold-out set: 0.53405\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3117487608149647\n",
            "Accuracy on hold-out set: 0.538\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.296202202065289\n",
            "Accuracy on hold-out set: 0.5462\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2926177751138805\n",
            "Accuracy on hold-out set: 0.54655\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2859147731766105\n",
            "Accuracy on hold-out set: 0.5488\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2761013721898198\n",
            "Accuracy on hold-out set: 0.55295\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2734364114165306\n",
            "Accuracy on hold-out set: 0.5531\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2677442533120513\n",
            "Accuracy on hold-out set: 0.55775\n",
            "Returned to Spot: Validation loss: 1.2677442533120513\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5255584057331084\n",
            "Accuracy on hold-out set: 0.4505\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.357597103691101\n",
            "Accuracy on hold-out set: 0.51255\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3121990466117859\n",
            "Accuracy on hold-out set: 0.5348\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2915892394542694\n",
            "Accuracy on hold-out set: 0.5421\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2389216272115708\n",
            "Accuracy on hold-out set: 0.56075\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1872743263006211\n",
            "Accuracy on hold-out set: 0.58345\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.179637415456772\n",
            "Accuracy on hold-out set: 0.58805\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.156122814297676\n",
            "Accuracy on hold-out set: 0.60195\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.158240344762802\n",
            "Accuracy on hold-out set: 0.60525\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1718138107299805\n",
            "Accuracy on hold-out set: 0.60715\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1761459641456604\n",
            "Accuracy on hold-out set: 0.6158\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.1761459641456604\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4892454751968385\n",
            "Accuracy on hold-out set: 0.4573\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3246603725910187\n",
            "Accuracy on hold-out set: 0.522\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2726396539211273\n",
            "Accuracy on hold-out set: 0.5436\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.202610960960388\n",
            "Accuracy on hold-out set: 0.57845\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1453454275131225\n",
            "Accuracy on hold-out set: 0.5992\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1367686812639237\n",
            "Accuracy on hold-out set: 0.6072\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1066449336528779\n",
            "Accuracy on hold-out set: 0.61825\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1370416638851166\n",
            "Accuracy on hold-out set: 0.61735\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1592107808589935\n",
            "Accuracy on hold-out set: 0.61875\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2077047234296798\n",
            "Accuracy on hold-out set: 0.61805\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.2077047234296798\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5810852385520935\n",
            "Accuracy on hold-out set: 0.42325\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3645740552544594\n",
            "Accuracy on hold-out set: 0.50755\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3297517198562623\n",
            "Accuracy on hold-out set: 0.5308\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2373213168144226\n",
            "Accuracy on hold-out set: 0.5672\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2343898380756377\n",
            "Accuracy on hold-out set: 0.57275\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2047283586621285\n",
            "Accuracy on hold-out set: 0.5788\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2283671085715293\n",
            "Accuracy on hold-out set: 0.5793\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2314919468611478\n",
            "Accuracy on hold-out set: 0.5804\n",
            "Returned to Spot: Validation loss: 1.2314919468611478\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 4, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.864269374525547\n",
            "Accuracy on hold-out set: 0.29325\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.631003987431526\n",
            "Accuracy on hold-out set: 0.3942\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5130688538551331\n",
            "Accuracy on hold-out set: 0.44495\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4705548140257596\n",
            "Accuracy on hold-out set: 0.46825\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4340355982661248\n",
            "Accuracy on hold-out set: 0.4874\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4110577443957328\n",
            "Accuracy on hold-out set: 0.47825\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3605647028416394\n",
            "Accuracy on hold-out set: 0.5189\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3801229436323046\n",
            "Accuracy on hold-out set: 0.52595\n",
            "Returned to Spot: Validation loss: 1.3801229436323046\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 4, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8790124933242798\n",
            "Accuracy on hold-out set: 0.23115\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.825386402797699\n",
            "Accuracy on hold-out set: 0.25555\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7693506196975708\n",
            "Accuracy on hold-out set: 0.27955\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7182087158203125\n",
            "Accuracy on hold-out set: 0.32525\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6881717154502869\n",
            "Accuracy on hold-out set: 0.3503\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6488475867271424\n",
            "Accuracy on hold-out set: 0.3741\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6135084859848023\n",
            "Accuracy on hold-out set: 0.3827\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.577140054988861\n",
            "Accuracy on hold-out set: 0.4083\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5512508707046508\n",
            "Accuracy on hold-out set: 0.4182\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.5454325681209564\n",
            "Accuracy on hold-out set: 0.4255\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.5054221093654632\n",
            "Accuracy on hold-out set: 0.4396\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4608308463573456\n",
            "Accuracy on hold-out set: 0.4517\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4372579167842865\n",
            "Accuracy on hold-out set: 0.4645\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.4248759373188018\n",
            "Accuracy on hold-out set: 0.46715\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4177432416439057\n",
            "Accuracy on hold-out set: 0.4723\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.433689385318756\n",
            "Accuracy on hold-out set: 0.46805\n",
            "Returned to Spot: Validation loss: 1.433689385318756\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.528703199005127\n",
            "Accuracy on hold-out set: 0.4454\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3071280673980712\n",
            "Accuracy on hold-out set: 0.5248\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2223500758171082\n",
            "Accuracy on hold-out set: 0.5614\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1759759449720382\n",
            "Accuracy on hold-out set: 0.59025\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1478925539016724\n",
            "Accuracy on hold-out set: 0.6013\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1107852102279663\n",
            "Accuracy on hold-out set: 0.623\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.0643081407427788\n",
            "Accuracy on hold-out set: 0.6344\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1461382786512375\n",
            "Accuracy on hold-out set: 0.62625\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1379683530688285\n",
            "Accuracy on hold-out set: 0.6409\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.162273492860794\n",
            "Accuracy on hold-out set: 0.64325\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.162273492860794\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.462359681224823\n",
            "Accuracy on hold-out set: 0.45815\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.2858061056137084\n",
            "Accuracy on hold-out set: 0.5395\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.245396059846878\n",
            "Accuracy on hold-out set: 0.5604\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2226735450029373\n",
            "Accuracy on hold-out set: 0.5744\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.164196671462059\n",
            "Accuracy on hold-out set: 0.599\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1641585409164428\n",
            "Accuracy on hold-out set: 0.60035\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2434971959590913\n",
            "Accuracy on hold-out set: 0.59065\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.194210805940628\n",
            "Accuracy on hold-out set: 0.6163\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2611822464227675\n",
            "Accuracy on hold-out set: 0.6153\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.2611822464227675\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 8, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.307066402387619\n",
            "Accuracy on hold-out set: 0.1012\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3083958285808563\n",
            "Accuracy on hold-out set: 0.1006\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3073799590110777\n",
            "Accuracy on hold-out set: 0.1009\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3089644124746322\n",
            "Accuracy on hold-out set: 0.10005\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 2.3089644124746322\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7948187494277954\n",
            "Accuracy on hold-out set: 0.3115\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7780681146621704\n",
            "Accuracy on hold-out set: 0.31825\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7470068738937379\n",
            "Accuracy on hold-out set: 0.3493\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7225109806060792\n",
            "Accuracy on hold-out set: 0.35165\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.7186061653137208\n",
            "Accuracy on hold-out set: 0.3563\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.7845551544189453\n",
            "Accuracy on hold-out set: 0.3521\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.7391687551498414\n",
            "Accuracy on hold-out set: 0.36515\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.7196956045150757\n",
            "Accuracy on hold-out set: 0.37295\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.7196956045150757\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6387964337056968\n",
            "Accuracy on hold-out set: 0.4216\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6479032016839832\n",
            "Accuracy on hold-out set: 0.42975\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4678417954441976\n",
            "Accuracy on hold-out set: 0.49645\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5508830020742288\n",
            "Accuracy on hold-out set: 0.4959\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5979276278592793\n",
            "Accuracy on hold-out set: 0.50495\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.478428796092694\n",
            "Accuracy on hold-out set: 0.5095\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.478428796092694\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 256, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.398713513612747\n",
            "Accuracy on hold-out set: 0.49325\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.2993656488120555\n",
            "Accuracy on hold-out set: 0.53635\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.1874336043119431\n",
            "Accuracy on hold-out set: 0.5813\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2226196984648705\n",
            "Accuracy on hold-out set: 0.57595\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.155558614385128\n",
            "Accuracy on hold-out set: 0.61455\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1701921136677265\n",
            "Accuracy on hold-out set: 0.62015\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2532175750702619\n",
            "Accuracy on hold-out set: 0.61675\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.33684553720057\n",
            "Accuracy on hold-out set: 0.6234\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.33684553720057\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 512, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4620268842697144\n",
            "Accuracy on hold-out set: 0.45465\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.247642887687683\n",
            "Accuracy on hold-out set: 0.54775\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2107279094219208\n",
            "Accuracy on hold-out set: 0.56715\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1386667939186097\n",
            "Accuracy on hold-out set: 0.594\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1391651433944703\n",
            "Accuracy on hold-out set: 0.60525\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1046578833580016\n",
            "Accuracy on hold-out set: 0.62005\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.131427917599678\n",
            "Accuracy on hold-out set: 0.62085\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2388661470413207\n",
            "Accuracy on hold-out set: 0.61015\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2804337785720825\n",
            "Accuracy on hold-out set: 0.6206\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.2804337785720825\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 4, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8252557337090374\n",
            "Accuracy on hold-out set: 0.3058\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6885619544766843\n",
            "Accuracy on hold-out set: 0.41595\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5665300059445202\n",
            "Accuracy on hold-out set: 0.4346\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5811230733463542\n",
            "Accuracy on hold-out set: 0.4597\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.550385647311993\n",
            "Accuracy on hold-out set: 0.4695\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.513663282015454\n",
            "Accuracy on hold-out set: 0.4799\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.520564863468241\n",
            "Accuracy on hold-out set: 0.4848\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5101414065248566\n",
            "Accuracy on hold-out set: 0.4814\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.514844455352216\n",
            "Accuracy on hold-out set: 0.50135\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.5847222801289522\n",
            "Accuracy on hold-out set: 0.4935\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4936106640221085\n",
            "Accuracy on hold-out set: 0.5025\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.554024096624041\n",
            "Accuracy on hold-out set: 0.495\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.544454081978457\n",
            "Accuracy on hold-out set: 0.51385\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.5823679849728942\n",
            "Accuracy on hold-out set: 0.4822\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.5823679849728942\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 4, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9289794297218323\n",
            "Accuracy on hold-out set: 0.2117\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8519112033843994\n",
            "Accuracy on hold-out set: 0.2539\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7764740825653076\n",
            "Accuracy on hold-out set: 0.30715\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7128692205429077\n",
            "Accuracy on hold-out set: 0.33435\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.617545074081421\n",
            "Accuracy on hold-out set: 0.40045\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5186249835014343\n",
            "Accuracy on hold-out set: 0.4349\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.49719660115242\n",
            "Accuracy on hold-out set: 0.44755\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4587310496330261\n",
            "Accuracy on hold-out set: 0.4857\n",
            "Returned to Spot: Validation loss: 1.4587310496330261\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.720930517554283\n",
            "Accuracy on hold-out set: 0.35825\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6539718074560166\n",
            "Accuracy on hold-out set: 0.38625\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6168035916805268\n",
            "Accuracy on hold-out set: 0.3977\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5877457780361175\n",
            "Accuracy on hold-out set: 0.4129\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5503443054437638\n",
            "Accuracy on hold-out set: 0.42245\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5348560169935226\n",
            "Accuracy on hold-out set: 0.42625\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5176633625984193\n",
            "Accuracy on hold-out set: 0.43995\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5036097057819366\n",
            "Accuracy on hold-out set: 0.43995\n",
            "Returned to Spot: Validation loss: 1.5036097057819366\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.445615411376953\n",
            "Accuracy on hold-out set: 0.47425\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3300365309357642\n",
            "Accuracy on hold-out set: 0.52455\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2857143261760473\n",
            "Accuracy on hold-out set: 0.55215\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1902127917826175\n",
            "Accuracy on hold-out set: 0.5847\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1676668340593577\n",
            "Accuracy on hold-out set: 0.59815\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.173976347053051\n",
            "Accuracy on hold-out set: 0.6016\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2161296724319457\n",
            "Accuracy on hold-out set: 0.60015\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2604726832643152\n",
            "Accuracy on hold-out set: 0.59565\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.2604726832643152\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8106083577394485\n",
            "Accuracy on hold-out set: 0.3068\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7648010666310787\n",
            "Accuracy on hold-out set: 0.3357\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6673199456870555\n",
            "Accuracy on hold-out set: 0.365\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6395404850959778\n",
            "Accuracy on hold-out set: 0.38175\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6428829717576503\n",
            "Accuracy on hold-out set: 0.3822\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6410299910843373\n",
            "Accuracy on hold-out set: 0.38985\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6373335033804177\n",
            "Accuracy on hold-out set: 0.39185\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5782061430722476\n",
            "Accuracy on hold-out set: 0.39675\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.625913769876957\n",
            "Accuracy on hold-out set: 0.4081\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.5588142936348914\n",
            "Accuracy on hold-out set: 0.40325\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.54698528906703\n",
            "Accuracy on hold-out set: 0.42045\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.5910666153728963\n",
            "Accuracy on hold-out set: 0.4124\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.5420777369767427\n",
            "Accuracy on hold-out set: 0.43365\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.678055175870657\n",
            "Accuracy on hold-out set: 0.40045\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.5113059350848197\n",
            "Accuracy on hold-out set: 0.4339\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.5442393163621426\n",
            "Accuracy on hold-out set: 0.4294\n",
            "Returned to Spot: Validation loss: 1.5442393163621426\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4500079243659973\n",
            "Accuracy on hold-out set: 0.47255\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3113313132047653\n",
            "Accuracy on hold-out set: 0.5258\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2511505563020706\n",
            "Accuracy on hold-out set: 0.55455\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1798737485408783\n",
            "Accuracy on hold-out set: 0.58235\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1621140974521638\n",
            "Accuracy on hold-out set: 0.5852\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1350503221750259\n",
            "Accuracy on hold-out set: 0.6026\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1841957991838454\n",
            "Accuracy on hold-out set: 0.5923\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1380814977169036\n",
            "Accuracy on hold-out set: 0.6066\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1517569412946702\n",
            "Accuracy on hold-out set: 0.6039\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.1517569412946702\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5081161859035492\n",
            "Accuracy on hold-out set: 0.44495\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4001708099842072\n",
            "Accuracy on hold-out set: 0.4965\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3195928559780121\n",
            "Accuracy on hold-out set: 0.52355\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.316277211356163\n",
            "Accuracy on hold-out set: 0.5349\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2431032304286957\n",
            "Accuracy on hold-out set: 0.55655\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1863450574636458\n",
            "Accuracy on hold-out set: 0.5775\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.181881500172615\n",
            "Accuracy on hold-out set: 0.58085\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2031479410409927\n",
            "Accuracy on hold-out set: 0.57995\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1957633688926697\n",
            "Accuracy on hold-out set: 0.5904\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1726410355091095\n",
            "Accuracy on hold-out set: 0.59615\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.129682093501091\n",
            "Accuracy on hold-out set: 0.608\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2036730892658234\n",
            "Accuracy on hold-out set: 0.5922\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.186641354560852\n",
            "Accuracy on hold-out set: 0.59805\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1445624197006226\n",
            "Accuracy on hold-out set: 0.6114\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.1445624197006226\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 512, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.481993449473381\n",
            "Accuracy on hold-out set: 0.45575\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4020235077857972\n",
            "Accuracy on hold-out set: 0.4834\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3390302181839944\n",
            "Accuracy on hold-out set: 0.515\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3011383185982703\n",
            "Accuracy on hold-out set: 0.534\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2739634880781174\n",
            "Accuracy on hold-out set: 0.54305\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2580051120877267\n",
            "Accuracy on hold-out set: 0.5516\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2454854471445083\n",
            "Accuracy on hold-out set: 0.5584\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.231860056090355\n",
            "Accuracy on hold-out set: 0.5649\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2115610993146897\n",
            "Accuracy on hold-out set: 0.5725\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2129731273174287\n",
            "Accuracy on hold-out set: 0.57325\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1942549422085285\n",
            "Accuracy on hold-out set: 0.58065\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.202300605994463\n",
            "Accuracy on hold-out set: 0.57575\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1847653810679912\n",
            "Accuracy on hold-out set: 0.58355\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1837517949104308\n",
            "Accuracy on hold-out set: 0.585\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1945430872783065\n",
            "Accuracy on hold-out set: 0.58235\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1817648113131523\n",
            "Accuracy on hold-out set: 0.58805\n",
            "Returned to Spot: Validation loss: 1.1817648113131523\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.536203207397461\n",
            "Accuracy on hold-out set: 0.43585\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3637343021392823\n",
            "Accuracy on hold-out set: 0.50465\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3383420303344726\n",
            "Accuracy on hold-out set: 0.51925\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.253685010433197\n",
            "Accuracy on hold-out set: 0.55355\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.17773058385849\n",
            "Accuracy on hold-out set: 0.5844\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1878084518671035\n",
            "Accuracy on hold-out set: 0.5856\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.172411710858345\n",
            "Accuracy on hold-out set: 0.58805\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1761415613889694\n",
            "Accuracy on hold-out set: 0.5836\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1101332772016526\n",
            "Accuracy on hold-out set: 0.6089\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1894329498052596\n",
            "Accuracy on hold-out set: 0.5919\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.136471261405945\n",
            "Accuracy on hold-out set: 0.60475\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1239832781791688\n",
            "Accuracy on hold-out set: 0.611\n",
            "Early stopping at epoch 11\n",
            "Returned to Spot: Validation loss: 1.1239832781791688\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4796011686563493\n",
            "Accuracy on hold-out set: 0.46685\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3227845457401126\n",
            "Accuracy on hold-out set: 0.53905\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3033553891538643\n",
            "Accuracy on hold-out set: 0.5566\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3295326912729069\n",
            "Accuracy on hold-out set: 0.5646\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3460130139183253\n",
            "Accuracy on hold-out set: 0.56935\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2977189017098396\n",
            "Accuracy on hold-out set: 0.59565\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3665098076794762\n",
            "Accuracy on hold-out set: 0.5934\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4220168498474173\n",
            "Accuracy on hold-out set: 0.5891\n",
            "Returned to Spot: Validation loss: 1.4220168498474173\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 256, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3049860934257507\n",
            "Accuracy on hold-out set: 0.099\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.306318339061737\n",
            "Accuracy on hold-out set: 0.0998\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.304966287136078\n",
            "Accuracy on hold-out set: 0.098\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3073603432655334\n",
            "Accuracy on hold-out set: 0.0991\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3054446990013124\n",
            "Accuracy on hold-out set: 0.0991\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3046469256401063\n",
            "Accuracy on hold-out set: 0.1006\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.305391945171356\n",
            "Accuracy on hold-out set: 0.1006\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.30687046918869\n",
            "Accuracy on hold-out set: 0.098\n",
            "Returned to Spot: Validation loss: 2.30687046918869\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4013963729858399\n",
            "Accuracy on hold-out set: 0.4937\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.284260600209236\n",
            "Accuracy on hold-out set: 0.5388\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.209191043305397\n",
            "Accuracy on hold-out set: 0.5726\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1740644096136093\n",
            "Accuracy on hold-out set: 0.5865\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1641030084133148\n",
            "Accuracy on hold-out set: 0.6044\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1854244198560715\n",
            "Accuracy on hold-out set: 0.605\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1843138526558876\n",
            "Accuracy on hold-out set: 0.60925\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2643861521363258\n",
            "Accuracy on hold-out set: 0.6129\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.2643861521363258\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8631937948226929\n",
            "Accuracy on hold-out set: 0.26295\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7159900455474852\n",
            "Accuracy on hold-out set: 0.3503\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6631512325286866\n",
            "Accuracy on hold-out set: 0.38425\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5435822616577148\n",
            "Accuracy on hold-out set: 0.4252\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4981814569473266\n",
            "Accuracy on hold-out set: 0.4433\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4693234441757201\n",
            "Accuracy on hold-out set: 0.46\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4177617221832275\n",
            "Accuracy on hold-out set: 0.47705\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3982724193572997\n",
            "Accuracy on hold-out set: 0.47875\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3895780888557434\n",
            "Accuracy on hold-out set: 0.4839\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3593276731491089\n",
            "Accuracy on hold-out set: 0.4953\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3532088436126708\n",
            "Accuracy on hold-out set: 0.49935\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3397724778175355\n",
            "Accuracy on hold-out set: 0.5105\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.368727245426178\n",
            "Accuracy on hold-out set: 0.497\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3924444772720337\n",
            "Accuracy on hold-out set: 0.4887\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.312919073009491\n",
            "Accuracy on hold-out set: 0.52105\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3143865483283996\n",
            "Accuracy on hold-out set: 0.5202\n",
            "Returned to Spot: Validation loss: 1.3143865483283996\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6142532363891602\n",
            "Accuracy on hold-out set: 0.4249\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3853477219581605\n",
            "Accuracy on hold-out set: 0.49315\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3485607158660888\n",
            "Accuracy on hold-out set: 0.5166\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2951152108192443\n",
            "Accuracy on hold-out set: 0.5395\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3277648301124574\n",
            "Accuracy on hold-out set: 0.53885\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3222581399917603\n",
            "Accuracy on hold-out set: 0.53835\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2726094687461853\n",
            "Accuracy on hold-out set: 0.56125\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.310678168296814\n",
            "Accuracy on hold-out set: 0.5505\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2570146565437317\n",
            "Accuracy on hold-out set: 0.56535\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2216830931663514\n",
            "Accuracy on hold-out set: 0.5697\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.229248218536377\n",
            "Accuracy on hold-out set: 0.57605\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.264189202594757\n",
            "Accuracy on hold-out set: 0.5651\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2788549817085266\n",
            "Accuracy on hold-out set: 0.56515\n",
            "Early stopping at epoch 12\n",
            "Returned to Spot: Validation loss: 1.2788549817085266\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.521080772972107\n",
            "Accuracy on hold-out set: 0.44595\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3521380626678468\n",
            "Accuracy on hold-out set: 0.51545\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2515253145217895\n",
            "Accuracy on hold-out set: 0.5527\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2148359481811524\n",
            "Accuracy on hold-out set: 0.57085\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.182346104335785\n",
            "Accuracy on hold-out set: 0.59125\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1598381448745727\n",
            "Accuracy on hold-out set: 0.59165\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.118089987182617\n",
            "Accuracy on hold-out set: 0.6113\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1345026364326478\n",
            "Accuracy on hold-out set: 0.6125\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1543560850143433\n",
            "Accuracy on hold-out set: 0.6165\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1522989460468291\n",
            "Accuracy on hold-out set: 0.6206\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.1522989460468291\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.228547569656372\n",
            "Accuracy on hold-out set: 0.17895\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.9744758631706238\n",
            "Accuracy on hold-out set: 0.27865\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8245812801361083\n",
            "Accuracy on hold-out set: 0.3173\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7656358404159547\n",
            "Accuracy on hold-out set: 0.32995\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.7152114594459533\n",
            "Accuracy on hold-out set: 0.3582\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6823810282707214\n",
            "Accuracy on hold-out set: 0.36605\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6492246037960052\n",
            "Accuracy on hold-out set: 0.37715\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.630374526500702\n",
            "Accuracy on hold-out set: 0.38785\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5916350126266479\n",
            "Accuracy on hold-out set: 0.40085\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.572455945968628\n",
            "Accuracy on hold-out set: 0.40875\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.5581246826648711\n",
            "Accuracy on hold-out set: 0.41225\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.5445385686397552\n",
            "Accuracy on hold-out set: 0.4221\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.5320800358772277\n",
            "Accuracy on hold-out set: 0.4285\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.518619786787033\n",
            "Accuracy on hold-out set: 0.4334\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.522498784685135\n",
            "Accuracy on hold-out set: 0.43195\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.5098864966392518\n",
            "Accuracy on hold-out set: 0.43795\n",
            "Returned to Spot: Validation loss: 1.5098864966392518\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.428078407368064\n",
            "Accuracy on hold-out set: 0.4872\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.2827217149868608\n",
            "Accuracy on hold-out set: 0.54555\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3695846035808326\n",
            "Accuracy on hold-out set: 0.53435\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1989750947918743\n",
            "Accuracy on hold-out set: 0.58585\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1958241496868431\n",
            "Accuracy on hold-out set: 0.5975\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2702046268106904\n",
            "Accuracy on hold-out set: 0.60665\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3823712614237258\n",
            "Accuracy on hold-out set: 0.6061\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5649399952364402\n",
            "Accuracy on hold-out set: 0.6077\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.5649399952364402\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 128, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6188755903244019\n",
            "Accuracy on hold-out set: 0.39965\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4681227570533752\n",
            "Accuracy on hold-out set: 0.46625\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.40607602519989\n",
            "Accuracy on hold-out set: 0.4901\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3158861541748046\n",
            "Accuracy on hold-out set: 0.5239\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.283235296344757\n",
            "Accuracy on hold-out set: 0.5383\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2785418515205382\n",
            "Accuracy on hold-out set: 0.5466\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2174427485466004\n",
            "Accuracy on hold-out set: 0.5638\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.219669930934906\n",
            "Accuracy on hold-out set: 0.5666\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1809204405784608\n",
            "Accuracy on hold-out set: 0.58025\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1724534012794494\n",
            "Accuracy on hold-out set: 0.587\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1832059816360474\n",
            "Accuracy on hold-out set: 0.5812\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1558089248657226\n",
            "Accuracy on hold-out set: 0.59255\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1812196970939637\n",
            "Accuracy on hold-out set: 0.58515\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.127020408821106\n",
            "Accuracy on hold-out set: 0.60215\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1345536514282226\n",
            "Accuracy on hold-out set: 0.6023\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1151780983924866\n",
            "Accuracy on hold-out set: 0.6105\n",
            "Returned to Spot: Validation loss: 1.1151780983924866\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 128, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7938709415435792\n",
            "Accuracy on hold-out set: 0.29025\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6917243267059325\n",
            "Accuracy on hold-out set: 0.3171\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6256419317245483\n",
            "Accuracy on hold-out set: 0.3494\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.550447679710388\n",
            "Accuracy on hold-out set: 0.40825\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4706862665176392\n",
            "Accuracy on hold-out set: 0.44465\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4885508600234985\n",
            "Accuracy on hold-out set: 0.44475\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4351728655815124\n",
            "Accuracy on hold-out set: 0.4625\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4148369989395142\n",
            "Accuracy on hold-out set: 0.47445\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4129072082519532\n",
            "Accuracy on hold-out set: 0.4742\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.401319456386566\n",
            "Accuracy on hold-out set: 0.48165\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4027503469467164\n",
            "Accuracy on hold-out set: 0.47885\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3809130679130555\n",
            "Accuracy on hold-out set: 0.48465\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3629930541992188\n",
            "Accuracy on hold-out set: 0.4956\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3578941829681397\n",
            "Accuracy on hold-out set: 0.49595\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3620128260612487\n",
            "Accuracy on hold-out set: 0.4934\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3833469765663147\n",
            "Accuracy on hold-out set: 0.4865\n",
            "Returned to Spot: Validation loss: 1.3833469765663147\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.572932494544983\n",
            "Accuracy on hold-out set: 0.42235\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4258908082962036\n",
            "Accuracy on hold-out set: 0.48405\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3110347455978393\n",
            "Accuracy on hold-out set: 0.5275\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.261932425403595\n",
            "Accuracy on hold-out set: 0.54195\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2403229231834412\n",
            "Accuracy on hold-out set: 0.5547\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1613526312828064\n",
            "Accuracy on hold-out set: 0.58705\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1496630859375\n",
            "Accuracy on hold-out set: 0.59305\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.11815333776474\n",
            "Accuracy on hold-out set: 0.6023\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1039451117515564\n",
            "Accuracy on hold-out set: 0.61445\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.0996001095294952\n",
            "Accuracy on hold-out set: 0.6127\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.091304949092865\n",
            "Accuracy on hold-out set: 0.62025\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.0987883417129516\n",
            "Accuracy on hold-out set: 0.6185\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.0726858669757844\n",
            "Accuracy on hold-out set: 0.63015\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1313943130493165\n",
            "Accuracy on hold-out set: 0.6203\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1042533583641052\n",
            "Accuracy on hold-out set: 0.63265\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1200655667304993\n",
            "Accuracy on hold-out set: 0.6231\n",
            "Early stopping at epoch 15\n",
            "Returned to Spot: Validation loss: 1.1200655667304993\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.667414705848694\n",
            "Accuracy on hold-out set: 0.39105\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5351394109725953\n",
            "Accuracy on hold-out set: 0.4352\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4901910238265992\n",
            "Accuracy on hold-out set: 0.45415\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4251758451461791\n",
            "Accuracy on hold-out set: 0.4846\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3698997325897218\n",
            "Accuracy on hold-out set: 0.50665\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3341365175247193\n",
            "Accuracy on hold-out set: 0.52125\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.30617493724823\n",
            "Accuracy on hold-out set: 0.53475\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.278669732761383\n",
            "Accuracy on hold-out set: 0.54325\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3038602571487428\n",
            "Accuracy on hold-out set: 0.54375\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3011973363876344\n",
            "Accuracy on hold-out set: 0.5458\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2177743201255797\n",
            "Accuracy on hold-out set: 0.56875\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2099415974617005\n",
            "Accuracy on hold-out set: 0.5742\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2395633083343507\n",
            "Accuracy on hold-out set: 0.56615\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2203777009010315\n",
            "Accuracy on hold-out set: 0.56965\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2048672289848328\n",
            "Accuracy on hold-out set: 0.57265\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.218412845993042\n",
            "Accuracy on hold-out set: 0.57525\n",
            "Returned to Spot: Validation loss: 1.218412845993042\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7134089626312257\n",
            "Accuracy on hold-out set: 0.3682\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6460166067123414\n",
            "Accuracy on hold-out set: 0.3811\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.515534271812439\n",
            "Accuracy on hold-out set: 0.44675\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.446116911315918\n",
            "Accuracy on hold-out set: 0.4749\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3908648982048035\n",
            "Accuracy on hold-out set: 0.49505\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3976684840202331\n",
            "Accuracy on hold-out set: 0.48525\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3449900403022765\n",
            "Accuracy on hold-out set: 0.50805\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3523662536621093\n",
            "Accuracy on hold-out set: 0.515\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2862603547096252\n",
            "Accuracy on hold-out set: 0.53015\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2853248136520385\n",
            "Accuracy on hold-out set: 0.53845\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2754447974205017\n",
            "Accuracy on hold-out set: 0.54265\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2533897631645203\n",
            "Accuracy on hold-out set: 0.54995\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2775310395240784\n",
            "Accuracy on hold-out set: 0.54695\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.216594847393036\n",
            "Accuracy on hold-out set: 0.56575\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.213370777797699\n",
            "Accuracy on hold-out set: 0.564\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2204048331260682\n",
            "Accuracy on hold-out set: 0.56605\n",
            "Returned to Spot: Validation loss: 1.2204048331260682\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6320547202587128\n",
            "Accuracy on hold-out set: 0.3769\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.596952739572525\n",
            "Accuracy on hold-out set: 0.3877\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5073378848314285\n",
            "Accuracy on hold-out set: 0.4316\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4393924058675767\n",
            "Accuracy on hold-out set: 0.4511\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.425793989443779\n",
            "Accuracy on hold-out set: 0.45245\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4386768786668778\n",
            "Accuracy on hold-out set: 0.45365\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3923270971775055\n",
            "Accuracy on hold-out set: 0.46745\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3853180413484574\n",
            "Accuracy on hold-out set: 0.47575\n",
            "Returned to Spot: Validation loss: 1.3853180413484574\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.475193952256441\n",
            "Accuracy on hold-out set: 0.48155\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3944569889307021\n",
            "Accuracy on hold-out set: 0.51885\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.406791630040109\n",
            "Accuracy on hold-out set: 0.5202\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4649155232449993\n",
            "Accuracy on hold-out set: 0.5215\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4192125112782232\n",
            "Accuracy on hold-out set: 0.55025\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 1.4192125112782232\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4588168254852294\n",
            "Accuracy on hold-out set: 0.4637\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3478317247390748\n",
            "Accuracy on hold-out set: 0.52245\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2758150427818298\n",
            "Accuracy on hold-out set: 0.5524\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2099584747314454\n",
            "Accuracy on hold-out set: 0.5749\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2040158583641052\n",
            "Accuracy on hold-out set: 0.57555\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1814323120117187\n",
            "Accuracy on hold-out set: 0.59225\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2410571145057678\n",
            "Accuracy on hold-out set: 0.57675\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1901388814926148\n",
            "Accuracy on hold-out set: 0.59545\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2066986998558045\n",
            "Accuracy on hold-out set: 0.58725\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.2066986998558045\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3069461380004883\n",
            "Accuracy on hold-out set: 0.09805\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.297726764011383\n",
            "Accuracy on hold-out set: 0.1155\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.275308843421936\n",
            "Accuracy on hold-out set: 0.11715\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.2040754125595092\n",
            "Accuracy on hold-out set: 0.2082\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.13585644402504\n",
            "Accuracy on hold-out set: 0.2273\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.089474342393875\n",
            "Accuracy on hold-out set: 0.2408\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.050692396402359\n",
            "Accuracy on hold-out set: 0.2514\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.0226434319496156\n",
            "Accuracy on hold-out set: 0.2632\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.0004815375328064\n",
            "Accuracy on hold-out set: 0.26605\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.9839601549625396\n",
            "Accuracy on hold-out set: 0.2752\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.9713501610279083\n",
            "Accuracy on hold-out set: 0.2794\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.9568482872009276\n",
            "Accuracy on hold-out set: 0.2885\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.9413874029159546\n",
            "Accuracy on hold-out set: 0.2979\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.9274880644798278\n",
            "Accuracy on hold-out set: 0.3035\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.9131854098320007\n",
            "Accuracy on hold-out set: 0.30855\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.8991223809719087\n",
            "Accuracy on hold-out set: 0.30885\n",
            "Returned to Spot: Validation loss: 1.8991223809719087\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8142289026618004\n",
            "Accuracy on hold-out set: 0.3226\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6724553958773614\n",
            "Accuracy on hold-out set: 0.3775\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5743161413371562\n",
            "Accuracy on hold-out set: 0.42975\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5286332228660584\n",
            "Accuracy on hold-out set: 0.44175\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.538637700498104\n",
            "Accuracy on hold-out set: 0.4434\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4517941996634007\n",
            "Accuracy on hold-out set: 0.47845\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4236065503418445\n",
            "Accuracy on hold-out set: 0.4857\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.408986592784524\n",
            "Accuracy on hold-out set: 0.5002\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3644585727453231\n",
            "Accuracy on hold-out set: 0.51325\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3506916525125503\n",
            "Accuracy on hold-out set: 0.5188\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3655182656899094\n",
            "Accuracy on hold-out set: 0.51325\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3231433009669185\n",
            "Accuracy on hold-out set: 0.53305\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.337986843469739\n",
            "Accuracy on hold-out set: 0.52565\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3212316577076912\n",
            "Accuracy on hold-out set: 0.53035\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2951912535369396\n",
            "Accuracy on hold-out set: 0.5424\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2951246853001415\n",
            "Accuracy on hold-out set: 0.5462\n",
            "Returned to Spot: Validation loss: 1.2951246853001415\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.736582655955851\n",
            "Accuracy on hold-out set: 0.3254\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7331997720211745\n",
            "Accuracy on hold-out set: 0.33875\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.675967285501957\n",
            "Accuracy on hold-out set: 0.36285\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6424967405974864\n",
            "Accuracy on hold-out set: 0.37475\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6325958637528122\n",
            "Accuracy on hold-out set: 0.3795\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6260811075001955\n",
            "Accuracy on hold-out set: 0.38375\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.61472403306216\n",
            "Accuracy on hold-out set: 0.391\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.6131161594338714\n",
            "Accuracy on hold-out set: 0.39155\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.6047785963945091\n",
            "Accuracy on hold-out set: 0.3912\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.6032087570562958\n",
            "Accuracy on hold-out set: 0.3978\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.592900001488626\n",
            "Accuracy on hold-out set: 0.39955\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.5930196088925004\n",
            "Accuracy on hold-out set: 0.4022\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.5910632159724831\n",
            "Accuracy on hold-out set: 0.4021\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.5811764354772866\n",
            "Accuracy on hold-out set: 0.4055\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.5816328588590025\n",
            "Accuracy on hold-out set: 0.40485\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.5869001545637846\n",
            "Accuracy on hold-out set: 0.4059\n",
            "Returned to Spot: Validation loss: 1.5869001545637846\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5236423610152328\n",
            "Accuracy on hold-out set: 0.4675\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5257893878860829\n",
            "Accuracy on hold-out set: 0.506\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4898850812557458\n",
            "Accuracy on hold-out set: 0.54025\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4193302226094298\n",
            "Accuracy on hold-out set: 0.56855\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.543149409138163\n",
            "Accuracy on hold-out set: 0.54475\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6067480865399741\n",
            "Accuracy on hold-out set: 0.5717\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4872552181518535\n",
            "Accuracy on hold-out set: 0.5735\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.4872552181518535\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.887517760848999\n",
            "Accuracy on hold-out set: 0.2831\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8143799024581908\n",
            "Accuracy on hold-out set: 0.315\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7601143666267396\n",
            "Accuracy on hold-out set: 0.344\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7022403129577637\n",
            "Accuracy on hold-out set: 0.36525\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6614268260955811\n",
            "Accuracy on hold-out set: 0.38165\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6309707226753234\n",
            "Accuracy on hold-out set: 0.3922\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6118816171169281\n",
            "Accuracy on hold-out set: 0.399\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5889479528427124\n",
            "Accuracy on hold-out set: 0.4093\n",
            "Returned to Spot: Validation loss: 1.5889479528427124\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.307467708683014\n",
            "Accuracy on hold-out set: 0.10075\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3079119644641874\n",
            "Accuracy on hold-out set: 0.10075\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3055819841861727\n",
            "Accuracy on hold-out set: 0.0993\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3040207736968994\n",
            "Accuracy on hold-out set: 0.1019\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3045328540325163\n",
            "Accuracy on hold-out set: 0.10075\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3061615423679354\n",
            "Accuracy on hold-out set: 0.0996\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.304352142572403\n",
            "Accuracy on hold-out set: 0.0988\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 2.304352142572403\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3012944684028627\n",
            "Accuracy on hold-out set: 0.10395\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.28393785238266\n",
            "Accuracy on hold-out set: 0.151\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.229961035680771\n",
            "Accuracy on hold-out set: 0.1676\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.1771418509960174\n",
            "Accuracy on hold-out set: 0.1957\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.138750896692276\n",
            "Accuracy on hold-out set: 0.2132\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.104698060798645\n",
            "Accuracy on hold-out set: 0.2278\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.0701368048667907\n",
            "Accuracy on hold-out set: 0.2469\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.036530383729935\n",
            "Accuracy on hold-out set: 0.2622\n",
            "Returned to Spot: Validation loss: 2.036530383729935\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 512, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.457203491103649\n",
            "Accuracy on hold-out set: 0.47035\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3348447386741638\n",
            "Accuracy on hold-out set: 0.52055\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3486278151929378\n",
            "Accuracy on hold-out set: 0.51435\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2844900612175465\n",
            "Accuracy on hold-out set: 0.55325\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.255408796161413\n",
            "Accuracy on hold-out set: 0.56265\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2147502174496652\n",
            "Accuracy on hold-out set: 0.5816\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2671086746037006\n",
            "Accuracy on hold-out set: 0.56455\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2464115588575602\n",
            "Accuracy on hold-out set: 0.58105\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.221674622027576\n",
            "Accuracy on hold-out set: 0.58535\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.221674622027576\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4496093177318572\n",
            "Accuracy on hold-out set: 0.47255\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.330265258640051\n",
            "Accuracy on hold-out set: 0.5268\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2745770268440246\n",
            "Accuracy on hold-out set: 0.55015\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2462250223994256\n",
            "Accuracy on hold-out set: 0.5612\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.211584810525179\n",
            "Accuracy on hold-out set: 0.5805\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2237178582787513\n",
            "Accuracy on hold-out set: 0.5809\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1460338537454604\n",
            "Accuracy on hold-out set: 0.6038\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1649602625489235\n",
            "Accuracy on hold-out set: 0.60275\n",
            "Returned to Spot: Validation loss: 1.1649602625489235\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.0432733382701875\n",
            "Accuracy on hold-out set: 0.2354\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8679347097873689\n",
            "Accuracy on hold-out set: 0.3045\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7649452189207078\n",
            "Accuracy on hold-out set: 0.34765\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7260408660411835\n",
            "Accuracy on hold-out set: 0.3615\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.669588369846344\n",
            "Accuracy on hold-out set: 0.3863\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6231881180763246\n",
            "Accuracy on hold-out set: 0.4098\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5841935665369034\n",
            "Accuracy on hold-out set: 0.41595\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.54150850584507\n",
            "Accuracy on hold-out set: 0.43645\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4951717147827148\n",
            "Accuracy on hold-out set: 0.45485\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4803810378313065\n",
            "Accuracy on hold-out set: 0.46145\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4629281210541725\n",
            "Accuracy on hold-out set: 0.46925\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.453179012274742\n",
            "Accuracy on hold-out set: 0.4759\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4132612829685212\n",
            "Accuracy on hold-out set: 0.48995\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3887479941129683\n",
            "Accuracy on hold-out set: 0.5009\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3760746749043464\n",
            "Accuracy on hold-out set: 0.50825\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3698344056844711\n",
            "Accuracy on hold-out set: 0.50775\n",
            "Returned to Spot: Validation loss: 1.3698344056844711\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.293634720611572\n",
            "Accuracy on hold-out set: 0.17665\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.0034264961242676\n",
            "Accuracy on hold-out set: 0.28405\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8987265777587892\n",
            "Accuracy on hold-out set: 0.31245\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.8436759769439697\n",
            "Accuracy on hold-out set: 0.3335\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.7968891584396363\n",
            "Accuracy on hold-out set: 0.3533\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.7534456760406494\n",
            "Accuracy on hold-out set: 0.36725\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.7118374969482422\n",
            "Accuracy on hold-out set: 0.3784\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.6820057426452637\n",
            "Accuracy on hold-out set: 0.39315\n",
            "Returned to Spot: Validation loss: 1.6820057426452637\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 512, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5787343594388106\n",
            "Accuracy on hold-out set: 0.42365\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5632153100895811\n",
            "Accuracy on hold-out set: 0.45185\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5305337984947867\n",
            "Accuracy on hold-out set: 0.4955\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4711982665409684\n",
            "Accuracy on hold-out set: 0.5121\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4135610235304816\n",
            "Accuracy on hold-out set: 0.5319\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4430531278417185\n",
            "Accuracy on hold-out set: 0.5351\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4382433634352603\n",
            "Accuracy on hold-out set: 0.55055\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4089054837669497\n",
            "Accuracy on hold-out set: 0.55135\n",
            "Returned to Spot: Validation loss: 1.4089054837669497\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.638772540664673\n",
            "Accuracy on hold-out set: 0.37625\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4915903571605682\n",
            "Accuracy on hold-out set: 0.4484\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4084282701969146\n",
            "Accuracy on hold-out set: 0.4787\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3756777012825012\n",
            "Accuracy on hold-out set: 0.5006\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3198786001205445\n",
            "Accuracy on hold-out set: 0.51925\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.29838987326622\n",
            "Accuracy on hold-out set: 0.52285\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2904025237560273\n",
            "Accuracy on hold-out set: 0.52685\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.277518331003189\n",
            "Accuracy on hold-out set: 0.5364\n",
            "Returned to Spot: Validation loss: 1.277518331003189\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3043501000881195\n",
            "Accuracy on hold-out set: 0.0976\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3040167331695556\n",
            "Accuracy on hold-out set: 0.10005\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3032914355278016\n",
            "Accuracy on hold-out set: 0.0976\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.303823060417175\n",
            "Accuracy on hold-out set: 0.10015\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.303612880945206\n",
            "Accuracy on hold-out set: 0.0976\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.303798386764526\n",
            "Accuracy on hold-out set: 0.10005\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 2.303798386764526\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 256, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5791905565261841\n",
            "Accuracy on hold-out set: 0.4152\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.396650789833069\n",
            "Accuracy on hold-out set: 0.48965\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3053886367797851\n",
            "Accuracy on hold-out set: 0.5371\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.253739414024353\n",
            "Accuracy on hold-out set: 0.558\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2095296085357665\n",
            "Accuracy on hold-out set: 0.5734\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2226763494491577\n",
            "Accuracy on hold-out set: 0.5711\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1825858094215393\n",
            "Accuracy on hold-out set: 0.5838\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1421845197677611\n",
            "Accuracy on hold-out set: 0.60465\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.144190205669403\n",
            "Accuracy on hold-out set: 0.60305\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.163386567401886\n",
            "Accuracy on hold-out set: 0.59965\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1294616726398468\n",
            "Accuracy on hold-out set: 0.6149\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1193053832530975\n",
            "Accuracy on hold-out set: 0.61825\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1078671285629274\n",
            "Accuracy on hold-out set: 0.6202\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1209031271934509\n",
            "Accuracy on hold-out set: 0.6198\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1183547894954682\n",
            "Accuracy on hold-out set: 0.6246\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1511560496330262\n",
            "Accuracy on hold-out set: 0.61535\n",
            "Early stopping at epoch 15\n",
            "Returned to Spot: Validation loss: 1.1511560496330262\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 128, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5503899185180665\n",
            "Accuracy on hold-out set: 0.4375\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4276451023101806\n",
            "Accuracy on hold-out set: 0.486\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4288210671424866\n",
            "Accuracy on hold-out set: 0.48075\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3032812150001525\n",
            "Accuracy on hold-out set: 0.53115\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.240123256778717\n",
            "Accuracy on hold-out set: 0.5541\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2146937160491944\n",
            "Accuracy on hold-out set: 0.56665\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.202176308441162\n",
            "Accuracy on hold-out set: 0.5743\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1710943806648255\n",
            "Accuracy on hold-out set: 0.5859\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1535151762962341\n",
            "Accuracy on hold-out set: 0.5967\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.144552198123932\n",
            "Accuracy on hold-out set: 0.60075\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.142043978214264\n",
            "Accuracy on hold-out set: 0.60155\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1345385706424713\n",
            "Accuracy on hold-out set: 0.6088\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.170405550479889\n",
            "Accuracy on hold-out set: 0.6066\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.15029422416687\n",
            "Accuracy on hold-out set: 0.61005\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1549791073799134\n",
            "Accuracy on hold-out set: 0.60925\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.1549791073799134\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.867631279750727\n",
            "Accuracy on hold-out set: 0.3171\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.9081570379279496\n",
            "Accuracy on hold-out set: 0.31545\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.808960529569653\n",
            "Accuracy on hold-out set: 0.3581\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.8411709466463362\n",
            "Accuracy on hold-out set: 0.3657\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.794794435526147\n",
            "Accuracy on hold-out set: 0.3432\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.8599797261379891\n",
            "Accuracy on hold-out set: 0.3493\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.9068218886153308\n",
            "Accuracy on hold-out set: 0.3689\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.929871759050787\n",
            "Accuracy on hold-out set: 0.3515\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.929871759050787\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 128, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6574702898763587\n",
            "Accuracy on hold-out set: 0.41925\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8136838021610882\n",
            "Accuracy on hold-out set: 0.44625\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6373070324043497\n",
            "Accuracy on hold-out set: 0.4416\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.645057843092037\n",
            "Accuracy on hold-out set: 0.48025\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.817552356821955\n",
            "Accuracy on hold-out set: 0.47865\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.7626865319354914\n",
            "Accuracy on hold-out set: 0.47165\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.7626865319354914\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6366887515306472\n",
            "Accuracy on hold-out set: 0.39765\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.548011083126068\n",
            "Accuracy on hold-out set: 0.4338\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5015469349861146\n",
            "Accuracy on hold-out set: 0.4503\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4705920418441296\n",
            "Accuracy on hold-out set: 0.4658\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4594276518940925\n",
            "Accuracy on hold-out set: 0.4654\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.429903168040514\n",
            "Accuracy on hold-out set: 0.48265\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4050419559627771\n",
            "Accuracy on hold-out set: 0.4886\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.400657526743412\n",
            "Accuracy on hold-out set: 0.49135\n",
            "Returned to Spot: Validation loss: 1.400657526743412\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8725155033349992\n",
            "Accuracy on hold-out set: 0.2413\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6606200585544109\n",
            "Accuracy on hold-out set: 0.37475\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5611456299781798\n",
            "Accuracy on hold-out set: 0.4047\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5503128812879323\n",
            "Accuracy on hold-out set: 0.41035\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5461505793780088\n",
            "Accuracy on hold-out set: 0.4269\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5146196452438832\n",
            "Accuracy on hold-out set: 0.43115\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5323882758021354\n",
            "Accuracy on hold-out set: 0.43275\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5090458060652017\n",
            "Accuracy on hold-out set: 0.4468\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4915522458434105\n",
            "Accuracy on hold-out set: 0.45815\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.444552582912147\n",
            "Accuracy on hold-out set: 0.4727\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4653547431573273\n",
            "Accuracy on hold-out set: 0.4787\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.40223008633554\n",
            "Accuracy on hold-out set: 0.4993\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3846418228656054\n",
            "Accuracy on hold-out set: 0.5072\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.519425287746638\n",
            "Accuracy on hold-out set: 0.4749\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.5151821489304305\n",
            "Accuracy on hold-out set: 0.47245\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3748621870659292\n",
            "Accuracy on hold-out set: 0.5179\n",
            "Returned to Spot: Validation loss: 1.3748621870659292\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4895458017110825\n",
            "Accuracy on hold-out set: 0.46245\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3326275314807892\n",
            "Accuracy on hold-out set: 0.52575\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.266832924759388\n",
            "Accuracy on hold-out set: 0.55835\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2343446839213372\n",
            "Accuracy on hold-out set: 0.56845\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2251222978830338\n",
            "Accuracy on hold-out set: 0.57885\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2318020516872406\n",
            "Accuracy on hold-out set: 0.5771\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2815307390034198\n",
            "Accuracy on hold-out set: 0.57495\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1789089684545995\n",
            "Accuracy on hold-out set: 0.60005\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2980900458931923\n",
            "Accuracy on hold-out set: 0.56875\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2032224703729153\n",
            "Accuracy on hold-out set: 0.5924\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.190584019652009\n",
            "Accuracy on hold-out set: 0.59905\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.190584019652009\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5485581272511744\n",
            "Accuracy on hold-out set: 0.44745\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5318852001846652\n",
            "Accuracy on hold-out set: 0.4772\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.41583883546367\n",
            "Accuracy on hold-out set: 0.52115\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4818564948744606\n",
            "Accuracy on hold-out set: 0.5143\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5003127594045524\n",
            "Accuracy on hold-out set: 0.5342\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4041982652505238\n",
            "Accuracy on hold-out set: 0.54845\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4721295056865087\n",
            "Accuracy on hold-out set: 0.55105\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.517229360907091\n",
            "Accuracy on hold-out set: 0.5308\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3807767336822399\n",
            "Accuracy on hold-out set: 0.57085\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3556922198313457\n",
            "Accuracy on hold-out set: 0.5891\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4154277330026248\n",
            "Accuracy on hold-out set: 0.57215\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4176494039276235\n",
            "Accuracy on hold-out set: 0.5805\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.5100973738883752\n",
            "Accuracy on hold-out set: 0.5489\n",
            "Early stopping at epoch 12\n",
            "Returned to Spot: Validation loss: 1.5100973738883752\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5502828590579332\n",
            "Accuracy on hold-out set: 0.4438\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4312330770318396\n",
            "Accuracy on hold-out set: 0.49965\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3892299973731046\n",
            "Accuracy on hold-out set: 0.52405\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3793902283017465\n",
            "Accuracy on hold-out set: 0.547\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.375346691172423\n",
            "Accuracy on hold-out set: 0.5491\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.299691007639721\n",
            "Accuracy on hold-out set: 0.57275\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3901668410711134\n",
            "Accuracy on hold-out set: 0.56935\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4144033495693396\n",
            "Accuracy on hold-out set: 0.5696\n",
            "Returned to Spot: Validation loss: 1.4144033495693396\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.560047235059738\n",
            "Accuracy on hold-out set: 0.4317\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.487967557477951\n",
            "Accuracy on hold-out set: 0.47145\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4286206200599672\n",
            "Accuracy on hold-out set: 0.4858\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3908681569099426\n",
            "Accuracy on hold-out set: 0.5032\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3594635940551758\n",
            "Accuracy on hold-out set: 0.5199\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3417015970230102\n",
            "Accuracy on hold-out set: 0.52495\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3246891805171968\n",
            "Accuracy on hold-out set: 0.53425\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3280993557453156\n",
            "Accuracy on hold-out set: 0.53045\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3139228261470794\n",
            "Accuracy on hold-out set: 0.5371\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2921338538646698\n",
            "Accuracy on hold-out set: 0.5452\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2788539885997772\n",
            "Accuracy on hold-out set: 0.54675\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2640810878276825\n",
            "Accuracy on hold-out set: 0.55495\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2507647772312165\n",
            "Accuracy on hold-out set: 0.5603\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2540591445446014\n",
            "Accuracy on hold-out set: 0.55785\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.237313850402832\n",
            "Accuracy on hold-out set: 0.5646\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2382981746673585\n",
            "Accuracy on hold-out set: 0.5632\n",
            "Returned to Spot: Validation loss: 1.2382981746673585\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4994363489866256\n",
            "Accuracy on hold-out set: 0.45655\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4324455855846405\n",
            "Accuracy on hold-out set: 0.4825\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3928848186612128\n",
            "Accuracy on hold-out set: 0.4998\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3329812017142773\n",
            "Accuracy on hold-out set: 0.52125\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3222424137532711\n",
            "Accuracy on hold-out set: 0.52875\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3329381687045097\n",
            "Accuracy on hold-out set: 0.5193\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.310420240420103\n",
            "Accuracy on hold-out set: 0.5398\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2425552922785281\n",
            "Accuracy on hold-out set: 0.5593\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2344843719542027\n",
            "Accuracy on hold-out set: 0.565\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2320635193824767\n",
            "Accuracy on hold-out set: 0.56535\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2213076356887818\n",
            "Accuracy on hold-out set: 0.5722\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2222004944443703\n",
            "Accuracy on hold-out set: 0.56955\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2975750496685505\n",
            "Accuracy on hold-out set: 0.54895\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.207439248174429\n",
            "Accuracy on hold-out set: 0.5769\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.228048586076498\n",
            "Accuracy on hold-out set: 0.57515\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1731590794563294\n",
            "Accuracy on hold-out set: 0.5902\n",
            "Returned to Spot: Validation loss: 1.1731590794563294\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7499386257171632\n",
            "Accuracy on hold-out set: 0.34025\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5884436794281005\n",
            "Accuracy on hold-out set: 0.41345\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5159501628875733\n",
            "Accuracy on hold-out set: 0.4396\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4127338892936707\n",
            "Accuracy on hold-out set: 0.4831\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.401382799243927\n",
            "Accuracy on hold-out set: 0.4865\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3659576828956603\n",
            "Accuracy on hold-out set: 0.50115\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.399283706188202\n",
            "Accuracy on hold-out set: 0.4917\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3254782128334046\n",
            "Accuracy on hold-out set: 0.5157\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3431774694442749\n",
            "Accuracy on hold-out set: 0.5158\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.321192643070221\n",
            "Accuracy on hold-out set: 0.52285\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2936691619873046\n",
            "Accuracy on hold-out set: 0.53565\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3139576014518737\n",
            "Accuracy on hold-out set: 0.5244\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2978310654640197\n",
            "Accuracy on hold-out set: 0.5383\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.276288584136963\n",
            "Accuracy on hold-out set: 0.54285\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3063043843269349\n",
            "Accuracy on hold-out set: 0.5345\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2710563829421997\n",
            "Accuracy on hold-out set: 0.5393\n",
            "Returned to Spot: Validation loss: 1.2710563829421997\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 32, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7687800181135536\n",
            "Accuracy on hold-out set: 0.35055\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5986507653102278\n",
            "Accuracy on hold-out set: 0.4164\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5290053691528738\n",
            "Accuracy on hold-out set: 0.45065\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4862138037493453\n",
            "Accuracy on hold-out set: 0.476\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4400935630522669\n",
            "Accuracy on hold-out set: 0.496\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4301820886086674\n",
            "Accuracy on hold-out set: 0.50545\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.401165714598354\n",
            "Accuracy on hold-out set: 0.5136\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.416995603672322\n",
            "Accuracy on hold-out set: 0.5261\n",
            "Returned to Spot: Validation loss: 1.416995603672322\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6867443822860717\n",
            "Accuracy on hold-out set: 0.37175\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5340250723838806\n",
            "Accuracy on hold-out set: 0.4261\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4645930781841279\n",
            "Accuracy on hold-out set: 0.4588\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.455951173210144\n",
            "Accuracy on hold-out set: 0.46855\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3636360721111298\n",
            "Accuracy on hold-out set: 0.50335\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3094124747276306\n",
            "Accuracy on hold-out set: 0.5289\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.362704347229004\n",
            "Accuracy on hold-out set: 0.51165\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2823409682273865\n",
            "Accuracy on hold-out set: 0.54195\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3039409678936005\n",
            "Accuracy on hold-out set: 0.54105\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2375911485671998\n",
            "Accuracy on hold-out set: 0.56035\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2664522018909454\n",
            "Accuracy on hold-out set: 0.5469\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.236442414999008\n",
            "Accuracy on hold-out set: 0.56065\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2328999953746795\n",
            "Accuracy on hold-out set: 0.56005\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2169363665103912\n",
            "Accuracy on hold-out set: 0.57325\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.207854522204399\n",
            "Accuracy on hold-out set: 0.57445\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2088010674476624\n",
            "Accuracy on hold-out set: 0.5721\n",
            "Returned to Spot: Validation loss: 1.2088010674476624\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5461542838096618\n",
            "Accuracy on hold-out set: 0.4378\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3771877680897713\n",
            "Accuracy on hold-out set: 0.49915\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3120118997097014\n",
            "Accuracy on hold-out set: 0.5316\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.300495745563507\n",
            "Accuracy on hold-out set: 0.532\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2783024679780006\n",
            "Accuracy on hold-out set: 0.54435\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2750404594361782\n",
            "Accuracy on hold-out set: 0.5509\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2604059994399548\n",
            "Accuracy on hold-out set: 0.5599\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.24062988063097\n",
            "Accuracy on hold-out set: 0.5676\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2802622232019902\n",
            "Accuracy on hold-out set: 0.55655\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2524164520204066\n",
            "Accuracy on hold-out set: 0.56915\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3830139803767205\n",
            "Accuracy on hold-out set: 0.5506\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.3830139803767205\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4181322575569153\n",
            "Accuracy on hold-out set: 0.4878\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.282173970222473\n",
            "Accuracy on hold-out set: 0.5396\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2651538297891616\n",
            "Accuracy on hold-out set: 0.54995\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.211736736369133\n",
            "Accuracy on hold-out set: 0.5671\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2019061565876008\n",
            "Accuracy on hold-out set: 0.58245\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2038293184041977\n",
            "Accuracy on hold-out set: 0.5824\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.226890533900261\n",
            "Accuracy on hold-out set: 0.5781\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.223903026652336\n",
            "Accuracy on hold-out set: 0.5891\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.223903026652336\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6971942824363708\n",
            "Accuracy on hold-out set: 0.3501\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6465672607421875\n",
            "Accuracy on hold-out set: 0.37885\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5075860439777373\n",
            "Accuracy on hold-out set: 0.4316\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4766533591270448\n",
            "Accuracy on hold-out set: 0.4424\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3904660551548005\n",
            "Accuracy on hold-out set: 0.48335\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.321753350877762\n",
            "Accuracy on hold-out set: 0.51795\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3068721091270448\n",
            "Accuracy on hold-out set: 0.5239\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2409061552524567\n",
            "Accuracy on hold-out set: 0.55085\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2671660072803497\n",
            "Accuracy on hold-out set: 0.5414\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2194057796478273\n",
            "Accuracy on hold-out set: 0.5577\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2050720100879668\n",
            "Accuracy on hold-out set: 0.56845\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.205206630706787\n",
            "Accuracy on hold-out set: 0.5698\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.195853820180893\n",
            "Accuracy on hold-out set: 0.5701\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1753553910732268\n",
            "Accuracy on hold-out set: 0.5831\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1827053928375244\n",
            "Accuracy on hold-out set: 0.5783\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1899700746536255\n",
            "Accuracy on hold-out set: 0.57865\n",
            "Returned to Spot: Validation loss: 1.1899700746536255\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.57702679104805\n",
            "Accuracy on hold-out set: 0.4181\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4173706582546235\n",
            "Accuracy on hold-out set: 0.4811\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.359801008462906\n",
            "Accuracy on hold-out set: 0.5074\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2629829158067702\n",
            "Accuracy on hold-out set: 0.5449\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.240594773554802\n",
            "Accuracy on hold-out set: 0.5572\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2295999021053314\n",
            "Accuracy on hold-out set: 0.5661\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2035080738067627\n",
            "Accuracy on hold-out set: 0.5762\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2290761974573134\n",
            "Accuracy on hold-out set: 0.56965\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1643324599266052\n",
            "Accuracy on hold-out set: 0.59335\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1980175209999084\n",
            "Accuracy on hold-out set: 0.5833\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1622837769508363\n",
            "Accuracy on hold-out set: 0.59975\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1411045014619827\n",
            "Accuracy on hold-out set: 0.6069\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1655226585149765\n",
            "Accuracy on hold-out set: 0.60475\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1973207701206208\n",
            "Accuracy on hold-out set: 0.6028\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2026748282432556\n",
            "Accuracy on hold-out set: 0.6068\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.2026748282432556\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 128, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.751009442576766\n",
            "Accuracy on hold-out set: 0.35655\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6300478294804692\n",
            "Accuracy on hold-out set: 0.39785\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5397641412824392\n",
            "Accuracy on hold-out set: 0.44155\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4846409462701529\n",
            "Accuracy on hold-out set: 0.47005\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4602572248269803\n",
            "Accuracy on hold-out set: 0.4909\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5175339274943807\n",
            "Accuracy on hold-out set: 0.47485\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3954096984422766\n",
            "Accuracy on hold-out set: 0.51395\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3981458776691928\n",
            "Accuracy on hold-out set: 0.5207\n",
            "Returned to Spot: Validation loss: 1.3981458776691928\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.449988982439041\n",
            "Accuracy on hold-out set: 0.47285\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3190553433418275\n",
            "Accuracy on hold-out set: 0.52575\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2579405540704727\n",
            "Accuracy on hold-out set: 0.55405\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1942529683828353\n",
            "Accuracy on hold-out set: 0.57785\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2454624333143234\n",
            "Accuracy on hold-out set: 0.5628\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1617639176607133\n",
            "Accuracy on hold-out set: 0.59135\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2166464162111283\n",
            "Accuracy on hold-out set: 0.58435\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2165845418453216\n",
            "Accuracy on hold-out set: 0.5907\n",
            "Returned to Spot: Validation loss: 1.2165845418453216\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7700749636828899\n",
            "Accuracy on hold-out set: 0.34115\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7264846031211316\n",
            "Accuracy on hold-out set: 0.36965\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6921542760930954\n",
            "Accuracy on hold-out set: 0.38535\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.655725217391923\n",
            "Accuracy on hold-out set: 0.3976\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6483456364162266\n",
            "Accuracy on hold-out set: 0.40805\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6192555840801448\n",
            "Accuracy on hold-out set: 0.41615\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5947965691257269\n",
            "Accuracy on hold-out set: 0.42795\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5760355879671872\n",
            "Accuracy on hold-out set: 0.43455\n",
            "Returned to Spot: Validation loss: 1.5760355879671872\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4665437923908233\n",
            "Accuracy on hold-out set: 0.47015\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3417666540950537\n",
            "Accuracy on hold-out set: 0.5205\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.278281296904385\n",
            "Accuracy on hold-out set: 0.5416\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2445087880000472\n",
            "Accuracy on hold-out set: 0.55805\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2174789099797607\n",
            "Accuracy on hold-out set: 0.5727\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.205144572904706\n",
            "Accuracy on hold-out set: 0.57545\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.195351142438501\n",
            "Accuracy on hold-out set: 0.58365\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1791917498294264\n",
            "Accuracy on hold-out set: 0.5933\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.165098003320396\n",
            "Accuracy on hold-out set: 0.60165\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1597714050292969\n",
            "Accuracy on hold-out set: 0.60185\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1525536371015013\n",
            "Accuracy on hold-out set: 0.606\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.160290801803395\n",
            "Accuracy on hold-out set: 0.6083\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1435489748269319\n",
            "Accuracy on hold-out set: 0.6148\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1516644717019051\n",
            "Accuracy on hold-out set: 0.616\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1497696528334171\n",
            "Accuracy on hold-out set: 0.61665\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.16511638641553\n",
            "Accuracy on hold-out set: 0.61825\n",
            "Early stopping at epoch 15\n",
            "Returned to Spot: Validation loss: 1.16511638641553\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 512, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5051237293720245\n",
            "Accuracy on hold-out set: 0.4507\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3998975463867187\n",
            "Accuracy on hold-out set: 0.48775\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3217846228599548\n",
            "Accuracy on hold-out set: 0.5227\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2808377122879029\n",
            "Accuracy on hold-out set: 0.54135\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2905441090106964\n",
            "Accuracy on hold-out set: 0.5387\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2620244683742523\n",
            "Accuracy on hold-out set: 0.5516\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2441634373903274\n",
            "Accuracy on hold-out set: 0.55785\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2339608906745911\n",
            "Accuracy on hold-out set: 0.56545\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2022876373767852\n",
            "Accuracy on hold-out set: 0.5755\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2021403940677642\n",
            "Accuracy on hold-out set: 0.57855\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1797348245620727\n",
            "Accuracy on hold-out set: 0.58385\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1778424213171006\n",
            "Accuracy on hold-out set: 0.5874\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2029679971456528\n",
            "Accuracy on hold-out set: 0.57795\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1734113430976867\n",
            "Accuracy on hold-out set: 0.5922\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.163694766998291\n",
            "Accuracy on hold-out set: 0.5909\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1550214302301407\n",
            "Accuracy on hold-out set: 0.5992\n",
            "Returned to Spot: Validation loss: 1.1550214302301407\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.533870042324066\n",
            "Accuracy on hold-out set: 0.4527\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3002406314849853\n",
            "Accuracy on hold-out set: 0.53205\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2444906772851945\n",
            "Accuracy on hold-out set: 0.55505\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2045452627658844\n",
            "Accuracy on hold-out set: 0.5733\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1806134266614914\n",
            "Accuracy on hold-out set: 0.5795\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1422187879800796\n",
            "Accuracy on hold-out set: 0.5974\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1165453830003738\n",
            "Accuracy on hold-out set: 0.6093\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1647878282546997\n",
            "Accuracy on hold-out set: 0.6012\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.103754087996483\n",
            "Accuracy on hold-out set: 0.6166\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1620204030275345\n",
            "Accuracy on hold-out set: 0.6039\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.122736533498764\n",
            "Accuracy on hold-out set: 0.6175\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1892279219150543\n",
            "Accuracy on hold-out set: 0.60375\n",
            "Early stopping at epoch 11\n",
            "Returned to Spot: Validation loss: 1.1892279219150543\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5184938796281815\n",
            "Accuracy on hold-out set: 0.43745\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3855740990757943\n",
            "Accuracy on hold-out set: 0.49995\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2929739388465882\n",
            "Accuracy on hold-out set: 0.54325\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2924210882663727\n",
            "Accuracy on hold-out set: 0.5478\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2664170326411723\n",
            "Accuracy on hold-out set: 0.56665\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2335737901568413\n",
            "Accuracy on hold-out set: 0.57795\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2123459217250347\n",
            "Accuracy on hold-out set: 0.58805\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2735705779373645\n",
            "Accuracy on hold-out set: 0.5827\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2428857494175434\n",
            "Accuracy on hold-out set: 0.59585\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2943724615573884\n",
            "Accuracy on hold-out set: 0.58885\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.2943724615573884\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6241517860472203\n",
            "Accuracy on hold-out set: 0.42625\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4592028265245258\n",
            "Accuracy on hold-out set: 0.4769\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.460716102065146\n",
            "Accuracy on hold-out set: 0.50155\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3885693807464092\n",
            "Accuracy on hold-out set: 0.52695\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3896274809960276\n",
            "Accuracy on hold-out set: 0.53735\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4461288481116295\n",
            "Accuracy on hold-out set: 0.53265\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.565678896933794\n",
            "Accuracy on hold-out set: 0.515\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.565678896933794\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5181694858551025\n",
            "Accuracy on hold-out set: 0.4451\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.379303517818451\n",
            "Accuracy on hold-out set: 0.4992\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.273795227098465\n",
            "Accuracy on hold-out set: 0.54705\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.223690092229843\n",
            "Accuracy on hold-out set: 0.5596\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1684939398527145\n",
            "Accuracy on hold-out set: 0.58845\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2009043989896775\n",
            "Accuracy on hold-out set: 0.58255\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1873745938777924\n",
            "Accuracy on hold-out set: 0.59065\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1992963170289994\n",
            "Accuracy on hold-out set: 0.5997\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.1992963170289994\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5425608226776124\n",
            "Accuracy on hold-out set: 0.4364\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3653519318580627\n",
            "Accuracy on hold-out set: 0.50845\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3057786372184754\n",
            "Accuracy on hold-out set: 0.5389\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2293128355026246\n",
            "Accuracy on hold-out set: 0.56485\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2104837721824646\n",
            "Accuracy on hold-out set: 0.57285\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.152493030643463\n",
            "Accuracy on hold-out set: 0.5996\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1854483556747437\n",
            "Accuracy on hold-out set: 0.5902\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.163447966480255\n",
            "Accuracy on hold-out set: 0.59215\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.142925111579895\n",
            "Accuracy on hold-out set: 0.60175\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1343071883201599\n",
            "Accuracy on hold-out set: 0.6058\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1397748962402343\n",
            "Accuracy on hold-out set: 0.6117\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1377362020492554\n",
            "Accuracy on hold-out set: 0.60435\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.144771109008789\n",
            "Accuracy on hold-out set: 0.60825\n",
            "Early stopping at epoch 12\n",
            "Returned to Spot: Validation loss: 1.144771109008789\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.498005634585023\n",
            "Accuracy on hold-out set: 0.4649\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.403347427341342\n",
            "Accuracy on hold-out set: 0.50975\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3614539826344698\n",
            "Accuracy on hold-out set: 0.5241\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2862471849961206\n",
            "Accuracy on hold-out set: 0.5589\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2881805872287602\n",
            "Accuracy on hold-out set: 0.5678\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.426992641227506\n",
            "Accuracy on hold-out set: 0.5533\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.387200616992684\n",
            "Accuracy on hold-out set: 0.55605\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.387200616992684\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8996752311706544\n",
            "Accuracy on hold-out set: 0.2796\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7249443883419038\n",
            "Accuracy on hold-out set: 0.36375\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6521443661689759\n",
            "Accuracy on hold-out set: 0.39205\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5989459583759307\n",
            "Accuracy on hold-out set: 0.41325\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5661535689353943\n",
            "Accuracy on hold-out set: 0.42965\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5232501452684402\n",
            "Accuracy on hold-out set: 0.44695\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5020323537111282\n",
            "Accuracy on hold-out set: 0.4512\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4985460300683975\n",
            "Accuracy on hold-out set: 0.44565\n",
            "Returned to Spot: Validation loss: 1.4985460300683975\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6371902496337891\n",
            "Accuracy on hold-out set: 0.40335\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.518308176612854\n",
            "Accuracy on hold-out set: 0.445\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.423375466632843\n",
            "Accuracy on hold-out set: 0.479\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3418896615982057\n",
            "Accuracy on hold-out set: 0.51585\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.325735165119171\n",
            "Accuracy on hold-out set: 0.5246\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2699989066123962\n",
            "Accuracy on hold-out set: 0.5464\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2533328977584839\n",
            "Accuracy on hold-out set: 0.55165\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2776759857177735\n",
            "Accuracy on hold-out set: 0.5376\n",
            "Returned to Spot: Validation loss: 1.2776759857177735\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6049374629020692\n",
            "Accuracy on hold-out set: 0.41475\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4387849000930786\n",
            "Accuracy on hold-out set: 0.4801\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3875757174491883\n",
            "Accuracy on hold-out set: 0.49965\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3028630146026612\n",
            "Accuracy on hold-out set: 0.5351\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2579962118148804\n",
            "Accuracy on hold-out set: 0.5522\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2539483462333678\n",
            "Accuracy on hold-out set: 0.552\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2224314541816712\n",
            "Accuracy on hold-out set: 0.5698\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1951769271850585\n",
            "Accuracy on hold-out set: 0.5767\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2182769391059876\n",
            "Accuracy on hold-out set: 0.5781\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1674948411941528\n",
            "Accuracy on hold-out set: 0.5902\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1767007246017456\n",
            "Accuracy on hold-out set: 0.59165\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1403984539031982\n",
            "Accuracy on hold-out set: 0.6021\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1882352281570434\n",
            "Accuracy on hold-out set: 0.5913\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1601051022529603\n",
            "Accuracy on hold-out set: 0.60055\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1727241339683532\n",
            "Accuracy on hold-out set: 0.6024\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.1727241339683532\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3073683319091796\n",
            "Accuracy on hold-out set: 0.1011\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3040484935760497\n",
            "Accuracy on hold-out set: 0.10095\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3007104316711424\n",
            "Accuracy on hold-out set: 0.1004\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.29646725730896\n",
            "Accuracy on hold-out set: 0.0997\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.2896789318084716\n",
            "Accuracy on hold-out set: 0.10455\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.2777464687347413\n",
            "Accuracy on hold-out set: 0.151\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.2549375007629395\n",
            "Accuracy on hold-out set: 0.2127\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.21454864692688\n",
            "Accuracy on hold-out set: 0.21715\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.1620783273696897\n",
            "Accuracy on hold-out set: 0.2288\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 2.1183803789138795\n",
            "Accuracy on hold-out set: 0.24365\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 2.0887182083129883\n",
            "Accuracy on hold-out set: 0.25405\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 2.067874701499939\n",
            "Accuracy on hold-out set: 0.2654\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 2.0509524797439576\n",
            "Accuracy on hold-out set: 0.27075\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 2.0363433258056642\n",
            "Accuracy on hold-out set: 0.27695\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 2.021559307098389\n",
            "Accuracy on hold-out set: 0.28035\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 2.007887244796753\n",
            "Accuracy on hold-out set: 0.2868\n",
            "Returned to Spot: Validation loss: 2.007887244796753\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.750184523487091\n",
            "Accuracy on hold-out set: 0.3377\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6274240659236907\n",
            "Accuracy on hold-out set: 0.39965\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4960284255027771\n",
            "Accuracy on hold-out set: 0.45405\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4026235122680664\n",
            "Accuracy on hold-out set: 0.49135\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3703652822494508\n",
            "Accuracy on hold-out set: 0.50665\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3463135332584382\n",
            "Accuracy on hold-out set: 0.51195\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3185161617279053\n",
            "Accuracy on hold-out set: 0.52985\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2871342622756958\n",
            "Accuracy on hold-out set: 0.54615\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2872435281515122\n",
            "Accuracy on hold-out set: 0.5468\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2513831511974334\n",
            "Accuracy on hold-out set: 0.5615\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2492779797554017\n",
            "Accuracy on hold-out set: 0.5607\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2466432067871094\n",
            "Accuracy on hold-out set: 0.5622\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.216971099972725\n",
            "Accuracy on hold-out set: 0.574\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1871039266109467\n",
            "Accuracy on hold-out set: 0.5875\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2099360536336898\n",
            "Accuracy on hold-out set: 0.5812\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2010146763801575\n",
            "Accuracy on hold-out set: 0.5892\n",
            "Returned to Spot: Validation loss: 1.2010146763801575\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8866313009381295\n",
            "Accuracy on hold-out set: 0.313\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6951482662081718\n",
            "Accuracy on hold-out set: 0.3716\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6457433804690837\n",
            "Accuracy on hold-out set: 0.3931\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.582753262448311\n",
            "Accuracy on hold-out set: 0.42015\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.528596328228712\n",
            "Accuracy on hold-out set: 0.44205\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4902001852840185\n",
            "Accuracy on hold-out set: 0.46015\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4537991652399302\n",
            "Accuracy on hold-out set: 0.473\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4347720643758775\n",
            "Accuracy on hold-out set: 0.481\n",
            "Returned to Spot: Validation loss: 1.4347720643758775\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.561221460056305\n",
            "Accuracy on hold-out set: 0.4352\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3985091348171235\n",
            "Accuracy on hold-out set: 0.49695\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.30504801902771\n",
            "Accuracy on hold-out set: 0.53155\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2350982008934022\n",
            "Accuracy on hold-out set: 0.5632\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2223810575008391\n",
            "Accuracy on hold-out set: 0.5731\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2195272930145264\n",
            "Accuracy on hold-out set: 0.5779\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1797625741958617\n",
            "Accuracy on hold-out set: 0.58785\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1604455473661424\n",
            "Accuracy on hold-out set: 0.59785\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1801056304216384\n",
            "Accuracy on hold-out set: 0.59775\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1257864156723023\n",
            "Accuracy on hold-out set: 0.61065\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.106235738968849\n",
            "Accuracy on hold-out set: 0.61805\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1477371604681015\n",
            "Accuracy on hold-out set: 0.60305\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.175890897989273\n",
            "Accuracy on hold-out set: 0.60375\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1376556176662445\n",
            "Accuracy on hold-out set: 0.61065\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.1376556176662445\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4771126872867346\n",
            "Accuracy on hold-out set: 0.4681\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4233444997251035\n",
            "Accuracy on hold-out set: 0.49425\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3075232003170998\n",
            "Accuracy on hold-out set: 0.5397\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3077907603763044\n",
            "Accuracy on hold-out set: 0.5478\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2107497094865889\n",
            "Accuracy on hold-out set: 0.5811\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2253801564265043\n",
            "Accuracy on hold-out set: 0.5814\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.223645063018333\n",
            "Accuracy on hold-out set: 0.5954\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.236137861765665\n",
            "Accuracy on hold-out set: 0.59575\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.236137861765665\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5462997158885001\n",
            "Accuracy on hold-out set: 0.43515\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4312053140759469\n",
            "Accuracy on hold-out set: 0.47535\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4052794446259738\n",
            "Accuracy on hold-out set: 0.4919\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3173781046703459\n",
            "Accuracy on hold-out set: 0.5349\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2851589737445117\n",
            "Accuracy on hold-out set: 0.5424\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2683273570500315\n",
            "Accuracy on hold-out set: 0.5576\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2300940383277834\n",
            "Accuracy on hold-out set: 0.5617\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2369382193591445\n",
            "Accuracy on hold-out set: 0.572\n",
            "Returned to Spot: Validation loss: 1.2369382193591445\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 4, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3063893873691557\n",
            "Accuracy on hold-out set: 0.0989\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.308559471106529\n",
            "Accuracy on hold-out set: 0.0982\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3068284286737444\n",
            "Accuracy on hold-out set: 0.10165\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.30751236038208\n",
            "Accuracy on hold-out set: 0.0999\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 2.30751236038208\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5275451926231385\n",
            "Accuracy on hold-out set: 0.44675\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4686933908462525\n",
            "Accuracy on hold-out set: 0.48375\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4074237362980841\n",
            "Accuracy on hold-out set: 0.5056\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3682212901353836\n",
            "Accuracy on hold-out set: 0.5201\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.419074964773655\n",
            "Accuracy on hold-out set: 0.5081\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4344625356256961\n",
            "Accuracy on hold-out set: 0.5097\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3938249544918537\n",
            "Accuracy on hold-out set: 0.53305\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.3938249544918537\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.303538416719437\n",
            "Accuracy on hold-out set: 0.09845\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3032541460037232\n",
            "Accuracy on hold-out set: 0.0983\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.303100075340271\n",
            "Accuracy on hold-out set: 0.0995\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3030240459918976\n",
            "Accuracy on hold-out set: 0.0983\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3028433530807497\n",
            "Accuracy on hold-out set: 0.09865\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.302881181716919\n",
            "Accuracy on hold-out set: 0.09865\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.302718784046173\n",
            "Accuracy on hold-out set: 0.09775\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.3030933809757235\n",
            "Accuracy on hold-out set: 0.09775\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.302875566005707\n",
            "Accuracy on hold-out set: 0.0983\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 2.3030301584243773\n",
            "Accuracy on hold-out set: 0.09775\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 2.3030301584243773\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5506917306691408\n",
            "Accuracy on hold-out set: 0.4501\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4431614993020891\n",
            "Accuracy on hold-out set: 0.4822\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.409768799155578\n",
            "Accuracy on hold-out set: 0.5117\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4042319380022585\n",
            "Accuracy on hold-out set: 0.51405\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4383735240273177\n",
            "Accuracy on hold-out set: 0.52435\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4242175784752238\n",
            "Accuracy on hold-out set: 0.5218\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4014343814287336\n",
            "Accuracy on hold-out set: 0.53765\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4452823349576442\n",
            "Accuracy on hold-out set: 0.52645\n",
            "Returned to Spot: Validation loss: 1.4452823349576442\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.953731158399582\n",
            "Accuracy on hold-out set: 0.20665\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8969827297687532\n",
            "Accuracy on hold-out set: 0.20825\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8802854177713395\n",
            "Accuracy on hold-out set: 0.23725\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7616186519265176\n",
            "Accuracy on hold-out set: 0.28285\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.648424945473671\n",
            "Accuracy on hold-out set: 0.3446\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6315983254671096\n",
            "Accuracy on hold-out set: 0.3555\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6199706590771674\n",
            "Accuracy on hold-out set: 0.3695\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5719927104115485\n",
            "Accuracy on hold-out set: 0.38895\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5511470496714115\n",
            "Accuracy on hold-out set: 0.43775\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.460487761053443\n",
            "Accuracy on hold-out set: 0.46545\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3848848237425089\n",
            "Accuracy on hold-out set: 0.4932\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3960648743785917\n",
            "Accuracy on hold-out set: 0.50045\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3715535350695252\n",
            "Accuracy on hold-out set: 0.5099\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3517655676819385\n",
            "Accuracy on hold-out set: 0.51495\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3514829103320838\n",
            "Accuracy on hold-out set: 0.5272\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3223768081896008\n",
            "Accuracy on hold-out set: 0.5332\n",
            "Returned to Spot: Validation loss: 1.3223768081896008\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5622796404444845\n",
            "Accuracy on hold-out set: 0.4497\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4974991613344988\n",
            "Accuracy on hold-out set: 0.5128\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4676541835412211\n",
            "Accuracy on hold-out set: 0.5413\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3837753149452447\n",
            "Accuracy on hold-out set: 0.55315\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.520225548533058\n",
            "Accuracy on hold-out set: 0.551\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5555363441528114\n",
            "Accuracy on hold-out set: 0.56855\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.441870403451889\n",
            "Accuracy on hold-out set: 0.57415\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.441870403451889\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 32, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7774910228893162\n",
            "Accuracy on hold-out set: 0.3335\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7209069061860442\n",
            "Accuracy on hold-out set: 0.35745\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6782685526907444\n",
            "Accuracy on hold-out set: 0.36965\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6503943256229163\n",
            "Accuracy on hold-out set: 0.39065\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6161307288385929\n",
            "Accuracy on hold-out set: 0.4004\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6071019567534328\n",
            "Accuracy on hold-out set: 0.40375\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5855264440424741\n",
            "Accuracy on hold-out set: 0.41695\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.57584217694439\n",
            "Accuracy on hold-out set: 0.4201\n",
            "Returned to Spot: Validation loss: 1.57584217694439\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 256, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4212787635803223\n",
            "Accuracy on hold-out set: 0.48415\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.274293130016327\n",
            "Accuracy on hold-out set: 0.54415\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3009635807037354\n",
            "Accuracy on hold-out set: 0.54615\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1812438360214232\n",
            "Accuracy on hold-out set: 0.58395\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1995626517295837\n",
            "Accuracy on hold-out set: 0.58475\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1533737558364867\n",
            "Accuracy on hold-out set: 0.5986\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.17288822889328\n",
            "Accuracy on hold-out set: 0.5962\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2084982520103456\n",
            "Accuracy on hold-out set: 0.5911\n",
            "Returned to Spot: Validation loss: 1.2084982520103456\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5373321282863617\n",
            "Accuracy on hold-out set: 0.43475\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4373124559402466\n",
            "Accuracy on hold-out set: 0.4714\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.320429892730713\n",
            "Accuracy on hold-out set: 0.5263\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2613328137874604\n",
            "Accuracy on hold-out set: 0.5467\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2030889254570007\n",
            "Accuracy on hold-out set: 0.5719\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1671998081445694\n",
            "Accuracy on hold-out set: 0.584\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.169320712208748\n",
            "Accuracy on hold-out set: 0.5874\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1404140883684157\n",
            "Accuracy on hold-out set: 0.59825\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1288581048727035\n",
            "Accuracy on hold-out set: 0.6042\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1213185411930084\n",
            "Accuracy on hold-out set: 0.61155\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1127535119652747\n",
            "Accuracy on hold-out set: 0.6122\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1065883630275726\n",
            "Accuracy on hold-out set: 0.613\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1182513360023498\n",
            "Accuracy on hold-out set: 0.6163\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1042215604543686\n",
            "Accuracy on hold-out set: 0.6226\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.0901628471374512\n",
            "Accuracy on hold-out set: 0.6244\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1114530757188796\n",
            "Accuracy on hold-out set: 0.62185\n",
            "Returned to Spot: Validation loss: 1.1114530757188796\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.42098654024899\n",
            "Accuracy on hold-out set: 0.4855\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3798689164742828\n",
            "Accuracy on hold-out set: 0.52795\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.316818562527746\n",
            "Accuracy on hold-out set: 0.5536\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2904409725129604\n",
            "Accuracy on hold-out set: 0.56895\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2970825341533607\n",
            "Accuracy on hold-out set: 0.58065\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3659409132530913\n",
            "Accuracy on hold-out set: 0.5707\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3604332412565825\n",
            "Accuracy on hold-out set: 0.57975\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.3604332412565825\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7212781350307083\n",
            "Accuracy on hold-out set: 0.4443\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6012003084525723\n",
            "Accuracy on hold-out set: 0.48465\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6592152697887217\n",
            "Accuracy on hold-out set: 0.4662\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.738575368434089\n",
            "Accuracy on hold-out set: 0.47845\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.7426140279930635\n",
            "Accuracy on hold-out set: 0.48935\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 1.7426140279930635\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5143088665187359\n",
            "Accuracy on hold-out set: 0.45415\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3518008447259664\n",
            "Accuracy on hold-out set: 0.51385\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3091716821849346\n",
            "Accuracy on hold-out set: 0.5373\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2554858518447727\n",
            "Accuracy on hold-out set: 0.56445\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.269571713554114\n",
            "Accuracy on hold-out set: 0.5692\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.254422923278436\n",
            "Accuracy on hold-out set: 0.5723\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2011118310928344\n",
            "Accuracy on hold-out set: 0.59535\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2146024383335374\n",
            "Accuracy on hold-out set: 0.58935\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2011684569854288\n",
            "Accuracy on hold-out set: 0.59715\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.207207911168551\n",
            "Accuracy on hold-out set: 0.6056\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.207207911168551\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 32, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9410781812548636\n",
            "Accuracy on hold-out set: 0.1965\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.920707550907135\n",
            "Accuracy on hold-out set: 0.19725\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.9200753091931344\n",
            "Accuracy on hold-out set: 0.19685\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.9073315249323846\n",
            "Accuracy on hold-out set: 0.2091\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.8902986519396305\n",
            "Accuracy on hold-out set: 0.2136\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.8906994865417481\n",
            "Accuracy on hold-out set: 0.2104\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.90805203871727\n",
            "Accuracy on hold-out set: 0.21545\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.8787746960163116\n",
            "Accuracy on hold-out set: 0.2168\n",
            "Returned to Spot: Validation loss: 1.8787746960163116\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3037843761444092\n",
            "Accuracy on hold-out set: 0.1017\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.304825546836853\n",
            "Accuracy on hold-out set: 0.09525\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3044944108963015\n",
            "Accuracy on hold-out set: 0.10125\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.305172007751465\n",
            "Accuracy on hold-out set: 0.09885\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 2.305172007751465\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3042871296882628\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.304993378162384\n",
            "Accuracy on hold-out set: 0.0977\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.308041664028168\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3041168640136718\n",
            "Accuracy on hold-out set: 0.0977\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3054714099884035\n",
            "Accuracy on hold-out set: 0.0977\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.30446598815918\n",
            "Accuracy on hold-out set: 0.09755\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3035652460098266\n",
            "Accuracy on hold-out set: 0.10305\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.3041932072639466\n",
            "Accuracy on hold-out set: 0.0977\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.305127164554596\n",
            "Accuracy on hold-out set: 0.1\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 2.3037624966621397\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 2.3037624966621397\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6076676829338075\n",
            "Accuracy on hold-out set: 0.4161\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4520313958287239\n",
            "Accuracy on hold-out set: 0.4702\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3808521480083467\n",
            "Accuracy on hold-out set: 0.50475\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3183909628152848\n",
            "Accuracy on hold-out set: 0.53775\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3285080416202546\n",
            "Accuracy on hold-out set: 0.5327\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2590900740742683\n",
            "Accuracy on hold-out set: 0.5564\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3087130704402923\n",
            "Accuracy on hold-out set: 0.54775\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2347517329573632\n",
            "Accuracy on hold-out set: 0.57505\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.232116257572174\n",
            "Accuracy on hold-out set: 0.5736\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2380729179978371\n",
            "Accuracy on hold-out set: 0.57415\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2311173042476178\n",
            "Accuracy on hold-out set: 0.5755\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2379531722426413\n",
            "Accuracy on hold-out set: 0.5697\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2651948838174343\n",
            "Accuracy on hold-out set: 0.5671\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.251974629715085\n",
            "Accuracy on hold-out set: 0.57735\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.251974629715085\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4292097782969475\n",
            "Accuracy on hold-out set: 0.4859\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4299378589067608\n",
            "Accuracy on hold-out set: 0.5135\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.25269008474797\n",
            "Accuracy on hold-out set: 0.558\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2497299237627537\n",
            "Accuracy on hold-out set: 0.57465\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3470554819425569\n",
            "Accuracy on hold-out set: 0.56595\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3489594885402825\n",
            "Accuracy on hold-out set: 0.5646\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2920117991585518\n",
            "Accuracy on hold-out set: 0.5826\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.2920117991585518\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6472527723625303\n",
            "Accuracy on hold-out set: 0.45335\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5529102395661176\n",
            "Accuracy on hold-out set: 0.48785\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4632499656185507\n",
            "Accuracy on hold-out set: 0.525\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.468770239558816\n",
            "Accuracy on hold-out set: 0.54425\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6240928226720541\n",
            "Accuracy on hold-out set: 0.53305\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5559264411006937\n",
            "Accuracy on hold-out set: 0.5492\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.5559264411006937\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9148904211997986\n",
            "Accuracy on hold-out set: 0.22555\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5582738692998885\n",
            "Accuracy on hold-out set: 0.4128\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4099077711820602\n",
            "Accuracy on hold-out set: 0.47545\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3491214919567107\n",
            "Accuracy on hold-out set: 0.50195\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.323243494462967\n",
            "Accuracy on hold-out set: 0.5041\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.303819677066803\n",
            "Accuracy on hold-out set: 0.5206\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3688492013216018\n",
            "Accuracy on hold-out set: 0.50685\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2904726285338401\n",
            "Accuracy on hold-out set: 0.52935\n",
            "Returned to Spot: Validation loss: 1.2904726285338401\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9727523105621338\n",
            "Accuracy on hold-out set: 0.1752\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.9305222400665283\n",
            "Accuracy on hold-out set: 0.17565\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.9114757286071777\n",
            "Accuracy on hold-out set: 0.18955\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.8914893795013428\n",
            "Accuracy on hold-out set: 0.19155\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.889286555480957\n",
            "Accuracy on hold-out set: 0.19285\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.8780929454803468\n",
            "Accuracy on hold-out set: 0.1985\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.8736898485183715\n",
            "Accuracy on hold-out set: 0.1997\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.867564817237854\n",
            "Accuracy on hold-out set: 0.2014\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.8655082540512085\n",
            "Accuracy on hold-out set: 0.20755\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.8836311521530151\n",
            "Accuracy on hold-out set: 0.19765\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.8649361082077027\n",
            "Accuracy on hold-out set: 0.2071\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.8587366554260254\n",
            "Accuracy on hold-out set: 0.2114\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.856347918510437\n",
            "Accuracy on hold-out set: 0.20885\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.8530538597106934\n",
            "Accuracy on hold-out set: 0.21185\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.8558166772842408\n",
            "Accuracy on hold-out set: 0.2123\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.850008839416504\n",
            "Accuracy on hold-out set: 0.21455\n",
            "Returned to Spot: Validation loss: 1.850008839416504\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 512, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.304157383918762\n",
            "Accuracy on hold-out set: 0.0981\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3032168684005736\n",
            "Accuracy on hold-out set: 0.09885\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3028516735076905\n",
            "Accuracy on hold-out set: 0.1019\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.306790686035156\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.303899213409424\n",
            "Accuracy on hold-out set: 0.0981\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.303080154418945\n",
            "Accuracy on hold-out set: 0.0974\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 2.303080154418945\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5398323123693467\n",
            "Accuracy on hold-out set: 0.43665\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3870602988004685\n",
            "Accuracy on hold-out set: 0.5014\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3122947651028634\n",
            "Accuracy on hold-out set: 0.5299\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2517879324316978\n",
            "Accuracy on hold-out set: 0.54735\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2314388111948966\n",
            "Accuracy on hold-out set: 0.5684\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1863948047548531\n",
            "Accuracy on hold-out set: 0.58865\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2277886157989502\n",
            "Accuracy on hold-out set: 0.5797\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1957812935441732\n",
            "Accuracy on hold-out set: 0.5907\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1690481638371943\n",
            "Accuracy on hold-out set: 0.59035\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.171545439952612\n",
            "Accuracy on hold-out set: 0.5917\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1727588521338999\n",
            "Accuracy on hold-out set: 0.5982\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1562757790654898\n",
            "Accuracy on hold-out set: 0.6001\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1732215296804904\n",
            "Accuracy on hold-out set: 0.59345\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1633455670058728\n",
            "Accuracy on hold-out set: 0.60805\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1646192997455598\n",
            "Accuracy on hold-out set: 0.6156\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.1646192997455598\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5388175529479982\n",
            "Accuracy on hold-out set: 0.43265\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4274013637542724\n",
            "Accuracy on hold-out set: 0.485\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3092075945854187\n",
            "Accuracy on hold-out set: 0.5226\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3009651268482207\n",
            "Accuracy on hold-out set: 0.5432\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.229407422065735\n",
            "Accuracy on hold-out set: 0.5696\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2184944765806198\n",
            "Accuracy on hold-out set: 0.56625\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.263879667210579\n",
            "Accuracy on hold-out set: 0.54985\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2043298978567123\n",
            "Accuracy on hold-out set: 0.576\n",
            "Returned to Spot: Validation loss: 1.2043298978567123\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7360503652572632\n",
            "Accuracy on hold-out set: 0.35125\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.47475791721344\n",
            "Accuracy on hold-out set: 0.45595\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3738248392105104\n",
            "Accuracy on hold-out set: 0.50145\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2903932643890381\n",
            "Accuracy on hold-out set: 0.5395\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2238141695022584\n",
            "Accuracy on hold-out set: 0.5638\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.270213472366333\n",
            "Accuracy on hold-out set: 0.5464\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.198199806213379\n",
            "Accuracy on hold-out set: 0.58415\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.175694759273529\n",
            "Accuracy on hold-out set: 0.59085\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1970872422218324\n",
            "Accuracy on hold-out set: 0.59705\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.227481926727295\n",
            "Accuracy on hold-out set: 0.5922\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3253433572769164\n",
            "Accuracy on hold-out set: 0.58315\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.3253433572769164\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8232013108611107\n",
            "Accuracy on hold-out set: 0.3174\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.747858207988739\n",
            "Accuracy on hold-out set: 0.34215\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7073005930185319\n",
            "Accuracy on hold-out set: 0.3554\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.689059035897255\n",
            "Accuracy on hold-out set: 0.3608\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.657058822786808\n",
            "Accuracy on hold-out set: 0.37175\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6441811374783515\n",
            "Accuracy on hold-out set: 0.37555\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.633770427954197\n",
            "Accuracy on hold-out set: 0.37865\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.625346475481987\n",
            "Accuracy on hold-out set: 0.383\n",
            "Returned to Spot: Validation loss: 1.625346475481987\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4540505442142486\n",
            "Accuracy on hold-out set: 0.47095\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3438803814411164\n",
            "Accuracy on hold-out set: 0.50645\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2691909825086594\n",
            "Accuracy on hold-out set: 0.54025\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2620313144207\n",
            "Accuracy on hold-out set: 0.5513\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1979516406774522\n",
            "Accuracy on hold-out set: 0.5759\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2039161123514175\n",
            "Accuracy on hold-out set: 0.57515\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2485915465116502\n",
            "Accuracy on hold-out set: 0.5741\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2324965363025666\n",
            "Accuracy on hold-out set: 0.5763\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.2324965363025666\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.304122998046875\n",
            "Accuracy on hold-out set: 0.1034\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.305826727247238\n",
            "Accuracy on hold-out set: 0.09775\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.305155604314804\n",
            "Accuracy on hold-out set: 0.09775\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3062572593688966\n",
            "Accuracy on hold-out set: 0.1022\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 2.3062572593688966\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.52158621571064\n",
            "Accuracy on hold-out set: 0.45345\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.395824773454666\n",
            "Accuracy on hold-out set: 0.49875\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.326049093425274\n",
            "Accuracy on hold-out set: 0.5235\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.323908080124855\n",
            "Accuracy on hold-out set: 0.53145\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2830310029268264\n",
            "Accuracy on hold-out set: 0.5446\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.234882879114151\n",
            "Accuracy on hold-out set: 0.557\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2505154343247413\n",
            "Accuracy on hold-out set: 0.5606\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2225658789277076\n",
            "Accuracy on hold-out set: 0.5689\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2584256109774112\n",
            "Accuracy on hold-out set: 0.5634\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2340450095713138\n",
            "Accuracy on hold-out set: 0.5681\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2301123309910298\n",
            "Accuracy on hold-out set: 0.57515\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.2301123309910298\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 512, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5647208172321319\n",
            "Accuracy on hold-out set: 0.4502\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.41212810921669\n",
            "Accuracy on hold-out set: 0.48965\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3570252238273621\n",
            "Accuracy on hold-out set: 0.514\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3750980436563491\n",
            "Accuracy on hold-out set: 0.5202\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3492363644123078\n",
            "Accuracy on hold-out set: 0.53195\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3135118867635727\n",
            "Accuracy on hold-out set: 0.55015\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.348571546638012\n",
            "Accuracy on hold-out set: 0.54015\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2927060495316982\n",
            "Accuracy on hold-out set: 0.55895\n",
            "Returned to Spot: Validation loss: 1.2927060495316982\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6430083564662505\n",
            "Accuracy on hold-out set: 0.4313\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7271609703926136\n",
            "Accuracy on hold-out set: 0.42155\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8405172292094802\n",
            "Accuracy on hold-out set: 0.42315\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.654421294391975\n",
            "Accuracy on hold-out set: 0.45925\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 1.654421294391975\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5865926076889039\n",
            "Accuracy on hold-out set: 0.4073\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4439079969406128\n",
            "Accuracy on hold-out set: 0.47535\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3472782033920288\n",
            "Accuracy on hold-out set: 0.5169\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2893571197509766\n",
            "Accuracy on hold-out set: 0.53905\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2480729063987732\n",
            "Accuracy on hold-out set: 0.55245\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2359907015800475\n",
            "Accuracy on hold-out set: 0.56265\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2405174235343932\n",
            "Accuracy on hold-out set: 0.56715\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1938470015525817\n",
            "Accuracy on hold-out set: 0.57565\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2155121428489686\n",
            "Accuracy on hold-out set: 0.5761\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1705283569335938\n",
            "Accuracy on hold-out set: 0.5921\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1939844305992127\n",
            "Accuracy on hold-out set: 0.5864\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1837110964775086\n",
            "Accuracy on hold-out set: 0.5875\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1710249751091004\n",
            "Accuracy on hold-out set: 0.59525\n",
            "Early stopping at epoch 12\n",
            "Returned to Spot: Validation loss: 1.1710249751091004\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7078978462219239\n",
            "Accuracy on hold-out set: 0.3481\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5681962364196778\n",
            "Accuracy on hold-out set: 0.4122\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4824687181472778\n",
            "Accuracy on hold-out set: 0.44935\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4536312713623047\n",
            "Accuracy on hold-out set: 0.45375\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.414442371749878\n",
            "Accuracy on hold-out set: 0.47335\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3786237909317016\n",
            "Accuracy on hold-out set: 0.4867\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3728510863304138\n",
            "Accuracy on hold-out set: 0.4923\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3160739988327026\n",
            "Accuracy on hold-out set: 0.51705\n",
            "Returned to Spot: Validation loss: 1.3160739988327026\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4933741379877552\n",
            "Accuracy on hold-out set: 0.4608\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4762383963832282\n",
            "Accuracy on hold-out set: 0.5111\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5663646753209803\n",
            "Accuracy on hold-out set: 0.5001\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4959214724200995\n",
            "Accuracy on hold-out set: 0.53845\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.460193707054422\n",
            "Accuracy on hold-out set: 0.54025\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5044411915019982\n",
            "Accuracy on hold-out set: 0.53905\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4109389152420437\n",
            "Accuracy on hold-out set: 0.56245\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4650310018519994\n",
            "Accuracy on hold-out set: 0.55935\n",
            "Returned to Spot: Validation loss: 1.4650310018519994\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6778512907028198\n",
            "Accuracy on hold-out set: 0.3735\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.599490680551529\n",
            "Accuracy on hold-out set: 0.40745\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5565973701477052\n",
            "Accuracy on hold-out set: 0.42315\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5387566266536712\n",
            "Accuracy on hold-out set: 0.4325\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5161721291065215\n",
            "Accuracy on hold-out set: 0.43925\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5078464179515838\n",
            "Accuracy on hold-out set: 0.4437\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4842810555458068\n",
            "Accuracy on hold-out set: 0.4519\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4702480583667754\n",
            "Accuracy on hold-out set: 0.459\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4794183755397796\n",
            "Accuracy on hold-out set: 0.45435\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4547886926174163\n",
            "Accuracy on hold-out set: 0.46295\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4505071300506591\n",
            "Accuracy on hold-out set: 0.46495\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4454292232513428\n",
            "Accuracy on hold-out set: 0.46745\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4375420634269713\n",
            "Accuracy on hold-out set: 0.47095\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.433552361536026\n",
            "Accuracy on hold-out set: 0.46955\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4323618627071382\n",
            "Accuracy on hold-out set: 0.4704\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.428906838607788\n",
            "Accuracy on hold-out set: 0.4731\n",
            "Returned to Spot: Validation loss: 1.428906838607788\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.530536161994934\n",
            "Accuracy on hold-out set: 0.44095\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3298284816265107\n",
            "Accuracy on hold-out set: 0.51935\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.250396908903122\n",
            "Accuracy on hold-out set: 0.5532\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2339783846616745\n",
            "Accuracy on hold-out set: 0.56085\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2021427371025086\n",
            "Accuracy on hold-out set: 0.57065\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1874466591358184\n",
            "Accuracy on hold-out set: 0.5796\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1613131489515305\n",
            "Accuracy on hold-out set: 0.5944\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1399048999547958\n",
            "Accuracy on hold-out set: 0.59635\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1845263384103775\n",
            "Accuracy on hold-out set: 0.59765\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.148610096359253\n",
            "Accuracy on hold-out set: 0.60715\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1306088001966477\n",
            "Accuracy on hold-out set: 0.6097\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1863287952184678\n",
            "Accuracy on hold-out set: 0.60715\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1394848053216935\n",
            "Accuracy on hold-out set: 0.616\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.15967165453434\n",
            "Accuracy on hold-out set: 0.6128\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.15967165453434\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4989009753122926\n",
            "Accuracy on hold-out set: 0.46845\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.2841639458313585\n",
            "Accuracy on hold-out set: 0.54195\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2077525016915054\n",
            "Accuracy on hold-out set: 0.57655\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1747853047985584\n",
            "Accuracy on hold-out set: 0.5915\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2328275906844997\n",
            "Accuracy on hold-out set: 0.58845\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2399039155687672\n",
            "Accuracy on hold-out set: 0.5937\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2723599006139674\n",
            "Accuracy on hold-out set: 0.60365\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.2723599006139674\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4924836164951325\n",
            "Accuracy on hold-out set: 0.4558\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4125590232908727\n",
            "Accuracy on hold-out set: 0.4954\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3542744407907128\n",
            "Accuracy on hold-out set: 0.5232\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2867797380149364\n",
            "Accuracy on hold-out set: 0.5459\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3116497287742794\n",
            "Accuracy on hold-out set: 0.54805\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2732638910714538\n",
            "Accuracy on hold-out set: 0.5623\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2447693407798186\n",
            "Accuracy on hold-out set: 0.57805\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2331455897878856\n",
            "Accuracy on hold-out set: 0.57855\n",
            "Returned to Spot: Validation loss: 1.2331455897878856\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7578192044258119\n",
            "Accuracy on hold-out set: 0.34275\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.69700250082016\n",
            "Accuracy on hold-out set: 0.3767\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.671019698905945\n",
            "Accuracy on hold-out set: 0.39335\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6364626474380493\n",
            "Accuracy on hold-out set: 0.4033\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.612526844406128\n",
            "Accuracy on hold-out set: 0.41395\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5989798526763916\n",
            "Accuracy on hold-out set: 0.4219\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5774082545280457\n",
            "Accuracy on hold-out set: 0.43035\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5653038432121278\n",
            "Accuracy on hold-out set: 0.4358\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5529747223377228\n",
            "Accuracy on hold-out set: 0.4385\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.5388169478416442\n",
            "Accuracy on hold-out set: 0.44185\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.527562664270401\n",
            "Accuracy on hold-out set: 0.4494\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.5186682629585266\n",
            "Accuracy on hold-out set: 0.45205\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.5115684184074403\n",
            "Accuracy on hold-out set: 0.4547\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.5093539669036866\n",
            "Accuracy on hold-out set: 0.45425\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4968307788848878\n",
            "Accuracy on hold-out set: 0.45945\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.49179454870224\n",
            "Accuracy on hold-out set: 0.46365\n",
            "Returned to Spot: Validation loss: 1.49179454870224\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5217315648406744\n",
            "Accuracy on hold-out set: 0.45425\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.40849339042902\n",
            "Accuracy on hold-out set: 0.4902\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3771704542607068\n",
            "Accuracy on hold-out set: 0.50365\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3941959332987666\n",
            "Accuracy on hold-out set: 0.5096\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3888459950238465\n",
            "Accuracy on hold-out set: 0.51135\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.431450141568482\n",
            "Accuracy on hold-out set: 0.48955\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.431450141568482\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 512, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6104756279585382\n",
            "Accuracy on hold-out set: 0.4636\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6808450419553373\n",
            "Accuracy on hold-out set: 0.49365\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7478850011683336\n",
            "Accuracy on hold-out set: 0.52445\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6563402631822006\n",
            "Accuracy on hold-out set: 0.54125\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 1.6563402631822006\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.0219825143814085\n",
            "Accuracy on hold-out set: 0.2553\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.9018852526664733\n",
            "Accuracy on hold-out set: 0.3095\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7905616638183595\n",
            "Accuracy on hold-out set: 0.3396\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7344708536148072\n",
            "Accuracy on hold-out set: 0.368\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6660429109573365\n",
            "Accuracy on hold-out set: 0.3883\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6460780727386475\n",
            "Accuracy on hold-out set: 0.4015\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.585593430185318\n",
            "Accuracy on hold-out set: 0.41835\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5576069557666778\n",
            "Accuracy on hold-out set: 0.4315\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5452011517047881\n",
            "Accuracy on hold-out set: 0.43755\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.5086071786880493\n",
            "Accuracy on hold-out set: 0.4553\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.498999879360199\n",
            "Accuracy on hold-out set: 0.45245\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4738265081882478\n",
            "Accuracy on hold-out set: 0.4704\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4731618262290955\n",
            "Accuracy on hold-out set: 0.47085\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.4495282408714294\n",
            "Accuracy on hold-out set: 0.47175\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4409708000659942\n",
            "Accuracy on hold-out set: 0.4804\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.4052669047355653\n",
            "Accuracy on hold-out set: 0.4948\n",
            "Returned to Spot: Validation loss: 1.4052669047355653\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3041608530044555\n",
            "Accuracy on hold-out set: 0.0979\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.306294660949707\n",
            "Accuracy on hold-out set: 0.0996\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3034998443603514\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.304002784729004\n",
            "Accuracy on hold-out set: 0.0979\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3055611389160156\n",
            "Accuracy on hold-out set: 0.0979\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.303327419662476\n",
            "Accuracy on hold-out set: 0.0988\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.304822031211853\n",
            "Accuracy on hold-out set: 0.10055\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.304637191581726\n",
            "Accuracy on hold-out set: 0.098\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.3050164306640624\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 2.3050164306640624\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5998857880830766\n",
            "Accuracy on hold-out set: 0.40595\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4412417143583298\n",
            "Accuracy on hold-out set: 0.48195\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.361919061565399\n",
            "Accuracy on hold-out set: 0.50655\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.279825031095743\n",
            "Accuracy on hold-out set: 0.5434\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.258393794876337\n",
            "Accuracy on hold-out set: 0.55435\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2472006008028984\n",
            "Accuracy on hold-out set: 0.55765\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2051046716451645\n",
            "Accuracy on hold-out set: 0.58075\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1694412882447243\n",
            "Accuracy on hold-out set: 0.58915\n",
            "Returned to Spot: Validation loss: 1.1694412882447243\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5757478761672974\n",
            "Accuracy on hold-out set: 0.414\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4464427822113037\n",
            "Accuracy on hold-out set: 0.46425\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3680167848587037\n",
            "Accuracy on hold-out set: 0.4973\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2980066529273986\n",
            "Accuracy on hold-out set: 0.52705\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3225006830215453\n",
            "Accuracy on hold-out set: 0.51595\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.289401413154602\n",
            "Accuracy on hold-out set: 0.5356\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2202106402397155\n",
            "Accuracy on hold-out set: 0.56475\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2046834774017334\n",
            "Accuracy on hold-out set: 0.5715\n",
            "Returned to Spot: Validation loss: 1.2046834774017334\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5858315490484238\n",
            "Accuracy on hold-out set: 0.4199\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4696975662589074\n",
            "Accuracy on hold-out set: 0.4759\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.375021151649952\n",
            "Accuracy on hold-out set: 0.5044\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.29860542178154\n",
            "Accuracy on hold-out set: 0.53505\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2804572850465774\n",
            "Accuracy on hold-out set: 0.54025\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.231625075662136\n",
            "Accuracy on hold-out set: 0.5618\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.27134655880332\n",
            "Accuracy on hold-out set: 0.55225\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2430433701574803\n",
            "Accuracy on hold-out set: 0.565\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.220202393490076\n",
            "Accuracy on hold-out set: 0.57155\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.20793090711236\n",
            "Accuracy on hold-out set: 0.5779\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.209109681174159\n",
            "Accuracy on hold-out set: 0.5817\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1701948353230953\n",
            "Accuracy on hold-out set: 0.59\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.183091149908304\n",
            "Accuracy on hold-out set: 0.5901\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1656337177574634\n",
            "Accuracy on hold-out set: 0.59525\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2479875298321248\n",
            "Accuracy on hold-out set: 0.56865\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.168595176011324\n",
            "Accuracy on hold-out set: 0.59435\n",
            "Returned to Spot: Validation loss: 1.168595176011324\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5357998548984528\n",
            "Accuracy on hold-out set: 0.4452\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4648635320663452\n",
            "Accuracy on hold-out set: 0.47075\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4062651535987853\n",
            "Accuracy on hold-out set: 0.4923\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3888315836906433\n",
            "Accuracy on hold-out set: 0.5059\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3401374880313874\n",
            "Accuracy on hold-out set: 0.52155\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.324059831237793\n",
            "Accuracy on hold-out set: 0.52855\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3097679891347884\n",
            "Accuracy on hold-out set: 0.53335\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2931789595603942\n",
            "Accuracy on hold-out set: 0.53795\n",
            "Returned to Spot: Validation loss: 1.2931789595603942\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.629646977668442\n",
            "Accuracy on hold-out set: 0.44695\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5107221253795957\n",
            "Accuracy on hold-out set: 0.49985\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4467120906212894\n",
            "Accuracy on hold-out set: 0.52885\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3737020508854003\n",
            "Accuracy on hold-out set: 0.5669\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4002753294698396\n",
            "Accuracy on hold-out set: 0.5632\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4848782179378206\n",
            "Accuracy on hold-out set: 0.5725\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4349076241338454\n",
            "Accuracy on hold-out set: 0.5645\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.4349076241338454\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4979342719495297\n",
            "Accuracy on hold-out set: 0.47045\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3431506367914379\n",
            "Accuracy on hold-out set: 0.5267\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3041774905721657\n",
            "Accuracy on hold-out set: 0.5529\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.335416366912704\n",
            "Accuracy on hold-out set: 0.5611\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.254655513458699\n",
            "Accuracy on hold-out set: 0.583\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3392748064721003\n",
            "Accuracy on hold-out set: 0.59095\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3372347673418001\n",
            "Accuracy on hold-out set: 0.5766\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4033226922249422\n",
            "Accuracy on hold-out set: 0.57055\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.4033226922249422\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5621371519327163\n",
            "Accuracy on hold-out set: 0.43955\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4242866532921792\n",
            "Accuracy on hold-out set: 0.4872\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3059491448640823\n",
            "Accuracy on hold-out set: 0.52855\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2969093305945396\n",
            "Accuracy on hold-out set: 0.54145\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2176781302988529\n",
            "Accuracy on hold-out set: 0.57215\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2510699864983559\n",
            "Accuracy on hold-out set: 0.56405\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1810030585467814\n",
            "Accuracy on hold-out set: 0.5888\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2355190081864595\n",
            "Accuracy on hold-out set: 0.58255\n",
            "Returned to Spot: Validation loss: 1.2355190081864595\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.2450959120750427\n",
            "Accuracy on hold-out set: 0.13785\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.1213084224700927\n",
            "Accuracy on hold-out set: 0.16505\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.129375580883026\n",
            "Accuracy on hold-out set: 0.18395\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.270859609746933\n",
            "Accuracy on hold-out set: 0.18425\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.1063760048389435\n",
            "Accuracy on hold-out set: 0.20325\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.1273734803199766\n",
            "Accuracy on hold-out set: 0.17755\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.0496293308734894\n",
            "Accuracy on hold-out set: 0.20945\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.0152606115818026\n",
            "Accuracy on hold-out set: 0.18845\n",
            "Returned to Spot: Validation loss: 2.0152606115818026\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4152539073467254\n",
            "Accuracy on hold-out set: 0.48295\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.372136128091812\n",
            "Accuracy on hold-out set: 0.50535\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2909401023864746\n",
            "Accuracy on hold-out set: 0.5628\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.265966312623024\n",
            "Accuracy on hold-out set: 0.5778\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2104014053344727\n",
            "Accuracy on hold-out set: 0.5992\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3242861052751542\n",
            "Accuracy on hold-out set: 0.5866\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2984056777358055\n",
            "Accuracy on hold-out set: 0.59805\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4162714557647704\n",
            "Accuracy on hold-out set: 0.5951\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.4162714557647704\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4641644013226032\n",
            "Accuracy on hold-out set: 0.47055\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3270761871904135\n",
            "Accuracy on hold-out set: 0.52885\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3222734079848975\n",
            "Accuracy on hold-out set: 0.5425\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2555582337399944\n",
            "Accuracy on hold-out set: 0.57175\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3425903011090121\n",
            "Accuracy on hold-out set: 0.558\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.227521109013632\n",
            "Accuracy on hold-out set: 0.58605\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2357974611642304\n",
            "Accuracy on hold-out set: 0.59615\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1980415782002731\n",
            "Accuracy on hold-out set: 0.6019\n",
            "Returned to Spot: Validation loss: 1.1980415782002731\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5601635040730237\n",
            "Accuracy on hold-out set: 0.43145\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.451063349055499\n",
            "Accuracy on hold-out set: 0.48485\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3374419190056621\n",
            "Accuracy on hold-out set: 0.5313\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.307883088313043\n",
            "Accuracy on hold-out set: 0.54135\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.307819314405322\n",
            "Accuracy on hold-out set: 0.5472\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.290057939633727\n",
            "Accuracy on hold-out set: 0.56475\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3038777700889856\n",
            "Accuracy on hold-out set: 0.5624\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2741903034554793\n",
            "Accuracy on hold-out set: 0.57335\n",
            "Returned to Spot: Validation loss: 1.2741903034554793\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 512, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5242167498023889\n",
            "Accuracy on hold-out set: 0.47685\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.756413398460529\n",
            "Accuracy on hold-out set: 0.50055\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6007035214892007\n",
            "Accuracy on hold-out set: 0.5288\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5426740544251478\n",
            "Accuracy on hold-out set: 0.5413\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 1.5426740544251478\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 4, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3029028285503386\n",
            "Accuracy on hold-out set: 0.0972\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3027572017669677\n",
            "Accuracy on hold-out set: 0.09985\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.30346717171669\n",
            "Accuracy on hold-out set: 0.0972\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3030624467372895\n",
            "Accuracy on hold-out set: 0.10095\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3029756976127627\n",
            "Accuracy on hold-out set: 0.10095\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 2.3029756976127627\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.308036257171631\n",
            "Accuracy on hold-out set: 0.09695\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3066242634773255\n",
            "Accuracy on hold-out set: 0.1001\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3060777866363527\n",
            "Accuracy on hold-out set: 0.10185\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3091898720264434\n",
            "Accuracy on hold-out set: 0.09695\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.303626976585388\n",
            "Accuracy on hold-out set: 0.1001\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3050841201305388\n",
            "Accuracy on hold-out set: 0.09795\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3094153431415556\n",
            "Accuracy on hold-out set: 0.10125\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.304660556411743\n",
            "Accuracy on hold-out set: 0.09695\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 2.304660556411743\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5920525780916215\n",
            "Accuracy on hold-out set: 0.4165\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4198004930973054\n",
            "Accuracy on hold-out set: 0.4844\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4040289502739907\n",
            "Accuracy on hold-out set: 0.4937\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3267013538599015\n",
            "Accuracy on hold-out set: 0.5245\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2499011907458306\n",
            "Accuracy on hold-out set: 0.5546\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2616692806363106\n",
            "Accuracy on hold-out set: 0.55535\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.205448869985342\n",
            "Accuracy on hold-out set: 0.57585\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1799624314725399\n",
            "Accuracy on hold-out set: 0.593\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1906277821600437\n",
            "Accuracy on hold-out set: 0.5928\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1834140081852675\n",
            "Accuracy on hold-out set: 0.59655\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1577506251648069\n",
            "Accuracy on hold-out set: 0.60535\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1346633922696114\n",
            "Accuracy on hold-out set: 0.6092\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1638156526774168\n",
            "Accuracy on hold-out set: 0.59815\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1758124300554396\n",
            "Accuracy on hold-out set: 0.60855\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.138437969222665\n",
            "Accuracy on hold-out set: 0.6165\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.138437969222665\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4480251900807024\n",
            "Accuracy on hold-out set: 0.4718\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3487902843400836\n",
            "Accuracy on hold-out set: 0.52525\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.344014659247175\n",
            "Accuracy on hold-out set: 0.5426\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2739007408469916\n",
            "Accuracy on hold-out set: 0.56365\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2913148200415074\n",
            "Accuracy on hold-out set: 0.55205\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2698641288619488\n",
            "Accuracy on hold-out set: 0.5741\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2785121926712337\n",
            "Accuracy on hold-out set: 0.57345\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2488495181467385\n",
            "Accuracy on hold-out set: 0.5741\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.366571819525957\n",
            "Accuracy on hold-out set: 0.55155\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2526939710650593\n",
            "Accuracy on hold-out set: 0.5807\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2487421185756102\n",
            "Accuracy on hold-out set: 0.5865\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2661973975413479\n",
            "Accuracy on hold-out set: 0.58655\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2519542409380897\n",
            "Accuracy on hold-out set: 0.5839\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.227929047116451\n",
            "Accuracy on hold-out set: 0.6034\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2342431671097875\n",
            "Accuracy on hold-out set: 0.59805\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3508220045860857\n",
            "Accuracy on hold-out set: 0.5727\n",
            "Returned to Spot: Validation loss: 1.3508220045860857\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.161990370249748\n",
            "Accuracy on hold-out set: 0.16625\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.1281702217817307\n",
            "Accuracy on hold-out set: 0.1674\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.1182285179138183\n",
            "Accuracy on hold-out set: 0.1706\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.1562315972566606\n",
            "Accuracy on hold-out set: 0.15255\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.2266043699264526\n",
            "Accuracy on hold-out set: 0.13465\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.278197885298729\n",
            "Accuracy on hold-out set: 0.15695\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 2.278197885298729\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5201274804592133\n",
            "Accuracy on hold-out set: 0.451\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4235148859024047\n",
            "Accuracy on hold-out set: 0.48645\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3888797773838044\n",
            "Accuracy on hold-out set: 0.51175\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3309078575849533\n",
            "Accuracy on hold-out set: 0.5281\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3499353325366974\n",
            "Accuracy on hold-out set: 0.522\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3258469570636748\n",
            "Accuracy on hold-out set: 0.5411\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2992516761302948\n",
            "Accuracy on hold-out set: 0.5519\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3318281546115875\n",
            "Accuracy on hold-out set: 0.5485\n",
            "Returned to Spot: Validation loss: 1.3318281546115875\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 512, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3077307419538498\n",
            "Accuracy on hold-out set: 0.10005\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.307907497692108\n",
            "Accuracy on hold-out set: 0.10055\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.308236398124695\n",
            "Accuracy on hold-out set: 0.10095\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.30675538892746\n",
            "Accuracy on hold-out set: 0.10005\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3055308041095732\n",
            "Accuracy on hold-out set: 0.10095\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3070194575071334\n",
            "Accuracy on hold-out set: 0.1012\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3095433720350265\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.3081029322862627\n",
            "Accuracy on hold-out set: 0.09955\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 2.3081029322862627\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 256, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3044226461648942\n",
            "Accuracy on hold-out set: 0.09995\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3105950701951983\n",
            "Accuracy on hold-out set: 0.1001\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.306512655043602\n",
            "Accuracy on hold-out set: 0.09875\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.309528663659096\n",
            "Accuracy on hold-out set: 0.0993\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 2.309528663659096\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 16, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8173777192562819\n",
            "Accuracy on hold-out set: 0.3341\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6794028072893619\n",
            "Accuracy on hold-out set: 0.3822\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6452884696394205\n",
            "Accuracy on hold-out set: 0.4009\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6333697233818472\n",
            "Accuracy on hold-out set: 0.4148\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5731317114207894\n",
            "Accuracy on hold-out set: 0.4373\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5440843420155346\n",
            "Accuracy on hold-out set: 0.44485\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.484809035476111\n",
            "Accuracy on hold-out set: 0.45825\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4792365374339744\n",
            "Accuracy on hold-out set: 0.46635\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.481243304661289\n",
            "Accuracy on hold-out set: 0.46985\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4285345642831178\n",
            "Accuracy on hold-out set: 0.4896\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.441618269782141\n",
            "Accuracy on hold-out set: 0.49085\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.407546785919182\n",
            "Accuracy on hold-out set: 0.4881\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.414896996480599\n",
            "Accuracy on hold-out set: 0.493\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.4298406889660285\n",
            "Accuracy on hold-out set: 0.49835\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3903594159767032\n",
            "Accuracy on hold-out set: 0.50395\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3938663620568812\n",
            "Accuracy on hold-out set: 0.50525\n",
            "Returned to Spot: Validation loss: 1.3938663620568812\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5221614977836608\n",
            "Accuracy on hold-out set: 0.4333\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3856035399913789\n",
            "Accuracy on hold-out set: 0.50075\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.32074482960701\n",
            "Accuracy on hold-out set: 0.5231\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.295946725177765\n",
            "Accuracy on hold-out set: 0.53945\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3130170522928237\n",
            "Accuracy on hold-out set: 0.5471\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.257011152291298\n",
            "Accuracy on hold-out set: 0.57535\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2725703472852707\n",
            "Accuracy on hold-out set: 0.5793\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3455860186100006\n",
            "Accuracy on hold-out set: 0.57685\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4085698402881621\n",
            "Accuracy on hold-out set: 0.5706\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.4085698402881621\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5854561954975128\n",
            "Accuracy on hold-out set: 0.4048\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4486146879673003\n",
            "Accuracy on hold-out set: 0.4663\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3723855595111847\n",
            "Accuracy on hold-out set: 0.49995\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3410500901222229\n",
            "Accuracy on hold-out set: 0.51455\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3268504135131836\n",
            "Accuracy on hold-out set: 0.5216\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3483817138671874\n",
            "Accuracy on hold-out set: 0.51135\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3065185046434402\n",
            "Accuracy on hold-out set: 0.52555\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2957941490650178\n",
            "Accuracy on hold-out set: 0.5293\n",
            "Returned to Spot: Validation loss: 1.2957941490650178\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6707720044851304\n",
            "Accuracy on hold-out set: 0.38925\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5140555894374848\n",
            "Accuracy on hold-out set: 0.44935\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4382644088029861\n",
            "Accuracy on hold-out set: 0.47565\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4101080276727675\n",
            "Accuracy on hold-out set: 0.4889\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3429683114051818\n",
            "Accuracy on hold-out set: 0.51205\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3199162853479385\n",
            "Accuracy on hold-out set: 0.52735\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.330945966386795\n",
            "Accuracy on hold-out set: 0.51745\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2601940600156785\n",
            "Accuracy on hold-out set: 0.55165\n",
            "Returned to Spot: Validation loss: 1.2601940600156785\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5883012694358827\n",
            "Accuracy on hold-out set: 0.41465\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4539298167228698\n",
            "Accuracy on hold-out set: 0.46715\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3608506443500519\n",
            "Accuracy on hold-out set: 0.50645\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2918415437698365\n",
            "Accuracy on hold-out set: 0.5375\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2765032384872437\n",
            "Accuracy on hold-out set: 0.5425\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.199868296599388\n",
            "Accuracy on hold-out set: 0.5778\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2101117949962616\n",
            "Accuracy on hold-out set: 0.57515\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1863136412858963\n",
            "Accuracy on hold-out set: 0.58615\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1874321748971939\n",
            "Accuracy on hold-out set: 0.5795\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1399404283761978\n",
            "Accuracy on hold-out set: 0.60325\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1699334612965584\n",
            "Accuracy on hold-out set: 0.59465\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.156526040482521\n",
            "Accuracy on hold-out set: 0.5971\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1346287161111832\n",
            "Accuracy on hold-out set: 0.6067\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1110890245199203\n",
            "Accuracy on hold-out set: 0.6105\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.122933943271637\n",
            "Accuracy on hold-out set: 0.6133\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1237852289438248\n",
            "Accuracy on hold-out set: 0.61585\n",
            "Returned to Spot: Validation loss: 1.1237852289438248\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 8, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.307141498827934\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.318171492958069\n",
            "Accuracy on hold-out set: 0.099\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3075692583084106\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.307781186437607\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 2.307781186437607\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5137600602388381\n",
            "Accuracy on hold-out set: 0.44805\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3608088329434396\n",
            "Accuracy on hold-out set: 0.51625\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3103764738559722\n",
            "Accuracy on hold-out set: 0.5435\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.25280405189991\n",
            "Accuracy on hold-out set: 0.5603\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1682403510689736\n",
            "Accuracy on hold-out set: 0.5946\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1716398767471314\n",
            "Accuracy on hold-out set: 0.5953\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1539796709299088\n",
            "Accuracy on hold-out set: 0.61085\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1380592263638973\n",
            "Accuracy on hold-out set: 0.6151\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.166027963644266\n",
            "Accuracy on hold-out set: 0.61145\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1379722338765859\n",
            "Accuracy on hold-out set: 0.61935\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1379516528859734\n",
            "Accuracy on hold-out set: 0.62085\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.171749642702937\n",
            "Accuracy on hold-out set: 0.61885\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1719989209607244\n",
            "Accuracy on hold-out set: 0.6222\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2185343857005237\n",
            "Accuracy on hold-out set: 0.62\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.2185343857005237\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4449000206708909\n",
            "Accuracy on hold-out set: 0.4817\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3388037023663522\n",
            "Accuracy on hold-out set: 0.535\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.309685547460988\n",
            "Accuracy on hold-out set: 0.5505\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2113518573909998\n",
            "Accuracy on hold-out set: 0.5869\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2417960305202753\n",
            "Accuracy on hold-out set: 0.58755\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2923395977064036\n",
            "Accuracy on hold-out set: 0.5805\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2230782335994765\n",
            "Accuracy on hold-out set: 0.5986\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.2230782335994765\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7897500525534153\n",
            "Accuracy on hold-out set: 0.34525\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6342199518740177\n",
            "Accuracy on hold-out set: 0.3971\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.548631791716814\n",
            "Accuracy on hold-out set: 0.4354\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5063541465520858\n",
            "Accuracy on hold-out set: 0.45515\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4771738890707493\n",
            "Accuracy on hold-out set: 0.4697\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4522207776665688\n",
            "Accuracy on hold-out set: 0.4811\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4048591203331948\n",
            "Accuracy on hold-out set: 0.4942\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3840094393864275\n",
            "Accuracy on hold-out set: 0.50085\n",
            "Returned to Spot: Validation loss: 1.3840094393864275\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4718091788053513\n",
            "Accuracy on hold-out set: 0.4573\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3980431882977487\n",
            "Accuracy on hold-out set: 0.50675\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2732552444338798\n",
            "Accuracy on hold-out set: 0.5486\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3022461961388587\n",
            "Accuracy on hold-out set: 0.5392\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.26947033944726\n",
            "Accuracy on hold-out set: 0.5626\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2179206103801727\n",
            "Accuracy on hold-out set: 0.575\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2028661963433027\n",
            "Accuracy on hold-out set: 0.58535\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1927419034004212\n",
            "Accuracy on hold-out set: 0.58355\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1873338577151298\n",
            "Accuracy on hold-out set: 0.5923\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1966614129185678\n",
            "Accuracy on hold-out set: 0.594\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1982360133260488\n",
            "Accuracy on hold-out set: 0.5964\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.229496594876051\n",
            "Accuracy on hold-out set: 0.5901\n",
            "Early stopping at epoch 11\n",
            "Returned to Spot: Validation loss: 1.229496594876051\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4634119645133614\n",
            "Accuracy on hold-out set: 0.47315\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4483601041823626\n",
            "Accuracy on hold-out set: 0.47775\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3448356168866158\n",
            "Accuracy on hold-out set: 0.5188\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.449876745800674\n",
            "Accuracy on hold-out set: 0.49565\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.301461945297569\n",
            "Accuracy on hold-out set: 0.5364\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3551276751451193\n",
            "Accuracy on hold-out set: 0.5293\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3123475507139228\n",
            "Accuracy on hold-out set: 0.54945\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2906619865432383\n",
            "Accuracy on hold-out set: 0.5476\n",
            "Returned to Spot: Validation loss: 1.2906619865432383\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.991538908958435\n",
            "Accuracy on hold-out set: 0.2729\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8382825664520264\n",
            "Accuracy on hold-out set: 0.329\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.705703818798065\n",
            "Accuracy on hold-out set: 0.3722\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6400685962677002\n",
            "Accuracy on hold-out set: 0.4006\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5902200417518615\n",
            "Accuracy on hold-out set: 0.41995\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.574354794359207\n",
            "Accuracy on hold-out set: 0.4221\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5355294230937957\n",
            "Accuracy on hold-out set: 0.44085\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5183631890773772\n",
            "Accuracy on hold-out set: 0.4456\n",
            "Returned to Spot: Validation loss: 1.5183631890773772\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3030963454723357\n",
            "Accuracy on hold-out set: 0.10065\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3027726049900057\n",
            "Accuracy on hold-out set: 0.0996\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3028021251678465\n",
            "Accuracy on hold-out set: 0.09615\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.302803953123093\n",
            "Accuracy on hold-out set: 0.09615\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3028048062324524\n",
            "Accuracy on hold-out set: 0.09615\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 2.3028048062324524\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.545028917169571\n",
            "Accuracy on hold-out set: 0.4305\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4141422286033631\n",
            "Accuracy on hold-out set: 0.48075\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.352395212507248\n",
            "Accuracy on hold-out set: 0.5117\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.324572062778473\n",
            "Accuracy on hold-out set: 0.52855\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3113491659641265\n",
            "Accuracy on hold-out set: 0.5277\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2290765133142472\n",
            "Accuracy on hold-out set: 0.5639\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2656256720542907\n",
            "Accuracy on hold-out set: 0.5641\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.184821671295166\n",
            "Accuracy on hold-out set: 0.58435\n",
            "Returned to Spot: Validation loss: 1.184821671295166\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6654097931861878\n",
            "Accuracy on hold-out set: 0.38535\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4560525612354278\n",
            "Accuracy on hold-out set: 0.4669\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.393903645849228\n",
            "Accuracy on hold-out set: 0.50405\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2239145935058593\n",
            "Accuracy on hold-out set: 0.56345\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2279075610399246\n",
            "Accuracy on hold-out set: 0.5667\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1913397221803665\n",
            "Accuracy on hold-out set: 0.5819\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2245355673074723\n",
            "Accuracy on hold-out set: 0.57345\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.188709452366829\n",
            "Accuracy on hold-out set: 0.6019\n",
            "Returned to Spot: Validation loss: 1.188709452366829\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5691080921649934\n",
            "Accuracy on hold-out set: 0.4289\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3576788761615752\n",
            "Accuracy on hold-out set: 0.5106\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2541282734394072\n",
            "Accuracy on hold-out set: 0.54945\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2089897278547288\n",
            "Accuracy on hold-out set: 0.56775\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1526443045139312\n",
            "Accuracy on hold-out set: 0.5947\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2115374324083328\n",
            "Accuracy on hold-out set: 0.57925\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.141100308585167\n",
            "Accuracy on hold-out set: 0.59755\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1824720607995987\n",
            "Accuracy on hold-out set: 0.588\n",
            "Returned to Spot: Validation loss: 1.1824720607995987\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4468016913414001\n",
            "Accuracy on hold-out set: 0.46705\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3428153091430663\n",
            "Accuracy on hold-out set: 0.52355\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2636035532951355\n",
            "Accuracy on hold-out set: 0.5499\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2443361153602601\n",
            "Accuracy on hold-out set: 0.56545\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2370959815025329\n",
            "Accuracy on hold-out set: 0.55935\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1931227849006654\n",
            "Accuracy on hold-out set: 0.57925\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2311573243141174\n",
            "Accuracy on hold-out set: 0.5714\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2100007341384889\n",
            "Accuracy on hold-out set: 0.5843\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2576394115447997\n",
            "Accuracy on hold-out set: 0.57045\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.2576394115447997\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.503552069091797\n",
            "Accuracy on hold-out set: 0.45445\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3463898355007171\n",
            "Accuracy on hold-out set: 0.51895\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3269364779949189\n",
            "Accuracy on hold-out set: 0.53905\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3036750493049623\n",
            "Accuracy on hold-out set: 0.549\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2587681548118592\n",
            "Accuracy on hold-out set: 0.56975\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2897238727092744\n",
            "Accuracy on hold-out set: 0.5606\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3614811228990555\n",
            "Accuracy on hold-out set: 0.54015\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3501283897161485\n",
            "Accuracy on hold-out set: 0.5724\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.3501283897161485\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 128, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.788837747848034\n",
            "Accuracy on hold-out set: 0.3112\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6988100169345737\n",
            "Accuracy on hold-out set: 0.37275\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6215357835695148\n",
            "Accuracy on hold-out set: 0.4108\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5758729206748308\n",
            "Accuracy on hold-out set: 0.4238\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5321909526765347\n",
            "Accuracy on hold-out set: 0.43915\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5138703090008347\n",
            "Accuracy on hold-out set: 0.44945\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4788619449282996\n",
            "Accuracy on hold-out set: 0.4683\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4788129647896626\n",
            "Accuracy on hold-out set: 0.47285\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4688077045791783\n",
            "Accuracy on hold-out set: 0.4809\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.446535881151911\n",
            "Accuracy on hold-out set: 0.48585\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4181702754109633\n",
            "Accuracy on hold-out set: 0.5038\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3873174088855507\n",
            "Accuracy on hold-out set: 0.5102\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3866687688301318\n",
            "Accuracy on hold-out set: 0.5153\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3535097497199662\n",
            "Accuracy on hold-out set: 0.5263\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4003842410446028\n",
            "Accuracy on hold-out set: 0.52485\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3369596785866655\n",
            "Accuracy on hold-out set: 0.5325\n",
            "Returned to Spot: Validation loss: 1.3369596785866655\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4045815830022097\n",
            "Accuracy on hold-out set: 0.4955\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.34046873755157\n",
            "Accuracy on hold-out set: 0.5403\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3242296154906974\n",
            "Accuracy on hold-out set: 0.5573\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2262970765512438\n",
            "Accuracy on hold-out set: 0.5884\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2825173775313887\n",
            "Accuracy on hold-out set: 0.59115\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.253193126194924\n",
            "Accuracy on hold-out set: 0.6004\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3204326523061667\n",
            "Accuracy on hold-out set: 0.6001\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.3204326523061667\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 4, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8078009952545167\n",
            "Accuracy on hold-out set: 0.2851\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.735487557196617\n",
            "Accuracy on hold-out set: 0.3176\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7019716152191162\n",
            "Accuracy on hold-out set: 0.33815\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6728888378620148\n",
            "Accuracy on hold-out set: 0.34795\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6462881201267243\n",
            "Accuracy on hold-out set: 0.3599\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6354748672723771\n",
            "Accuracy on hold-out set: 0.3615\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6270836480855941\n",
            "Accuracy on hold-out set: 0.3675\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.6064334547042847\n",
            "Accuracy on hold-out set: 0.3789\n",
            "Returned to Spot: Validation loss: 1.6064334547042847\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 8, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5534307844215771\n",
            "Accuracy on hold-out set: 0.4644\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5799936665630325\n",
            "Accuracy on hold-out set: 0.51535\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4134992659665149\n",
            "Accuracy on hold-out set: 0.55145\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4258707129580226\n",
            "Accuracy on hold-out set: 0.56175\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4803948947011052\n",
            "Accuracy on hold-out set: 0.56455\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6487187149683924\n",
            "Accuracy on hold-out set: 0.5776\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.6487187149683924\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.614021751254797\n",
            "Accuracy on hold-out set: 0.4097\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5001525262951851\n",
            "Accuracy on hold-out set: 0.46435\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4941548801489175\n",
            "Accuracy on hold-out set: 0.4848\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5050409282270818\n",
            "Accuracy on hold-out set: 0.50485\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.472773576689139\n",
            "Accuracy on hold-out set: 0.51565\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6180290460668505\n",
            "Accuracy on hold-out set: 0.49515\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5010947620384396\n",
            "Accuracy on hold-out set: 0.5013\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5838463577482849\n",
            "Accuracy on hold-out set: 0.4996\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.5838463577482849\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3060643287658693\n",
            "Accuracy on hold-out set: 0.1014\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.0841998499393464\n",
            "Accuracy on hold-out set: 0.2066\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.0593601014137266\n",
            "Accuracy on hold-out set: 0.19505\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.2397728710174563\n",
            "Accuracy on hold-out set: 0.15915\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.2303057062149048\n",
            "Accuracy on hold-out set: 0.13895\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.1507410233974458\n",
            "Accuracy on hold-out set: 0.16645\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 2.1507410233974458\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9848899760246277\n",
            "Accuracy on hold-out set: 0.26835\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.862227240562439\n",
            "Accuracy on hold-out set: 0.3148\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7404179861068725\n",
            "Accuracy on hold-out set: 0.36075\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6717427920341492\n",
            "Accuracy on hold-out set: 0.38505\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6195651836395264\n",
            "Accuracy on hold-out set: 0.4034\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5814235319614411\n",
            "Accuracy on hold-out set: 0.4196\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5873547906875611\n",
            "Accuracy on hold-out set: 0.42575\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5342193258285521\n",
            "Accuracy on hold-out set: 0.43735\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5108961581230163\n",
            "Accuracy on hold-out set: 0.44765\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4837550832748414\n",
            "Accuracy on hold-out set: 0.4625\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4794013309955596\n",
            "Accuracy on hold-out set: 0.4672\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4589940266609192\n",
            "Accuracy on hold-out set: 0.46905\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4781658029079436\n",
            "Accuracy on hold-out set: 0.46705\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.4245402961254119\n",
            "Accuracy on hold-out set: 0.4821\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4212623515605927\n",
            "Accuracy on hold-out set: 0.48835\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.390372361946106\n",
            "Accuracy on hold-out set: 0.4979\n",
            "Returned to Spot: Validation loss: 1.390372361946106\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4604901183605195\n",
            "Accuracy on hold-out set: 0.46555\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3752804255008697\n",
            "Accuracy on hold-out set: 0.5023\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3346964179039003\n",
            "Accuracy on hold-out set: 0.5178\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3064537980556488\n",
            "Accuracy on hold-out set: 0.52785\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2991458278656005\n",
            "Accuracy on hold-out set: 0.54005\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2279925842523576\n",
            "Accuracy on hold-out set: 0.5615\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2214280720472335\n",
            "Accuracy on hold-out set: 0.5665\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2431572832345963\n",
            "Accuracy on hold-out set: 0.55625\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2266141533136368\n",
            "Accuracy on hold-out set: 0.56925\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2194515720129013\n",
            "Accuracy on hold-out set: 0.57495\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2900653245925904\n",
            "Accuracy on hold-out set: 0.53405\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2167560425043107\n",
            "Accuracy on hold-out set: 0.5709\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2096162192344666\n",
            "Accuracy on hold-out set: 0.5814\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2079121218919755\n",
            "Accuracy on hold-out set: 0.5736\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2017588990926742\n",
            "Accuracy on hold-out set: 0.5824\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2088771149158477\n",
            "Accuracy on hold-out set: 0.5763\n",
            "Returned to Spot: Validation loss: 1.2088771149158477\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.642829914753139\n",
            "Accuracy on hold-out set: 0.39925\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5728099340297281\n",
            "Accuracy on hold-out set: 0.4354\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5335531443454324\n",
            "Accuracy on hold-out set: 0.45365\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5006318969912826\n",
            "Accuracy on hold-out set: 0.46325\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4859935496851802\n",
            "Accuracy on hold-out set: 0.4737\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.476999218319077\n",
            "Accuracy on hold-out set: 0.47715\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4537320717687718\n",
            "Accuracy on hold-out set: 0.4883\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4297283319626004\n",
            "Accuracy on hold-out set: 0.498\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4360496770519764\n",
            "Accuracy on hold-out set: 0.49905\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4153992875223746\n",
            "Accuracy on hold-out set: 0.50675\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4060475260279142\n",
            "Accuracy on hold-out set: 0.50965\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3960366338583174\n",
            "Accuracy on hold-out set: 0.51495\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3881712785533165\n",
            "Accuracy on hold-out set: 0.51865\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3869848160044407\n",
            "Accuracy on hold-out set: 0.51885\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3807377656928264\n",
            "Accuracy on hold-out set: 0.5213\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3733779663685826\n",
            "Accuracy on hold-out set: 0.52605\n",
            "Returned to Spot: Validation loss: 1.3733779663685826\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4869082083612681\n",
            "Accuracy on hold-out set: 0.45515\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4357770778998733\n",
            "Accuracy on hold-out set: 0.4821\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.348802080976963\n",
            "Accuracy on hold-out set: 0.52355\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3192574820831418\n",
            "Accuracy on hold-out set: 0.53495\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2866179084055125\n",
            "Accuracy on hold-out set: 0.5495\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3044242982104421\n",
            "Accuracy on hold-out set: 0.5552\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2915269412361086\n",
            "Accuracy on hold-out set: 0.55835\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2684562255401164\n",
            "Accuracy on hold-out set: 0.56815\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2411955887246877\n",
            "Accuracy on hold-out set: 0.57355\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2990506185069681\n",
            "Accuracy on hold-out set: 0.5616\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3190018538972363\n",
            "Accuracy on hold-out set: 0.5672\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.302860150129348\n",
            "Accuracy on hold-out set: 0.57675\n",
            "Early stopping at epoch 11\n",
            "Returned to Spot: Validation loss: 1.302860150129348\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4588018281936646\n",
            "Accuracy on hold-out set: 0.45995\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.309367708683014\n",
            "Accuracy on hold-out set: 0.5283\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2448424808502196\n",
            "Accuracy on hold-out set: 0.5601\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.171334526157379\n",
            "Accuracy on hold-out set: 0.5873\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1498817532539367\n",
            "Accuracy on hold-out set: 0.6002\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1417696805953979\n",
            "Accuracy on hold-out set: 0.6016\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.120482248878479\n",
            "Accuracy on hold-out set: 0.6097\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1871524349212645\n",
            "Accuracy on hold-out set: 0.6019\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1593306765079499\n",
            "Accuracy on hold-out set: 0.61145\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1901825585365295\n",
            "Accuracy on hold-out set: 0.60985\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.1901825585365295\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5998517294704915\n",
            "Accuracy on hold-out set: 0.41425\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5142165835797787\n",
            "Accuracy on hold-out set: 0.4499\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4607722144782542\n",
            "Accuracy on hold-out set: 0.47395\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4274573642909527\n",
            "Accuracy on hold-out set: 0.48685\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4028369571536778\n",
            "Accuracy on hold-out set: 0.4982\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3853213557422162\n",
            "Accuracy on hold-out set: 0.5037\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3675910396367312\n",
            "Accuracy on hold-out set: 0.51355\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3465042650327086\n",
            "Accuracy on hold-out set: 0.5199\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.334779709005356\n",
            "Accuracy on hold-out set: 0.52375\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3249490218549966\n",
            "Accuracy on hold-out set: 0.52965\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.313609765675664\n",
            "Accuracy on hold-out set: 0.5333\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.300717280742526\n",
            "Accuracy on hold-out set: 0.53855\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2872736028075218\n",
            "Accuracy on hold-out set: 0.5449\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2827033839046955\n",
            "Accuracy on hold-out set: 0.5442\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2717535578653216\n",
            "Accuracy on hold-out set: 0.5499\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2659050039544701\n",
            "Accuracy on hold-out set: 0.5544\n",
            "Returned to Spot: Validation loss: 1.2659050039544701\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4434245896697044\n",
            "Accuracy on hold-out set: 0.4773\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.2610853311061858\n",
            "Accuracy on hold-out set: 0.5506\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2208996845841409\n",
            "Accuracy on hold-out set: 0.5766\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1734205713629722\n",
            "Accuracy on hold-out set: 0.5896\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.188340057951212\n",
            "Accuracy on hold-out set: 0.59825\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2057918012455107\n",
            "Accuracy on hold-out set: 0.61055\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2217634515464306\n",
            "Accuracy on hold-out set: 0.60325\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.2217634515464306\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4467481814950705\n",
            "Accuracy on hold-out set: 0.48535\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4293718136548996\n",
            "Accuracy on hold-out set: 0.50155\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3175815808918327\n",
            "Accuracy on hold-out set: 0.5445\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.341756600406952\n",
            "Accuracy on hold-out set: 0.5443\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2741363599643112\n",
            "Accuracy on hold-out set: 0.5686\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.222110435044393\n",
            "Accuracy on hold-out set: 0.5856\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.361833992564492\n",
            "Accuracy on hold-out set: 0.5643\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3082713675016537\n",
            "Accuracy on hold-out set: 0.57485\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2239923438362776\n",
            "Accuracy on hold-out set: 0.58785\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.2239923438362776\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5551349276781081\n",
            "Accuracy on hold-out set: 0.42055\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4531395205259323\n",
            "Accuracy on hold-out set: 0.4663\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.384345477950573\n",
            "Accuracy on hold-out set: 0.4988\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.36214081312418\n",
            "Accuracy on hold-out set: 0.5114\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.313592384493351\n",
            "Accuracy on hold-out set: 0.5236\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2805445848166943\n",
            "Accuracy on hold-out set: 0.5412\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2356626084446907\n",
            "Accuracy on hold-out set: 0.5537\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2261318247079849\n",
            "Accuracy on hold-out set: 0.55855\n",
            "Returned to Spot: Validation loss: 1.2261318247079849\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.577966236114502\n",
            "Accuracy on hold-out set: 0.425\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.570237042236328\n",
            "Accuracy on hold-out set: 0.44455\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3938200849056244\n",
            "Accuracy on hold-out set: 0.49505\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3446483394145965\n",
            "Accuracy on hold-out set: 0.5136\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3298039416313172\n",
            "Accuracy on hold-out set: 0.52155\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2648587728977203\n",
            "Accuracy on hold-out set: 0.5502\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2761698983907699\n",
            "Accuracy on hold-out set: 0.5516\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2105114710569382\n",
            "Accuracy on hold-out set: 0.57485\n",
            "Returned to Spot: Validation loss: 1.2105114710569382\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5416396458387376\n",
            "Accuracy on hold-out set: 0.44505\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4564177873522044\n",
            "Accuracy on hold-out set: 0.4783\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4006731077849865\n",
            "Accuracy on hold-out set: 0.4965\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3722821746766567\n",
            "Accuracy on hold-out set: 0.5143\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3478483790025115\n",
            "Accuracy on hold-out set: 0.5202\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.323944540566206\n",
            "Accuracy on hold-out set: 0.53015\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3196458503559232\n",
            "Accuracy on hold-out set: 0.53515\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3153805195838213\n",
            "Accuracy on hold-out set: 0.53585\n",
            "Returned to Spot: Validation loss: 1.3153805195838213\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 512, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5709907047092915\n",
            "Accuracy on hold-out set: 0.42755\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6659671623408794\n",
            "Accuracy on hold-out set: 0.4205\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6122032405734061\n",
            "Accuracy on hold-out set: 0.4399\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7223813940793276\n",
            "Accuracy on hold-out set: 0.43185\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 1.7223813940793276\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5863245587825776\n",
            "Accuracy on hold-out set: 0.42395\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4710746814250946\n",
            "Accuracy on hold-out set: 0.4643\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4227390719890594\n",
            "Accuracy on hold-out set: 0.48645\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4088960779666901\n",
            "Accuracy on hold-out set: 0.49155\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3648237107753753\n",
            "Accuracy on hold-out set: 0.50825\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3422908116817474\n",
            "Accuracy on hold-out set: 0.51705\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.329924574804306\n",
            "Accuracy on hold-out set: 0.52265\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.313908027601242\n",
            "Accuracy on hold-out set: 0.5336\n",
            "Returned to Spot: Validation loss: 1.313908027601242\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5190995260804891\n",
            "Accuracy on hold-out set: 0.4501\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.368017345957458\n",
            "Accuracy on hold-out set: 0.52675\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3127197055287658\n",
            "Accuracy on hold-out set: 0.56675\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2534136276073289\n",
            "Accuracy on hold-out set: 0.58375\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.289082054067962\n",
            "Accuracy on hold-out set: 0.58925\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2895196677550673\n",
            "Accuracy on hold-out set: 0.59535\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3599822031513322\n",
            "Accuracy on hold-out set: 0.59945\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.3599822031513322\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8352408510804177\n",
            "Accuracy on hold-out set: 0.32755\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6698744087696076\n",
            "Accuracy on hold-out set: 0.3806\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5794666033685207\n",
            "Accuracy on hold-out set: 0.4199\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.534312731063366\n",
            "Accuracy on hold-out set: 0.4446\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.485666004061699\n",
            "Accuracy on hold-out set: 0.46105\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4239225033164025\n",
            "Accuracy on hold-out set: 0.48545\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4061854849115014\n",
            "Accuracy on hold-out set: 0.49195\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3763325224488974\n",
            "Accuracy on hold-out set: 0.50525\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3881188823342323\n",
            "Accuracy on hold-out set: 0.49875\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.353521645221114\n",
            "Accuracy on hold-out set: 0.52075\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3084019329637289\n",
            "Accuracy on hold-out set: 0.53425\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3053211497545243\n",
            "Accuracy on hold-out set: 0.52985\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2754377153918146\n",
            "Accuracy on hold-out set: 0.54885\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2743127906978131\n",
            "Accuracy on hold-out set: 0.552\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.246360268600285\n",
            "Accuracy on hold-out set: 0.5595\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2620856935918332\n",
            "Accuracy on hold-out set: 0.5566\n",
            "Returned to Spot: Validation loss: 1.2620856935918332\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3054090030670165\n",
            "Accuracy on hold-out set: 0.1015\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.30417410030365\n",
            "Accuracy on hold-out set: 0.1009\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.303377302932739\n",
            "Accuracy on hold-out set: 0.09755\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.304271361541748\n",
            "Accuracy on hold-out set: 0.1015\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3068405643463135\n",
            "Accuracy on hold-out set: 0.0981\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3031419292449953\n",
            "Accuracy on hold-out set: 0.1015\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3059551094055175\n",
            "Accuracy on hold-out set: 0.09885\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.3049634429931642\n",
            "Accuracy on hold-out set: 0.1019\n",
            "Returned to Spot: Validation loss: 2.3049634429931642\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.915942351770401\n",
            "Accuracy on hold-out set: 0.2823\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.765458247423172\n",
            "Accuracy on hold-out set: 0.3432\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.694536238861084\n",
            "Accuracy on hold-out set: 0.375\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6409334153175354\n",
            "Accuracy on hold-out set: 0.39525\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6011360587835313\n",
            "Accuracy on hold-out set: 0.40855\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5637958970308303\n",
            "Accuracy on hold-out set: 0.429\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.528272005558014\n",
            "Accuracy on hold-out set: 0.4405\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.50860059902668\n",
            "Accuracy on hold-out set: 0.451\n",
            "Returned to Spot: Validation loss: 1.50860059902668\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4886655506134032\n",
            "Accuracy on hold-out set: 0.4635\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.299710728096962\n",
            "Accuracy on hold-out set: 0.5332\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2909479694962502\n",
            "Accuracy on hold-out set: 0.53845\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2520422973752021\n",
            "Accuracy on hold-out set: 0.56275\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2125395716249943\n",
            "Accuracy on hold-out set: 0.57025\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2197292148351668\n",
            "Accuracy on hold-out set: 0.5756\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2436444867908956\n",
            "Accuracy on hold-out set: 0.5735\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1867042482078076\n",
            "Accuracy on hold-out set: 0.5931\n",
            "Returned to Spot: Validation loss: 1.1867042482078076\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 8, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.021235894036293\n",
            "Accuracy on hold-out set: 0.222\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8320315085083245\n",
            "Accuracy on hold-out set: 0.32835\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7410212310299278\n",
            "Accuracy on hold-out set: 0.36205\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6178584413543344\n",
            "Accuracy on hold-out set: 0.4048\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6071018102638424\n",
            "Accuracy on hold-out set: 0.4169\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5583298214469106\n",
            "Accuracy on hold-out set: 0.43105\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5608024800933897\n",
            "Accuracy on hold-out set: 0.43505\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5596696622663178\n",
            "Accuracy on hold-out set: 0.4471\n",
            "Returned to Spot: Validation loss: 1.5596696622663178\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4776217087745667\n",
            "Accuracy on hold-out set: 0.4646\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3368174647808075\n",
            "Accuracy on hold-out set: 0.5219\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2602833119392396\n",
            "Accuracy on hold-out set: 0.55235\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2324562958478928\n",
            "Accuracy on hold-out set: 0.56685\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.235303517317772\n",
            "Accuracy on hold-out set: 0.57075\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1721391241788863\n",
            "Accuracy on hold-out set: 0.5893\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1591921561002732\n",
            "Accuracy on hold-out set: 0.59475\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1646563449144363\n",
            "Accuracy on hold-out set: 0.5911\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.154880661201477\n",
            "Accuracy on hold-out set: 0.60095\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1496771190643311\n",
            "Accuracy on hold-out set: 0.60255\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.181060525226593\n",
            "Accuracy on hold-out set: 0.60405\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1959883856534959\n",
            "Accuracy on hold-out set: 0.5868\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1226260604739189\n",
            "Accuracy on hold-out set: 0.6147\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.204342097711563\n",
            "Accuracy on hold-out set: 0.59785\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1761885809183121\n",
            "Accuracy on hold-out set: 0.60865\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1352562084913254\n",
            "Accuracy on hold-out set: 0.6129\n",
            "Early stopping at epoch 15\n",
            "Returned to Spot: Validation loss: 1.1352562084913254\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.520892605161667\n",
            "Accuracy on hold-out set: 0.45045\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.383280867099762\n",
            "Accuracy on hold-out set: 0.50415\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.249235917520523\n",
            "Accuracy on hold-out set: 0.5547\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1859848509788513\n",
            "Accuracy on hold-out set: 0.58305\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.169315846824646\n",
            "Accuracy on hold-out set: 0.58775\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1189268266677856\n",
            "Accuracy on hold-out set: 0.60815\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1296375043392182\n",
            "Accuracy on hold-out set: 0.60685\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.135726507639885\n",
            "Accuracy on hold-out set: 0.6071\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1317653287649154\n",
            "Accuracy on hold-out set: 0.6232\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.1317653287649154\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3030223217010497\n",
            "Accuracy on hold-out set: 0.10045\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.302740113735199\n",
            "Accuracy on hold-out set: 0.10045\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3027419464111327\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3027457242965697\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3027303374290464\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3027310455322265\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.302728553199768\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.3027293595314027\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.302728954601288\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 2.302728140449524\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 2.3027260449409486\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 2.3027172651290893\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 2.3027174996376036\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 2.3027245881080627\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 2.3027265412330626\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 2.3027265412330626\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.306411561203003\n",
            "Accuracy on hold-out set: 0.09905\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3039604446411133\n",
            "Accuracy on hold-out set: 0.0951\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3043719844818114\n",
            "Accuracy on hold-out set: 0.0951\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.303031253814697\n",
            "Accuracy on hold-out set: 0.10085\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.304857345199585\n",
            "Accuracy on hold-out set: 0.0988\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.303534722137451\n",
            "Accuracy on hold-out set: 0.1008\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3034626373291016\n",
            "Accuracy on hold-out set: 0.09995\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 2.3034626373291016\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5337913378775119\n",
            "Accuracy on hold-out set: 0.439\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4144813770085574\n",
            "Accuracy on hold-out set: 0.47755\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3482012064114213\n",
            "Accuracy on hold-out set: 0.51095\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3498472913525998\n",
            "Accuracy on hold-out set: 0.52335\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2923214722663163\n",
            "Accuracy on hold-out set: 0.54065\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2806496924743056\n",
            "Accuracy on hold-out set: 0.5442\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2494638711832464\n",
            "Accuracy on hold-out set: 0.56095\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.280628872993961\n",
            "Accuracy on hold-out set: 0.5457\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.247786582844332\n",
            "Accuracy on hold-out set: 0.56305\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.238604616304487\n",
            "Accuracy on hold-out set: 0.56215\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2391347781088202\n",
            "Accuracy on hold-out set: 0.56175\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2522286384260282\n",
            "Accuracy on hold-out set: 0.5725\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2734874800533056\n",
            "Accuracy on hold-out set: 0.5537\n",
            "Early stopping at epoch 12\n",
            "Returned to Spot: Validation loss: 1.2734874800533056\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5502055959701537\n",
            "Accuracy on hold-out set: 0.43215\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4937676959991455\n",
            "Accuracy on hold-out set: 0.4561\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4230173188209534\n",
            "Accuracy on hold-out set: 0.48385\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3813744614601136\n",
            "Accuracy on hold-out set: 0.5023\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3583689986228944\n",
            "Accuracy on hold-out set: 0.5096\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3369350374221802\n",
            "Accuracy on hold-out set: 0.5151\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.317629864692688\n",
            "Accuracy on hold-out set: 0.52625\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2996291444778443\n",
            "Accuracy on hold-out set: 0.5328\n",
            "Returned to Spot: Validation loss: 1.2996291444778443\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6085950260668993\n",
            "Accuracy on hold-out set: 0.4303\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.488989660668373\n",
            "Accuracy on hold-out set: 0.49565\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.509320417966321\n",
            "Accuracy on hold-out set: 0.5062\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5671531373606995\n",
            "Accuracy on hold-out set: 0.5146\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.8474633663917892\n",
            "Accuracy on hold-out set: 0.48765\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 1.8474633663917892\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5308612099170684\n",
            "Accuracy on hold-out set: 0.4396\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4033320865392684\n",
            "Accuracy on hold-out set: 0.4903\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.321448886704445\n",
            "Accuracy on hold-out set: 0.52505\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2420143314898013\n",
            "Accuracy on hold-out set: 0.5589\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2171628588855266\n",
            "Accuracy on hold-out set: 0.5729\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.194259923839569\n",
            "Accuracy on hold-out set: 0.5845\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2004065861523152\n",
            "Accuracy on hold-out set: 0.5882\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2068969598829746\n",
            "Accuracy on hold-out set: 0.5876\n",
            "Returned to Spot: Validation loss: 1.2068969598829746\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.0466731616973877\n",
            "Accuracy on hold-out set: 0.21605\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.851729740333557\n",
            "Accuracy on hold-out set: 0.3146\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7862798281669616\n",
            "Accuracy on hold-out set: 0.33495\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7057621930122375\n",
            "Accuracy on hold-out set: 0.3649\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.650873688697815\n",
            "Accuracy on hold-out set: 0.39675\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6060132405281067\n",
            "Accuracy on hold-out set: 0.4056\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5765421410560607\n",
            "Accuracy on hold-out set: 0.4215\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5385887164592742\n",
            "Accuracy on hold-out set: 0.43835\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5254991105079652\n",
            "Accuracy on hold-out set: 0.4409\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4979320581436157\n",
            "Accuracy on hold-out set: 0.45155\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.485346373271942\n",
            "Accuracy on hold-out set: 0.45915\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4838843169689178\n",
            "Accuracy on hold-out set: 0.4603\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4620240941047669\n",
            "Accuracy on hold-out set: 0.4669\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.454247455739975\n",
            "Accuracy on hold-out set: 0.47085\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.438912195968628\n",
            "Accuracy on hold-out set: 0.47585\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.4127741965293885\n",
            "Accuracy on hold-out set: 0.4819\n",
            "Returned to Spot: Validation loss: 1.4127741965293885\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3052213764190674\n",
            "Accuracy on hold-out set: 0.0975\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3037919952392576\n",
            "Accuracy on hold-out set: 0.1012\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.303340250778198\n",
            "Accuracy on hold-out set: 0.1009\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.303769785308838\n",
            "Accuracy on hold-out set: 0.1016\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.302906025314331\n",
            "Accuracy on hold-out set: 0.1012\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.304404578781128\n",
            "Accuracy on hold-out set: 0.0988\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3038761505126955\n",
            "Accuracy on hold-out set: 0.1005\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.303476993560791\n",
            "Accuracy on hold-out set: 0.0984\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 2.303476993560791\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6105570457220078\n",
            "Accuracy on hold-out set: 0.4008\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4176024095773696\n",
            "Accuracy on hold-out set: 0.48185\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.339094312942028\n",
            "Accuracy on hold-out set: 0.5114\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2971192934274673\n",
            "Accuracy on hold-out set: 0.5391\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2679716799080372\n",
            "Accuracy on hold-out set: 0.5464\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.221918433457613\n",
            "Accuracy on hold-out set: 0.5704\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2370467640697955\n",
            "Accuracy on hold-out set: 0.5667\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2469727664351464\n",
            "Accuracy on hold-out set: 0.5725\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.219236461544037\n",
            "Accuracy on hold-out set: 0.5798\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2014325492858886\n",
            "Accuracy on hold-out set: 0.5929\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2641207372516394\n",
            "Accuracy on hold-out set: 0.58775\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2256553271710873\n",
            "Accuracy on hold-out set: 0.59325\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.276099622068554\n",
            "Accuracy on hold-out set: 0.58755\n",
            "Early stopping at epoch 12\n",
            "Returned to Spot: Validation loss: 1.276099622068554\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5665863901615142\n",
            "Accuracy on hold-out set: 0.4213\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3898400722503663\n",
            "Accuracy on hold-out set: 0.4967\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5025064504146577\n",
            "Accuracy on hold-out set: 0.47305\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.336488530254364\n",
            "Accuracy on hold-out set: 0.51735\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3151448704004287\n",
            "Accuracy on hold-out set: 0.52985\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.301916238474846\n",
            "Accuracy on hold-out set: 0.54105\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3014863790273667\n",
            "Accuracy on hold-out set: 0.54225\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3155202074050902\n",
            "Accuracy on hold-out set: 0.5384\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3509738289833069\n",
            "Accuracy on hold-out set: 0.5338\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3561067677497864\n",
            "Accuracy on hold-out set: 0.5379\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.3561067677497864\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.616323914641142\n",
            "Accuracy on hold-out set: 0.38895\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5144650907337665\n",
            "Accuracy on hold-out set: 0.4236\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5065246790498494\n",
            "Accuracy on hold-out set: 0.44505\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.451298396253586\n",
            "Accuracy on hold-out set: 0.465\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4382186933994294\n",
            "Accuracy on hold-out set: 0.47295\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3933175535500049\n",
            "Accuracy on hold-out set: 0.4828\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.512398532012105\n",
            "Accuracy on hold-out set: 0.45845\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4304519651278853\n",
            "Accuracy on hold-out set: 0.4812\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.396679508651793\n",
            "Accuracy on hold-out set: 0.4891\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.396679508651793\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5192140965938568\n",
            "Accuracy on hold-out set: 0.44695\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3694159398555756\n",
            "Accuracy on hold-out set: 0.5096\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2776463826656341\n",
            "Accuracy on hold-out set: 0.53985\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.201246739411354\n",
            "Accuracy on hold-out set: 0.57275\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1565881531238555\n",
            "Accuracy on hold-out set: 0.59685\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1521810267925263\n",
            "Accuracy on hold-out set: 0.59825\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1470662847280502\n",
            "Accuracy on hold-out set: 0.60165\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1062979637861252\n",
            "Accuracy on hold-out set: 0.61925\n",
            "Returned to Spot: Validation loss: 1.1062979637861252\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5499750067710876\n",
            "Accuracy on hold-out set: 0.44095\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.421380447435379\n",
            "Accuracy on hold-out set: 0.49005\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3351771742343903\n",
            "Accuracy on hold-out set: 0.52535\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2859955494403839\n",
            "Accuracy on hold-out set: 0.53885\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2360858685970306\n",
            "Accuracy on hold-out set: 0.5556\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.229253907608986\n",
            "Accuracy on hold-out set: 0.56675\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1983198960065842\n",
            "Accuracy on hold-out set: 0.574\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1825446780204774\n",
            "Accuracy on hold-out set: 0.5829\n",
            "Returned to Spot: Validation loss: 1.1825446780204774\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.586903349685669\n",
            "Accuracy on hold-out set: 0.4171\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.449531087589264\n",
            "Accuracy on hold-out set: 0.47105\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3662282961845398\n",
            "Accuracy on hold-out set: 0.499\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3207374846458435\n",
            "Accuracy on hold-out set: 0.52725\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2262890999794007\n",
            "Accuracy on hold-out set: 0.5619\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2719718511581422\n",
            "Accuracy on hold-out set: 0.5556\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1903818061828613\n",
            "Accuracy on hold-out set: 0.5802\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1602504940986633\n",
            "Accuracy on hold-out set: 0.5939\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1496941534042358\n",
            "Accuracy on hold-out set: 0.59795\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1509316549301147\n",
            "Accuracy on hold-out set: 0.5978\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1211605348110198\n",
            "Accuracy on hold-out set: 0.6106\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.119526127243042\n",
            "Accuracy on hold-out set: 0.6134\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.0987071434974671\n",
            "Accuracy on hold-out set: 0.6201\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1129939985275268\n",
            "Accuracy on hold-out set: 0.61995\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1207219427108766\n",
            "Accuracy on hold-out set: 0.6146\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.0989610620498658\n",
            "Accuracy on hold-out set: 0.6241\n",
            "Early stopping at epoch 15\n",
            "Returned to Spot: Validation loss: 1.0989610620498658\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.548534450483322\n",
            "Accuracy on hold-out set: 0.4432\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3902103235244752\n",
            "Accuracy on hold-out set: 0.49555\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3185917284488677\n",
            "Accuracy on hold-out set: 0.52975\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2844062425374985\n",
            "Accuracy on hold-out set: 0.5412\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.200610306072235\n",
            "Accuracy on hold-out set: 0.57895\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2354942067623138\n",
            "Accuracy on hold-out set: 0.5809\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.165984364247322\n",
            "Accuracy on hold-out set: 0.5906\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.176689490890503\n",
            "Accuracy on hold-out set: 0.5995\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2314100343465806\n",
            "Accuracy on hold-out set: 0.5973\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.233591024184227\n",
            "Accuracy on hold-out set: 0.5943\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.233591024184227\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.565370811700821\n",
            "Accuracy on hold-out set: 0.42525\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3842902449131012\n",
            "Accuracy on hold-out set: 0.5039\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2893643216609956\n",
            "Accuracy on hold-out set: 0.54195\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2134075435638427\n",
            "Accuracy on hold-out set: 0.57095\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2048515191078186\n",
            "Accuracy on hold-out set: 0.5771\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1796334614276887\n",
            "Accuracy on hold-out set: 0.5856\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.145251351070404\n",
            "Accuracy on hold-out set: 0.60095\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1236011323451995\n",
            "Accuracy on hold-out set: 0.6087\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1648558157920836\n",
            "Accuracy on hold-out set: 0.60805\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1206051767110825\n",
            "Accuracy on hold-out set: 0.6123\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.150555108332634\n",
            "Accuracy on hold-out set: 0.6081\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1281574748277665\n",
            "Accuracy on hold-out set: 0.61905\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1535952755212784\n",
            "Accuracy on hold-out set: 0.61355\n",
            "Early stopping at epoch 12\n",
            "Returned to Spot: Validation loss: 1.1535952755212784\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3050463191986084\n",
            "Accuracy on hold-out set: 0.10185\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3037009719848633\n",
            "Accuracy on hold-out set: 0.1018\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3024063343048096\n",
            "Accuracy on hold-out set: 0.10015\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3010297512054443\n",
            "Accuracy on hold-out set: 0.10185\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.29938761177063\n",
            "Accuracy on hold-out set: 0.1065\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.2972445301055906\n",
            "Accuracy on hold-out set: 0.1286\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.2941276252746583\n",
            "Accuracy on hold-out set: 0.1572\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.289200886917114\n",
            "Accuracy on hold-out set: 0.18645\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.2817041595458982\n",
            "Accuracy on hold-out set: 0.18455\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 2.269841854095459\n",
            "Accuracy on hold-out set: 0.1737\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 2.250188982772827\n",
            "Accuracy on hold-out set: 0.17455\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 2.214307999801636\n",
            "Accuracy on hold-out set: 0.18795\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 2.1619927352905273\n",
            "Accuracy on hold-out set: 0.1984\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 2.1174241090774535\n",
            "Accuracy on hold-out set: 0.20825\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 2.0848372144699097\n",
            "Accuracy on hold-out set: 0.22085\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 2.0595813249588013\n",
            "Accuracy on hold-out set: 0.2325\n",
            "Returned to Spot: Validation loss: 2.0595813249588013\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 512, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.531710502317548\n",
            "Accuracy on hold-out set: 0.45875\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4938969088386744\n",
            "Accuracy on hold-out set: 0.5101\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3748931756444276\n",
            "Accuracy on hold-out set: 0.52965\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2896621294140815\n",
            "Accuracy on hold-out set: 0.55675\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3225086519269738\n",
            "Accuracy on hold-out set: 0.5736\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4049951573271304\n",
            "Accuracy on hold-out set: 0.5567\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3876173727569636\n",
            "Accuracy on hold-out set: 0.55725\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.3876173727569636\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 4, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9344355963379145\n",
            "Accuracy on hold-out set: 0.24535\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8826680832281708\n",
            "Accuracy on hold-out set: 0.2789\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8563078288435937\n",
            "Accuracy on hold-out set: 0.29415\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.860615335136652\n",
            "Accuracy on hold-out set: 0.29485\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.8185921945258976\n",
            "Accuracy on hold-out set: 0.3088\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.7896727472446858\n",
            "Accuracy on hold-out set: 0.32435\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.7635301688604057\n",
            "Accuracy on hold-out set: 0.3535\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.7552352060772478\n",
            "Accuracy on hold-out set: 0.35845\n",
            "Returned to Spot: Validation loss: 1.7552352060772478\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4940572607815266\n",
            "Accuracy on hold-out set: 0.45695\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3980643737509846\n",
            "Accuracy on hold-out set: 0.5036\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3249427136071026\n",
            "Accuracy on hold-out set: 0.54395\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2869517201904208\n",
            "Accuracy on hold-out set: 0.56245\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.239290882874932\n",
            "Accuracy on hold-out set: 0.57655\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.229828486158978\n",
            "Accuracy on hold-out set: 0.592\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.257313425924629\n",
            "Accuracy on hold-out set: 0.59685\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.236380718271248\n",
            "Accuracy on hold-out set: 0.5994\n",
            "Returned to Spot: Validation loss: 1.236380718271248\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7000892451763152\n",
            "Accuracy on hold-out set: 0.3476\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4648185739547015\n",
            "Accuracy on hold-out set: 0.4743\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5104985758028924\n",
            "Accuracy on hold-out set: 0.4776\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4316905048554762\n",
            "Accuracy on hold-out set: 0.5208\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.396882446894422\n",
            "Accuracy on hold-out set: 0.5332\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3974470159534365\n",
            "Accuracy on hold-out set: 0.5443\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.444490295990836\n",
            "Accuracy on hold-out set: 0.55365\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5742134641017764\n",
            "Accuracy on hold-out set: 0.5341\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.5742134641017764\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 4, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7115993636250495\n",
            "Accuracy on hold-out set: 0.34645\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5774565523862838\n",
            "Accuracy on hold-out set: 0.41315\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4773473159313202\n",
            "Accuracy on hold-out set: 0.4743\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3868934245128184\n",
            "Accuracy on hold-out set: 0.5135\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3556985781081021\n",
            "Accuracy on hold-out set: 0.5196\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3129299934998155\n",
            "Accuracy on hold-out set: 0.54625\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.359359441320598\n",
            "Accuracy on hold-out set: 0.5386\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.308007786832191\n",
            "Accuracy on hold-out set: 0.5554\n",
            "Returned to Spot: Validation loss: 1.308007786832191\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5564522732257844\n",
            "Accuracy on hold-out set: 0.43525\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3831846187114716\n",
            "Accuracy on hold-out set: 0.50205\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3048095542907714\n",
            "Accuracy on hold-out set: 0.5326\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.279697235441208\n",
            "Accuracy on hold-out set: 0.54755\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2145963551521302\n",
            "Accuracy on hold-out set: 0.57325\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.229034992480278\n",
            "Accuracy on hold-out set: 0.5639\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1802646192550659\n",
            "Accuracy on hold-out set: 0.5841\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1534132308840752\n",
            "Accuracy on hold-out set: 0.59575\n",
            "Returned to Spot: Validation loss: 1.1534132308840752\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.541224970138073\n",
            "Accuracy on hold-out set: 0.43745\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.449147278803587\n",
            "Accuracy on hold-out set: 0.474\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3960480239480735\n",
            "Accuracy on hold-out set: 0.4964\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3697826312988997\n",
            "Accuracy on hold-out set: 0.5088\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.337476400053501\n",
            "Accuracy on hold-out set: 0.52425\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3083044090628624\n",
            "Accuracy on hold-out set: 0.53575\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3086234772443772\n",
            "Accuracy on hold-out set: 0.53615\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2890883934244513\n",
            "Accuracy on hold-out set: 0.5461\n",
            "Returned to Spot: Validation loss: 1.2890883934244513\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4582255064964293\n",
            "Accuracy on hold-out set: 0.46955\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3323255103230476\n",
            "Accuracy on hold-out set: 0.5252\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2492559545993804\n",
            "Accuracy on hold-out set: 0.55425\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1931713679909706\n",
            "Accuracy on hold-out set: 0.5809\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1963073208153248\n",
            "Accuracy on hold-out set: 0.576\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1480344183146953\n",
            "Accuracy on hold-out set: 0.59635\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1447177296608686\n",
            "Accuracy on hold-out set: 0.6111\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1426386052191257\n",
            "Accuracy on hold-out set: 0.61405\n",
            "Returned to Spot: Validation loss: 1.1426386052191257\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.775534935748577\n",
            "Accuracy on hold-out set: 0.36715\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5410203356981278\n",
            "Accuracy on hold-out set: 0.44055\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3294487041085958\n",
            "Accuracy on hold-out set: 0.5277\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3363687094234862\n",
            "Accuracy on hold-out set: 0.5393\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2703627927191556\n",
            "Accuracy on hold-out set: 0.57495\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2084410125529395\n",
            "Accuracy on hold-out set: 0.59585\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2381131987908855\n",
            "Accuracy on hold-out set: 0.59245\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2357772737733088\n",
            "Accuracy on hold-out set: 0.6037\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2585298459073528\n",
            "Accuracy on hold-out set: 0.60895\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.2585298459073528\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3058753903388975\n",
            "Accuracy on hold-out set: 0.0999\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3051546782493593\n",
            "Accuracy on hold-out set: 0.0989\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3054580949783325\n",
            "Accuracy on hold-out set: 0.0999\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3052301896095275\n",
            "Accuracy on hold-out set: 0.10145\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3037102777481078\n",
            "Accuracy on hold-out set: 0.10145\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.303505483055115\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3053885164260866\n",
            "Accuracy on hold-out set: 0.0979\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.3045515835762025\n",
            "Accuracy on hold-out set: 0.09905\n",
            "Returned to Spot: Validation loss: 2.3045515835762025\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5312700084418058\n",
            "Accuracy on hold-out set: 0.4458\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4956475167583674\n",
            "Accuracy on hold-out set: 0.4778\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3805161542862654\n",
            "Accuracy on hold-out set: 0.51625\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2533619691256435\n",
            "Accuracy on hold-out set: 0.5652\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2830173291899263\n",
            "Accuracy on hold-out set: 0.56265\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2796788131374865\n",
            "Accuracy on hold-out set: 0.56595\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2955705938960425\n",
            "Accuracy on hold-out set: 0.5708\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.2955705938960425\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 4, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.923422474718094\n",
            "Accuracy on hold-out set: 0.25585\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.794766632962227\n",
            "Accuracy on hold-out set: 0.32795\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5954732029676437\n",
            "Accuracy on hold-out set: 0.3909\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5457154643535613\n",
            "Accuracy on hold-out set: 0.43375\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5769532282471657\n",
            "Accuracy on hold-out set: 0.45\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5065878707170486\n",
            "Accuracy on hold-out set: 0.454\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5176700703501702\n",
            "Accuracy on hold-out set: 0.47845\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5798015952587128\n",
            "Accuracy on hold-out set: 0.48495\n",
            "Returned to Spot: Validation loss: 1.5798015952587128\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4126612861171364\n",
            "Accuracy on hold-out set: 0.50105\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3983695311714517\n",
            "Accuracy on hold-out set: 0.5315\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3209261715853513\n",
            "Accuracy on hold-out set: 0.564\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.383295036130142\n",
            "Accuracy on hold-out set: 0.57085\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.335971830634388\n",
            "Accuracy on hold-out set: 0.60115\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.314645814949082\n",
            "Accuracy on hold-out set: 0.6084\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.449110259155502\n",
            "Accuracy on hold-out set: 0.6113\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4737854514009705\n",
            "Accuracy on hold-out set: 0.6138\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5297027861564192\n",
            "Accuracy on hold-out set: 0.62025\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.5297027861564192\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6013907177388669\n",
            "Accuracy on hold-out set: 0.4332\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6274254986949266\n",
            "Accuracy on hold-out set: 0.45795\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.560645678508468\n",
            "Accuracy on hold-out set: 0.48665\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5988218897985293\n",
            "Accuracy on hold-out set: 0.4731\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6234065309641883\n",
            "Accuracy on hold-out set: 0.4772\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6639016122706234\n",
            "Accuracy on hold-out set: 0.487\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.6639016122706234\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 512, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5347007665872574\n",
            "Accuracy on hold-out set: 0.43795\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.427925970184803\n",
            "Accuracy on hold-out set: 0.48415\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.418509808921814\n",
            "Accuracy on hold-out set: 0.48485\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3833606039524078\n",
            "Accuracy on hold-out set: 0.50415\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.332649522805214\n",
            "Accuracy on hold-out set: 0.50535\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3374265225470066\n",
            "Accuracy on hold-out set: 0.51445\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3099680036962031\n",
            "Accuracy on hold-out set: 0.529\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3013940046191215\n",
            "Accuracy on hold-out set: 0.53095\n",
            "Returned to Spot: Validation loss: 1.3013940046191215\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 16, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6963871286273002\n",
            "Accuracy on hold-out set: 0.37395\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6066600397087634\n",
            "Accuracy on hold-out set: 0.4164\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5596734996920452\n",
            "Accuracy on hold-out set: 0.444\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5041168544761836\n",
            "Accuracy on hold-out set: 0.46205\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4809539353427477\n",
            "Accuracy on hold-out set: 0.47185\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4540993080308662\n",
            "Accuracy on hold-out set: 0.4873\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.434912297421368\n",
            "Accuracy on hold-out set: 0.4964\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.417286547784647\n",
            "Accuracy on hold-out set: 0.5036\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4050995071454906\n",
            "Accuracy on hold-out set: 0.51135\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3946131573572755\n",
            "Accuracy on hold-out set: 0.5147\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3868878812863026\n",
            "Accuracy on hold-out set: 0.5237\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.373669784537144\n",
            "Accuracy on hold-out set: 0.5299\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3702967760106097\n",
            "Accuracy on hold-out set: 0.53035\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.373752905434929\n",
            "Accuracy on hold-out set: 0.5336\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3674049927527085\n",
            "Accuracy on hold-out set: 0.5355\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3770915191776352\n",
            "Accuracy on hold-out set: 0.53785\n",
            "Returned to Spot: Validation loss: 1.3770915191776352\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.501297019815445\n",
            "Accuracy on hold-out set: 0.45425\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.426904198423028\n",
            "Accuracy on hold-out set: 0.48235\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3832557665862144\n",
            "Accuracy on hold-out set: 0.50655\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.329102886157483\n",
            "Accuracy on hold-out set: 0.5479\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2826180626021697\n",
            "Accuracy on hold-out set: 0.5494\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3351972924102098\n",
            "Accuracy on hold-out set: 0.53945\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.304933175746398\n",
            "Accuracy on hold-out set: 0.56455\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.319725939744059\n",
            "Accuracy on hold-out set: 0.5644\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.319725939744059\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5055537081718444\n",
            "Accuracy on hold-out set: 0.4523\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.326279971408844\n",
            "Accuracy on hold-out set: 0.52325\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2377784937620162\n",
            "Accuracy on hold-out set: 0.5619\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2393915433704854\n",
            "Accuracy on hold-out set: 0.56535\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2050706733644008\n",
            "Accuracy on hold-out set: 0.57925\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1909745478510856\n",
            "Accuracy on hold-out set: 0.5897\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2239350686967372\n",
            "Accuracy on hold-out set: 0.58925\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.213051145297289\n",
            "Accuracy on hold-out set: 0.59445\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2411882239341736\n",
            "Accuracy on hold-out set: 0.58845\n",
            "Early stopping at epoch 8\n",
            "Returned to Spot: Validation loss: 1.2411882239341736\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.640087369465828\n",
            "Accuracy on hold-out set: 0.36695\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5821777476072312\n",
            "Accuracy on hold-out set: 0.39585\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.528024046778679\n",
            "Accuracy on hold-out set: 0.4181\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5375090851068496\n",
            "Accuracy on hold-out set: 0.4274\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4256746960639954\n",
            "Accuracy on hold-out set: 0.47055\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.403763661336899\n",
            "Accuracy on hold-out set: 0.4901\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.519382884055376\n",
            "Accuracy on hold-out set: 0.46635\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.324006092429161\n",
            "Accuracy on hold-out set: 0.51505\n",
            "Returned to Spot: Validation loss: 1.324006092429161\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6137120404720307\n",
            "Accuracy on hold-out set: 0.4284\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5161146466612816\n",
            "Accuracy on hold-out set: 0.474\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.446209582567215\n",
            "Accuracy on hold-out set: 0.49595\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4502028604984283\n",
            "Accuracy on hold-out set: 0.4996\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4311331338047981\n",
            "Accuracy on hold-out set: 0.5027\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4523466938972474\n",
            "Accuracy on hold-out set: 0.4981\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.471361422753334\n",
            "Accuracy on hold-out set: 0.52745\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4015340739488602\n",
            "Accuracy on hold-out set: 0.5409\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.452269690167904\n",
            "Accuracy on hold-out set: 0.5095\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.50818956772089\n",
            "Accuracy on hold-out set: 0.5182\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.5250327778339385\n",
            "Accuracy on hold-out set: 0.50045\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.5250327778339385\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 32, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6271641514468007\n",
            "Accuracy on hold-out set: 0.423\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6590028867707967\n",
            "Accuracy on hold-out set: 0.46035\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6541288575053834\n",
            "Accuracy on hold-out set: 0.4582\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.581249888487464\n",
            "Accuracy on hold-out set: 0.5112\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5839257425984676\n",
            "Accuracy on hold-out set: 0.50015\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6619802937470631\n",
            "Accuracy on hold-out set: 0.5166\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.8068687059291544\n",
            "Accuracy on hold-out set: 0.50275\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.8068687059291544\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.69262995929718\n",
            "Accuracy on hold-out set: 0.3679\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.609595244216919\n",
            "Accuracy on hold-out set: 0.3971\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5581378490448\n",
            "Accuracy on hold-out set: 0.41795\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5179274202346802\n",
            "Accuracy on hold-out set: 0.43715\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4973617740631104\n",
            "Accuracy on hold-out set: 0.44315\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4777344252586364\n",
            "Accuracy on hold-out set: 0.4537\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4548868406295776\n",
            "Accuracy on hold-out set: 0.4639\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.445077248764038\n",
            "Accuracy on hold-out set: 0.46575\n",
            "Returned to Spot: Validation loss: 1.445077248764038\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 8, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7613483574867248\n",
            "Accuracy on hold-out set: 0.3302\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6824755518913268\n",
            "Accuracy on hold-out set: 0.3555\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6346402435302734\n",
            "Accuracy on hold-out set: 0.3716\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.604832372379303\n",
            "Accuracy on hold-out set: 0.38405\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5947361196517944\n",
            "Accuracy on hold-out set: 0.3908\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5713340215682983\n",
            "Accuracy on hold-out set: 0.3975\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5616665967941283\n",
            "Accuracy on hold-out set: 0.40245\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5452393602371215\n",
            "Accuracy on hold-out set: 0.4124\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5451899562835694\n",
            "Accuracy on hold-out set: 0.4152\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.5275601105690002\n",
            "Accuracy on hold-out set: 0.4231\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.5181002814769744\n",
            "Accuracy on hold-out set: 0.42825\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.536110140657425\n",
            "Accuracy on hold-out set: 0.42315\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.5058274334430695\n",
            "Accuracy on hold-out set: 0.4352\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.5111910690307617\n",
            "Accuracy on hold-out set: 0.4322\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4820657857894897\n",
            "Accuracy on hold-out set: 0.44715\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.4768732035636902\n",
            "Accuracy on hold-out set: 0.45395\n",
            "Returned to Spot: Validation loss: 1.4768732035636902\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 4, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7838132709503174\n",
            "Accuracy on hold-out set: 0.28855\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6674326466560363\n",
            "Accuracy on hold-out set: 0.3573\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6475467790603637\n",
            "Accuracy on hold-out set: 0.37355\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6439681240081787\n",
            "Accuracy on hold-out set: 0.38815\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5615727527618408\n",
            "Accuracy on hold-out set: 0.41675\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5142644332408906\n",
            "Accuracy on hold-out set: 0.4463\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4487579855442048\n",
            "Accuracy on hold-out set: 0.47755\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.44333525390625\n",
            "Accuracy on hold-out set: 0.49605\n",
            "Returned to Spot: Validation loss: 1.44333525390625\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.035484635448456\n",
            "Accuracy on hold-out set: 0.24745\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8943558052062988\n",
            "Accuracy on hold-out set: 0.3048\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8004024423599243\n",
            "Accuracy on hold-out set: 0.342\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7212972178459167\n",
            "Accuracy on hold-out set: 0.3682\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6519175006866456\n",
            "Accuracy on hold-out set: 0.3978\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.60091632771492\n",
            "Accuracy on hold-out set: 0.41435\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5900968547821044\n",
            "Accuracy on hold-out set: 0.4179\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.530587996006012\n",
            "Accuracy on hold-out set: 0.4399\n",
            "Returned to Spot: Validation loss: 1.530587996006012\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5998300346851348\n",
            "Accuracy on hold-out set: 0.4167\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4915261362463237\n",
            "Accuracy on hold-out set: 0.4735\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.391447420115769\n",
            "Accuracy on hold-out set: 0.50945\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.37623559583202\n",
            "Accuracy on hold-out set: 0.5149\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3075403955403715\n",
            "Accuracy on hold-out set: 0.5462\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3215529520340263\n",
            "Accuracy on hold-out set: 0.54545\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2615841743651777\n",
            "Accuracy on hold-out set: 0.5605\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.242274902792275\n",
            "Accuracy on hold-out set: 0.56975\n",
            "Returned to Spot: Validation loss: 1.242274902792275\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 256, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6240393126624986\n",
            "Accuracy on hold-out set: 0.44535\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.9151223330239715\n",
            "Accuracy on hold-out set: 0.40865\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.2453758005442084\n",
            "Accuracy on hold-out set: 0.4319\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.8982198383161926\n",
            "Accuracy on hold-out set: 0.4778\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 1.8982198383161926\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3072367932081224\n",
            "Accuracy on hold-out set: 0.1002\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3045394266605377\n",
            "Accuracy on hold-out set: 0.1002\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.306739068055153\n",
            "Accuracy on hold-out set: 0.10005\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3064716835975645\n",
            "Accuracy on hold-out set: 0.0993\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3038635276794435\n",
            "Accuracy on hold-out set: 0.09845\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.306441037154198\n",
            "Accuracy on hold-out set: 0.10005\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.306123599743843\n",
            "Accuracy on hold-out set: 0.1005\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.3118641943454743\n",
            "Accuracy on hold-out set: 0.0993\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 2.3118641943454743\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.15799198179245\n",
            "Accuracy on hold-out set: 0.2179\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.9178354852676391\n",
            "Accuracy on hold-out set: 0.29645\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7791762944221496\n",
            "Accuracy on hold-out set: 0.34655\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6836070779800416\n",
            "Accuracy on hold-out set: 0.39305\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.61725726480484\n",
            "Accuracy on hold-out set: 0.41705\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.570879638671875\n",
            "Accuracy on hold-out set: 0.4286\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5374356571674348\n",
            "Accuracy on hold-out set: 0.44195\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.539457605457306\n",
            "Accuracy on hold-out set: 0.4289\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5048376167297364\n",
            "Accuracy on hold-out set: 0.4461\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4631058159828185\n",
            "Accuracy on hold-out set: 0.469\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.445140405845642\n",
            "Accuracy on hold-out set: 0.47525\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4323358116626739\n",
            "Accuracy on hold-out set: 0.48225\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4209051260471344\n",
            "Accuracy on hold-out set: 0.48545\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.406243554544449\n",
            "Accuracy on hold-out set: 0.4921\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3886976237773896\n",
            "Accuracy on hold-out set: 0.49605\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3800306380271912\n",
            "Accuracy on hold-out set: 0.50065\n",
            "Returned to Spot: Validation loss: 1.3800306380271912\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 128, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.595920894432068\n",
            "Accuracy on hold-out set: 0.40965\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4075430617332458\n",
            "Accuracy on hold-out set: 0.4845\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3276311051368714\n",
            "Accuracy on hold-out set: 0.52475\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2581436966896058\n",
            "Accuracy on hold-out set: 0.55385\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1826055087089538\n",
            "Accuracy on hold-out set: 0.5813\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.200200850391388\n",
            "Accuracy on hold-out set: 0.5786\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.186198048400879\n",
            "Accuracy on hold-out set: 0.5867\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1407299230098724\n",
            "Accuracy on hold-out set: 0.5993\n",
            "Returned to Spot: Validation loss: 1.1407299230098724\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.945459662628174\n",
            "Accuracy on hold-out set: 0.27355\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.699001181858778\n",
            "Accuracy on hold-out set: 0.3807\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6296761679589749\n",
            "Accuracy on hold-out set: 0.40075\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5906922686696052\n",
            "Accuracy on hold-out set: 0.4087\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5398053229868411\n",
            "Accuracy on hold-out set: 0.4301\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5096618636846542\n",
            "Accuracy on hold-out set: 0.44315\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4667233701050282\n",
            "Accuracy on hold-out set: 0.45705\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4479472797632218\n",
            "Accuracy on hold-out set: 0.4723\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4284751403853297\n",
            "Accuracy on hold-out set: 0.47935\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4068534866482019\n",
            "Accuracy on hold-out set: 0.4876\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4135013885080814\n",
            "Accuracy on hold-out set: 0.49135\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.360270436991751\n",
            "Accuracy on hold-out set: 0.50235\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3635604327246547\n",
            "Accuracy on hold-out set: 0.50575\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3296640992492437\n",
            "Accuracy on hold-out set: 0.51765\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.333960287477076\n",
            "Accuracy on hold-out set: 0.5207\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3179982271268964\n",
            "Accuracy on hold-out set: 0.52735\n",
            "Returned to Spot: Validation loss: 1.3179982271268964\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 8, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8639903958380222\n",
            "Accuracy on hold-out set: 0.2592\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.8458817102760077\n",
            "Accuracy on hold-out set: 0.28545\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8044734625607728\n",
            "Accuracy on hold-out set: 0.3031\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.780671382728219\n",
            "Accuracy on hold-out set: 0.31965\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.7849460999429225\n",
            "Accuracy on hold-out set: 0.3301\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.7763540658533574\n",
            "Accuracy on hold-out set: 0.3405\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.76270069899261\n",
            "Accuracy on hold-out set: 0.34155\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.741878121562302\n",
            "Accuracy on hold-out set: 0.3583\n",
            "Returned to Spot: Validation loss: 1.741878121562302\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.541077610206604\n",
            "Accuracy on hold-out set: 0.4321\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4342890329837799\n",
            "Accuracy on hold-out set: 0.48295\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3054247043132783\n",
            "Accuracy on hold-out set: 0.5296\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3107368699073791\n",
            "Accuracy on hold-out set: 0.5278\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2592322531700135\n",
            "Accuracy on hold-out set: 0.55015\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2450919269561767\n",
            "Accuracy on hold-out set: 0.55735\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2547333433151244\n",
            "Accuracy on hold-out set: 0.5556\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1825427953720093\n",
            "Accuracy on hold-out set: 0.5817\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1649083084106446\n",
            "Accuracy on hold-out set: 0.58685\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.171546476626396\n",
            "Accuracy on hold-out set: 0.58855\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1562251917362214\n",
            "Accuracy on hold-out set: 0.59495\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.209912662935257\n",
            "Accuracy on hold-out set: 0.5796\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1710279447078704\n",
            "Accuracy on hold-out set: 0.593\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.191900940465927\n",
            "Accuracy on hold-out set: 0.58515\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.191900940465927\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5034427450180055\n",
            "Accuracy on hold-out set: 0.47205\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.2945976433753967\n",
            "Accuracy on hold-out set: 0.54125\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2512328372001649\n",
            "Accuracy on hold-out set: 0.56055\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2110907301902771\n",
            "Accuracy on hold-out set: 0.5891\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3007853558540343\n",
            "Accuracy on hold-out set: 0.57895\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2377582907676696\n",
            "Accuracy on hold-out set: 0.5955\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2650841888427735\n",
            "Accuracy on hold-out set: 0.60165\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.2650841888427735\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9381751545906067\n",
            "Accuracy on hold-out set: 0.2942\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7971678470134735\n",
            "Accuracy on hold-out set: 0.35115\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6883479023456573\n",
            "Accuracy on hold-out set: 0.38445\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.6178626664161682\n",
            "Accuracy on hold-out set: 0.40575\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5809992532253265\n",
            "Accuracy on hold-out set: 0.4139\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5394089184999467\n",
            "Accuracy on hold-out set: 0.43035\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5131916936159133\n",
            "Accuracy on hold-out set: 0.44445\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4778549068927764\n",
            "Accuracy on hold-out set: 0.45585\n",
            "Returned to Spot: Validation loss: 1.4778549068927764\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7015155277252196\n",
            "Accuracy on hold-out set: 0.3743\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.635652132487297\n",
            "Accuracy on hold-out set: 0.40305\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.590456673103571\n",
            "Accuracy on hold-out set: 0.41845\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.568482292175293\n",
            "Accuracy on hold-out set: 0.4248\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.554170063173771\n",
            "Accuracy on hold-out set: 0.4288\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.537796498054266\n",
            "Accuracy on hold-out set: 0.43495\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5267673579812049\n",
            "Accuracy on hold-out set: 0.44145\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5161228376835585\n",
            "Accuracy on hold-out set: 0.4453\n",
            "Returned to Spot: Validation loss: 1.5161228376835585\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.305104531478882\n",
            "Accuracy on hold-out set: 0.0999\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3052336099624635\n",
            "Accuracy on hold-out set: 0.09875\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3059408113479614\n",
            "Accuracy on hold-out set: 0.0996\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.304487776184082\n",
            "Accuracy on hold-out set: 0.10065\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3049997524261476\n",
            "Accuracy on hold-out set: 0.098\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3058456293106078\n",
            "Accuracy on hold-out set: 0.0999\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3053681562423707\n",
            "Accuracy on hold-out set: 0.1014\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 2.3053681562423707\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.730897052192688\n",
            "Accuracy on hold-out set: 0.33255\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5334066223084926\n",
            "Accuracy on hold-out set: 0.415\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.568706860077381\n",
            "Accuracy on hold-out set: 0.41735\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4570101277828216\n",
            "Accuracy on hold-out set: 0.47005\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3636076617747546\n",
            "Accuracy on hold-out set: 0.50455\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4102053412348032\n",
            "Accuracy on hold-out set: 0.50065\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3385866625249385\n",
            "Accuracy on hold-out set: 0.52295\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3839226496607064\n",
            "Accuracy on hold-out set: 0.49915\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4860725783236324\n",
            "Accuracy on hold-out set: 0.4838\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3377843427181244\n",
            "Accuracy on hold-out set: 0.52495\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2836765386521816\n",
            "Accuracy on hold-out set: 0.5392\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.4914180082663893\n",
            "Accuracy on hold-out set: 0.48495\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.313030899426341\n",
            "Accuracy on hold-out set: 0.5341\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3661570167653263\n",
            "Accuracy on hold-out set: 0.5146\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.3661570167653263\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 4, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3064391399383544\n",
            "Accuracy on hold-out set: 0.1034\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.303915782546997\n",
            "Accuracy on hold-out set: 0.1034\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3031761224746705\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3029106897354126\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.302816633987427\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3027862052917483\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.3027847677230837\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.302792971420288\n",
            "Accuracy on hold-out set: 0.09935\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.3028062479019167\n",
            "Accuracy on hold-out set: 0.09915\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 2.3028195817947386\n",
            "Accuracy on hold-out set: 0.09915\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 2.3028195817947386\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.197437245416641\n",
            "Accuracy on hold-out set: 0.20315\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.9314991114139557\n",
            "Accuracy on hold-out set: 0.27635\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8128642411231994\n",
            "Accuracy on hold-out set: 0.3132\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.7471985587596894\n",
            "Accuracy on hold-out set: 0.33185\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6928528033256531\n",
            "Accuracy on hold-out set: 0.3522\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6587021741628647\n",
            "Accuracy on hold-out set: 0.36695\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.6651961311101913\n",
            "Accuracy on hold-out set: 0.3725\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.6034479558229446\n",
            "Accuracy on hold-out set: 0.39255\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5678817193508148\n",
            "Accuracy on hold-out set: 0.402\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.550241799879074\n",
            "Accuracy on hold-out set: 0.41355\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.5337896157503128\n",
            "Accuracy on hold-out set: 0.42405\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.5253392876148224\n",
            "Accuracy on hold-out set: 0.42975\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.5095917401075363\n",
            "Accuracy on hold-out set: 0.4362\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.4920941741943359\n",
            "Accuracy on hold-out set: 0.4377\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.4723210167884826\n",
            "Accuracy on hold-out set: 0.4483\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.4657755815982818\n",
            "Accuracy on hold-out set: 0.45515\n",
            "Returned to Spot: Validation loss: 1.4657755815982818\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 4, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7545480082258582\n",
            "Accuracy on hold-out set: 0.3258\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7699096306999214\n",
            "Accuracy on hold-out set: 0.3786\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6008734730481635\n",
            "Accuracy on hold-out set: 0.44095\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5823294533374719\n",
            "Accuracy on hold-out set: 0.465\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5879604841184163\n",
            "Accuracy on hold-out set: 0.4641\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.549072503819375\n",
            "Accuracy on hold-out set: 0.48135\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.537669729405106\n",
            "Accuracy on hold-out set: 0.50105\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5739599999100844\n",
            "Accuracy on hold-out set: 0.48145\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.5167056555845309\n",
            "Accuracy on hold-out set: 0.49495\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4548495127964793\n",
            "Accuracy on hold-out set: 0.5114\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4394002803934272\n",
            "Accuracy on hold-out set: 0.51945\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.5166481084175378\n",
            "Accuracy on hold-out set: 0.512\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.4534175994392717\n",
            "Accuracy on hold-out set: 0.51025\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.4840153528249291\n",
            "Accuracy on hold-out set: 0.52245\n",
            "Early stopping at epoch 13\n",
            "Returned to Spot: Validation loss: 1.4840153528249291\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.304406952095032\n",
            "Accuracy on hold-out set: 0.09725\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.303022660446167\n",
            "Accuracy on hold-out set: 0.1004\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3038189706802368\n",
            "Accuracy on hold-out set: 0.10115\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3041886325836183\n",
            "Accuracy on hold-out set: 0.09975\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3048224634170533\n",
            "Accuracy on hold-out set: 0.10065\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 2.3048224634170533\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3042849695205687\n",
            "Accuracy on hold-out set: 0.1002\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3031791482925414\n",
            "Accuracy on hold-out set: 0.1013\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.305307182884216\n",
            "Accuracy on hold-out set: 0.1013\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.306211248588562\n",
            "Accuracy on hold-out set: 0.0996\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3037787652015687\n",
            "Accuracy on hold-out set: 0.1013\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 2.3037787652015687\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7680081143677235\n",
            "Accuracy on hold-out set: 0.3472\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6241156773768366\n",
            "Accuracy on hold-out set: 0.4059\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5726121031224727\n",
            "Accuracy on hold-out set: 0.4292\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5374065861821176\n",
            "Accuracy on hold-out set: 0.4505\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5059152625098824\n",
            "Accuracy on hold-out set: 0.4661\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4924024943133816\n",
            "Accuracy on hold-out set: 0.4725\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.486739799855044\n",
            "Accuracy on hold-out set: 0.4832\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4586631808014587\n",
            "Accuracy on hold-out set: 0.4868\n",
            "Returned to Spot: Validation loss: 1.4586631808014587\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.551169102191925\n",
            "Accuracy on hold-out set: 0.43695\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.416638207912445\n",
            "Accuracy on hold-out set: 0.49015\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3098766451358794\n",
            "Accuracy on hold-out set: 0.5256\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2676046391963958\n",
            "Accuracy on hold-out set: 0.54245\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2456863802433014\n",
            "Accuracy on hold-out set: 0.549\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2125645106077194\n",
            "Accuracy on hold-out set: 0.5666\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2179971180438995\n",
            "Accuracy on hold-out set: 0.56745\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.226029860663414\n",
            "Accuracy on hold-out set: 0.56845\n",
            "Returned to Spot: Validation loss: 1.226029860663414\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 256, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5202430253982544\n",
            "Accuracy on hold-out set: 0.4475\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3914086688041687\n",
            "Accuracy on hold-out set: 0.49795\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3433089659690858\n",
            "Accuracy on hold-out set: 0.52085\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3150980281829834\n",
            "Accuracy on hold-out set: 0.53235\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2846929370880127\n",
            "Accuracy on hold-out set: 0.5434\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2655867159843446\n",
            "Accuracy on hold-out set: 0.55275\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2344030531883239\n",
            "Accuracy on hold-out set: 0.56565\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2233245191574096\n",
            "Accuracy on hold-out set: 0.57155\n",
            "Returned to Spot: Validation loss: 1.2233245191574096\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 256, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5846643182754516\n",
            "Accuracy on hold-out set: 0.40525\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4314991222381592\n",
            "Accuracy on hold-out set: 0.4796\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3369190102577209\n",
            "Accuracy on hold-out set: 0.51555\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3071910179138184\n",
            "Accuracy on hold-out set: 0.5273\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.258411805152893\n",
            "Accuracy on hold-out set: 0.553\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.208210613155365\n",
            "Accuracy on hold-out set: 0.57155\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1886702037811279\n",
            "Accuracy on hold-out set: 0.5825\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1627376702308654\n",
            "Accuracy on hold-out set: 0.5929\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1346504122257233\n",
            "Accuracy on hold-out set: 0.6029\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.152639419746399\n",
            "Accuracy on hold-out set: 0.59985\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1408300563812255\n",
            "Accuracy on hold-out set: 0.6046\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1826919541835785\n",
            "Accuracy on hold-out set: 0.5994\n",
            "Early stopping at epoch 11\n",
            "Returned to Spot: Validation loss: 1.1826919541835785\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 4, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5657130837082862\n",
            "Accuracy on hold-out set: 0.42475\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5014648430109023\n",
            "Accuracy on hold-out set: 0.46315\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4271655964482575\n",
            "Accuracy on hold-out set: 0.5015\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.447827986792475\n",
            "Accuracy on hold-out set: 0.51435\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3897209243908524\n",
            "Accuracy on hold-out set: 0.5154\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3603035537387245\n",
            "Accuracy on hold-out set: 0.5476\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5802954374264926\n",
            "Accuracy on hold-out set: 0.5006\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3940222072958945\n",
            "Accuracy on hold-out set: 0.5387\n",
            "Returned to Spot: Validation loss: 1.3940222072958945\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5023178004741669\n",
            "Accuracy on hold-out set: 0.45375\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3791198980927468\n",
            "Accuracy on hold-out set: 0.50745\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3551475016117096\n",
            "Accuracy on hold-out set: 0.51935\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3387181210398673\n",
            "Accuracy on hold-out set: 0.53225\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2822612268447875\n",
            "Accuracy on hold-out set: 0.54955\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2681276191055775\n",
            "Accuracy on hold-out set: 0.56115\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.249848374682665\n",
            "Accuracy on hold-out set: 0.565\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.230312885031104\n",
            "Accuracy on hold-out set: 0.57255\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2420253599584103\n",
            "Accuracy on hold-out set: 0.5714\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2981660113215447\n",
            "Accuracy on hold-out set: 0.56\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3284536243498326\n",
            "Accuracy on hold-out set: 0.5572\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.3284536243498326\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 512, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7722529700517655\n",
            "Accuracy on hold-out set: 0.34995\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.624038286501169\n",
            "Accuracy on hold-out set: 0.4075\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5511204334199429\n",
            "Accuracy on hold-out set: 0.43765\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5135385313868523\n",
            "Accuracy on hold-out set: 0.44725\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4700172508239746\n",
            "Accuracy on hold-out set: 0.47135\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4275597888588905\n",
            "Accuracy on hold-out set: 0.48065\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3871969547182321\n",
            "Accuracy on hold-out set: 0.5032\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3576274952620269\n",
            "Accuracy on hold-out set: 0.5164\n",
            "Returned to Spot: Validation loss: 1.3576274952620269\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3216111615777018\n",
            "Accuracy on hold-out set: 0.1102\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.305858609580994\n",
            "Accuracy on hold-out set: 0.0991\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.314347839164734\n",
            "Accuracy on hold-out set: 0.0993\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3096657308101656\n",
            "Accuracy on hold-out set: 0.0993\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3052048529863356\n",
            "Accuracy on hold-out set: 0.1008\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.307105814528465\n",
            "Accuracy on hold-out set: 0.1008\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.308858497214317\n",
            "Accuracy on hold-out set: 0.09905\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.3088520610809327\n",
            "Accuracy on hold-out set: 0.0993\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 2.3088520610809327\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.303679646396637\n",
            "Accuracy on hold-out set: 0.0987\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.304586737537384\n",
            "Accuracy on hold-out set: 0.09895\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.306138249015808\n",
            "Accuracy on hold-out set: 0.0987\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.305167899417877\n",
            "Accuracy on hold-out set: 0.1012\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 2.305167899417877\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6977695100784302\n",
            "Accuracy on hold-out set: 0.37055\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5445036642074585\n",
            "Accuracy on hold-out set: 0.4349\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.467954178714752\n",
            "Accuracy on hold-out set: 0.4709\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4000424360275268\n",
            "Accuracy on hold-out set: 0.49725\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3590657775878907\n",
            "Accuracy on hold-out set: 0.5151\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2861354336738586\n",
            "Accuracy on hold-out set: 0.54085\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2639164068222046\n",
            "Accuracy on hold-out set: 0.55505\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2123114210128785\n",
            "Accuracy on hold-out set: 0.56855\n",
            "Returned to Spot: Validation loss: 1.2123114210128785\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.517507629585266\n",
            "Accuracy on hold-out set: 0.44425\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4133732941627501\n",
            "Accuracy on hold-out set: 0.47815\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3445811549186706\n",
            "Accuracy on hold-out set: 0.52135\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.29572112698555\n",
            "Accuracy on hold-out set: 0.5429\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2261539609432222\n",
            "Accuracy on hold-out set: 0.5646\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2069056517362595\n",
            "Accuracy on hold-out set: 0.5768\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.20164067029953\n",
            "Accuracy on hold-out set: 0.5773\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1899517424345016\n",
            "Accuracy on hold-out set: 0.5856\n",
            "Returned to Spot: Validation loss: 1.1899517424345016\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3060032291412353\n",
            "Accuracy on hold-out set: 0.1006\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.3049235355377196\n",
            "Accuracy on hold-out set: 0.1007\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3039578567504884\n",
            "Accuracy on hold-out set: 0.1018\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.303063624572754\n",
            "Accuracy on hold-out set: 0.1055\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3021935157775877\n",
            "Accuracy on hold-out set: 0.1106\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3012940868377685\n",
            "Accuracy on hold-out set: 0.115\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.300302424240112\n",
            "Accuracy on hold-out set: 0.117\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 2.299139519882202\n",
            "Accuracy on hold-out set: 0.1134\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 2.2977122470855713\n",
            "Accuracy on hold-out set: 0.1087\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 2.295808542251587\n",
            "Accuracy on hold-out set: 0.10535\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 2.293138586807251\n",
            "Accuracy on hold-out set: 0.1083\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 2.289355456161499\n",
            "Accuracy on hold-out set: 0.1233\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 2.2836589141845702\n",
            "Accuracy on hold-out set: 0.1408\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 2.2745135719299316\n",
            "Accuracy on hold-out set: 0.15685\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 2.2589217498779295\n",
            "Accuracy on hold-out set: 0.17405\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 2.2312529209136964\n",
            "Accuracy on hold-out set: 0.17485\n",
            "Returned to Spot: Validation loss: 2.2312529209136964\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4801538418769837\n",
            "Accuracy on hold-out set: 0.4589\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3562214169979097\n",
            "Accuracy on hold-out set: 0.51285\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2994264295101166\n",
            "Accuracy on hold-out set: 0.5349\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2646872377872467\n",
            "Accuracy on hold-out set: 0.5511\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2483081604003907\n",
            "Accuracy on hold-out set: 0.5592\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2472473228693008\n",
            "Accuracy on hold-out set: 0.5604\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2458607324838638\n",
            "Accuracy on hold-out set: 0.5596\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.211370676970482\n",
            "Accuracy on hold-out set: 0.574\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2508069638490678\n",
            "Accuracy on hold-out set: 0.5648\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2069308641910552\n",
            "Accuracy on hold-out set: 0.57885\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1979579925775528\n",
            "Accuracy on hold-out set: 0.58235\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2011149706602096\n",
            "Accuracy on hold-out set: 0.58625\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1799964341163636\n",
            "Accuracy on hold-out set: 0.5864\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2271452126264573\n",
            "Accuracy on hold-out set: 0.57465\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2095096362113953\n",
            "Accuracy on hold-out set: 0.58775\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1945108407020568\n",
            "Accuracy on hold-out set: 0.5892\n",
            "Early stopping at epoch 15\n",
            "Returned to Spot: Validation loss: 1.1945108407020568\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.498795594882965\n",
            "Accuracy on hold-out set: 0.4537\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.394934591960907\n",
            "Accuracy on hold-out set: 0.5043\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2870921548843384\n",
            "Accuracy on hold-out set: 0.54565\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2402025733947755\n",
            "Accuracy on hold-out set: 0.5746\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2342835592269898\n",
            "Accuracy on hold-out set: 0.5775\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2453564238548278\n",
            "Accuracy on hold-out set: 0.57265\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.237734246635437\n",
            "Accuracy on hold-out set: 0.58765\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2415997797012328\n",
            "Accuracy on hold-out set: 0.5916\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.2415997797012328\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.1341198782444\n",
            "Accuracy on hold-out set: 0.1658\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.20973859167099\n",
            "Accuracy on hold-out set: 0.15615\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.140602841615677\n",
            "Accuracy on hold-out set: 0.1808\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.226771391391754\n",
            "Accuracy on hold-out set: 0.1478\n",
            "Early stopping at epoch 3\n",
            "Returned to Spot: Validation loss: 2.226771391391754\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7426231328293682\n",
            "Accuracy on hold-out set: 0.3993\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5493918283313513\n",
            "Accuracy on hold-out set: 0.4605\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5235863301545383\n",
            "Accuracy on hold-out set: 0.4716\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5624316729884595\n",
            "Accuracy on hold-out set: 0.4823\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5178877438172698\n",
            "Accuracy on hold-out set: 0.47775\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.6242958348162473\n",
            "Accuracy on hold-out set: 0.48595\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.556990478972718\n",
            "Accuracy on hold-out set: 0.4987\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5456344100613146\n",
            "Accuracy on hold-out set: 0.49645\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.5456344100613146\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 32, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.696127449528128\n",
            "Accuracy on hold-out set: 0.3711\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5502550559200345\n",
            "Accuracy on hold-out set: 0.45\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4840273451020942\n",
            "Accuracy on hold-out set: 0.4767\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4584743902073474\n",
            "Accuracy on hold-out set: 0.5088\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4270319501219375\n",
            "Accuracy on hold-out set: 0.51995\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4462815456499696\n",
            "Accuracy on hold-out set: 0.5237\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4092115469703\n",
            "Accuracy on hold-out set: 0.52925\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3563466473846288\n",
            "Accuracy on hold-out set: 0.5434\n",
            "Returned to Spot: Validation loss: 1.3563466473846288\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 512, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6227739912509918\n",
            "Accuracy on hold-out set: 0.37425\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5235581073760986\n",
            "Accuracy on hold-out set: 0.4164\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4933300231456756\n",
            "Accuracy on hold-out set: 0.42945\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.460894212436676\n",
            "Accuracy on hold-out set: 0.4443\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4575098749637603\n",
            "Accuracy on hold-out set: 0.4452\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.426030985021591\n",
            "Accuracy on hold-out set: 0.4612\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4453149211883545\n",
            "Accuracy on hold-out set: 0.45335\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4423472781658173\n",
            "Accuracy on hold-out set: 0.44985\n",
            "Returned to Spot: Validation loss: 1.4423472781658173\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.9249661965847016\n",
            "Accuracy on hold-out set: 0.28815\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7303676012516023\n",
            "Accuracy on hold-out set: 0.36495\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.64493841984272\n",
            "Accuracy on hold-out set: 0.39795\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.571015314078331\n",
            "Accuracy on hold-out set: 0.4274\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.540251346039772\n",
            "Accuracy on hold-out set: 0.4369\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4996032163858413\n",
            "Accuracy on hold-out set: 0.45425\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4581566185235977\n",
            "Accuracy on hold-out set: 0.47275\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4462989956855774\n",
            "Accuracy on hold-out set: 0.4765\n",
            "Returned to Spot: Validation loss: 1.4462989956855774\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.634743648147583\n",
            "Accuracy on hold-out set: 0.4038\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5086655940055846\n",
            "Accuracy on hold-out set: 0.4476\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4078659297943115\n",
            "Accuracy on hold-out set: 0.4948\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3577164167404174\n",
            "Accuracy on hold-out set: 0.51325\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2748994096755981\n",
            "Accuracy on hold-out set: 0.5453\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2603671242713927\n",
            "Accuracy on hold-out set: 0.554\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2655527863502503\n",
            "Accuracy on hold-out set: 0.55305\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2503615036964417\n",
            "Accuracy on hold-out set: 0.5604\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.233152623271942\n",
            "Accuracy on hold-out set: 0.56575\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2236859950065613\n",
            "Accuracy on hold-out set: 0.573\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1817291563987733\n",
            "Accuracy on hold-out set: 0.58915\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1647276723861695\n",
            "Accuracy on hold-out set: 0.59505\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.164804302406311\n",
            "Accuracy on hold-out set: 0.59345\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1656938139915467\n",
            "Accuracy on hold-out set: 0.59285\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1838021591186523\n",
            "Accuracy on hold-out set: 0.5908\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.1838021591186523\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5657483596354722\n",
            "Accuracy on hold-out set: 0.43885\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5700460799247027\n",
            "Accuracy on hold-out set: 0.43225\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.408915651397407\n",
            "Accuracy on hold-out set: 0.51225\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.526115377140045\n",
            "Accuracy on hold-out set: 0.5029\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4841254418283236\n",
            "Accuracy on hold-out set: 0.52305\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4194070397250353\n",
            "Accuracy on hold-out set: 0.53355\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.4194070397250353\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8706213567376138\n",
            "Accuracy on hold-out set: 0.32025\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6352070203125477\n",
            "Accuracy on hold-out set: 0.39525\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5901749713361264\n",
            "Accuracy on hold-out set: 0.41325\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4978614463210105\n",
            "Accuracy on hold-out set: 0.45385\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4903365024209023\n",
            "Accuracy on hold-out set: 0.4543\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4295106825888158\n",
            "Accuracy on hold-out set: 0.48025\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4264898676246405\n",
            "Accuracy on hold-out set: 0.4818\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4114988458693027\n",
            "Accuracy on hold-out set: 0.48445\n",
            "Returned to Spot: Validation loss: 1.4114988458693027\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 512, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7650357119619846\n",
            "Accuracy on hold-out set: 0.3578\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.626164725804329\n",
            "Accuracy on hold-out set: 0.4005\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5525570983171464\n",
            "Accuracy on hold-out set: 0.43885\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4922717399716376\n",
            "Accuracy on hold-out set: 0.4593\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4802856846779584\n",
            "Accuracy on hold-out set: 0.46425\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4209928462326527\n",
            "Accuracy on hold-out set: 0.485\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3782793688565493\n",
            "Accuracy on hold-out set: 0.5019\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3867816857933999\n",
            "Accuracy on hold-out set: 0.50675\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3686423197031021\n",
            "Accuracy on hold-out set: 0.5144\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3177387905605138\n",
            "Accuracy on hold-out set: 0.5318\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.313931055021286\n",
            "Accuracy on hold-out set: 0.539\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2946260219872\n",
            "Accuracy on hold-out set: 0.54685\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.2738105444006622\n",
            "Accuracy on hold-out set: 0.5549\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2719659267056733\n",
            "Accuracy on hold-out set: 0.5558\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2428643211238086\n",
            "Accuracy on hold-out set: 0.56565\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2652347042381764\n",
            "Accuracy on hold-out set: 0.55925\n",
            "Returned to Spot: Validation loss: 1.2652347042381764\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.531155077981949\n",
            "Accuracy on hold-out set: 0.4376\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4614434580802917\n",
            "Accuracy on hold-out set: 0.4661\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3670436628341676\n",
            "Accuracy on hold-out set: 0.5066\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3223170926094054\n",
            "Accuracy on hold-out set: 0.52855\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3176307549476625\n",
            "Accuracy on hold-out set: 0.53465\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3015808010101317\n",
            "Accuracy on hold-out set: 0.54525\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.317482698917389\n",
            "Accuracy on hold-out set: 0.54155\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2621720672607422\n",
            "Accuracy on hold-out set: 0.5597\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3073157489776612\n",
            "Accuracy on hold-out set: 0.55835\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3381837108373642\n",
            "Accuracy on hold-out set: 0.55485\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2857928179264069\n",
            "Accuracy on hold-out set: 0.56035\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.2857928179264069\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.579531952881813\n",
            "Accuracy on hold-out set: 0.42485\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3937460785150528\n",
            "Accuracy on hold-out set: 0.48635\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3763956095576286\n",
            "Accuracy on hold-out set: 0.5061\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.318815844786167\n",
            "Accuracy on hold-out set: 0.52215\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2718905962109566\n",
            "Accuracy on hold-out set: 0.54495\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2636401228308678\n",
            "Accuracy on hold-out set: 0.5467\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2302364025592805\n",
            "Accuracy on hold-out set: 0.56345\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2211942920684815\n",
            "Accuracy on hold-out set: 0.5678\n",
            "Returned to Spot: Validation loss: 1.2211942920684815\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 256, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.46435423848629\n",
            "Accuracy on hold-out set: 0.4737\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3541353217601777\n",
            "Accuracy on hold-out set: 0.5351\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.1844964095115662\n",
            "Accuracy on hold-out set: 0.5827\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1941591370478273\n",
            "Accuracy on hold-out set: 0.60065\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2198678839564323\n",
            "Accuracy on hold-out set: 0.59975\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2639981867488475\n",
            "Accuracy on hold-out set: 0.59945\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.2639981867488475\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6353741332878358\n",
            "Accuracy on hold-out set: 0.4095\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5429116667461582\n",
            "Accuracy on hold-out set: 0.4497\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5574965689529083\n",
            "Accuracy on hold-out set: 0.4739\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4768172954505776\n",
            "Accuracy on hold-out set: 0.4821\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.6125108609578571\n",
            "Accuracy on hold-out set: 0.47785\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5983785601708849\n",
            "Accuracy on hold-out set: 0.4796\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5857056022727236\n",
            "Accuracy on hold-out set: 0.4903\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.5857056022727236\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 512, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.8527696075350046\n",
            "Accuracy on hold-out set: 0.3278\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6262898294959218\n",
            "Accuracy on hold-out set: 0.4183\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5132917174465954\n",
            "Accuracy on hold-out set: 0.4579\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4856938423318788\n",
            "Accuracy on hold-out set: 0.47815\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4527375594306737\n",
            "Accuracy on hold-out set: 0.48665\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4154865714778193\n",
            "Accuracy on hold-out set: 0.5038\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.430511120084126\n",
            "Accuracy on hold-out set: 0.5121\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.364845274067705\n",
            "Accuracy on hold-out set: 0.5299\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3537083537580068\n",
            "Accuracy on hold-out set: 0.5396\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3752175763572159\n",
            "Accuracy on hold-out set: 0.53475\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.3518167500523268\n",
            "Accuracy on hold-out set: 0.549\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2986696359086491\n",
            "Accuracy on hold-out set: 0.5608\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3087686186294276\n",
            "Accuracy on hold-out set: 0.5672\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.410745810302703\n",
            "Accuracy on hold-out set: 0.5496\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3938069409629723\n",
            "Accuracy on hold-out set: 0.55815\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.3938069409629723\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 256, 'lr': 0.001, 'batch_size': 2, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6911391379629785\n",
            "Accuracy on hold-out set: 0.44265\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.454550662366039\n",
            "Accuracy on hold-out set: 0.51825\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3469037724719186\n",
            "Accuracy on hold-out set: 0.56005\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.374226270865903\n",
            "Accuracy on hold-out set: 0.5567\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3830300590432543\n",
            "Accuracy on hold-out set: 0.589\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4056828970070256\n",
            "Accuracy on hold-out set: 0.5919\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.4056828970070256\n",
            "----------------------------------------------\n",
            "config: {'l1': 4, 'l2': 512, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adagrad', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adagrad', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adagrad\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5929384098529815\n",
            "Accuracy on hold-out set: 0.3974\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.550492338693142\n",
            "Accuracy on hold-out set: 0.41805\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.506204314380884\n",
            "Accuracy on hold-out set: 0.42855\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4815424014881253\n",
            "Accuracy on hold-out set: 0.43985\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4625667936146258\n",
            "Accuracy on hold-out set: 0.4472\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4605710203796625\n",
            "Accuracy on hold-out set: 0.45085\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.441809455114603\n",
            "Accuracy on hold-out set: 0.4582\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4278822326421738\n",
            "Accuracy on hold-out set: 0.4635\n",
            "Returned to Spot: Validation loss: 1.4278822326421738\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.2974119488716127\n",
            "Accuracy on hold-out set: 0.1344\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.2680496166229247\n",
            "Accuracy on hold-out set: 0.1741\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.1717019320964814\n",
            "Accuracy on hold-out set: 0.20965\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.127447530889511\n",
            "Accuracy on hold-out set: 0.23185\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.0919053194522856\n",
            "Accuracy on hold-out set: 0.2588\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.05704583067894\n",
            "Accuracy on hold-out set: 0.28145\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 2.0190668859004974\n",
            "Accuracy on hold-out set: 0.2924\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.9774009263038634\n",
            "Accuracy on hold-out set: 0.297\n",
            "Returned to Spot: Validation loss: 1.9774009263038634\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4827573152065276\n",
            "Accuracy on hold-out set: 0.4491\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3505093588352204\n",
            "Accuracy on hold-out set: 0.51545\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2760256152629852\n",
            "Accuracy on hold-out set: 0.5436\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1857167891979217\n",
            "Accuracy on hold-out set: 0.57675\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1775934564113617\n",
            "Accuracy on hold-out set: 0.5857\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2274569563388824\n",
            "Accuracy on hold-out set: 0.58575\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1611865690469743\n",
            "Accuracy on hold-out set: 0.60245\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.258023078608513\n",
            "Accuracy on hold-out set: 0.5905\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.2485480224609375\n",
            "Accuracy on hold-out set: 0.60115\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2993029011249542\n",
            "Accuracy on hold-out set: 0.6061\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.2993029011249542\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 4, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7567401844024657\n",
            "Accuracy on hold-out set: 0.32935\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.574986743736267\n",
            "Accuracy on hold-out set: 0.406\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4572943641662597\n",
            "Accuracy on hold-out set: 0.4588\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4252035715103148\n",
            "Accuracy on hold-out set: 0.4647\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.36613752784729\n",
            "Accuracy on hold-out set: 0.4926\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.344612653541565\n",
            "Accuracy on hold-out set: 0.51285\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3293295179367066\n",
            "Accuracy on hold-out set: 0.51845\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3459361221313477\n",
            "Accuracy on hold-out set: 0.5155\n",
            "Returned to Spot: Validation loss: 1.3459361221313477\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.470664893245697\n",
            "Accuracy on hold-out set: 0.46415\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3658803072929382\n",
            "Accuracy on hold-out set: 0.5082\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2994821392059326\n",
            "Accuracy on hold-out set: 0.54215\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3103604617118836\n",
            "Accuracy on hold-out set: 0.5436\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2854037917137147\n",
            "Accuracy on hold-out set: 0.55835\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3065159101486206\n",
            "Accuracy on hold-out set: 0.55585\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3121018629074097\n",
            "Accuracy on hold-out set: 0.5576\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.263646462583542\n",
            "Accuracy on hold-out set: 0.57265\n",
            "Returned to Spot: Validation loss: 1.263646462583542\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 8, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7098792402267455\n",
            "Accuracy on hold-out set: 0.3714\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.524614040184021\n",
            "Accuracy on hold-out set: 0.447\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4499251397132873\n",
            "Accuracy on hold-out set: 0.47435\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3748205422401427\n",
            "Accuracy on hold-out set: 0.5066\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2948595191955565\n",
            "Accuracy on hold-out set: 0.54035\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2284501719474792\n",
            "Accuracy on hold-out set: 0.5646\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.219159289932251\n",
            "Accuracy on hold-out set: 0.56975\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2024406298637391\n",
            "Accuracy on hold-out set: 0.5774\n",
            "Returned to Spot: Validation loss: 1.2024406298637391\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 128, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5336942831039428\n",
            "Accuracy on hold-out set: 0.4384\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3398991189956666\n",
            "Accuracy on hold-out set: 0.52045\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3434482788085937\n",
            "Accuracy on hold-out set: 0.5171\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2462297426223754\n",
            "Accuracy on hold-out set: 0.56135\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2693164776802064\n",
            "Accuracy on hold-out set: 0.56275\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2193517345428466\n",
            "Accuracy on hold-out set: 0.57285\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2695564154624939\n",
            "Accuracy on hold-out set: 0.55855\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1761727347373963\n",
            "Accuracy on hold-out set: 0.5907\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1959659236907958\n",
            "Accuracy on hold-out set: 0.58955\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2114823141098023\n",
            "Accuracy on hold-out set: 0.59085\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2835848495483397\n",
            "Accuracy on hold-out set: 0.5761\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.2835848495483397\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.476720130777359\n",
            "Accuracy on hold-out set: 0.4664\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.38614100689888\n",
            "Accuracy on hold-out set: 0.4966\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.380018474340439\n",
            "Accuracy on hold-out set: 0.5072\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3029317942619323\n",
            "Accuracy on hold-out set: 0.5287\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2987953293323518\n",
            "Accuracy on hold-out set: 0.54585\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2814269133329392\n",
            "Accuracy on hold-out set: 0.5433\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2590744317531586\n",
            "Accuracy on hold-out set: 0.554\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2483319211483002\n",
            "Accuracy on hold-out set: 0.55975\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.26878742415905\n",
            "Accuracy on hold-out set: 0.55625\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2573060791492463\n",
            "Accuracy on hold-out set: 0.5578\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.261670992875099\n",
            "Accuracy on hold-out set: 0.5651\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.261670992875099\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 8, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6014696632772685\n",
            "Accuracy on hold-out set: 0.41745\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4753057916581631\n",
            "Accuracy on hold-out set: 0.46635\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.443555919712037\n",
            "Accuracy on hold-out set: 0.50735\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3811344874680043\n",
            "Accuracy on hold-out set: 0.52735\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3398596944868564\n",
            "Accuracy on hold-out set: 0.5448\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3438580655053258\n",
            "Accuracy on hold-out set: 0.5531\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3438865494097583\n",
            "Accuracy on hold-out set: 0.57455\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3508589702086524\n",
            "Accuracy on hold-out set: 0.5805\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.3508589702086524\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 32, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5667968538284303\n",
            "Accuracy on hold-out set: 0.42015\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4524545506477355\n",
            "Accuracy on hold-out set: 0.47035\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3660327609062195\n",
            "Accuracy on hold-out set: 0.5017\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3006768766403198\n",
            "Accuracy on hold-out set: 0.525\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2578870988845825\n",
            "Accuracy on hold-out set: 0.5447\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2255467770576478\n",
            "Accuracy on hold-out set: 0.5566\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2492908730506898\n",
            "Accuracy on hold-out set: 0.54865\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2056025497436524\n",
            "Accuracy on hold-out set: 0.56265\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1881207375526428\n",
            "Accuracy on hold-out set: 0.57385\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.171401869392395\n",
            "Accuracy on hold-out set: 0.58085\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1659988941192627\n",
            "Accuracy on hold-out set: 0.58555\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1797520862579345\n",
            "Accuracy on hold-out set: 0.5783\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.187035294151306\n",
            "Accuracy on hold-out set: 0.57745\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1490038475036621\n",
            "Accuracy on hold-out set: 0.58755\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1596118466377259\n",
            "Accuracy on hold-out set: 0.5901\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.1584958662986755\n",
            "Accuracy on hold-out set: 0.59105\n",
            "Returned to Spot: Validation loss: 1.1584958662986755\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.3056156456947328\n",
            "Accuracy on hold-out set: 0.10125\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.304379354953766\n",
            "Accuracy on hold-out set: 0.0969\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.303750154685974\n",
            "Accuracy on hold-out set: 0.09885\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3060166153907775\n",
            "Accuracy on hold-out set: 0.1028\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.3055021503448487\n",
            "Accuracy on hold-out set: 0.09785\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.3077146691322326\n",
            "Accuracy on hold-out set: 0.09785\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 2.3077146691322326\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.560855993795395\n",
            "Accuracy on hold-out set: 0.4065\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4720447598457336\n",
            "Accuracy on hold-out set: 0.44105\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.455564839220047\n",
            "Accuracy on hold-out set: 0.4412\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.394554196548462\n",
            "Accuracy on hold-out set: 0.46735\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.376905933380127\n",
            "Accuracy on hold-out set: 0.48835\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3089005920410157\n",
            "Accuracy on hold-out set: 0.5134\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2715100466251372\n",
            "Accuracy on hold-out set: 0.53345\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.302815075802803\n",
            "Accuracy on hold-out set: 0.5286\n",
            "Returned to Spot: Validation loss: 1.302815075802803\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.2921188641786574\n",
            "Accuracy on hold-out set: 0.16195\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.0996844489276407\n",
            "Accuracy on hold-out set: 0.2513\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.0054052091121672\n",
            "Accuracy on hold-out set: 0.281\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.9542271397709847\n",
            "Accuracy on hold-out set: 0.2962\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.9173585516870022\n",
            "Accuracy on hold-out set: 0.30885\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.8752708602011203\n",
            "Accuracy on hold-out set: 0.32465\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.843429768973589\n",
            "Accuracy on hold-out set: 0.33015\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.8064922824308276\n",
            "Accuracy on hold-out set: 0.34635\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.781494766265154\n",
            "Accuracy on hold-out set: 0.3539\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.752747549727559\n",
            "Accuracy on hold-out set: 0.3638\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.7289413838282228\n",
            "Accuracy on hold-out set: 0.37405\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.7121296819463372\n",
            "Accuracy on hold-out set: 0.38175\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.6869356309011578\n",
            "Accuracy on hold-out set: 0.38915\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.667134429474175\n",
            "Accuracy on hold-out set: 0.3947\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.656993297663331\n",
            "Accuracy on hold-out set: 0.39815\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.642074985215813\n",
            "Accuracy on hold-out set: 0.40385\n",
            "Returned to Spot: Validation loss: 1.642074985215813\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 256, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6198899981170893\n",
            "Accuracy on hold-out set: 0.4035\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4392306517124176\n",
            "Accuracy on hold-out set: 0.47555\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3980374003328382\n",
            "Accuracy on hold-out set: 0.5054\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3411957866426558\n",
            "Accuracy on hold-out set: 0.53255\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2974269278150052\n",
            "Accuracy on hold-out set: 0.54475\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3076631654143334\n",
            "Accuracy on hold-out set: 0.5448\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2800391379490494\n",
            "Accuracy on hold-out set: 0.5547\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2779543415501713\n",
            "Accuracy on hold-out set: 0.56045\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.316740050173551\n",
            "Accuracy on hold-out set: 0.5464\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.3026755425952374\n",
            "Accuracy on hold-out set: 0.55525\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4008426087904722\n",
            "Accuracy on hold-out set: 0.544\n",
            "Early stopping at epoch 10\n",
            "Returned to Spot: Validation loss: 1.4008426087904722\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4860257863283157\n",
            "Accuracy on hold-out set: 0.47215\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3706483565092087\n",
            "Accuracy on hold-out set: 0.50885\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3002121302425862\n",
            "Accuracy on hold-out set: 0.5423\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3230757791876793\n",
            "Accuracy on hold-out set: 0.5498\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.272042365461588\n",
            "Accuracy on hold-out set: 0.56645\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3834362902164459\n",
            "Accuracy on hold-out set: 0.5635\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3790724706679582\n",
            "Accuracy on hold-out set: 0.56355\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3680869388759136\n",
            "Accuracy on hold-out set: 0.56875\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.3680869388759136\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4710213181048633\n",
            "Accuracy on hold-out set: 0.4681\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3879198735803366\n",
            "Accuracy on hold-out set: 0.5039\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.308105159175396\n",
            "Accuracy on hold-out set: 0.5425\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3149101701334118\n",
            "Accuracy on hold-out set: 0.54145\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.331856780385971\n",
            "Accuracy on hold-out set: 0.5454\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3198228529788554\n",
            "Accuracy on hold-out set: 0.5566\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.3198228529788554\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 8, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adamax', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adamax', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adamax\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7924533536911011\n",
            "Accuracy on hold-out set: 0.3065\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6126331610679627\n",
            "Accuracy on hold-out set: 0.3927\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.5142460067272185\n",
            "Accuracy on hold-out set: 0.44055\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4540688385009766\n",
            "Accuracy on hold-out set: 0.4735\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4213723516345025\n",
            "Accuracy on hold-out set: 0.49015\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3519190903782845\n",
            "Accuracy on hold-out set: 0.50645\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.334452798116207\n",
            "Accuracy on hold-out set: 0.52365\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.314826511323452\n",
            "Accuracy on hold-out set: 0.52875\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3027093025505543\n",
            "Accuracy on hold-out set: 0.5363\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.2661773701369763\n",
            "Accuracy on hold-out set: 0.54655\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.2855263191580772\n",
            "Accuracy on hold-out set: 0.54005\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.2429174457669259\n",
            "Accuracy on hold-out set: 0.56045\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.239839191377163\n",
            "Accuracy on hold-out set: 0.5627\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.2287947438716889\n",
            "Accuracy on hold-out set: 0.56735\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.2241648425877094\n",
            "Accuracy on hold-out set: 0.57165\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.2216629703164101\n",
            "Accuracy on hold-out set: 0.56905\n",
            "Returned to Spot: Validation loss: 1.2216629703164101\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 4, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.964944744491577\n",
            "Accuracy on hold-out set: 0.22985\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.7523430236816406\n",
            "Accuracy on hold-out set: 0.31275\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6446071524620056\n",
            "Accuracy on hold-out set: 0.3655\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5694948550701142\n",
            "Accuracy on hold-out set: 0.4142\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.502873328113556\n",
            "Accuracy on hold-out set: 0.4402\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4511685960769654\n",
            "Accuracy on hold-out set: 0.46585\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.4698831719875336\n",
            "Accuracy on hold-out set: 0.46775\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4230540306091308\n",
            "Accuracy on hold-out set: 0.48835\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4335653238296509\n",
            "Accuracy on hold-out set: 0.4867\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4012904020786285\n",
            "Accuracy on hold-out set: 0.49605\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.4901283642768859\n",
            "Accuracy on hold-out set: 0.4946\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3594274033546447\n",
            "Accuracy on hold-out set: 0.51815\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3431383620262145\n",
            "Accuracy on hold-out set: 0.52295\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3531961841106415\n",
            "Accuracy on hold-out set: 0.52\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3616616406440736\n",
            "Accuracy on hold-out set: 0.52075\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.4092948355674744\n",
            "Accuracy on hold-out set: 0.507\n",
            "Early stopping at epoch 15\n",
            "Returned to Spot: Validation loss: 1.4092948355674744\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 256, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.947104945755005\n",
            "Accuracy on hold-out set: 0.27105\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.0325418630599974\n",
            "Accuracy on hold-out set: 0.23635\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.8779386861801148\n",
            "Accuracy on hold-out set: 0.27165\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.8932420053482055\n",
            "Accuracy on hold-out set: 0.278\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.8699067992210388\n",
            "Accuracy on hold-out set: 0.28935\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.8428153203964233\n",
            "Accuracy on hold-out set: 0.29815\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.7985967381000518\n",
            "Accuracy on hold-out set: 0.3259\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.8536382776260376\n",
            "Accuracy on hold-out set: 0.29715\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.8648613410949706\n",
            "Accuracy on hold-out set: 0.29915\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.852083815574646\n",
            "Accuracy on hold-out set: 0.2919\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.852083815574646\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 512, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4214416662693024\n",
            "Accuracy on hold-out set: 0.48375\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3494929727554321\n",
            "Accuracy on hold-out set: 0.5161\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.230911896586418\n",
            "Accuracy on hold-out set: 0.55795\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2161675471305846\n",
            "Accuracy on hold-out set: 0.568\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2121950096607208\n",
            "Accuracy on hold-out set: 0.58115\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2222395140886306\n",
            "Accuracy on hold-out set: 0.57885\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.20077547249794\n",
            "Accuracy on hold-out set: 0.58925\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1996502252817154\n",
            "Accuracy on hold-out set: 0.59505\n",
            "Returned to Spot: Validation loss: 1.1996502252817154\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5483968508854509\n",
            "Accuracy on hold-out set: 0.4343\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3938679828718306\n",
            "Accuracy on hold-out set: 0.50895\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3165004464782775\n",
            "Accuracy on hold-out set: 0.54045\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2741174919143319\n",
            "Accuracy on hold-out set: 0.5568\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3093276951387525\n",
            "Accuracy on hold-out set: 0.5482\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2996119266752153\n",
            "Accuracy on hold-out set: 0.55665\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.293618412310537\n",
            "Accuracy on hold-out set: 0.5561\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.293618412310537\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 64, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RMSprop', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'RMSprop', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RMSprop\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.303854409408569\n",
            "Accuracy on hold-out set: 0.1013\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.306279998588562\n",
            "Accuracy on hold-out set: 0.10105\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 2.3029013025283813\n",
            "Accuracy on hold-out set: 0.10105\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 2.3052503479003907\n",
            "Accuracy on hold-out set: 0.0974\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 2.304014182853699\n",
            "Accuracy on hold-out set: 0.10005\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 2.30448764667511\n",
            "Accuracy on hold-out set: 0.10035\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 2.30448764667511\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 64, 'lr': 0.001, 'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5509427159070968\n",
            "Accuracy on hold-out set: 0.42205\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5498855199605226\n",
            "Accuracy on hold-out set: 0.4413\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4385629479646682\n",
            "Accuracy on hold-out set: 0.47805\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.4459482977852225\n",
            "Accuracy on hold-out set: 0.47725\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.377990754877776\n",
            "Accuracy on hold-out set: 0.50215\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.397345241586864\n",
            "Accuracy on hold-out set: 0.4974\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3308399329267442\n",
            "Accuracy on hold-out set: 0.5242\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.341260230897367\n",
            "Accuracy on hold-out set: 0.52925\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.3462095993503929\n",
            "Accuracy on hold-out set: 0.52925\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.33953148997128\n",
            "Accuracy on hold-out set: 0.5315\n",
            "Early stopping at epoch 9\n",
            "Returned to Spot: Validation loss: 1.33953148997128\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 16, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4615031679153443\n",
            "Accuracy on hold-out set: 0.46895\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3551378212928773\n",
            "Accuracy on hold-out set: 0.5187\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2404062218666077\n",
            "Accuracy on hold-out set: 0.56395\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2331465725898743\n",
            "Accuracy on hold-out set: 0.5728\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.1516265190124513\n",
            "Accuracy on hold-out set: 0.60275\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2087320872306824\n",
            "Accuracy on hold-out set: 0.59425\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2731309504508972\n",
            "Accuracy on hold-out set: 0.5901\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2916202207565308\n",
            "Accuracy on hold-out set: 0.593\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.2916202207565308\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 64, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.683201112209359\n",
            "Accuracy on hold-out set: 0.45145\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.5281082284548786\n",
            "Accuracy on hold-out set: 0.50695\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4003043513928513\n",
            "Accuracy on hold-out set: 0.54425\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.478278072866887\n",
            "Accuracy on hold-out set: 0.5396\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.449413033042386\n",
            "Accuracy on hold-out set: 0.56505\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5191606162780478\n",
            "Accuracy on hold-out set: 0.5704\n",
            "Early stopping at epoch 5\n",
            "Returned to Spot: Validation loss: 1.5191606162780478\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adadelta', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adadelta', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adadelta\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.517037652349472\n",
            "Accuracy on hold-out set: 0.4399\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4793105034470557\n",
            "Accuracy on hold-out set: 0.4728\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4539562115430833\n",
            "Accuracy on hold-out set: 0.4855\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.486327516746521\n",
            "Accuracy on hold-out set: 0.5007\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.4012895305991173\n",
            "Accuracy on hold-out set: 0.5169\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4276229270219802\n",
            "Accuracy on hold-out set: 0.5023\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.3894005042910575\n",
            "Accuracy on hold-out set: 0.51385\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4731742725014687\n",
            "Accuracy on hold-out set: 0.5089\n",
            "Returned to Spot: Validation loss: 1.4731742725014687\n",
            "----------------------------------------------\n",
            "config: {'l1': 64, 'l2': 128, 'lr': 0.001, 'batch_size': 16, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'AdamW', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'AdamW', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: AdamW\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4698146829605103\n",
            "Accuracy on hold-out set: 0.4642\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3137901150226594\n",
            "Accuracy on hold-out set: 0.52415\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2468490602016449\n",
            "Accuracy on hold-out set: 0.55055\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2184560022115707\n",
            "Accuracy on hold-out set: 0.55955\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2037291581630707\n",
            "Accuracy on hold-out set: 0.5688\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.141337222313881\n",
            "Accuracy on hold-out set: 0.5934\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.156776544380188\n",
            "Accuracy on hold-out set: 0.59285\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1387567801237106\n",
            "Accuracy on hold-out set: 0.60355\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1120268674135207\n",
            "Accuracy on hold-out set: 0.61355\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.1387190987110138\n",
            "Accuracy on hold-out set: 0.61175\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.146460668706894\n",
            "Accuracy on hold-out set: 0.6012\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1358662155389785\n",
            "Accuracy on hold-out set: 0.6145\n",
            "Early stopping at epoch 11\n",
            "Returned to Spot: Validation loss: 1.1358662155389785\n",
            "----------------------------------------------\n",
            "config: {'l1': 128, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4205520279884338\n",
            "Accuracy on hold-out set: 0.4872\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3368117308139802\n",
            "Accuracy on hold-out set: 0.5241\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.2774258935689926\n",
            "Accuracy on hold-out set: 0.55175\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2554346217155457\n",
            "Accuracy on hold-out set: 0.5647\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2300399969816207\n",
            "Accuracy on hold-out set: 0.588\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1836762080430985\n",
            "Accuracy on hold-out set: 0.5988\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2020358563661575\n",
            "Accuracy on hold-out set: 0.59615\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.1903771290302276\n",
            "Accuracy on hold-out set: 0.5989\n",
            "Returned to Spot: Validation loss: 1.1903771290302276\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 32, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.5019204119682312\n",
            "Accuracy on hold-out set: 0.44725\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.3974862360477447\n",
            "Accuracy on hold-out set: 0.4844\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3447214726328849\n",
            "Accuracy on hold-out set: 0.51765\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2825426403403282\n",
            "Accuracy on hold-out set: 0.54795\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2792076563835144\n",
            "Accuracy on hold-out set: 0.5551\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2392831360548735\n",
            "Accuracy on hold-out set: 0.57075\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.26807978169322\n",
            "Accuracy on hold-out set: 0.55805\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.193650727415085\n",
            "Accuracy on hold-out set: 0.58375\n",
            "Returned to Spot: Validation loss: 1.193650727415085\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 16, 'lr': 0.001, 'batch_size': 16, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 16, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.6164487335205078\n",
            "Accuracy on hold-out set: 0.3846\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4694975585460663\n",
            "Accuracy on hold-out set: 0.4521\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.454125749874115\n",
            "Accuracy on hold-out set: 0.46815\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.3838415714740753\n",
            "Accuracy on hold-out set: 0.49935\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.3820721367835997\n",
            "Accuracy on hold-out set: 0.5014\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3220527871131897\n",
            "Accuracy on hold-out set: 0.519\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.309393763780594\n",
            "Accuracy on hold-out set: 0.52805\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.3049913212776183\n",
            "Accuracy on hold-out set: 0.52665\n",
            "Returned to Spot: Validation loss: 1.3049913212776183\n",
            "----------------------------------------------\n",
            "config: {'l1': 16, 'l2': 128, 'lr': 0.001, 'batch_size': 4, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'SGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 4, 'optimizer': 'SGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: SGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 2.2931361185073853\n",
            "Accuracy on hold-out set: 0.1771\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 2.1332544505596163\n",
            "Accuracy on hold-out set: 0.22615\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.9999168070077895\n",
            "Accuracy on hold-out set: 0.26645\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.9559073974490166\n",
            "Accuracy on hold-out set: 0.2851\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.9221651547551155\n",
            "Accuracy on hold-out set: 0.2949\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.90033092648983\n",
            "Accuracy on hold-out set: 0.30955\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.875076256775856\n",
            "Accuracy on hold-out set: 0.3124\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.8521367456316948\n",
            "Accuracy on hold-out set: 0.32235\n",
            "Returned to Spot: Validation loss: 1.8521367456316948\n",
            "----------------------------------------------\n",
            "config: {'l1': 256, 'l2': 128, 'lr': 0.001, 'batch_size': 8, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4521655884742737\n",
            "Accuracy on hold-out set: 0.48045\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.322544062101841\n",
            "Accuracy on hold-out set: 0.53045\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.286103621828556\n",
            "Accuracy on hold-out set: 0.5593\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.1491875249147414\n",
            "Accuracy on hold-out set: 0.6008\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2441899462938308\n",
            "Accuracy on hold-out set: 0.5894\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.1957140087202192\n",
            "Accuracy on hold-out set: 0.60905\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2585503623902798\n",
            "Accuracy on hold-out set: 0.6122\n",
            "Early stopping at epoch 6\n",
            "Returned to Spot: Validation loss: 1.2585503623902798\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 8, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'ASGD', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'ASGD', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: ASGD\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.878346491666138\n",
            "Accuracy on hold-out set: 0.3148\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6856302183240652\n",
            "Accuracy on hold-out set: 0.3892\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6031991845808924\n",
            "Accuracy on hold-out set: 0.41645\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.5232258051492273\n",
            "Accuracy on hold-out set: 0.4432\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.486565706565976\n",
            "Accuracy on hold-out set: 0.46885\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.4997734322959557\n",
            "Accuracy on hold-out set: 0.4692\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.441148230115045\n",
            "Accuracy on hold-out set: 0.48925\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.4582059291109444\n",
            "Accuracy on hold-out set: 0.4883\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.4105920773438179\n",
            "Accuracy on hold-out set: 0.5122\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.4279371148222824\n",
            "Accuracy on hold-out set: 0.5149\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.400616953969997\n",
            "Accuracy on hold-out set: 0.5228\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.3743029778847646\n",
            "Accuracy on hold-out set: 0.5341\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.3655340440948318\n",
            "Accuracy on hold-out set: 0.54655\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.3874442494011716\n",
            "Accuracy on hold-out set: 0.54535\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.3614526632509194\n",
            "Accuracy on hold-out set: 0.55145\n",
            "Epoch: 16\n",
            "Loss on hold-out set: 1.3823190921934965\n",
            "Accuracy on hold-out set: 0.5575\n",
            "Returned to Spot: Validation loss: 1.3823190921934965\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 64, 'lr': 0.001, 'batch_size': 8, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 8, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.513629580783844\n",
            "Accuracy on hold-out set: 0.44665\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.369776652264595\n",
            "Accuracy on hold-out set: 0.513\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.3164939794421195\n",
            "Accuracy on hold-out set: 0.5364\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.2763273853302002\n",
            "Accuracy on hold-out set: 0.5529\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.228821398794651\n",
            "Accuracy on hold-out set: 0.5686\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.2335162105083466\n",
            "Accuracy on hold-out set: 0.5785\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.2005032851874828\n",
            "Accuracy on hold-out set: 0.58825\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2080452667891979\n",
            "Accuracy on hold-out set: 0.5859\n",
            "Returned to Spot: Validation loss: 1.2080452667891979\n",
            "----------------------------------------------\n",
            "config: {'l1': 8, 'l2': 4, 'lr': 0.001, 'batch_size': 32, 'epochs': 8, 'k_folds': 0, 'patience': 3, 'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 8, 'lr': 0.001, 'batch_size': 32, 'optimizer': 'Adam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: Adam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7556394248962401\n",
            "Accuracy on hold-out set: 0.3071\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.706314186859131\n",
            "Accuracy on hold-out set: 0.32565\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.6305153888702393\n",
            "Accuracy on hold-out set: 0.3617\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.58998933467865\n",
            "Accuracy on hold-out set: 0.3867\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.5435727073669434\n",
            "Accuracy on hold-out set: 0.40375\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5134871194839477\n",
            "Accuracy on hold-out set: 0.4254\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5077032037734985\n",
            "Accuracy on hold-out set: 0.44255\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.5015363671302795\n",
            "Accuracy on hold-out set: 0.45265\n",
            "Returned to Spot: Validation loss: 1.5015363671302795\n",
            "----------------------------------------------\n",
            "config: {'l1': 32, 'l2': 128, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'RAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'RAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: RAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.4998206735710613\n",
            "Accuracy on hold-out set: 0.4779\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4960919409795896\n",
            "Accuracy on hold-out set: 0.49815\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.4933098441830972\n",
            "Accuracy on hold-out set: 0.53695\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.532014709974637\n",
            "Accuracy on hold-out set: 0.5397\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.45220339569988\n",
            "Accuracy on hold-out set: 0.55695\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.5329027990590978\n",
            "Accuracy on hold-out set: 0.5666\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.5430970467521907\n",
            "Accuracy on hold-out set: 0.5694\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.6083141253320627\n",
            "Accuracy on hold-out set: 0.56425\n",
            "Early stopping at epoch 7\n",
            "Returned to Spot: Validation loss: 1.6083141253320627\n",
            "----------------------------------------------\n",
            "config: {'l1': 512, 'l2': 512, 'lr': 0.001, 'batch_size': 2, 'epochs': 16, 'k_folds': 0, 'patience': 3, 'optimizer': 'NAdam', 'criterion': CrossEntropyLoss()}\n",
            "Removed attributes: {'epochs': 16, 'lr': 0.001, 'batch_size': 2, 'optimizer': 'NAdam', 'patience': 3, 'k_folds': 0}\n",
            "Optimizer_instatance: NAdam\n",
            "Epoch: 1\n",
            "Loss on hold-out set: 1.7088282559417187\n",
            "Accuracy on hold-out set: 0.39035\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.6498270378271118\n",
            "Accuracy on hold-out set: 0.42555\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.7865137608228223\n",
            "Accuracy on hold-out set: 0.42175\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.758526653885737\n",
            "Accuracy on hold-out set: 0.40705\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.8068479383904328\n",
            "Accuracy on hold-out set: 0.43675\n",
            "Early stopping at epoch 4\n",
            "Returned to Spot: Validation loss: 1.8068479383904328\n",
            "----------------------------------------------\n",
            "spotPython tuning: [##########] 100.00% Done...\n",
            "\r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<spotPython.spot.spot.Spot at 0x1722f99c0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#| echo: true\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                   lower = lower,\n",
        "                   upper = upper,\n",
        "                   fun_evals = inf,\n",
        "                   fun_repeats = 1,\n",
        "                   max_time = MAX_TIME,\n",
        "                   noise = False,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type = var_type,\n",
        "                   var_name = var_name,\n",
        "                   infill_criterion = \"y\",\n",
        "                   n_points = 1,\n",
        "                   seed=123,\n",
        "                   log_level = 50,\n",
        "                   show_models= False,\n",
        "                   show_progress= True,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": INIT_SIZE,\n",
        "                                   \"repeats\": 1},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"cod_type\": \"norm\",\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": len(var_name),\n",
        "                                      \"model_optimizer\": differential_evolution,\n",
        "                                      \"model_fun_evals\": 10_000,\n",
        "                                      \"log_level\": 50\n",
        "                                      })\n",
        "spot_tuner.run(X_start=X_start)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "During the run, the following output is shown:\n",
        "\n",
        "```{raw}\n",
        "config: {'l1': 64, 'l2': 32, 'lr': 0.008391430243550081, \n",
        "    'batch_size': 4, 'epochs': 16, 'k_folds': 0, 'patience': 3,\n",
        "    'optimizer': 'Adam', 'criterion': CrossEntropyLoss()}\n",
        "Epoch: 9\n",
        "Batch:  1000. Batch Size: 4. Training Loss (running): 2.308\n",
        "Batch:  2000. Batch Size: 4. Training Loss (running): 1.153\n",
        "Batch:  3000. Batch Size: 4. Training Loss (running): 0.769\n",
        "Batch:  4000. Batch Size: 4. Training Loss (running): 0.576\n",
        "Batch:  5000. Batch Size: 4. Training Loss (running): 0.461\n",
        "Batch:  6000. Batch Size: 4. Training Loss (running): 0.384\n",
        "Batch:  7000. Batch Size: 4. Training Loss (running): 0.330\n",
        "Loss on hold-out set: 2.306006399059296\n",
        "Accuracy on hold-out set: 0.1007\n",
        "Early stopping at epoch 8\n",
        "Returned to Spot: Validation loss: 2.306006399059296\n",
        "```\n",
        "\n",
        "\n",
        "## Results {#sec-results-tuning}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "SAVE = False\n",
        "LOAD = False\n",
        "\n",
        "if SAVE:\n",
        "    result_file_name = \"res_\" + experiment_name + \".pkl\"\n",
        "    with open(result_file_name, 'wb') as f:\n",
        "        pickle.dump(spot_tuner, f)\n",
        "\n",
        "if LOAD:\n",
        "    result_file_name = \"res_ch10-friedman-hpt-0_maans03_60min_20init_1K_2023-04-14_10-11-19.pkl\"\n",
        "    with open(result_file_name, 'rb') as f:\n",
        "        spot_tuner =  pickle.load(f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized. The following code generates the progress plot from @fig-progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#| echo: true\n",
        "#| label: fig-progress\n",
        "#| fig-cap: \"Progress plot. *Black* dots denote results from the initial design. *Red* dots  illustrate the improvement found by the surrogate model based optimization.\"\n",
        "spot_tuner.plot_progress(log_y=False, filename=\"./figures\" + experiment_name+\"_progress.pdf\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Progress plot. `Black` dots denote results from the initial design. `Red` dots  illustrate the improvement found by the surrogate model based optimization (surrogate model based optimization).](./figures/14-torch_bartz09_30min_10init_2023-05-14_14-45-25_progress.png){#fig-progress}\n",
        "\n",
        "@fig-progress shows a typical behaviour that can be observed in many hyperparameter studies [@bart21i]: the largest improvement is obtained during the evaluation of the initial design. The surrogate model based optimization-optimization with the surrogate refines the results. @fig-progress also illustrates one major difference between `ray[tune]` as used in @pyto23a and `spotPython`: the `ray[tune]` uses a random search and will generate results similar to the *black* dots, whereas `spotPython` uses a surrogate model based optimization and presents results represented by *red* dots in @fig-progress. The surrogate model based optimization is considered to be more efficient than a random search, because the surrogate model guides the search towards promising regions in the hyperparameter space.\n",
        "\n",
        "In addition to the improved (\"optimized\") hyperparameter values, `spotPython` allows a statistical analysis, e.g., a sensitivity analysis, of the results. We can print the results of the hyperparameter tuning, see @tbl-results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| name       | type   | default          |   lower |   upper |   tuned | transform             |   importance | stars   |\n",
            "|------------|--------|------------------|---------|---------|---------|-----------------------|--------------|---------|\n",
            "| l1         | int    | 5                |     2.0 |     9.0 |     6.0 | transform_power_2_int |        15.41 | *       |\n",
            "| l2         | int    | 5                |     2.0 |     9.0 |     4.0 | transform_power_2_int |        18.15 | *       |\n",
            "| lr         | float  | 0.001            |   0.001 |   0.001 |   0.001 | None                  |         0.00 |         |\n",
            "| batch_size | int    | 4                |     1.0 |     5.0 |     5.0 | transform_power_2_int |        21.24 | *       |\n",
            "| epochs     | int    | 3                |     3.0 |     4.0 |     4.0 | transform_power_2_int |         0.01 |         |\n",
            "| k_folds    | int    | 2                |     0.0 |     0.0 |     0.0 | None                  |         0.00 |         |\n",
            "| patience   | int    | 5                |     3.0 |     3.0 |     3.0 | None                  |         0.00 |         |\n",
            "| optimizer  | factor | SGD              |     0.0 |     9.0 |     3.0 | None                  |       100.00 | ***     |\n",
            "| criterion  | factor | CrossEntropyLoss |     0.0 |     0.0 |     0.0 | None                  |         0.00 |         |\n"
          ]
        }
      ],
      "source": [
        "#| echo: true\n",
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| name       | type   |   default |   lower |   upper |      tuned | transform             |   importance | stars   |\n",
        "|------------|--------|-----------|---------|---------|------|-----------------------|--------------|---------|\n",
        "| l1         | int    |       5.0 |     2.0 |     9.0 |                  6.0 | power_2_int |        74.93 | **      |\n",
        "| l2         | int    |       5.0 |     2.0 |     9.0 |                  5.0 | power_2_int |         0.00 |         |\n",
        "| lr         | float  |     0.001 |   1e-05 |    0.01 | 0.0038 | None                  |       100.00 | ***     |\n",
        "| batch_size | int    |       4.0 |     1.0 |     5.0 |                  4.0 | power_2_int |        75.39 | **      |\n",
        "| epochs     | int    |       3.0 |     3.0 |     4.0 |                  4.0 | power_2_int |         0.00 |         |\n",
        "| k_folds    | int    |       2.0 |     0.0 |     0.0 |                  0.0 | None                  |         0.00 |         |\n",
        "| patience   | int    |       5.0 |     5.0 |     5.0 |                  5.0 | None                  |         0.00 |         |\n",
        ": Results of the hyperparameter tuning. The table shows the hyperparameters, their types, default values, lower and upper bounds, and the transformation function. The column \"tuned\" shows the tuned values. The column \"importance\" shows the importance of the hyperparameters. The column \"stars\" shows the importance of the hyperparameters in stars. The importance is computed by the SPOT software. {#tbl-results}\n",
        "\n",
        "To visualize the most important hyperparameters, `spotPython` provides the function `plot_importance`. The following code generates the importance plot from @fig-importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhPklEQVR4nO3dfVhUdf7/8dcYt6KMggqygXCphZaZN6Wom3dcsq3rZrG5llvmmnYjFpqpVHiTJuq1qWmmZq7arlbbldqNG9WSN7sbImK6mYZmmGw2mCmMaCDB+f3hz/Ntkk3NofkMPR/Xda5LzjlzeDNH5XnNnJlxWJZlCQAAwCANfD0AAADA9xEoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIwT4OsBfoyamhodOXJEjRs3lsPh8PU4AADgIliWpZMnTyomJkYNGvzwYyR+GShHjhxRbGysr8cAAAA/QnFxsa688sof3McvA6Vx48aSzv6A4eHhPp4GAABcDLfbrdjYWPv3+A/xy0A597ROeHg4gQIAgJ+5mMszuEgWAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxrnkQNm6dasGDRqkmJgYORwObdiwwWO7ZVmaMmWKWrZsqdDQUCUnJ+vAgQMe+xw/flzDhg1TeHi4mjRpopEjR6q8vPyyfhAAAFB/XHKgnDp1Sh07dtTixYtr3T537lwtXLhQS5cuVV5ensLCwpSSkqKKigp7n2HDhunjjz/We++9p7feektbt27V6NGjf/xPAQAA6hWHZVnWj76xw6H169dr8ODBks4+ehITE6NHHnlEEyZMkCSVlZUpKipKq1at0tChQ7Vv3z61b99e+fn56tq1qyQpOztbv/71r/Xf//5XMTExF/y+brdbTqdTZWVlfFggAAB+4lJ+f3v1GpSioiK5XC4lJyfb65xOp7p166bc3FxJUm5urpo0aWLHiSQlJyerQYMGysvLq/W4lZWVcrvdHgsAAKi/Arx5MJfLJUmKioryWB8VFWVvc7lcatGihecQAQGKiIiw9/m+rKwsTZ8+3ZujAgD8QPzkjb4e4Wfr0OyBPv3+fvEqnoyMDJWVldlLcXGxr0cCAAB1yKuBEh0dLUkqKSnxWF9SUmJvi46O1tGjRz22f/vttzp+/Li9z/cFBwcrPDzcYwEAAPWXVwMlISFB0dHRysnJsde53W7l5eUpKSlJkpSUlKTS0lIVFBTY+7z//vuqqalRt27dvDkOAADwU5d8DUp5ebk+/fRT++uioiLt2rVLERERiouLU3p6umbOnKm2bdsqISFBmZmZiomJsV/p065dO/3qV7/SqFGjtHTpUlVVVSktLU1Dhw69qFfwAACA+u+SA2XHjh3q27ev/fX48eMlScOHD9eqVas0ceJEnTp1SqNHj1Zpaal69eql7OxshYSE2LdZs2aN0tLS1L9/fzVo0ECpqalauHChF34cAABQH1zW+6D4Cu+DAgA/D7yKx3fq4lU8PnsfFAAAAG8gUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABjH64FSXV2tzMxMJSQkKDQ0VK1bt9aMGTNkWZa9j2VZmjJlilq2bKnQ0FAlJyfrwIED3h4FAAD4Ka8Hypw5c7RkyRI9++yz2rdvn+bMmaO5c+dq0aJF9j5z587VwoULtXTpUuXl5SksLEwpKSmqqKjw9jgAAMAPBXj7gB988IFuueUWDRw4UJIUHx+vl156Sdu3b5d09tGTBQsW6IknntAtt9wiSXrxxRcVFRWlDRs2aOjQod4eCQAA+BmvP4LSo0cP5eTkaP/+/ZKk3bt361//+pduvvlmSVJRUZFcLpeSk5Pt2zidTnXr1k25ubm1HrOyslJut9tjAQAA9ZfXH0GZPHmy3G63EhMTdcUVV6i6ulpPPfWUhg0bJklyuVySpKioKI/bRUVF2du+LysrS9OnT/f2qAAAwFBefwTlb3/7m9asWaO1a9dq586dWr16tf70pz9p9erVP/qYGRkZKisrs5fi4mIvTgwAAEzj9UdQHn30UU2ePNm+lqRDhw76/PPPlZWVpeHDhys6OlqSVFJSopYtW9q3Kykp0fXXX1/rMYODgxUcHOztUQEAgKG8/gjK6dOn1aCB52GvuOIK1dTUSJISEhIUHR2tnJwce7vb7VZeXp6SkpK8PQ4AAPBDXn8EZdCgQXrqqacUFxena665Rh9++KHmzZunP/7xj5Ikh8Oh9PR0zZw5U23btlVCQoIyMzMVExOjwYMHe3scAADgh7weKIsWLVJmZqYefPBBHT16VDExMbrvvvs0ZcoUe5+JEyfq1KlTGj16tEpLS9WrVy9lZ2crJCTE2+MAAAA/5LC++xavfsLtdsvpdKqsrEzh4eG+HgcAUEfiJ2/09Qg/W4dmD/T6MS/l9zefxQMAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4dRIoX3zxhf7whz8oMjJSoaGh6tChg3bs2GFvtyxLU6ZMUcuWLRUaGqrk5GQdOHCgLkYBAAB+yOuBcuLECfXs2VOBgYF6++23tXfvXj399NNq2rSpvc/cuXO1cOFCLV26VHl5eQoLC1NKSooqKiq8PQ4AAPBDAd4+4Jw5cxQbG6uVK1fa6xISEuw/W5alBQsW6IknntAtt9wiSXrxxRcVFRWlDRs2aOjQod4eCQAA+BmvP4LyxhtvqGvXrrr99tvVokULderUScuXL7e3FxUVyeVyKTk52V7ndDrVrVs35ebm1nrMyspKud1ujwUAANRfXg+Uzz77TEuWLFHbtm31zjvv6IEHHtBDDz2k1atXS5JcLpckKSoqyuN2UVFR9rbvy8rKktPptJfY2Fhvjw0AAAzi9UCpqalR586dNWvWLHXq1EmjR4/WqFGjtHTp0h99zIyMDJWVldlLcXGxFycGAACm8XqgtGzZUu3bt/dY165dOx0+fFiSFB0dLUkqKSnx2KekpMTe9n3BwcEKDw/3WAAAQP3l9UDp2bOnCgsLPdbt379frVq1knT2gtno6Gjl5OTY291ut/Ly8pSUlOTtcQAAgB/y+qt4xo0bpx49emjWrFkaMmSItm/frueff17PP/+8JMnhcCg9PV0zZ85U27ZtlZCQoMzMTMXExGjw4MHeHgcAAPghrwfKDTfcoPXr1ysjI0NPPvmkEhIStGDBAg0bNszeZ+LEiTp16pRGjx6t0tJS9erVS9nZ2QoJCfH2OAAAwA85LMuyfD3EpXK73XI6nSorK+N6FACox+Inb/T1CD9bh2YP9PoxL+X3N5/FAwAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDh1HiizZ8+Ww+FQenq6va6iokJjxoxRZGSkGjVqpNTUVJWUlNT1KAAAwE/UaaDk5+dr2bJluu666zzWjxs3Tm+++aZeffVVbdmyRUeOHNFtt91Wl6MAAAA/UmeBUl5ermHDhmn58uVq2rSpvb6srEwrVqzQvHnz1K9fP3Xp0kUrV67UBx98oG3bttXVOAAAwI/UWaCMGTNGAwcOVHJyssf6goICVVVVeaxPTExUXFyccnNzaz1WZWWl3G63xwIAAOqvgLo46Msvv6ydO3cqPz//vG0ul0tBQUFq0qSJx/qoqCi5XK5aj5eVlaXp06fXxagAAMBAXn8Epbi4WA8//LDWrFmjkJAQrxwzIyNDZWVl9lJcXOyV4wIAADN5PVAKCgp09OhRde7cWQEBAQoICNCWLVu0cOFCBQQEKCoqSmfOnFFpaanH7UpKShQdHV3rMYODgxUeHu6xAACA+svrT/H0799fH330kce6ESNGKDExUZMmTVJsbKwCAwOVk5Oj1NRUSVJhYaEOHz6spKQkb48DAAD8kNcDpXHjxrr22ms91oWFhSkyMtJeP3LkSI0fP14REREKDw/X2LFjlZSUpO7du3t7HAAA4Ifq5CLZC5k/f74aNGig1NRUVVZWKiUlRc8995wvRgEAAAZyWJZl+XqIS+V2u+V0OlVWVsb1KABQj8VP3ujrEX62Ds0e6PVjXsrvbz6LBwAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHECfD0AAFyu+MkbfT3Cz9ah2QN9PQLqKa8/gpKVlaUbbrhBjRs3VosWLTR48GAVFhZ67FNRUaExY8YoMjJSjRo1UmpqqkpKSrw9CgAA8FNeD5QtW7ZozJgx2rZtm9577z1VVVVpwIABOnXqlL3PuHHj9Oabb+rVV1/Vli1bdOTIEd12223eHgUAAPgprz/Fk52d7fH1qlWr1KJFCxUUFOimm25SWVmZVqxYobVr16pfv36SpJUrV6pdu3batm2bunfv7u2RAACAn6nzi2TLysokSREREZKkgoICVVVVKTk52d4nMTFRcXFxys3NrfUYlZWVcrvdHgsAAKi/6jRQampqlJ6erp49e+raa6+VJLlcLgUFBalJkyYe+0ZFRcnlctV6nKysLDmdTnuJjY2ty7EBAICP1WmgjBkzRnv27NHLL798WcfJyMhQWVmZvRQXF3tpQgAAYKI6e5lxWlqa3nrrLW3dulVXXnmlvT46OlpnzpxRaWmpx6MoJSUlio6OrvVYwcHBCg4OrqtRAQCAYbz+CIplWUpLS9P69ev1/vvvKyEhwWN7ly5dFBgYqJycHHtdYWGhDh8+rKSkJG+PAwAA/JDXH0EZM2aM1q5dq9dff12NGze2rytxOp0KDQ2V0+nUyJEjNX78eEVERCg8PFxjx45VUlISr+ABAACS6iBQlixZIknq06ePx/qVK1fqnnvukSTNnz9fDRo0UGpqqiorK5WSkqLnnnvO26MAAAA/5fVAsSzrgvuEhIRo8eLFWrx4sbe/PfA/8XbovsPboQO4VHxYIAAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADBOnX2asT/jHUd9h3ccBQBIPIICAAAMRKAAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACM49NAWbx4seLj4xUSEqJu3bpp+/btvhwHAAAYwmeB8sorr2j8+PGaOnWqdu7cqY4dOyolJUVHjx711UgAAMAQPguUefPmadSoURoxYoTat2+vpUuXqmHDhvrzn//sq5EAAIAhAnzxTc+cOaOCggJlZGTY6xo0aKDk5GTl5uaet39lZaUqKyvtr8vKyiRJbre7TuarqTxdJ8fFhdXVOZU4r75Ul+dV4tz6Eue2/qqLc3vumJZlXXBfnwTKsWPHVF1draioKI/1UVFR+uSTT87bPysrS9OnTz9vfWxsbJ3NCN9wLvD1BKgLnNf6i3Nbf9XluT158qScTucP7uOTQLlUGRkZGj9+vP11TU2Njh8/rsjISDkcDh9OZha3263Y2FgVFxcrPDzc1+PAizi39RPntf7i3NbOsiydPHlSMTExF9zXJ4HSrFkzXXHFFSopKfFYX1JSoujo6PP2Dw4OVnBwsMe6Jk2a1OWIfi08PJx/EPUU57Z+4rzWX5zb813okZNzfHKRbFBQkLp06aKcnBx7XU1NjXJycpSUlOSLkQAAgEF89hTP+PHjNXz4cHXt2lU33nijFixYoFOnTmnEiBG+GgkAABjCZ4Hy+9//Xl999ZWmTJkil8ul66+/XtnZ2eddOIuLFxwcrKlTp573dBj8H+e2fuK81l+c28vnsC7mtT4AAAA/IT6LBwAAGIdAAQAAxiFQAACAcQgUP9anTx+lp6f7egzUAc5t3fLF/Xvo0CE5HA7t2rXL68fevHmzHA6HSktLvX5s1C4+Pl4LFiy4rGNMmzZN119/vVfmqY8IlHpi3bp1GjBggP3uunXxnyB+elVVVZo0aZI6dOigsLAwxcTE6O6779aRI0d8PdrPmmlB0KNHD3355ZcX/QZYuHirVq2q9Y1B8/PzNXr06Ms69oQJEzzeDwyeCJR64tSpU+rVq5fmzJnj61HgRadPn9bOnTuVmZmpnTt3at26dSosLNRvf/tbX48GgwQFBSk6OpqP/vgJNW/eXA0bNrysYzRq1EiRkZFemuh8Z86cqbNj/xQIlHrirrvu0pQpU5ScnOzrUeBFTqdT7733noYMGaKrr75a3bt317PPPquCggIdPnzY1+P5tW+//VZpaWlyOp1q1qyZMjMz7U9Y/ctf/qKuXbuqcePGio6O1p133qmjR49KOvtUTd++fSVJTZs2lcPh0D333CPp7Dtiz507V23atFFwcLDi4uL01FNPeXzfzz77TH379lXDhg3VsWPHWj/BvTaff/65Bg0apKZNmyosLEzXXHON/v73v0s6/xGdPn36yOFwnLccOnRIklRaWqp7771XzZs3V3h4uPr166fdu3dfzt1prMrKSj300ENq0aKFQkJC1KtXL+Xn50v6v/tt48aNuu666xQSEqLu3btrz5499vYRI0aorKzMvg+nTZsm6fyneBwOh5YtW6bf/OY3atiwodq1a6fc3Fx9+umn6tOnj8LCwtSjRw8dPHjQvs33n+Kp7ZzFx8fb2/fs2aObb75ZjRo1UlRUlO666y4dO3bM3t6nTx+lpaUpPT1dzZo1U0pKivfv0J8QgQL4mXP/WfJ5VJdn9erVCggI0Pbt2/XMM89o3rx5euGFFySdfWptxowZ2r17tzZs2KBDhw7ZERIbG6vXXntNklRYWKgvv/xSzzzzjKSzH2w6e/ZsZWZmau/evVq7du15bz75+OOPa8KECdq1a5euuuoq3XHHHfr2228vOO+YMWNUWVmprVu36qOPPtKcOXPUqFGjWvddt26dvvzyS3u57bbbdPXVV9uz3H777Tp69KjefvttFRQUqHPnzurfv7+OHz/+o+5Lk02cOFGvvfaaVq9erZ07d6pNmzZKSUnx+FkfffRRPf3008rPz1fz5s01aNAgVVVVqUePHlqwYIHCw8Pt+3LChAn/83vNmDFDd999t3bt2qXExETdeeeduu+++5SRkaEdO3bIsiylpaX9z9t/95x9+umnatOmjW666SZJZ6OyX79+6tSpk3bs2KHs7GyVlJRoyJAhHsdYvXq1goKC9O9//1tLly69zHvPxyz4rd69e1sPP/ywx7qioiJLkvXhhx/6ZCZ4R23n1rIs65tvvrE6d+5s3XnnnT/9UPVI7969rXbt2lk1NTX2ukmTJlnt2rWrdf/8/HxLknXy5EnLsixr06ZNliTrxIkT9j5ut9sKDg62li9fXusxzv3bfOGFF+x1H3/8sSXJ2rdv3wVn7tChgzVt2rRat9U2zznz5s2zmjRpYhUWFlqWZVn//Oc/rfDwcKuiosJjv9atW1vLli274Bz+pLy83AoMDLTWrFljrztz5owVExNjzZ07177fXn75ZXv7119/bYWGhlqvvPKKZVmWtXLlSsvpdJ537FatWlnz58+3v5ZkPfHEE/bXubm5liRrxYoV9rqXXnrJCgkJsb+eOnWq1bFjx/OOXVNTY916661Wly5drNOnT1uWZVkzZsywBgwY4LFfcXGxJck+t71797Y6dep0EfeMf+ARFMBPVFVVaciQIbIsS0uWLPH1OH6ve/fuHtdsJCUl6cCBA6qurlZBQYEGDRqkuLg4NW7cWL1795akH3xabd++faqsrFT//v1/8Pted9119p9btmwpSfbTRz/koYce0syZM9WzZ09NnTpV//nPfy54m7fffluTJ0/WK6+8oquuukqStHv3bpWXlysyMlKNGjWyl6KiIo+nH+qDgwcPqqqqSj179rTXBQYG6sYbb9S+ffvsdd/9kNqIiAhdffXVHtsv1nfP7blHqzp06OCxrqKiQm63+weP89hjjyk3N1evv/66QkNDJZ09b5s2bfI4Z4mJifbPeU6XLl0ueW5T+eyzeABcvHNx8vnnn+v999/n49vrUEVFhVJSUpSSkqI1a9aoefPmOnz4sFJSUn7wosNzv0guJDAw0P7zuUCqqam54O3uvfdepaSkaOPGjXr33XeVlZWlp59+WmPHjq11/71792ro0KGaPXu2BgwYYK8vLy9Xy5YttXnz5vNuw9OGl6e2c3up5/uvf/2r5s+fr82bN+sXv/iFvb68vFyDBg2q9YUQ50JXksLCwn78D2AYHkEBDHcuTg4cOKB//OMfdXrV/89JXl6ex9fbtm1T27Zt9cknn+jrr7/W7Nmz9ctf/lKJiYnnPcIRFBQkSaqurrbXtW3bVqGhoXX6stHY2Fjdf//9WrdunR555BEtX7681v2OHTumQYMGKTU1VePGjfPY1rlzZ7lcLgUEBKhNmzYeS7Nmzepsdl9o3bq1fT3GOVVVVcrPz1f79u3tddu2bbP/fOLECe3fv1/t2rWTdPZcf/c816Xc3Fzde++9WrZsmbp37+6xrXPnzvr4448VHx9/3nmrT1HyXQRKPXH8+HHt2rVLe/fulXT24r1du3bJ5XL5eDJcjqqqKv3ud7/Tjh07tGbNGlVXV8vlcsnlcvn9Swh97fDhwxo/frwKCwv10ksvadGiRXr44YcVFxenoKAgLVq0SJ999pneeOMNzZgxw+O2rVq1ksPh0FtvvaWvvvpK5eXlCgkJ0aRJkzRx4kS9+OKLOnjwoLZt26YVK1Z4Zd709HS98847Kioq0s6dO7Vp0yb7l+j3paamqmHDhpo2bZr998Xlcqm6ulrJyclKSkrS4MGD9e677+rQoUP64IMP9Pjjj2vHjh1emdUUYWFheuCBB/Too48qOztbe/fu1ahRo3T69GmNHDnS3u/JJ59UTk6O9uzZo3vuuUfNmjXT4MGDJZ19tU55eblycnJ07NgxnT59uk5mdblcuvXWWzV06FClpKTY5+yrr76SdPYi6ePHj+uOO+5Qfn6+Dh48qHfeeUcjRoz4yQLqJ+fri2Dw4333QsqVK1daks5bpk6d6tMZ8eOcO7fnLqysbdm0aZOvx/RbvXv3th588EHr/vvvt8LDw62mTZtajz32mH3R7Nq1a634+HgrODjYSkpKst54443zLj5/8sknrejoaMvhcFjDhw+3LMuyqqurrZkzZ1qtWrWyAgMDrbi4OGvWrFmWZdV+AfuJEycu+lympaVZrVu3toKDg63mzZtbd911l3Xs2DHLss6/SPZ//Z0pKiqyLOvsBb1jx461YmJirMDAQCs2NtYaNmyYdfjw4cu6X030zTffWGPHjrWaNWtmBQcHWz179rS2b99uWdb/3W9vvvmmdc0111hBQUHWjTfeaO3evdvjGPfff78VGRnp8X9qbRfJrl+/3v66tvP9/fP03Ytkz237/tKqVSv79vv377duvfVWq0mTJlZoaKiVmJhopaen239v/9fF9f7KYVn//4X/AAD8jGzevFl9+/bViRMnuP7GQDzFAwAAjEOgAIABzr1DaG3LrFmzfD0e8JPjKR4AMMAXX3yhb775ptZtERERioiI+IknAnyLQAEAAMbhKR4AAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcf4fnPHxPkrqW9IAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#| echo: true\n",
        "spot_tuner.plot_importance(threshold=0.025, filename=\"./figures\" + experiment_name+\"_importance.pdf\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Variable importance](./figures/14-torch_bartz09_30min_10init_2023-05-14_14-45-25_importance.png){#fig-importance width=\"50%\"}\n",
        "\n",
        "\n",
        "## Get SPOT Results {#sec-get-spot-results}\n",
        "\n",
        "The architecture of the `spotPython` model can be obtained by the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net_CIFAR10(\n",
              "  (criterion): CrossEntropyLoss()\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
              "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#| echo: true\n",
        "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
        "model_spot = get_one_core_model_from_X(X, fun_control)\n",
        "model_spot"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, the numerical representation of the hyperparameters are obtained, i.e., the numpy array `X` is generated. This array is then used to generate the model `model_spot` by the function `get_one_core_model_from_X`. The model `model_spot` has the following architecture:\n",
        "\n",
        "\n",
        "```{raw}\n",
        "Net_CIFAR10(\n",
        "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
        "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
        "  (fc1): Linear(in_features=400, out_features=64, bias=True)\n",
        "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
        "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "## Get Default Hyperparameters\n",
        "\n",
        "In a similar manner as in @sec-get-spot-results, the default hyperparameters can be obtained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: true\n",
        "# fun_control was modified, we generate a new one with the original default hyperparameters\n",
        "fc = copy.deepcopy(fun_control)\n",
        "fc.update({\"core_model_hyper_dict\": hyper_dict[fun_control[\"core_model\"].__name__]})\n",
        "model_default = get_one_core_model_from_X(X_start, fun_control=fc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The corresponding default model has the following architecture:\n",
        "\n",
        "```{raw}\n",
        "Net_CIFAR10(\n",
        "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
        "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
        "  (fc1): Linear(in_features=400, out_features=32, bias=True)\n",
        "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
        "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Evaluation of the Tuned Architecture\n",
        "\n",
        "The method `train_save` takes a model architecture without trained weights and trains this model with the train data. The train data is split into train and validation data. The validation data is used for early stopping. The trained model weights are saved as a dictionary.\n",
        "\n",
        " This evaluation is similar to the final evaluation in @pyto23a. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "md-indent": " "
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Batch:  1000. Batch Size: 16. Training Loss (running): 2.304\n",
            "Loss on hold-out set: 2.303545287513733\n",
            "Accuracy on hold-out set: 0.0966\n",
            "Epoch: 2\n",
            "Batch:  1000. Batch Size: 16. Training Loss (running): 2.302\n",
            "Loss on hold-out set: 2.300948340988159\n",
            "Accuracy on hold-out set: 0.1041\n",
            "Epoch: 3\n",
            "Batch:  1000. Batch Size: 16. Training Loss (running): 2.299\n",
            "Loss on hold-out set: 2.2969878238677977\n",
            "Accuracy on hold-out set: 0.1372\n",
            "Epoch: 4\n",
            "Batch:  1000. Batch Size: 16. Training Loss (running): 2.295\n",
            "Loss on hold-out set: 2.288547473335266\n",
            "Accuracy on hold-out set: 0.14215\n",
            "Epoch: 5\n",
            "Batch:  1000. Batch Size: 16. Training Loss (running): 2.284\n",
            "Loss on hold-out set: 2.2667920484542847\n",
            "Accuracy on hold-out set: 0.1442\n",
            "Epoch: 6\n",
            "Batch:  1000. Batch Size: 16. Training Loss (running): 2.256\n",
            "Loss on hold-out set: 2.223152983665466\n",
            "Accuracy on hold-out set: 0.17735\n",
            "Epoch: 7\n",
            "Batch:  1000. Batch Size: 16. Training Loss (running): 2.208\n",
            "Loss on hold-out set: 2.1730712332725526\n",
            "Accuracy on hold-out set: 0.19705\n",
            "Epoch: 8\n",
            "Batch:  1000. Batch Size: 16. Training Loss (running): 2.155\n",
            "Loss on hold-out set: 2.1247826151847837\n",
            "Accuracy on hold-out set: 0.2213\n",
            "Returned to Spot: Validation loss: 2.1247826151847837\n",
            "----------------------------------------------\n",
            "Loss on hold-out set: 2.1173975866317747\n",
            "Accuracy on hold-out set: 0.2296\n",
            "Returned to Spot: Validation loss: 2.1173975866317747\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2.1173975866317747, nan)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#|echo: true\n",
        "train_save(net=model_default,train_dataset=train, shuffle=True, device = \"cpu\", show_batch_interval=1_000, path=\"model_default_trained.pt\", save_model=True)\n",
        "test_saved(net=model_default,test_dataset=test, shuffle=False, device = \"cpu\", path=\"model_default_trained.pt\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " The following code trains the model `model_spot` and saves the weights of the trained model to the file `model_spot_trained.pt`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Loss on hold-out set: 1.657503804397583\n",
            "Accuracy on hold-out set: 0.3923\n",
            "Epoch: 2\n",
            "Loss on hold-out set: 1.4658662826538087\n",
            "Accuracy on hold-out set: 0.4686\n",
            "Epoch: 3\n",
            "Loss on hold-out set: 1.387681554222107\n",
            "Accuracy on hold-out set: 0.5033\n",
            "Epoch: 4\n",
            "Loss on hold-out set: 1.294242335510254\n",
            "Accuracy on hold-out set: 0.5393\n",
            "Epoch: 5\n",
            "Loss on hold-out set: 1.2711270239830017\n",
            "Accuracy on hold-out set: 0.55035\n",
            "Epoch: 6\n",
            "Loss on hold-out set: 1.3005977874755859\n",
            "Accuracy on hold-out set: 0.53885\n",
            "Epoch: 7\n",
            "Loss on hold-out set: 1.1957526369094849\n",
            "Accuracy on hold-out set: 0.576\n",
            "Epoch: 8\n",
            "Loss on hold-out set: 1.2184363176345825\n",
            "Accuracy on hold-out set: 0.57525\n",
            "Epoch: 9\n",
            "Loss on hold-out set: 1.1579525871276855\n",
            "Accuracy on hold-out set: 0.592\n",
            "Epoch: 10\n",
            "Loss on hold-out set: 1.183681702041626\n",
            "Accuracy on hold-out set: 0.5874\n",
            "Epoch: 11\n",
            "Loss on hold-out set: 1.1480174397468568\n",
            "Accuracy on hold-out set: 0.59815\n",
            "Epoch: 12\n",
            "Loss on hold-out set: 1.1313072934150696\n",
            "Accuracy on hold-out set: 0.60995\n",
            "Epoch: 13\n",
            "Loss on hold-out set: 1.1531383703231812\n",
            "Accuracy on hold-out set: 0.60695\n",
            "Epoch: 14\n",
            "Loss on hold-out set: 1.1542490805625916\n",
            "Accuracy on hold-out set: 0.6039\n",
            "Epoch: 15\n",
            "Loss on hold-out set: 1.1358611861228942\n",
            "Accuracy on hold-out set: 0.608\n",
            "Early stopping at epoch 14\n",
            "Returned to Spot: Validation loss: 1.1358611861228942\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1.1358611861228942, nan)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#| echo: true\n",
        "train_save(net=model_spot, train_dataset=train,\n",
        "                shuffle=True, path=\"model_spot_trained.pt\", save_model=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{raw}\n",
        "Loss on hold-out set: 1.1649643966913223\n",
        "Accuracy on hold-out set: 0.5948\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss on hold-out set: 1.1259592000287943\n",
            "Accuracy on hold-out set: 0.6114\n",
            "Returned to Spot: Validation loss: 1.1259592000287943\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1.1259592000287943, nan)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#| echo: true\n",
        "test_saved(net=model_spot, test_dataset=test,\n",
        "            shuffle=False, path=\"model_spot_trained.pt\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{raw}\n",
        "Loss on hold-out set: 1.1034918918132781\n",
        "Accuracy on hold-out set: 0.6184\n",
        "```\n",
        "\n",
        "\n",
        "## Comparison with Default Hyperparameters and Ray Tune\n",
        "\n",
        "@tbl-comparison shows the loss and accuracy of the default model, the model with the hyperparameters from SPOT, and the model with the hyperparameters from `ray[tune]`.\n",
        "\n",
        "| Model     | Validation Loss | Validation Accuracy | Loss    | Accuracy |\n",
        "|:----------|----------------:|--------------------:|--------:|---------:|\n",
        "| Default   | 1.3152          | 0.5316              | 1.1561  | 0.5934   |\n",
        "| `spotPython`      | 1.0686          | 0.6291             | 1.1035  | 0.6184   |\n",
        "| `ray[tune]`  | 1.1815          | 0.5836              | -       | 0.5806   |\n",
        ": Comparison of the loss and accuracy of the default model, the model with the hyperparameters from SPOT, and the model with the hyperparameters from `ray[tune]`. `ray[tune]` only shows the validation loss, because training loss is not reported by `ray[tune]`. {#tbl-comparison}\n",
        "\n",
        "\n",
        "## Detailed Hyperparameter Plots\n",
        "\n",
        "The contour plots in this section visualize the interactions of the three most important hyperparameters, `lr`, `batch_size`,  and `l1` of the surrogate model used to optimize the hyperparameters. Since these hyperparameters take integer values, a step-like fitness landcape (or response surface) is generated.\n",
        "SPOT draws the interactions of the main hyperparameters by default. It is also possible to visualize all interactions. For this, again refer to the notebook [@bart23e].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "l1:  15.411413705379095\n",
            "l2:  18.150781109500148\n",
            "batch_size:  21.240488273336183\n",
            "optimizer:  100.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtkAAAEnCAYAAAB8PV9qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC/ZUlEQVR4nOy9d3hc5Z3+/TlnmkYjadRlFUty772ATTNJCHGysAlL2IXkF0rCkgYJkJCw+24wKZCQyiakkRBKIAUSSCO0pRgwYGNLsiXL6rKq1euMppzy/jE6xzOqM6ouz+e6DJ5TnvOcGdm+z3fu5/5Kuq7rCAQCgUAgEAgEghlDnu8JCAQCgUAgEAgEZxpCZAsEAoFAIBAIBDOMENkCgUAgEAgEAsEMI0S2QCAQCAQCgUAwwwiRLRAIBAKBQCAQzDBCZAsEAoFAIBAIBDOMENkCgUAgEAgEAsEMI0S2QCAQCAQCgUAwwwiRLRAIBAKBQCAQzDBCZAsEAoFAIBAIBDOMENmCCTly5AhXXnklBQUFxMXFkZubyyWXXMKPf/zj+Z7arPPss8+yZ8+e+Z6GQCAQCASC0xBJ13V9vichODXZt28fF198Mfn5+Vx77bUsWLCAxsZG3n77bWpqaqiurp7vKc4qn//853nggQcQf0QEAoFAIBDEinW+JyA4dfnWt76F2+3mwIEDJCcnR+xrb2+fkWt4PB5cLteo7bqu4/P5cDqdM3IdgUAgEAgEgrlE2EUE41JTU8OaNWtGCWyAzMxMAOrr65EkiYcffnjUMZIkRdgt9uzZgyRJHD16lGuuuYaUlBTOP/98AAoLC/mXf/kXnn/+ebZu3YrT6eQXv/gFALW1tXz0ox8lNTWV+Ph4zj33XP7xj3+Mut7x48e5/PLLcblcZGZmcuutt/L8888jSRKvvvqqedzrr7/ORz/6UfLz83E4HCxcuJBbb72VoaEh85jrrruOBx54wLwP45eBpmn86Ec/Ys2aNcTFxZGVlcVNN91ET09P1O+vQCAQCASCMxdRyRaMS0FBAW+99RalpaWsXbt2xsb96Ec/yrJly7jnnnsirBgVFRVcffXV3HTTTdx4442sWLGCtrY2du7cidfr5ZZbbiEtLY1HHnmEyy+/nKeeeoqPfOQjQKgi/p73vIfW1la+8IUvsGDBAp544gleeeWVUdd/8skn8Xq9fOYznyEtLY39+/fz4x//mKamJp588kkAbrrpJlpaWnjxxRd57LHHRo1x00038fDDD3P99ddzyy23UFdXx09+8hOKiop48803sdlsM/Z+CQQCgUAgOA3RBYJxeOGFF3SLxaJbLBZ9x44d+h133KE///zzeiAQMI+pq6vTAf03v/nNqPMB/a677jJf33XXXTqgX3311aOOLSgo0AH9ueeei9j+xS9+UQf0119/3dw2MDCgL1q0SC8sLNRVVdV1Xde///3v64D+zDPPmMcNDQ3pK1eu1AH9lVdeMbd7vd5R17/33nt1SZL048ePm9s+97nP6WP9EXn99dd1QH/88ccjtj/33HNjbhcIBAKBQHD2IewignG55JJLeOutt7j88sspKSnhvvvu49JLLyU3N5e//vWvUx7305/+9JjbFy1axKWXXhqx7dlnn2X79u2mrQQgISGB//zP/6S+vp6jR48C8Nxzz5Gbm8vll19uHhcXF8eNN9446jrhPm+Px0NnZyc7d+5E13WKioomnf+TTz6J2+3mkksuobOz0/y1ZcsWEhISxqyeCwQCgUAgOLsQIlswIdu2bePPf/4zPT097N+/nzvvvJOBgQGuvPJKU+DGyqJFi6Lefvz4cVasWDFq+6pVq8z9xv+XLFkS4ZsGWLp06ahzGxoauO6660hNTSUhIYGMjAwuuugiAPr6+iadf1VVFX19fWRmZpKRkRHxa3BwcMYWhQoEAoFAIDh9EZ5sQVTY7Xa2bdvGtm3bWL58Oddffz1PPvkk11133ZjHq6o67ljjJYbMRZKIqqpccskldHd385WvfIWVK1ficrlobm7muuuuQ9O0ScfQNI3MzEwef/zxMfdnZGTM9LQFAoFAIBCcZgiRLYiZrVu3AtDa2kpKSgoAvb29EccYFebpUlBQQEVFxajtx44dM/cb/z969Ci6rkdUs0dmeR85coTKykoeeeQRPvGJT5jbX3zxxVHXGFkVN1iyZAkvvfQS5513nogYFAgEAoFAMCbCLiIYl1deeWXMRizPPvssACtWrCApKYn09HT27t0bccxPf/rTGZnDBz/4Qfbv389bb71lbvN4PPzyl7+ksLCQ1atXA3DppZfS3Nwc4RX3+Xw8+OCDEeNZLBaAiPvSdZ37779/1LWN/O6RDxBXXXUVqqryjW98Y9Q5iqKMOl4gEAgEAsHZh6hkC8bl5ptvxuv18pGPfISVK1cSCATYt28ff/jDHygsLOT6668H4FOf+hTf/va3+dSnPsXWrVvZu3cvlZWVMzKHr371q/zud79j9+7d3HLLLaSmpvLII49QV1fHn/70J2Q59Jx400038ZOf/ISrr76aL3zhC2RnZ/P4448TFxcHnKxKr1y5kiVLlvClL32J5uZmkpKS+NOf/jRmvvWWLVsAuOWWW7j00kuxWCz8x3/8BxdddBE33XQT9957L8XFxbz//e/HZrNRVVXFk08+yf3338+VV145I/cvEAgEAoHgNGVes00EpzT//Oc/9RtuuEFfuXKlnpCQoNvtdn3p0qX6zTffrLe1tZnHeb1e/ZOf/KTudrv1xMRE/aqrrtLb29vHjfDr6OgYda2CggL9Qx/60JjzqKmp0a+88ko9OTlZj4uL07dv367//e9/H3VcbW2t/qEPfUh3Op16RkaGfvvtt+t/+tOfdEB/++23zeOOHj2qv+9979MTEhL09PR0/cYbb9RLSkpGRREqiqLffPPNekZGhi5J0qg4v1/+8pf6li1bdKfTqScmJurr1q3T77jjDr2lpSXat1ggEAgEAsEZiqTrY/gBBIIzhB/96EfceuutNDU1kZubO9/TEQgEAoFAcJYgRLbgjGFoaChiIaLP52PTpk2oqjpj9hWBQCAQCASCaBCebMEZwxVXXEF+fj4bN26kr6+P3/72txw7dmzcqD2BQCAQCASC2UKIbMEZw6WXXsqvfvUrHn/8cVRVZfXq1fz+97/n3//93+d7agKBQCAQCM4y5tUusmfPHu6+++6IbStWrDAzkAUCgUAgEAgEgtORea9kr1mzhpdeesl8bbXO+5QEAoFAIBAIBIJpMe+K1mq1smDBgvmehkAgEAgEAoFAMGPMu8iuqqoiJyeHuLg4duzYwb333kt+fv6Yx/r9fvx+v/la0zS6u7tJS0sbtwW2QCA4s9B1nYGBAXJycsxmRLHi8/kIBAKTHme3282GRgKBQCAQxMK8erL/+c9/Mjg4yIoVK2htbeXuu++mubmZ0tJSEhMTRx0/lodbIBCcnTQ2NpKXlxfzeT6fD/eiHAInRnf5HMmCBQuoq6sTQlsgEAgEMXNK5WT39vZSUFDAD37wAz75yU+O2j+ykt3X1xeqem9rBGtS7BesmM5sZ5nuoSgOKpv1acw/xfM9gdOAjfM9gWmwZgrnDADL6O3txe12x3x2f38/brebCxt/jTUpftzjlH4vexd+kr6+PpKSpvD3i0AgEAjOaubdLhJOcnIyy5cvp7q6esz9DocDh8Mxeoc1aWoie2rfNM8RtiiOcc36LOYf5+SHnPWczj8HUxev07WIWZPiJxTZAoFAIBBMh1NKZg4ODlJTU0N2dvZ8T0UgEAgEAoFAIJgy8yqyv/SlL/Haa69RX1/Pvn37+MhHPoLFYuHqq6+ez2kJBAKBQCAQCATTYl7tIk1NTVx99dV0dXWRkZHB+eefz9tvv01GRsZ8TksgEAgEAoFAIJgW8yqyf//738/n5QUCgUAgEAgEglnhlPJkCwQCgUAgEAgEZwJCZAsEAoFAIBAIBDOMENkCgUAgEAgEAsEMI0S2QCAQCAQCgUAwwwiRLRAIBAKBQCAQzDBCZAsEAoFAIBAIBDOMENkCgUAgEAgEAsEMI0S2QCAQCAQCgUAwwwiRLRAIBDPE3r17ueyyy8jJyUGSJJ555plJz/H7/fz3f/83BQUFOBwOCgsLeeihh2Z/sgLBGYimafj9fvx+P6qqouv6fE9JcBYzrx0fBQKB4EzC4/GwYcMGbrjhBq644oqozrnqqqtoa2vj17/+NUuXLqW1tRVN02Z5pgLBmYWu62iaRjAYxOfzoWkakiQhyzI2mw2r1YrFYkGWZSRJmu/pCs4ShMgWCASCGWL37t3s3r076uOfe+45XnvtNWpra0lNTQWgsLBwlmYnEJyZ6LpOMBg0K9cWi8UU0rqu4/P5AJAkiYGBAVJSUnA4HEJ0C2YdYRcRCE57Ds33BM5o+vv7I375/f4ZG/uvf/0rW7du5b777iM3N5fly5fzpS99iaGhoRm7hkBwJqNpGoFAAEVRkCQJSZLo7+9HURRkWcZisZiVbFmWKSoqYmBggMHBQfr7+xkYGMDr9RIIBIS9RDDjnN2V7FVA+XxPQjA+QjwKZo86FiGTMO5+jUEAFi5cGLH9rrvuYs+ePTMyh9raWt544w3i4uJ4+umn6ezs5LOf/SxdXV385je/mZFrCARnIrquo6oqbW1tVFdXc84556AoCmVlZbS3t6NpGgkJCaSkpJCcnExycjI2mw1JkrBarVitVtNiYlS6ZVlGlmVzv6h0C6bL2S2yBYIzhkPA5vmexBQ4DKyf70lMSGNjI0lJSeZrh8MxY2MbvtHHH38ct9sNwA9+8AOuvPJKfvrTn+J0OmfsWgLBmUK4PcTwYff19VFSUkJ8fDw7d+5E13V6e3vp7e2lpqYGr9dLYmIiuq7T3d1NVlYWVmtIAlksFnRdN4W7qqr4fD4hugXTRohswSmKqGLHzukqtE9tkpKSIkT2TJKdnU1ubq4psAFWrVqFrus0NTWxbNmyWbmuQHC6oqoqwWAQTdNMwRsIBDhw4ABLly6loKAARVHQdZ2srCyysrKAUIpPT08PR48epb6+nsrKShITE0lJSSElJQW3222KaGCU6Pb7/UiShMViMQW31Wo1LSoCwVgIkS04BRECe+qcjkL71K9mzxbnnXceTz75JIODgyQkhKwrlZWVyLJMXl7ePM9OIDh10HUdRVFMAS3LMoFAgKqqKhRF4ZxzziE5OXlcT7XD4WDBggVUVFSwceNGZFmmt7eXnp4eysvLCQQCuN1ukpOTTdFtVLKN6xtzCAaDprg2xLYhvIXoFoQjRLZgmghBfOpxOgrtM4PBwUGqq6vN13V1dRQXF5Oamkp+fj533nknzc3NPProowBcc801fOMb3+D666/n7rvvprOzky9/+cvccMMNwioiEAyjaRqKoqCqKhDyTnd3d3P48GFcLhcOh4Pk5OSYxnQ6nTidTrKzs9F1naGhIXp6eujt7aWlpQVFUXC73WalOzExMWrRbbPZsFgsEZVxwdmJENmCaSAEtmCmOBzDsZ5Zm8V0effdd7n44ovN17fddhsA1157LQ8//DCtra00NDSY+xMSEnjxxRe5+eab2bp1K2lpaVx11VV885vfnPO5CwSnGuHZ17quI0kSuq5TVVXF8ePHWblyJS6Xi8OHo//7wxhj5Lb4+Hji4+PJzc1F13W8Xi89PT309PTQ2NiIpmlTEt3BYBCXy2UKbyG6zy6EyD5tiUWUCM4+RDV7Pti1a9eEEWAPP/zwqG0rV67kxRdfnMVZCQSnH+H2EAgJYZ/PR0lJCYqicO6555KYmEhvb++Yf+YMUT7e2BMhSRIulwuXy0VeXh66ruPxeEzRffz4cQAztSQlJYWEhIQxRff+/ftZt26duT/cWiJE95mPENkCwRmLENoCgeD0w6heq6pqdm08ceIEpaWlZGdns3LlSiwWCzB2ZXoipuKXliSJhIQEEhISWLhwIbquMzAwYHq66+rqkGXZFNwpKSnEx8ebAtrI6TZSUQKBgFnpFqL7zEaIbIFAIBAIBPOOkeahKIqZHqJpGmVlZbS2trJ27VoWLFgQcU6sItu4znSQJMlMHcrPz0fTNAYGBujp6aGjo4Pq6mqsVivJyclmDrfL5RpV6TYeJoLBoDluuOg20ksEpy9CZAsEAoFAIJhXwrOvIbS40ePxUFJSgizL7Ny5k/j4+FHnzUUlezJkWcbtduN2uyksLETTNPr7++np6aG9vZ0jR45gt9sjKt1Op9OsxkOk6B6r0h2eXiI4fRAiWyAQCAQCwbxh5FADZqW3ubmZ8vJy8vPzWbZs2bg2ivmoZE+GYR1JTk6moaGBzZs3EwwG6e3tpbW1lYqKChwOh9mNMiUlhbi4uElFd3ibeMNeIkT3qY0Q2QKBQCAQCOYcwx5iVHsvuugiVFWlrKyMrq4uNm3aRHp6+oRjnAqV7MmQZZnU1FRSU1MBUBSFvr4+enp6aGpqory8HKfTaVa5U1JSsNvtUYnukZ5uIbpPLYTIFggEAoFAMKeE20MM73V/fz8lJSU4nU7OO+88HA7HpOOcipXsya5ltVpJS0sjLS0NCIluYxHl8ePHKSsrw+VyRdhLjOp1+JiaphEIBMxulEJ0n3oIkS0QCAQCgWDOGNkaXZZlFEVh//79LFmyhEWLFkUtDkeK7MnOmw/ROdk1rVYr6enpZtXesJYYySWlpaUkJCSYgjs5OdkU0hApuvv7+zl69CibN28WovsUQIhsgUAgEAgEs87I7GtZlgkGgxw7dgxN0zjnnHNISUmJaUxDNIbnYk8mJOeykj0VbDYbGRkZZGRkABAIBMyM7urqarxeL4mJiabodrvdEaJ7aGgIWZbRdR2/308gEAAQonseECJbIBAIBALBrGL4iTVNA0KCr6uri8OHD5OQkIAkSTELbBhbZEdz/FwxE4LebreTlZVFVlYWAH6/3xTdFRUV+P1+U3THxcUBJxeQWiwWszGOIbrD7SWGDcVqtSLLshDdM4wQ2QKBQCAQCGaF8AV7hj3EaI1eX1/PihUrSEtL4/XXX5/S+OEi20BRFHRdHzORZCoe7uky08LV4XCwYMECMzN8aGiInp4eent7aWlpQVVVDh06ZHq63W73uKLb5/OZczREt1HpFqJ7+giRLRAIBAKBYMYZK/va5/Nx+PBhAoGA2RrdEHrRVqPDGSmyW1tbKS0tBTBFZmpqKi6Xa14E41wIeqfTidPpJCcnh97eXkpLS8nKyqKnp4eWlhYURcHtdpv2ksTExKhEt1HhFqJ76giRLRAIBAKBYEYJb41uiLO2tjZTAG7dujWiNTpMT2QrikJFRQUnTpxg7dq12Gy2UW3PU1JSUBTFFJJnIkYFPzc3l9zcXHRdx+v1mvaSxsZGNE2LSnQb3SoBc4GqEN2xIUS2QCA4K6lrXQyDSeMfMNA/d5MRCM4QxmuNXlFRQUtLC2vWrCE7OzviHEPgGcfHgiHy3n33XSwWCzt27MBut6MoSkTbc6MDY2dnJ8eOHaO+vt6schu51LPFXArRkTYZSZJwuVy4XC7y8vLQdZ3BwcGIyEA4WfVPTk4mISFhXNHt9/vx+XxCdEeJENkCgUAgEAimzXRaowPmoshYaG9vB0IicfXq1WZiSTjhHRg7OjooKCjAarXS3d1t5lKPFZE3XeYjxWSybwMkSSIxMZHExEQWLlyIrusMDAzQ09NDd3c3tbW15vtlvB/x8fERwt0Q3aqqmt06+/v7zdbxhs3EaA1/NiNEtkAgEAgEgmkxMvsaoKWlhaNHj07aGt3YHosoNarjzc3NACxdujTqKrgsyxHNYMIj8qqqqvD5fCQlJUVE5MVaYQ9nLoWmpmkxXU+SJJKSkkhKSqKgoABN00zR3dHRQXV1NVarNUJ0O51Os5INoc+tpaUFl8uFw+EwxfVIT/fZKLqFyBYIBAKBQDAljOzr8vJyU7iqqsrRo0fp7Oxk48aNZt7zeMRayR4aGqK4uBhd19m5cyd79+6NWqCPJfJGRuQZaR09PT00NzejqirJycmmtcSIHJyMU7GSPRmyLON2u3G73RQWFqJpGn19ffT29tLW1kZlZSV2u92s+BuiW9M0rFYrNpvNrHQrikIwGBxXdE/nweV0QYhsgUAgEAgEMRMezdfX10d8fLzZGj0uLo6dO3eauc0TYYiwaERpe3s7R44cYcGCBaxcudKskMYiaCc7NjytQ9d1PB6PaacwFlGGi26n0zmpRWOuGC+6cKoYC0ZTUlJYtGgRqqrS19dHT08Pra2tVFRU4HA40DQNm82G3+83q9nhle7xRLeR032mim4hsgUCgUAgEERNePa1UTmVZdlcVLh48WIWL14ck7g0FkiOh6ZpVFVV0dDQwJo1a8jJyTH3xSKyp5JekpCQQEJCAgsXLjTtFN3d3RGVXUNwp6Sk4HA4YrrGTBKrXSRWLBYLqamppKamAqFUl76+PsrLy+np6eHNN9/E6XSa74WxqHQi0Q1jd6M8E0S3ENkCgUAgEAiiYuTiRkmSCAaD9Pf3o2kaW7dunXLnxvGEss/no7i4GEVR2LFjBwkJCVGfO949TJVwO4VR2TWSOhobGzl69Cgul8v0cs8107WLxIrVaiUtLQ2Hw0FBQQGpqakRySVlZWXm+2HYS2w225iiOxgMEggEzEq3IbpPnDhBVlYWTqdzzu5rphAiWyAQCAQCwaSMlX3d3d1NSUkJkiSRn58/JYENIaE8ViW7o6ODw4cPk5mZyerVq81s7ZHnhgvnubRuWCyWiEWUwWDQ9HPX1tYCUFJSYlZ/p7uIcjJm2i4SLcaCV6vVSnp6Ounp6cDJ96O3t5e6ujpKS0vHTHIZKbqNn7VgMMju3bu57777uOyyy+b8vqaLENkCgUAgEAjGZazsayCiNXpvb++0F9yFC2Vd16murqa+vp7Vq1eTm5s77rlzWcmeDJvNRmZmJpmZmaiqymuvvUZ2djZ9fX2UlZWZ3RcNe0liYuKMCv/ZtotMdN2xHoDC3w8YneQyNDREYmJiRJKLYRkBzFzvxMTEOb2fmUKIbIFAIBAIBGMyVva13++npKQkojX6wMDAlHKuDcIr2Ubrdb/fb44/2bmz5cmeDsacsrKyzEYwXq+X7u7uiEYw4f7l+Pj4ac1xru0iBsa3G5MxMsnF7/eboruiogK/309SUpJpLYmPj8fj8eByuaY1v7179/Ld736XgwcP0traytNPP82HP/zhCc/x+/18/etf57e//S0nTpwgOzubr33ta9xwww1RX/eUEtnf/va3ufPOO/nCF77Aj370o/mejkAgEAgEZy0js68lSTLTPTIzM9myZYvZtGWyhYuTYVSyu7q6KCkpIT09nc2bN0fVFCYWuwjMfbSeMZ/w7ovGIsrBwUG6u7vNTGqbzWYK7tTU1JgXUc63XSRWHA4HCxYsYMGCBUBkfGJpaSkf+9jHcDgcPProowwNDbFjxw5sNlvM1/F4PGzYsIEbbriBK664IqpzrrrqKtra2vj1r3/N0qVLaW1tjfln/JQR2QcOHOAXv/gF69evn++pCAQCgUBw1mIkPyiKYoo2Xdc5duwYTU1No9I9ICSSFUWZ8jUlSaK5uZm2tjZWrlxJXl5e1BXZU7WSPRmyLJuNYAoLCyPi8ZqamigvLyc+Pt4U3MnJyZMKzFPNLhIr4fGJmqbxt7/9jcsvv5yGhgauvvpqSktLp+T73717N7t37476+Oeee47XXnuN2tpaM0mlsLAw5uueEiJ7cHCQj33sYzz44IN885vfnO/pCAQCgUBwVqJpGoqiRNhDvF4vJSUlAOzcuXPMr+6nU8n2+/34fD4UReGcc84hKSkppvNPJU/2dK4THo+3ZMkSgsGgmdRRU1OD1+slMTHR9HO73e5RwnY+7CLGQsWZrqDLskx+fj69vb088sgjuN3uObu3v/71r2zdupX77ruPxx57DJfLxeWXX843vvGNmFJOTgmR/bnPfY4PfehDvO9975tQZPv9fvx+v/m6v79/LqYnEAgEAsEZzVjZ10Z1+ejRoyxcuJDly5dP2Bp9KiLbSCeRZZnly5fHLLBhtMg2IuHGO3aumeo1bTYbGRkZZsdMv99v+rnLy8sJBoO43W7TXpKYmDgvdhHjc5+N63o8HgBcLtecfna1tbW88cYbxMXF8fTTT9PZ2clnP/tZurq6+M1vfhP1OPMusn//+99z6NAhDhw4MOmx9957L3ffffcczEogEAgEgrODcHsIhESh0Rq9o6ODDRs2mOkQ4xGryNZ1nbq6Ompqali+fDktLS1TFmkjRbZRGR+r/XmsVe/pMNPXcTgcZGdnk52dja7rDA0NmaK7oaEBXdex2+04HA48Hs+0F1FGy2yKbK/Xi9PpnBErSiwYtpvHH3/czDv/wQ9+wJVXXslPf/rTqKvZ89pOp7GxkS984Qs8/vjjUbVevfPOO+nr6zN/NTY2zsEsBQKBIDr27t3LZZddRk5ODpIk8cwzz0x4/KuvvmpWDMN/nThxYm4mLDjr0TSNQCDA66+/Tm9vL7IsMzAwwL59+/D5fJx33nmTCmwIWR2iFdmBQIBDhw7R2NjI9u3bKSgomJbdJFw4t7W18dZbb/Huu++yb98+ysvLaWtrIxAImMfP9cLH2UCSJOLj48nLy2PdunVccMEFbNq0CbvdztDQEAcOHODNN9+krKyM1tZWfD7frM3F+NxmQwgPDg7OeRUbIDs7m9zc3IiGQqtWrULXdZqamqIeZ14r2QcPHqS9vZ3Nmzeb21RVZe/evfzkJz/B7/dHfGgOh2Ne25UKBALBRExlBTtARUVFxNfk0YgagWA6jMy+VlUVVVU5fvw4lZWVMbdGj1Yk9/b2UlxcTFJSEjt37jQX8o3MyY4FI/6voqKChoYGVq9ejdvtNtufG50HExMTURQFp9M5Kx7iieY3F9dISkoiISEBt9vN4sWLzUWUzc3NHDt2jLi4uIj271NJ6RgLVVXNAsFMMxPxfVPhvPPO48knn2RwcNDsMFpZWYksy+Tl5UU9zryK7Pe+970cOXIkYtv111/PypUr+cpXvjLnXw8IBALBdIh1BbtBZmYmycnJMz8hgWAMxsq+lmWZ6upq/H4/W7ZsMRMVomUyka3ruingly9fTkFBQYQom04lW9d1qqqq0HWdHTt2EBcXRzAYjOjEGAgE6O7upqamhtbWVlpaWkhOTjYXGs5GtXQ+KuaGJ1uWZVNML168GEVR6O3tpbu72+y8GN4EJjk5ecqaazYfWAyRPd3PZnBwkOrqavN1XV0dxcXFpKamkp+fz5133klzczOPPvooANdccw3f+MY3uP7667n77rvp7Ozky1/+MjfccMPps/AxMTGRtWvXRmxzuVykpaWN2i4QCATzwcgF1rPxjdrGjRvx+/2sXbuWPXv2cN55583o+AKBgWEPCc++7u7uxuPxkJiYyM6dO7Hb7TGPO5FIDgaDlJaW0tfXx7Zt28aMYJuqV7q3txePx4Pb7Wbr1q1YrdYxowTtdjsLFiygo6MDt9tNWloa3d3dpui0WCxmVN5U8qknYi6tDuNF+I1sdz5WExhjEWVqaiqJiYlRC+e5ENnT5d133+Xiiy82X992220AXHvttTz88MO0trbS0NBg7k9ISODFF1/k5ptvZuvWraSlpXHVVVfFnIA3JZHd29vLU089RU1NDV/+8pdJTU3l0KFDZGVlTdj6VCAQCE4ZKh3gmuAfUk9o38KFCyM233XXXezZs2dGppCdnc3Pf/5ztm7dit/v51e/+hW7du3inXfeibDRCQTTxbCHGOkhhiiqrq6mrq4Op9PJwoULpySwYXyR3dfXR3FxMQkJCRMK+KksnGxoaKCyshKHw0F+fn5UjWsMRjaF6evro7u7m+bmZsrLy3G5XBHWitPlm/VoI/zCm8AYiygN0d3U1ISmaWalPyUlZcJq8kxlZI9FuF1jOuzatWvCh7iHH3541LaVK1fy4osvTuu6MYvsw4cP8773vQ+32019fT033ngjqamp/PnPf6ahocEstU+VV199dVrnCwQCwUzS2NgY4ZeeyQrXihUrWLFihfl6586d1NTU8MMf/pDHHntsxq4jOLsZrzX64cOH8fl8nHPOOabdYqrIsmyOb1zTEMFLlixh0aJFE4q/WCrZiqJw9OhRurq62Lp1KxUVFaPGmug6Y83dENMQqrz39PTQ3d1NZWWlWeU1qtyJiYlRCdn5tIvEgrGIMj4+ntzcXHRdZ3BwkJ6eHrq6uqipqYmo9KekpERYJqJtqT4V5suTPVPELLJvu+02rrvuOu677z4SExPN7R/84Ae55pprZnRyAoFAMN8YHdnmiu3bt/PGG2/M2fUEZzYTtUbPyMgwW5dbLJYIkRwr4ZVoRVEoLS2lp6cnan93tJVsj8dDUVERNpuNnTt34nA4ZrwZjc1mIzMz01yA7PV6TdFtWArCrSWTeXRPBbtILEiSRGJiIomJieTn56NpGv39/XR3d9Pa2kpFRQUOh8MU3LNpF/F6vTNSyZ4vYhbZRvvzkeTm5orYKYFAIJgmxcXFZGdnz/c0BKc5I7OvJ2uNPrISHSvG+P39/RQXF+N0Ok0RHA3RCOW2tjaOHDlCXl5eRGOc2W6rHl7l1TTNTC05ceIElZWV46Z2zFcle6ZFvSzLJCcnm4uzjUWUPT09HD9+nMHBQWRZpqqqylxEGYt1ZyLOukq2w+EYs9NiZWWl2ZVIIBAIzkZiXcH+ox/9iEWLFrFmzRp8Ph+/+tWvePnll3nhhRfm6xYEZwBG58bwJiEej2fC1uix5FyPhSRJBINB3nnnHRYtWsSSJUtiEnsTVbI1TaOqqoqGhgbWrVvHggULRl07XNBOdt3p2mLcbjdut5tFixZFpHbU1tYyNDRktj6fD3E4Fx0fRy6ibGhooLW1FVVVTXtNUlKSWe1PSkqa8pxmypM9X8Qssi+//HK+/vWv88c//hEI/TA3NDTwla98hX/7t3+b8QkKBALB6UKsK9gDgQC33347zc3NxMfHs379el566aWIMQSCaAlvjR5uD2lpaaGsrIy8vDxWrFgxpuCZTiVbURSqq6vRNI1t27aZsXmxYGRdj8Tv91NSUoLf72fHjh1jCq7ZrmRPxEjB6fP5TGtJc3MzACUlJaa1ZLa7MM6EXSRWZFkmLi6OlStXApiLKI33QNM009OekpIyZifO8fB4POZ7ezoSs8j+/ve/z5VXXklmZiZDQ0NcdNFFnDhxgh07dvCtb31rNuYoEAgEpwWxrmC/4447uOOOO2Z5VoKzgbEWN6qqSnl5Oe3t7ZO2RrdYLBFdEaNlYGCA4uJi0x4Qa762wVgiv7e3l6KiIlJSUkzv+FiMJbInEnGzaeOIi4szW597PB7eeecdkpOT6ezspKamBpvNZorN1NTUKae5jMds2EUmY6Qn2+l04nQ6ycnJQdd1PB6PKbrr6uoiFpoaiyjHm7PX6z277CJut5sXX3yRN954g8OHDzM4OMjmzZt53/veNxvzEwgEAoFAMAFG9dpIeZAkif7+fkpKSrDb7Zx33nnExcVNOMZU7CLNzc0cPXqUgoIC8vLy2Lt375RFXrhQDk8mWbZs2ajGNROdG8115gpJkpBlmYKCAgoKClBV1YwKbGho4OjRoyQkJJhVbrfbPe0ovLmwi4xkogg/SZJISEggISHBjEs0PO1tbW1mBKMhuEc+eBj57acrMYvshoYGsrKyOP/88zn//PPN7bqu09jYSH5+/oxOUCAQCAQCwWiM7Ovq6mqcTidZWVkAZmfF8bzRmq7zc0Xl360W0ob3xZIuYlTI29ra2LhxIxkZGWYVfKpJE4Yne2Q831iNa0Yy0+kis4XFYjEFNZzsQtnT00N5eTnBYDAiKjAWW4XBfFSyY4nwG+lpV1XVXETZ2NjI0aNHcblcpKSk0NXVxdDQ0LQr2Xv37uW73/0uBw8epLW1laeffpoPf/jD4x7/6quvjmnZa21tHbUeYDJiFtmFhYWsWrWKv/71ryxZssTc3t7ebr5hAoFAIBAIZo9we0h/f79ZzS4rK6O3t3fc6LxOXedLfoV9msYmWWaHJSTIovVkDw4OmvaQnTt3mvF1RiVzqosnjYWTb7/9dkQ8X7TnxnKduWIyMW90oTQawni9XlN019fXI8tyhLVksm8jYH482dOJ8LNYLKSlpZk+fiOjvKenh7vuuov9+/fT1tZm9mUZ2RwsGjweDxs2bOCGG27giiuuiPq8ioqKiPjWiexW4zGljJVVq1axfft2/vjHP/Le977X3D5fT4cCgUAgEJwtjMy+tlqteDwe9u3bR2JiIuedd96YXt99qsaXAgqdw/9WV2g6O4a/5Y/GLtLa2kppaSkLFy6MiNADzN9PVWR7PB46OjooKCgYNfZkjLdocrxj51KrRCt4JUka1YXSyKZuaWmhoqICp9NpVrnHi8mbL0/2THV8DM8of/7559m6dSu7d++mtrYWj8czpTF3797N7t27Yz4vMzPTjC2cKjGLbEmS+OlPf8rjjz/Ohz70Ie677z5uueUWc59AIBAIBILZQVVV05phCNGBgQH6+vpYsWLFmP5lVde5P6jyS0UlXIpWaCfF5kR2EVVVOXbsGCdOnBh3AaUkSTGJXQMjnu/EiRMkJSWZCRWxMBVLxVww3ahAI5t68eLFBINBMyqwqqoKn89HUlJSRBdKI6t8PjzZM72A08Dj8XDFFVdw4YUXzsr4E7Fx40b8fj9r165lz549nHfeeTGPEbPINn5obr31VlauXMnVV1/NkSNH+NrXvhbzxQUCgUAgEESPIWYBszW6EXNWWFg45jnVuk6bDqmSZFaxASr0k4J4PLuI1+uluLgYSZLYsWMH8fHx484t2q6NBuHxfIsWLRqzB0c0jBT3J06coKOjwxSgRnMY49jTEZvNRkZGhtmPZGhoiO7ubrq7u2lsbARCXSiDweCUUmKmw5nWVj07O5uf//znbN26Fb/fz69+9St27drFO++8w+bNm2Maa1oteXbv3s2+ffu4/PLL2b9//3SGEggEAoFAMAmGyO7o6ODIkSOkp6eTlpbGwMDAuOeskGW+4whVOY/qOn9UNH6nqFRrOpquI0vSmHaREydOUFpaSm5u7rj52uHEIrJ7e3spLi4mOTmZzZs309raSm9vb1TnjsQQzpqmUVlZSVNTE5mZmdTX1/ODBwfx+t1csE1l1444dF0/Je0iseJ0OsnNzSU3Nxdd183Ejs7OTo4ePUpNTY35kBHehXI2ONPaqq9YsYIVK1aYr3fu3ElNTQ0//OEPeeyxx2IaK2aRfdFFF0V8LbB69WreeecdrrjiCuHJFggEAoFgFtE0jWPHjtHY2Mjq1avJzc2loaEhqkWLkiSxRpL4sk3iz4qKDziuwyIpspKtaRoVFRU0Nzezdu3aqBMVohHZRhJZRUVFRDyfYXWYCsaiyYMHD+L3+znnnHMIKjZ+/qSTf7xqQdN0/rFXw2JR2LhC4bZPVBIfH09aWlpUiwmnylxpIkmSSEpKIikpicbGRtatW4eqqmYudWlpqdmF0ogKnElRPFsiOxAIEAwGT4kIv+3bt/PGG2/EfF7MIvuVV14ZtS0tLY3XXnst5osLBAKBQCCIHkVRGBwcjOh+aLFYUBQl6jESJImLLDIvqBoVmsYi2WJWsoeGhiguLkbTNHbs2BHTV/WTJZSoqkpZWdmY8XzTWZAYDAbp7OwkLS2NTZs20XzCwo3/baWyTkaSwGKRwCIDVg4ezaGrrxX7iRNUVlaaiwnT0tJITk6esQV84fc1l+i6jtVqJTk52Uzs8Pv9prWkrKwMVVVJTk42q9wul2ta81RVdcbfNwgl2QCnRFv14uJisrOzYz4vKpHd399vxphM5pkKjzsRCAQCgUAwczgcDrZu3RqxzWq1xhyf+8FhkV2p63yAk0J93759LFiwgJUrV0YtnAIa/HeJhb8f38EHFJ2bt8Jid+QxHo+HoqIibDYbO3bsGFVBjtXPbdDS0kJbWxtut5uNGzfy5kGZz99lpbcfGEs3ShJltTn8ywdSURSFnp4eurq6qKioIBAI4Ha7SUtLIzU1ddricz4YK8LP4XCYXSiNDozd3d10dXVRU1OD1WqNsJZEG50Yfs3ZqGQPDg4iSdKE6wCiHae6utp8XVdXR3FxMampqeTn53PnnXfS3NzMo48+CsCPfvQjFi1axJo1a/D5fPzqV7/i5Zdf5oUXXoj52lGJ7JSUFFpbW804k7F+6IzYGJGTLRAIBALB7DGy6htLIxmDiy0yTkIJI5qmUV9fj67rrFq1ipycnKjHafTCZw/ZONIn0WF38YsOiV/8E9KAwx8OkBIX6qNx+PBh8vLyxo3ni7WSHe6/zsjIoKPXze33WPnLSxZCb8X4Y71TErIfWK1WczGhrusMDQ3R1dVFd3c3tbW1pvg0RHesvub5sNBOFuEX3oExPz/f7EIZ3gwmISHBzOaOpro/WyLb6/USHx8/7bHffffdiOYyt912GwDXXnstDz/8MK2trTQ0NJj7A4EAt99+O83NzcTHx7N+/XpeeumlMRvUTEZUIvvll182Q+3HsosIBAKBQCCYH6Yisp2SxMUWmcOKyv6igwSDQSC2hhv/1yZxe4mVvqCEBFhkHUULCbwu4FdlMv+aeIzjx4+zbt26Cb3dsVSyA4GAmUqyZesOvvaDIBV1DlRdIhpdW1rtYtAbICGsQGpUTOPj482caiMy7/jx45SVlZGYmGgK7qSkpKjE31w3v4k1wi+8C+WSJUsIBAL09PTQ3d1NRUUFfr+f5ORkU3QnJiaO7iA6gznZ4QwODs7Itwm7du2a8IHn4Ycfjnh9xx13cMcdd0zrmgZRieyLLrpozN8LBALBaUs5MNGaJ99cTUQgmB5WqzUmT7bB+YMD/EWyYklIYPPy5bz88stRCV1Vh+9XWPh5jSWiXmyVdMJn8dtyH+cWtEX4x8cj2ozt/v5+Dh06hNvtJmfhZm74qoN3D2vo6NisMgkunWWFGodKxxeaiirx+gELuy8a/8HE6LZoFBjDfc1HjhxB0zRzf2pqqtn5cj4xhOR0RKndbicrK4usrCyzum/c9/Hjx5Fl2RTcRhfK2Yrwm4/4vpkm5oWPzz33HAkJCZx//vkAPPDAAzz44IOsXr2aBx54IGIhg0AgEAgEgpllunYRXdeprq4m/vhxErfvwL5qNTY5JMwmG6fTD18osrKva7Sosso6DJ+uA3VSPNu378DhmFxqRJMu0tLSQllZGYsXL6bbs4SPfMZGR5cEkma6QwY9EhW1MhYLqGNodml4bq++Y51QZI9kpK/ZiMw7MWIBpeFrtlgsc24XMa43U4I3vLqfl5eHpmnmfbe2tppdKIPBIH19fbhcrjG7UE4VQ2Sfbr74cGL+JL785S+bix+PHDnCbbfdxgc/+EHq6upMn4tgBkif7Kl4/ZxMY2JiC2UXzDXi8xEIzgYMQRdNJdjn83HgwAFOnDjBBeecw6UOBxXDPt7J0kEOdEt86HXbmAIbhkU2IRErAYpF5un66DoBTlTJ1jSN8vJyjh49ysaNG9l3ZBnXfNEeEthj4BmSKMyb+L3Yu9/CFDvAm5F5hYWFbNmyhQsuuIAlS5ag6zqVlZXs3buXoqIiTpw4Mae53DNRyZ4IWZZxu90sWrRo1H03NTXx+uuvc/DgQWpra+nr65vSQtZwzspKdl1dHatXrwbgT3/6E5dddhn33HMPhw4d4oMf/OCMT3DWWUXoa+NTkXQndA5NcMB64PBczWYcZlPIHZrFsc9kTkdxHctD49S6wgkEZyqGH1ZRlAnbW3d1dVFSUkJaWhqbN2/GarXyQVXjjeGS71gNaQweqpV59oRMnIWTKjoMHR10DWnEzidqZP5jxfhiS9NAlsevZAcCAYqLiwkEAmzdtoNv/yKJP/x9cv9vomtiYdvVK1FyTGbT6ukJQRh7AaVR5Q4Gg7z55psR1pLZakFufHZzVfm1Wq2kp6cDmJ0QDWtJc3MzmqZFWEucTmdMczM82aczMYtsu92O1+sF4KWXXuITn/gEAKmpqVNuiTrvnMpCe1Jmq6I93+IdIsWiENwTczoKa4NT4VsZgeD0YaRQMUT2eFVoXdepqamhrq6OlStXkpeXZ45xvizxJ0U3xxk5xkAQ7jhs5bkTJ6vXKQ6dhU6dsn4ZVQdN11GGF07aLBAIG2J/39hV76ACdz9mYVW+zsfeq40psvv6+igqKsLtdpObv5kbvhpHUVl0X8B39kwg5oYv8+rbVjatntkW5OEWi4SEBEpLS1mzZg1dXV00NDRw9OjRWWsMM9uV7LEwhL0sy9jtdnJycsjJyUHXdQYHB+nq6qKjo4OqqirsdnuEpWayhw2Px3NKZGRPh5hF9vnnn89tt93Geeedx/79+/nDH/4AQGVlJXl5eTM+wahYDUT7YFg6mxOZBSatZs8WhvA5FcQ2CME9HqezuAYhsAWC6SMNt0UfS2QbSRxDQ0Occ845o3pZ2CSJgmFRNtIucqxf4jOHrNR7QvsVq45m0enxy/QEJFYkahztAyUYNC0rVl0noJ4Uef0S7D8B28OCRdp64DM/slJULbNxqcbH3quNsouE+697vEu48b+sOBywfJFGTYPMqFsdUbhuapVJcev09I8vOF9528KtN4y7e9oYSR8pKSnmerVAIGDGBJaWlkZUe9PS0qa1gHK+RXY4kiSRmJhIYmIihYWFqKo6ZlqLIbiTk5NHjeH1es++SvZPfvITPvvZz/LUU0/xs5/9jNzcXAD++c9/8oEPfGDGJzjjrGVsoX0qV7PnTWjDqWFJGYkhLE8lsX26i935QAhsgWCmGEtkd3d3U1JSQkpKCps2bRp3UdpOi0y7rkfYRf7UJPP/lVrxDQ/pS1DpdUnEqzp2f0jTqj4PStCO1WrFYrEQVBTTlx3Og0ctbF8QGuhAhcTn/tdKR29ICBZXy1Q3S2Qnh0R2eEv3jRs38uJbWdz1Iyvh4SlxDlizTOPwMUOUGcsZI8nLnlhkH6uVaW2XyM6cuwWKdrs9YgGlUe1tb2+nqqqKuLi4iA6UsSwkNBrRnAoieyQWi4W0tLSILpRGVODRo0dRFMXsQmk0AhocHJx2JXvv3r1897vf5eDBg7S2tvL000/z4Q9/OKpz33zzTS666CLWrl1LcXHxlK4fs8jOz8/n73//+6jtP/zhDyNef/vb3+bTn/40ycnJU5rYrCKEdoycikIbhLA9nRECWyCYScJj/HRdp66ujpqaGpYvX05+fv6EwutcWeLYcNV1KKhy52ELv28MWVB0dPrTNbzIoIJiCS3kCypBGoMSNrsdeXhsiVCM30he6ZABlUdekPnm45GCGeDJvTJf/HDILvLuu++a/uvvPpjEE38d7b/2+SEQnPw90bUxxPMIPf7y2xY+dnns8YfRMlljmPBqr9GBsru7m6qqKnw+H2632xTdCQkJE443WSOa2UBVVXPRbCw4HA4WLFjAggULzC6Uxr3X1tby7LPPcvDgQdLS0mhpaYmpQVI4Ho+HDRs2cMMNN3DFFVdEfV5vby+f+MQneO9730tbW9uUrg1TENnRcs8993DVVVedmiJ7IoTQHodTzT4iOH0RAlsgmA5jCSmjkh0IBDhy5AiDg4Ns374dt9s9xggjzpUk4nV4w57M/1eeQa0/JGw1WacnUyOgnBRQihSyPMiyjM/qYpELjnvDJ6djlUEJW094Qpf4yrMW/nZYZsU5OtYhncY6ie5h3/Qzb8hc/55BAGw2G7n5m/nknXETZl3XNMjY7BAMhHTzqOWLEtQ3y8gSjKW1DV592zprIjvWVJHwBZQQskuEZ1RbLBZSUlLMhjgjPc2xNqKZCWai22N4F0qjEZAsy5SVlXH48GEWLlzIAw88wKc//emYx969eze7d++O+bxPf/rTXHPNNVgsFp555pmYzzeYtU9jPtqJxsTaCfatmrNZxM6k0X6zjRBIgukgfn4EgtnAYrHQ39/Pvn37kCSJnTt3RiWwDWqDOl9fsIhDq3U8i/z404J0ZEUKbABNk7BYrVhtNiRJItU+4t96PbT40ZyXDMnxUOaVGApKlHVJlHhlurMkVgynjrR2aTz2tyYAFHkDV3zWOaHABggGYUn+eMkgOpqqMeBhzCi/8Bnv3W/h3z7n5H8fsVF0VJ5yrN94TKeybORTr1+/ngsuuIA1a9YQFxdHY2Mjb7zxBvv376empoaenh40TZuXSvZstFSXZZkLL7yQ1NRUbr75Zjo6OvjoRz86o9eYiN/85jfU1tZy1113TXusWatknxaMZxuB+RfaE1XT57WiDaKqLYgdIa4FgtlC13UCgYBpDyksLIxZbL3XIfP39nKOJ2byfEo2ryQHGbRr6EMWNE/ol67I6JqEbJOQhsVoZ2D0dawWIAh2K7jjQJZATh59TWcaBBUFTVUp61hDd5uVp/7PgaJEN3dHRCFXN9+LYDCIjo6ugKYMoiqhBA9JHj2uDhypkDlSYeenv4XtBSqpCToXXqhy4YUq6emnRsEwfAGl0f7cqHKXlZWhqioJCQlomobX6yU+Pn7yQWeA2WqpDifTRYyum3NBVVUVX/3qV3n99ddnpLHO2S2yT2Ums63Mu9AWCAQCwXwQLqCDwSClpaX4fD7y8/NZtGjRlMe1WCysk3x8OFvGr0nkdGkoLhU5XoEM0IIyuseKMmTF5rEgAY1eiQyHTodfAkkCXccmg8sOLsfJxOw6VTJ2A8Oxgj1edM2OzW7n9aN2UmwFrNms0t5sobV5cqF9omP4mOH/aZpGMBhEtliwWSzo6ASUeFN4h793uh6arkG8HfIdGm/vDQnGZ5+1IkmwcqXGhReqXHCBwubNGrHortn8Rt9ut0d4mgcHB2lubqa/v5933nkHh8Nh2kpSUlJmtBNjOLPVUh3mPsJPVVWuueYa7r77bpYvXz4jYwqRLRAIBALBaUhfXx/FxcW4XC4yMjKm3eQkPKHEIUss9upUJjAsYiVkuw72IIPtNhQZkoYgToEcZ0hkG95ouyXSMgIwqEgsLdCorpdNMdwtO1i40EJbm4SqQXN/Ip0+C5IskbVOp6dKIuAbf75tHRJZGTotbSHRHAwGsVqtyBYLDFsnWjviSE3R6R+wouk6qqqga6HKvzy8YC8zWSOu38qx6kixqOtQXi5TXi7zi1/YSEiA97xH4Xvf80f9ns6FfcNYQJmZmUlPTw/btm0z4/Kqq6sjFlCmpqaSmJg4Y/OaDbuIgdfrnVORPTAwwLvvvktRURGf//znAUwbjtVq5YUXXuA973lPTGMKkS0QCAQCwWmErus0NDRQUVHBkiVLWLRokRmDNh2MnGxd16mqqmJ9t0Tl8oJRx0k2DV2R8TpCInsoPDlwgurtwAKJVUlDtNUP0dmThCRbyc7XaGsb1UCStl6JlUs1jk3izV6QodHYEpqz3W5DluQIz7UO5OdolFZakCUJXZfR0LBZrWiaTp7bQ0elhVZvaNGgJMnD/x99rcFB+OtfrXzsY0E2bZph8/YMYHiyjU6MRjdGowNlV1cXx48fR5bliA6UDodjytecLZFtJI7MZU52UlISR44cidj205/+lJdffpmnnnpqSt8SzZrIvuCCC6YVqi4QCAQCgWA0fX191NTUsGXLFtOvOl4zmliwWCwMDQ3x7rvv4vP5uGv9Jv6sgDZCcEpOFYasBC0QlKFmUCbeojMwweV1oMmr0qDKWBcnk2yTSKjWONwkEdTBJp08zricY5J1mzo67e0D6LozVJWWxhF7+mjFLEkSG/I1jh1IRFHAatXRdQ1NU1EUBVmWwkR35PnPPGNl06bJO0XOdQDEeOkiTqeT3NxccnNz0TSN/v5+urq6aGpqory83PQ9p6WlxdyBcjY92YODgyQmJk57jOrqavN1XV0dxcXFpKamkp+fz5133klzczOPPvoosiyzdm1kKkZmZiZxcXGjtkfLlES2pmlUV1fT3t4e0aEJ4MILLwTg2WefndKEBAKB4HRlvhsfCM4OUlJSuPDCCyPEjdVqZWhoeut0gsEg7e3tZGRkmM1r8ppVGpyR6llP0KA79PshO9h8sCRBp7h77HHDPdF2u50kCbJbdQ53yfQEgWyQh0D22IhXwKmHFku29I1vadD0kOWkpcNJvNPC0ND4leWyKpnCXI3kJJ2OriDHmy1szNEofuvk+xcS0pbhzpWGTUBDVYPD+08K7n/8w8p//3eAaNw5c5n2EU26iCzLJCcnk5ycPO4CyuTkZNPP7XQ6JxzzVPdkv/vuu1x88cXm69tuuw2Aa6+9locffpjW1lYaGhqmdY2JiFlkv/3221xzzTUcP3581FOaJEnTfpIWCASC05X5bnwgOHsYWT2cTiVb13UaGxtpamrC5XKxYcMGU1hdYpX49cjjE05ex2eDRN9wtscYYsxcjCjLWK1WFsoQqIXKfhmHFbM5jOYEzSnTD/QrYPVC/6DEilx91CJIVVNRggoWqwUkKwU5Po7VjBB6YafohDKzaQZJh+XuHpRBN2vXajQ0yPT3j2wJDhaLjJFyrGnhVW6dri6Jxx/v4CMfsZGUlDTn2dTjYXR8jIWRCyg9Hg9dXV10dHRQVVU16QLK2bSLzERb9V27dk34jcLDDz884fl79uxhz549U75+zCL705/+NFu3buUf//gH2dnZc57JKBAIBKcq8934QHB2MFEzmlhRVZWysjK6urrIz8/H6/VGjH+TW+Ih74im5RJYAJWQE8NngzqPhBUNZcTYiqJgsViwWK2s0zWqSmX8inEfw4EkEHkBKyhJoABaQIdhka0DqqqgKipWmxWLHHrQiIvSUpzk1HD7hqg44sI27E+RZY3CQpWUFOjtlamvl9FH2EtGVrl1XeO55xJZuvQAuq6bDWLS0tIi/M3zYReZjiYLbwpTUFCAqqpmF8aamhqGhoZISkoyRXdiYuKsiWyfz4eqqtO2i8w3MYvsqqoqnnrqKZYuXTob8xEIBIJTiv7+/ojXDodjWguFRmI0Pvjtb3/LN7/5zRkbV3B2Ed5WPVo8Hg/FxcVYrVZ27NhBV1cXAwMDEcesiJNI65bpjIu0Y8gWHVUNCbohO3g8EovjVcr7dHRAGc6/ttpsWGWZjUMaRZWjxZjVAsEJpl2ryLgI+a+VoIKma9iGFzgatHWF4vomIidFRT2hUd9iI7w/pKZBfb1EfT2ATlKSQmEhHD5sG3Oc0IOBzJEjaaxadQF2e8jf3NLSwrFjx0hISDBF6Fw3h5npjo8Wi2XMBZTd3d00NDQgSRI2mw273Y7f75/Rvxc9Hg/AnKaLzAYxi+xzzjmH6upqIbIFAsHpTSUwkadyeF3TwoULIzbfdddd0/r6MJyZbnwgOHuQJCmiUhprJbu9vZ3Dhw+Tm5vLihUrkGV53DHOR+aZEY3LJZsGaqiSbCyARJLIkwc4EQAdCbvdTrwEiV0aRU1jiz+rNdS9cTz67ZASpzHYr4AUsjdII7JIOrospLkHGRwa+w/0imyVxiMaXu/kgre/X+LwYcjLU2lqGn9Bn6LA3/9u47rrkkhKSmLRokUEg0G6urro7u6mtLTU9Cu3tLSMqnLPBlOxi8TCWAsoq6ur8Xg8vPnmm+YCytTUVJKTk6cl+AcHB5Fl+bQP0Ijqb/XDh0929rv55pu5/fbbOXHiBOvWrcNmi3zaW79edHYTCARnDo2NjSQlJZmvZ+ofytlofCA4e4lWZBvxfMePH2ft2rVkZ2eb+2RZHhVmAHCjW+KZkdHQThV8J0Wozw5VgzJBLYF4C6xNsaD6NPadsCApEmnjzMdhhSEwvdmjsEIwcwhp0I7VahsV9WeQ4vYzOMa6zw25QY68I6ENR6REq0HT07UJRTbA009bue66k08INpstwt/c0NBAY2Mjra2tVFRUEB8fb9pKYk3xiIa5rJwbCygTExNJTk6moKDArHIbcZIpKSmm6I6Pj49pboYf+3S3JEclsjdu3DjqqfmGG24wf2/sEwsfBQLBmUZSUlKEyJ4pZqPxgeDsxWKxTGoXCQQClJSU4PP52LFjx6iv4setZLskEgYkBu1hKjhehZ6TL4dsYBu+vmp10NatcbRHRlchzg6bcjV6h6C+OzLH2mFjdEj2CHoTnbitMpoOA15IGrkWToK6pkRWL9OIjw81qWnr1FmTrlDy1tREWkvL5MeUl8tUVMisWDH6wUSSJJxOJ3FxcWzZsiXUfGc4q9pI8Qj3csfFxU1pnuHMtF0kGjRNw2azYbPZyMrKIisry1xA2d3dTWdnJzU1Ndjt9ohs7sm+uRscHDx7RHZdXd1sz0MgEAjOKmaj8YHg7GFk4ctqtU5Y5Ort7aW4uJjk5GQznm8kRjOasdiqWng1bFmjnhh2nB5yOavxNqyeAA6PTtmAbFam/RoUtYTEnztOpyBFR9OhtlvCGxhutz5BbxevU8apQ28bqIMQtyjUVTIcVZOorAtdIyFOY5U7iBSEFSt06uokAoFwsTb5gsT2dolFi1Tq6iauZj/zjJWvfGXszOzwz2ekCB0cHKSrq4sTJ05QWVlpVrmnY7WYaw84hL6RG5l0E76AMj8/H1VVzQ6UtbW1lJWVkZSUZGZzj9WBcq4b0cwWUYnsgoLRHZ8EAoFAEMl8Nz4QnL0YVeiRQsuI56uoqGDp0qUUFhaOK8QsFsuYdhGAa1wSr4bvsoQC7tRhHSlJoDhklDYL3cHI8XU1JMJloM8ncbg1tN8iw7J0jY5+GWWiBooS9DhBGwy99AyAPXnsQ7NTNfR2lSMVJ+0hdjusXKnhcEBDg0p7+wTXCsPt1kI3OgGlpe18/esBLrggnh074omLGxkHOHYjnMTERBITEyksLCQYDNLT00NXVxdHjx6NqHIbWdXRMNue7PGuOdkDgcViMSv2y5Ytw+fzmVX9xsZGALPCbXjXDZE9nfuJtW/BG2+8wVe+8hWOHTuG1+uloKCAm266iVtvvXXKc4h5pc29995LVlZWhF0E4KGHHqKjo4OvfOUrU56MQCAQnM7Md+MDwdlLKF5OjxDZ4fF84d0hJxpjvEr2lUnw+U6JgPVkdVZCRcJiRvoFJFCybUg+0L2EzNYqoIPiAPsIX7eqgdMONgsoEyx+BNBygdLQ7/39oCePcJnosDxHpblUY3BwOBpQD/3y+6G8PFQx1zQLaWlDLF5spbh4YnF4/DjIsm76ucOxWjVWrarnnXf6eOcd+O1ve3E4JLZtc3LRRS527XLhcEQX4Wez2cjMzCQzMzOiyt3W1kZlZSVOp9MUqRNVueejkj2VCL+4uDhycnLIyclB0zQGBgbMhJaKigpaWlr4+9//jtVqxefzTdlKE2vfApfLxec//3nWr1+Py+XijTfe4KabbsLlcvGf//mfU5qDpMcY5FhYWMgTTzzBzp07I7a/8847/Md//EdM1pKf/exn/OxnP6M+lJ3DmjVr+NrXvhZ1zmx/fz9utxs+2Qf2KXomS6d22pxQPsn+zul195o+hyc/RCAAYCYXRPcDC+jr65uSVzrqvzcC/fBr95SvIxDMJoqiRAhiVVV58cUXec973oPdbsfr9VJUVITVamXDhg1RCZWhoSFee+01Lr300jHF2vubVd4xuj/qOlQ7CQasWAFVOSlqjVN1HfADXkg+AY7+0fZrp02n1yvR3T9ihxQS35o6XC3Xgb+GxgJwL4T44TXImq6RH99Oa00aY9vSdXM+mqaiaRrx8TZsNvB6hy82DsuWSVRVRVaz4+MVcnNrqKryjnseQHY2bNgwxP33r5+y+FUUxaz6dnd3EwwGI7zc4VXu2tpaAoEAK1eunNK1psKhQ4fIyclhwYIFMzJeMBjknXfe4Tvf+Q7vvPMOkiRx++23841vfGNa40qSFFMHXoMrrrgCl8vFY489NqXrxlzJPnHiRMRqZIOMjAxaW1tjGisvL49vf/vbLFu2DF3XeeSRR/jXf/1XioqKWLNmTaxTEwgEAoHgrMSoJqqqOmY8XzQY3lpN00b5bAH+uQAeO9bC7wMOqjLS6I7TsfnHz7mWJCAu9MvbDYNucPrAFVbR9gYlliR76e6PDzsRnHGQPLxJ1cDrg8EVwFHAD95+iM8I5XWvTQ1w8K0E7HadsQWzNHxfKqqqYrVaCQRg+XKV0lILoIeljkSeHxcXaRnJyPBjs1VTVTW2Dzuc5maVhgYr73vfAJdfPrUHdavVGlHlNjoytre3U1VVZVa5U1NTUVV1XjzZM7nY0mazcf7553Pw4EGSk5O555578Pl8MzZ+LBQVFbFv375p9S+IWWQvXLiQN998c9SinDfffJOcnJyYxrrssssiXn/rW9/iZz/7GW+//bYQ2QKBQCAQRIkkSciyTG1tLS0tLaPi+aLBENZjLWbz+/0UFxezTFH486ZNxMfbaUjW+GWVyrNdMtVIKBNpLTuoKgw6wREEq3aywUww4EOS40OLH6VQeogrLCnTIkNiPORdoFOvSKhBUHygoLHGqXLkoAxI+P0BZFk2f4ULTkVRhpMw7OZ2RZEjq+6h3w2/n6FXdXVgteooikRamh9FqaSjI7qmP8aY99/fxe7diWaXyakysiOjoiiml/vYsWMEAgEcDgdNTU1mbN5sM1sdH71eLwkJCaxevXrGx56MvLw8Ojo6UBSFPXv28KlPfWrKY8Ussm+88Ua++MUvEgwGzXip//u//+OOO+7g9ttvn/JEVFXlySefxOPxsGPHjjGP8fv9+P0nH4FHdmITCAQCgeBsYGTFMhAIoOs6nZ2dY8bzRUN4NTycvr4+ioqKSE5OZsuWLWYySX6CxDc3qXwTFb8KT9TK/PxIL3WuNAZHCErdQcijLYHHCUmDOsHhLjTtSgo2KdTQxu1ScY6MDjHmoUmsXqHT2iKhqjDkk7EnKCQmwUC/HV3X0TQNTdNQVQWQzOzv0ALIyLzA6moZtxv6+sLzs3XT9gIwMACrVinU1FhITKylvj62rpoAjY1B/vjHPj72seSYz50Iq9VKRkYGGRkZ6LrO0aNH8fv9dHR0UFVVRVxcXISXe6xvJ6bLbInswcHBeev2+PrrrzM4OMjbb7/NV7/6VZYuXcrVV189pbFiFtlf/vKX6erq4rOf/SyBQOjrkri4OL7yla/w1a9+NeYJHDlyhB07duDz+UhISODpp58e98nl3nvv5e677475GgKBQCAQnKkY8XyyLLNq1aopixOjGh6eMNLc3MzRo0cnTSZxWOD6ZRr5DQfYunUrpT43v6mz8NSAhYAFNBfQGzrWZwObFsQmS1itNnQdlmXqtA4qWCzjV3s3ODVerZYJDIBdBme8jpQm49EtLFmrk+TS6Dwh0Xj8ZEU+JLZDojkYVCKq3KoKixbpFBeHX1OKENwAsqyxYkUDR44MDb9PoeNi4ac/7eKKK5JwOmcnx1qSJCwWC263myVLloyqcgeDQZKTk03RPVNV7rG+9ZgJPB4PKSkpMz5uNBhOjXXr1tHW1saePXvmTmRLksR3vvMd/ud//ofy8nKcTifLli2bche0FStWUFxcTF9fH0899RTXXnstr7322phC+8477zRX60Ookj2y5bFAIBAIBGcDI+P5mpubpz2mkTCiaRrHjh2jtbWVTZs2kZ6eHtX5hkg/LwvOy1Jp3yvxkiKjxoM0XB3WAX+iDaf3ZIP0BBfIYesIVR0MvS1JsEHSKH5XRraCZgcf4AtIvFRuRbbDwHFwahZkCdLyISvNR1Odh54uFxaLNaLKrSgKshx6oOju1oHIztUnCbWhdDha8fm8rF9vp6lJobtbI9JWMrng7uhQeeSRXj796YkTXqZDeLrIyCq31+ulq6uLzs5OqqurzSp3amoqKSkpUxbKs2kXORX0naZpEQ6KWIlZZN9www3cf//9JCYmsm3bNnO7x+Ph5ptv5qGHHoppPLvdztKlSwHYsmULBw4c4P777+cXv/jFqGMdDseMtTQWCAQCgeB0RVVVjhw5QmdnpxnP19bWNu2uy7Is4/P5KC8vR1EUduzYEVPVc2TW9m3LFV46akeSQdZ1VCkkrAMOCcUPtuHpNvRIZDkDtA056NFCIjvdAvEWnXyPTnFNqFOkbYQeVi2gJkMQiQEVbIOgdai0tsqsXB5Pf29I5hiV3pCYPCm4q6t1kpP76e93mlVuQzTb7RrLl9dTVNQXcc2CAjupqRb6+jTq6xU0LdLHPZ7ofvDBbq6+2o3bPfOVXxi/46MkSbhcLlwuF/n5+SiKQm9vL11dXVRWVhIIBMwqd6wt0GdLZHs8nmlX22PpWwDwwAMPkJ+fb6az7N27l+9973vccsstU55DzCL7kUce4dvf/jaJiYkR24eGhnj00UdjFtkjme5Tg0AgEAgEZzodHR14vV527txpxvNF01o9Go4cOUJaWlqE/zpaRtpNdi2AtBKdTpsEko6EZGpQjxOSB0+emxSncGwoHtUHsg2ynDrWZjjWbrRi13HYGQ7BDrtoqOAMFgi6YXBQI8Fmo6HZTmKSwsCo5VsSsmxBlkNid/FiKCmRUFXVtJS43UEyMuopLR2tRxoaAhhx94mJFvLzbVRVKfj9xqTGTkYeGND45S+7+fKXM6J5K2Mm2mY0VquV9PR00tPTzSq3ERNotEA3bCUTVbmNbwdmS2RP15Mda98CTdO48847qaurw2q1smTJEr7zne9w0003TXkOUf/p6e/vN4PuBwYGIjI3VVXl2WefJTMzM6aL33nnnezevZv8/HwGBgZ44oknePXVV3n++edjGkcgEAgEgrOJ7Oxs0tLSIkTVZK3VJ6OpqQm/309ubi5r166dUhzcSJHt8XjY4h/ieVsOsk1GC3sG8NsgaAlVsxUd9ne7UQOABJIG3koY8EimwEYHWT7ZaGY8fMk2kgZ1FAUWr4SSdyeec2+vDYtFwmIJCcf09AGCwUqqqlTznk5WuSMZGFApK1PZtMlFUZEhyI3Fk6H3IWTjAIsF9u9v4uMfb+Cii9K56KI0li+fucV9U2lGE17lXrhwIaqqml7uyspK/H7/KC+3cQ3jc54tT/Z0RfauXbuYqBXMww8/HPH65ptv5uabb57WNUcStchOTk5GkiQkSWL58uWj9kuSFPOixPb2dj7xiU/Q2tqK2+1m/fr1PP/881xyySUxjSMQCAQCwdnGSEE1UcfGiQj3X8fHx5Oenj7lvOVwkd3Z2UlJSQm3FBTyYmcO2IERhfZBJ8QNQp8/1H7dqHKrKvR5DM92SGAb+2RLKDvbZISO0lwwNAhOwOO3EGo7OT5NTRJ5eTpNTRLLlg3S1nacgQELdrslwscNJxeHjowIPH7cj80GocAUCVUNomk6NpsNSQKnE3JzeykuHgBg//5evvvdarKz49i1K42LLkpjx45UnM6pC9bx7CKxYLFYIqrcQ0NDdHV10dXVRW1trVnlTk1NNR0Nsxnhd7oTtch+5ZVX0HWd97znPfzpT3+KaM9qt9spKCiIOSf717/+dUzHCwQCgUAgGC2wYWp2ESP/2vBfl5aWRlSiY0WWZVRVpb6+nqqqKlavXk1ubi6LXtRpiJPMjo0GARsE4oZ1so8IPRx0gn1oWEGH3a7VAurINuyGZWSYQZeE06NTUy+Rlq7R1TmxEMzIgJSUbo4dayQYPHn/4RXsyMWTaoTg7u5W2LjRRXGx34wmNCIDU1IgMbGb6moPkiSZrgCAlpYhfve7Zn73u2bsdplzzknhrrtWkJ/vHDXHyZjptuqSJBEfH098fLxZ5Ta83NXV1WaTmKamJtLT03G5XDNyfaPpzlklsi+66CIgZBxfuHDhrDy5CAQCgUAgmBqx2kWM/OuUlBTWrFmD1WqdcjXcQJIkmpqaGBoaYtu2bSQnJwPwsQUq3/JboXuMk5xgcYKk6qh+Cfyg+yF5gcoKWedEj0xr90nxZrOBf5ImgGoC+L065ywbwGaz0tVpn/B4q7UN6GPhQht1df4x7SiRiycJE9whUV1drQy3dbdgG16hmZ0NqtpBQ4MvYpxwDMHt96vs3dvJxz8+yKOPbqKw0DXxTY4gWk/2VLFYLKZtBKC7u9tMh6uvr8dms0V4uWP184dz1olsg4KCAiBUym9oaDCzsg3Wr18/MzMTCAQCgUAQNRaLZdS/yePR1NREeXn5qPxroxI9Ffx+P/39/VgsFnbs2BGxdusLKzXubQ15qfUROlAGJBVUTUKyATaQEqClQabNK2H36RSk6CxI1fH6oKzOwiAjGEMU+5N0ig8FWLdeI+RVGY3ForN2bQMHDpxU/0lJFgoLHei6Tm2tH49n7Mp+eJVb0zS6uxUWL9aoqZEIBgO4XBJebyd9fRN/uxAujHVdp7XVx//7f4f4zW/WU1joGtcPPpKZrmRPht1ux2KxsGHDhogqd01NDUNDQ7jdblN0x1rlPmtFdkdHB9dffz3//Oc/x9w/3fgggUAgmBOOMvHfgNMPaRAIZo3x7CKT/Rs8Wf71yAi+aDGq4haLhYULF0YIbIB4G2y26RxEinBIW6WQ9UMLy9A27kyzQcAFQy6Jul44URPaszS7n66epNHCeoRlxOuw4LBYKT+qkLdQpakx0u8cH6+Sn19HSclAxPb+fpXDh0O+FqtVYtmyOBISZIqKRnhdjHlqOoqiDNt1XMTFaaiqRm5uJxUVoXMmWjwZcQvDn2tbW4Drrz/Mww9vYOHCOHOf4QUfa5yZ8GTHQniyyMgqd7iXu66uDpvNRmpqqunnnqjKbdhFXK7YKvmnIjF/Gl/84hfp7e3lnXfewel08txzz/HII4+wbNky/vrXv87GHAUCgUAgEEzCZJ5sv9/PgQMH6OnpYceOHWM2mJmKXaS1tZX9+/eTn58/YZe+zxSqSGGqwwYowdFJIWYQXpgOG0iWCFohGAwyOKQzSksmA4tHbJNgwJ2AokB2dqSJOy0tQFpaJceODTARiqJTVeWjqMjL2rWjfdKGXcSw2pw4EWTtWgfLllmorw9gt9tNQakoCn5/yLOtquqEyRcQEtr/8z8VPPFEE83NIbuJqqooikIgEEBRlIgHotm2i4xkovg+p9NJXl4eGzZs4IILLmDVqlVYrVZqa2t5/fXXOXToEPX19QwMDIx6H7xeL7quj4qKPh2JWWS//PLL/OAHP2Dr1q3IskxBQQEf//jHue+++7j33ntnY44CgUAgEAhGMFJQTeTJ7u3tZd++fcTFxXHuueeO2+gjFruIrutUVVVRVlbGhg0bWLx48YQi/apCDbcjJKhsDCdxjNCZEicr2bo9tNs4pDcVNFmiy5NEgi3sxCwgOzRoUqKO3X6yMYwiWenREiir0tGGxdzChV6gksbGSYzdI+jvj7wvQ/BardYIsdnfH8Rq7TUfHmRZxmq1YrfbsdvtZgJLMBgcUywbrFwZT2lpF/fcU86ll77Ohz70Jt/7XjX79/eiKLqZejLRGLPJRC3Vq6uD7NnTzcsvD+H3S6SmprJs2TLOPfdczj33XLKysujv7+fQoUO8+eablJeX097eTjAYxOPxAEzLLrJ3714uu+wycnJykCSJZ555ZsLj//znP3PJJZeQkZFBUlISO3bsmJE46ZhFtsfjMfOwU1JS6OjoAEI93g8dOjTtCQkEAoFAIIid8QRuU1MTBw4coLCwkPXr10+YaxytXURRFIqKimhtbeXcc881dcHInOxwJAnek6Vh1Y2ou4nRXJIpunVAs0oMZlgIqipxccPXyAeMsDMZ4l2QmqqTlaWzZaFKvAJBZxy1g4l02GwM2nWqmwdo75i4ijwWDQ0BVq92Dt+/iqqq2Gy2CIGdlCRhsXRSWdlLYaGDTZuSKCw8+UBjLJ602WyjqtyBQMCscq9e7aS6uhef7+TnWV/v4eGH67jhhgOcf/6rfPGLR3j66VY6OwMMDQ2ZjfyMMWZbdI9Xyfb7dW69tZMnnhjk05/uYPv2Zj71qXb6+0PzcTqd5Obmsn79ei644AJWr16N1Wqlrq6OF154gX/7t38jJyeH8vLySav94+HxeNiwYQMPPPBAVMfv3buXSy65hGeffZaDBw9y8cUXc9lll1FUVDSl6xvE7MlesWIFFRUVFBYWsmHDBn7xi19QWFjIz3/+c7Kzs6c1GYFAIBAIBFNjpMgO919v3rzZ9MtONoYRzTYeXq+XQ4cO4XA4OPfcc7HbTy4qnEhkAzz0AZV/LdV5rETm7S6ZvolKfVaQdNBONolEjZPxJgMntJA9xBF2vA6KBFYdNmVoFB2SSXJDICihDS+4HMQGllyw5CIH/Vj1PhL1NmxydFVtr1c1q8ahDOyT3yZkZoYEdm3tEAD19V7q60Oe7ORkG/n58aiqRF2dF683stENnIwIXLJEp7j4xLD32jIqkxtgcFDhpZdO8NJLJ9B1nZwcnZ07U3A6JdxuHV0/+XMQrR/cwOdT0XUmzeweT2R/+9s9VFScfIrSdZ1///cEkpJGHyvLMqmpqWYsdGdnJ+95z3t46KGH2LVrFytXruTAgQNRzTuc3bt3s3v37qiP/9GPfhTx+p577uEvf/kLf/vb39i0aVPM1zeIWWR/4QtfoLW1FYC77rqLD3zgAzz++OPY7fZR3XMEAoFAIBDMDkbmsoHVajU92SPzr8ezh4xkMrtIV1cXxcXF5OTksGLFilEiS5blCX3hFhk+sk7l8tUBNE3jSKuVB9+18kqLhSZdGr2WUdWQrJHX8CfJSHEyaIyymwStKhscGkWHbOY2qzXk/Q4NGGrvDqAtcBBYlUXX3nTSg0ewypMns1RVecjP12htdURsz8+XGBhoo7197DF6e4P09vYNz0di48Zkiosj+71LksTWrW6Kijqx2x1mRKCRuz2WWNZ1nWAwSFOTzJ/+1EdVVSUVFQOkptrJzHSQleWgoCCe885LY+NGNzabZcLFk0eODHL77ZW0tPjZts3Nrl3J7NqVQkHB2H70kWO88IKXxx8/mf1is8H//m86731vdD9/6enp7N69mz/+8Y/U1tZSX18f1XkzjaZpDAwMRPSEmQoxi+yPf/zj5u+3bNnC8ePHOXbsGPn5+WMuohAIBAKBQDD7GJXs3t5eioqKSE1NZe3atTG1vZ7ILtLQ0EBFRQUrV65k4cKFYx4zWSVb13XTyiDLMhvzdB7ICwJBOgbhV/ut/KjUhtcS0s+yRWKs0XR7qLptkUENgK4BGsRLCkXFEkhBU5DabBK+IeNEQidmAyslc5ABeQ1LEo/S3e0f42qhxZnBYBBJkoiLSwROiunly6GpqcWsTk+GougcOdLLqlVJlJefFKRpaTbKyk5GCY5V5VZVhWBQN4WypmlmdvfGjSmUlPSg69DaOkRr65A51oMP1pGYaOW889K44IJ0zj8/jbQ0h3kNXZf4+c+beOCBJhQl9BDy5pu9vPlmL9/6Vj0FBXFceGEKu3Ylc845bux2eZQnu7VV4b/+6+T87XaJH/84nYsvjq2xjpEsYrfbWbFiRUznzhTf+973GBwc5KqrrprWOFNPCif0oTudTjZv3jytSQgEAoFAIJgeRrrIgQMHRuVfxzLGyEq2pmmUl5fT1tbG1q1bJ0wQGU+kG10OjbHHskBkJMBt53moa+jjCU9ByI9tgTFVNiF9LMugWUNiGxX6uh1YF4CtXwN/KPkjdJ2wnOwlEhSEDRQPfo+V2u4V5CeV098faRg3qsXGAsa6ugDLl8dRWelj3Tqd8vIWU5hGi6rq1NUNsGiRi7q6kKUkN9fK4cPj+dlPNsIx3kfjvVRVlRUr4jh0qGtCS8jAgMJzz7Xx3HNtSBKsWZPEhRems3lzKj/5yQmKigbH/Xk5ftzHY4+18thjreTkOFm/Po9lyxRWr7aY93PbbV2m79pigZ/8JJ1du2LvXOn1emese+RUeOKJJ7j77rv5y1/+Yq41mCpTEtm//vWv+eEPf0hVVRUAy5Yt44tf/CKf+tSnpjWZeWEtUDrfkxiHVUD5BPvTY//hjYrOocmPAWC2Gw8dnuXxzwZEcyiB4EwlXIRomkZNTQ0AGzduJCMjY0pjjrSLBAIBioqKTNuJ0znxvztGdTWc8HbkxjFjCaiBgQGKi4v59MZk/vp6AR4ZdFuoA+R4KArYrCejABWHhC8BWGDB6rdgH9Cx9+vQT6iKvQ4YqZsSAQ/4bA70uEXQX2nuCmVgByM6PYbuCTZtUikubh2zO2Q0+HwaPT0+srIc2GxQWtob1Xmh9/Pkoss1a1yUlPQNv786knTSVjKeUNV1KC3tp6dH44knBujtVcyxDcY6Ny0tDlXN4LnnhvjHP3R03cnKla1kZ1s4ePDkB/X+98dPSWADDA4OzltG9u9//3s+9alP8eSTT/K+971v2uPFLLK/9rWv8YMf/ICbb76ZHTt2APDWW29x66230tDQwNe//vVpTypmlgNxkx4V4tgY29YO//9UFNurhv8/kdieacLFe9SCezYYSyAK4T02p7mYjuWBUQuO3ZpZIDhLCfdfA7jd7imPFV6JHhgY4NChQyQlJbFly5ao2mSPrGSH20PG8wFDaMHbkSNHyM/PZ/HixXyiWeFn9VZ0BxOKbKsFlECocipJYIvTUdSQOFQcIdHtTZcgFxgilKc9kjA9V93tJn7ITaKzz4zIGxnRpwFxCYOcONHLhg3JeDwKtbWDTKUXX29vkOxsmQULbDQ1Ta7WjQq21RoS2CFvd6/52YQ/0CiKYr7nYy18zM9PorfXQX9/6OdmvHbvxr6MDCeQTlubFrZforo6SHV1ZPX/+uunnnE9X41ofve733HDDTfw+9//ng996EMzMmbMIvtnP/sZDz74IFdffbW57fLLL2f9+vXcfPPN8yOyY2Hl8P/HE9unotCG+RHbcAoJboPTXEwKTjJb38QIBGcR4f7rNWvW8NJLL02r87JhF2lra+Pw4cMsWrSIJUuWRP3Vfbgne6T/erwxGhoaqK6uZvXq1SxYsACAu98f5OGfW/HFEapCj4HNcjIKUBm+ZU2XsMjDNhKdk8LXRkjxqAz7sMMGCluTp0vgYSFBbwIOqR2ngwhxKsfJ9F28hv3Fh3G2+mhtDaWSuFwWFi92ARL19R4GBqJrGWuxQEYGvPtuKzk58WRmxuPx6NTWelFVHc1uQ01MwNbVYwpsm82KJMk4nRYzvcQg3FYCRAhuOOnzXrw4mY4OOx7P+POMTE5xoijpdHVpo/aNZPNmBxs3OsbdPxmDg4PTbqk+ODhIdXW1+bquro7i4mJSU1PJz8/nzjvvpLm5mUcffRQIWUSuvfZa7r//fs455xxOnDgBhOIGp/PQGrPIDgaDbN26ddT2LVu2TLii+JRjJadfVRvmT2zDKSi4BaclQlwLBDNCS0sLhw8fZtmyZRQUFJgCazoiW5IkAoEAhw8fZt26dabojRZDZEcjsDVNo7KykhMnTrB582aSk5PNfU4b/EeBwkMNVkadKYFNGjtrW7UDPlA1435C1e5AeGdJHVAIdQqRAMdw4ogGDKpgcRLAQYAFDASC2PQB4iy9JGV6aD9vNUGrHcsIEejxqBw5EnoasFgklixxIUlQXe0xj/FnpOPo6DRf2+0SS5ZYOXw4tK2lxUtLS0g0u1w2cpalU7p0K5a6JtT2DlQ1MjZw5cokiop6xv0sYOzFk9nZdurrFYJBbVJbCUBSkh1FyaC7WzMTbYxfBQUqXq+V3t6Tx99ww/Q6NRqe7Onw7rvvcvHFF5uvb7vtNgCuvfZaHn74YVpbW2loaDD3//KXv0RRFD73uc/xuc99ztxuHD9VYhbZ/+///T9+9rOf8YMf/CBi+y9/+Us+9rGPTXki88JkVe35ZiKhP59iG2ZfKAkRf2YhhLVAMOPEx8ePyr8Oj/GLFUVRqKmpQVEUdu7cSVJSUsxjSJJkVlwnEtiKonD48GF8Ph/nnHPOmF7vey8N8sQvrSgaqLIxfqgIHRzvFq0gaaAPH6/roWMtMigj1xQar4OEmto0a6HScrhrQ7YRJJVgcioDOy2magrGj1/dVFWdmhoPLpeFvLw4Gpt89J23nUBmGplP/xMAl0smO1unvHxs71uf5KAhdzOqxUkcEouzguTkpNHTo9HY6CMpyUZFxTgl/nGQJImkpDg8HjegYrFMHhEIsGRJJkVFWsQ4qqqQkzNEa6uErissXGgjJcWOw2Hl4ovtE7ZcnwyPxzPtSvauXbsmbGQzUji/+uqr07reeEQlso0nAAi9ub/61a944YUXOPfccwF45513aGho4BOf+MSsTHJSVhHhqRqX8UTreFXt+SaaqvqqCfZNl/kS8DC2KBPCOzqEoBUIzgpSUlJGCeqpVrKHhobM7nYhMRa7wNb1ULScx+Ph2LFjZGZmkpKSMkpkDw0NUVxcjMPhYNu2bdhstjHHczngilyFJ5tCUkUeLjiPEssjkNWTotxAG09vSYBDhzwJFlpCgrsD6JCgUw9VvBcAOy2hY4OABn49h7ah9+KQOnFaG7Bbehj5LOHxqDicFgY+cCG+zHSkQEjMpqRYSUwMcqzDguR0YhmK/LdNcbvpvegiNGcc6DqKI46ODujsDAnyjIw4li93MTCg0t2t0Nw8FPXiy+XL0ykqCllcwgV1uK3E+BxlWSYuzkpNjUx4xIuqKjgcQYJBK7oe2t7YGMTn0/nNb9LRdQ1l+EOKtREOhKweZ0okdFQie2RbyS1btgCYK5nT09NJT0+nrKxshqc3w0wkWieqas8382VhCRfw8ym4DU438TjbDwWn2/sxEbE8LCrAW7M1EYHg9GGsCvFURHZPTw9FRUVkZmayaNEiXn/9dXRdjylCzbCHJCcns27dOjo7OyktLUXTNNLT08nIyCA9PZ3BwUFKSkrIyspi+fLlk4qv73wgyN8OWhjSJXQV1CjEpBRtN3Ep1KhGdkkElWE7iQ3IAXKGm9306JAqgZfICrdDQt/txteWhK+1AOnEAA69g0R7BRZLSExrskzl9vNR0pND75HVSlaWDRiiUsqg//3bQZax9vZib2nB0dIKEvRecCG63XayEptwMs7OapXIynLy5psnzKk4nVby8lwkJNjp6AjS1DR290qHw0JNjYLdLrFmTRy1tQMsXBiPJFk4fjxAf3/o5yZ88WRWlpXaWp8plEPbVRYvtlJZeXJFamamjccfX0RhYeiByfgmQ9d180HQWIQ50QJYCFWyFy1aFM0neMoTlch+5ZVXZnsec8tECxxP1ao2zK9f/FQT3KcDZ5IIng1m81uYeWLv3r1897vf5eDBg7S2tvL000/z4Q9/eNzj33jjDb7yla9w7NgxvF4vBQUF3HTTTdx6661zN2nBGYWRlR0tTU1NlJeXs2LFChYuXGhaB4wmJ9Ew0n+dmZlJZmYmuq7T399PR0cHtbW1lJaWous6mZmZFBYWRlXdTImHT21V+Pk+G74oNb9kdpwZtcMUypIc8mprGgR0kPXQNgNNI+TZThseZ6S4lwmlmuVLkG9F11LwtSfja12CpbUNl6WCwcu2o7nDvmaXJbwonMhYjGfNGnOzkpyMkpyMd/Vqc5shsCVJQhu20tjtMkuWJFFaGunDHhpSqKrqM1+np8eRl5eAz6dTWztEIBB66li1KgOvV6K/P0hRUagq3tcXOs/wkScl2ensVGlsDGCzWQkEsrFaleEqdxBdh1Wr/JSXG1nnIYH9xBOLWLTo5GLHkRVy41f4A+B4Ve6hoaGoO5Se6kyrGc1pTTRV7flmPLE/34szheAWTJUzUFiH4/F42LBhAzfccANXXHHFpMe7XC4+//nPs379elwuF2+88QY33XQTLpeL//zP/5yDGQvONKxWa1SVbE3TqKiooKWlJcLXbQjrkd38xiO8UjnSfy1JEm63m6SkJGRZpq6ujuzsbLxeL2+88QYJCQlkZGSQmZlJQkLCuJXzb3xEYc/lCs/sl3n8LSvvtFron0Bw6/LEatxiCf1SlZCNRAZkBbSwfjWSxMQWDKs0wrsNLJBggQV1Uw79ag5YdAjqoVWaoZmhblqHPzVvwpJ8uMAG0BwOnC4beTlOyst7J7w3RY/jqOdfOXpMwx5ow22pYdVKL06nDV2HysqxF0qGfOTh3SftrFmTTUcH9PXJeDwaILFkiYXaWp9pLUlPh29/20FKyhC6bh/1GY60pBgPZMbCybGq3DORLnKqcPaKbIFAIJhhdu/eze7du6M+ftOmTWzatMl8XVhYyJ///Gdef/11IbIFkzJVu0gwGKS4uBi/38+OHTsiqobhgmgiDJFkCKeJEkSOHj1KT08P27dvJzExlDwRCATo7Oyko6OD48ePY7PZyMjIICMjg5SUlFHVTYsF/m2Hxr/tCLUzf7dK5sFXLLxaa6FVldDDLq2Po2wkiZBFxBKK/JNlDVmS0FQJWY1sLDm5yB6nWm5OGPBI4CEkwB0hM3m9kgGKPlxJl0NBJwpoupWTuYIqEiqhvEGQZImUXDdVlZ1jXclE0610Oy9Dc4Qqyr64QnwU0lEbYFPG2zQ39054fjh5eam8/noQXQ8gSSp5eSqZmam0tfkBCzabhawsK/ffn0BcXC/FxcUApKWlmRbikV574zMNjxc0BHd4lbuxsXHSn7/TBSGyBQKBYAL6+yNX8DscDhyOqWfATkRRURH79u3jm9/85qyMLzjzmUxkDw4OcujQIRISEjj33HNHNZgxKooTjTGyg+N4AjsQCFBSUoKmaWzfvj3iz43dbicnJ4ecnBxUVaW7u5uOjo4xfdxjNcHZukxj6zINCNLcBR/+XwfHhoaj6ow87BFI0slsbR3QkUEKSeWEePBYQtF/k+o7fXiwICEP92RowFAonFtTkgAJVA1V0wgJ65HvnQUdy7DI15FRqe2wT9hzT9NluuIuR4sbYVP06chtUDcoY7ePfe5INm7MoaTk5LcUS5YoxMcnASp+f+jNycmx8/jji8jPtwML0XWdvr4+Ojo6qK+vp6ysDLfbbQrusb6pGKvK/dvf/paGhoZ5a6k+0wiRLRAIzk4qCFWYxmP4H9qFCxdGbL7rrrvYs2fPjE4lLy+Pjo4OFEVhz549fOpTn5rR8QVnDxNF+HV0dFBSUkJ+fj7Lli0bV8hMJNTDv+4HxvVVezweioqKSEpKYs2aNRNaTywWi1nFHsvHnZqaau6PixstNXPT4IUv+1l7t5N+adj2Mca683CBHX7rOjDo0VHipeH5hJJM/IEx3wBMUewPt4JEifG2ShITSjDTYSKh6VZ6496LHPRgl5twyg3YOWHeg6ZDt/1DqM5Ii4U0pGNpDaIpOqrqIppWuRs35lBcHPpsFUVhwQKFpqY4VDUwPG2J7dtd3HdfLgsXnlTtkiSRnJxMcnIyy5Ytw+fz0dnZSWdnJ7W1tdjtdlNwp6amjvp5kCSJJ598ki9/+cv87W9/49JLL510rqcDQmQLBALBBDQ2NkbEmc1GFfv1119ncHCQt99+m69+9assXbo0oquuQBAtYwlkXdepr6+nurqatWvXkp2dPeEY41WywyvYEzUw6erq4vDhwyxcuDCmbpFw0sftdrtZunQpXq+Xjo4O2traqKioGNfHnZIAT33Sz+5fOVAtIKmgD+s4iVBO9lgCO+zC5m9VNawQPsoyEnbyVOLIdeM/k7wnI68bL6HbHfjcy/GxEimoYvV3EafU4bMWorhSImfp1bCcULBIErJVQtMmzznetCmHoqKTAtvh0NB1V8TPQk6Oje9+N4+8vInL4nFxceTl5ZGXl4eqqvT09NDZ2UlFRQV+v5+UlBRTdMfHx/P000/z+c9/nj/84Q9njMAGIbIFAoFgQpKSkqaUGRwLRlzVunXraGtrY8+ePUJkCyZlPE92IHCyBKuqKmVlZXR1dbF9+/aoWkRbLJZRnthoW6Q3NTVRUVHBqlWryMnJifGORhMfH09BQQEFBQWT+rh3rIT/uTDInjdsoaxsS0g7y9LJ5jXj6X19vG+1whJJjNemX3sqtmHJsIjESLyG7jYkm4RutxK0ZREkc/QlPBq2dhVNg+Dw52i3u1i7NglZlqiv99LfH9kuc9OmXLPhTCCgAjrLlydSXn4ypi8vL2QRmUxgj8RisZiCWtd188Gpvb2dBx54gGeeeYbe3l6++tWvnlECG6YosmVZZtWqVRG52KtWraKysnJa7VwFAoHgbEfTNPx+/+QHCgRgtrk2CK9k+3w+s8/Fzp07o/4WZmQ1PDyCbTyBres6lZWVtLa2snnzZlJSUkYdM12i8XF/bHsGb1Yt5JUuK7IM6KGFhTC+wAbQxvBWSxLoEashQQ7ZuLHaIC4R+uUR7donQtJDJfUJjxljHAlIlqEx7EIaJ4vhxo3pOtKghq1DRQlGPgH4/fGUlobWl8iyxOLFLtxuKx0dfjIz0zl0KPR5Dww4CAZt7NqlcPjwybzthQtDAjs3NzaBPer2JAmXy4XL5aKwsJDjx4/z8ssvs2TJEn7yk58wNDTEPffcM61rnEpMSWQ/9NBDJCcnR2y79957zbxFgUAgOBsZHBykurrafF1XV0dxcTGpqank5+dz55130tzczKOPPgrAAw88QH5+PitXhnJD9+7dy/e+9z1uueWWeZm/4PTHyMnu7e2lqKiI9PR01qxZE1PHPaPpiJEgYgjuiVqkl5aW4vF42L59+5xkHE/k475xbSnHm3ZR5UtE04e16CTuDM06uomNFJ7SNyywIbQtqIDul7DEh3SzrocSS7Tx6ozSsEXEMoESH09gS0D481EgGFL5QT0UBWiVwCYhD2hIbQrKGO0tVdWJrktIko6m6dTWegDYtCmPxkaZDRvslJVpDA0lYrFIHD58Mupv4UI7TzyxiJyc6Qnskfzf//0fn/nMZ/jFL37BNddcg67rDA2dWZ2dpySyr7vuulHbJmq4IBAIBGcD7777LhdffLH5+rbbbgPg2muv5eGHH6a1tZWGhgZzv6Zp3HnnndTV1WG1WlmyZAnf+c53uOmmm+Z87oIzA6vVitfr5cCBAyxbtoyCgoKYkxoMoR7NAkefz0dxcTE2m43t27eP2yJ9NhnLx/3b/CpeO9jPs2WLONK9gC4cETF/o8cYzsq2hr2Wh0VzmMAOR5dCSSSGs2bct1kKE73Wk5nZEcp/IoEN4Bg+IKiCVQ4t2rafPEDqUaBTnSB2UEJVnciy17yXTZsWUlSkoOsqtbUWgsF4JAk0Taevz4nbPUB+vp0nnlhMdvbMfq579+7lmmuu4cc//jHXXHMNkiSZVe4zCeHJFggEghli165dEV/dj+Thhx+OeH3zzTdz8803z/KsBGcy4XYRXdc5ceIEXq+XLVu2kJGRMaUxZVlGUZRJ/df9/f0UFRWRkZHBypUrY6qWzyb9/f20tLTwL7tWcMNVyXR2NlFW3csTr7l5p2UBzaoLTZZGVbclBbCetISoaqgLZLQ+bjN4xPwrQAdJQhpujmP+1eBnWDSHnzxi8HCBDaHukooWMphbIhvhyH0q0rDADv/rRx9e+SnLofK6qtro7NyNLHvJzvbwzjud2GwKAwNxrF6t8fzzGTz7bJAnnvCwf7+NBQucPPFEwYwL7DfffJOrrrqK73//+1x33XVnTFzfWMQksktKSvjb3/5GamoqV111Fenp6ea+/v5+vvjFL/LQQw/N+CQFAoFAIBCMTzAY5PDhwwwMDBAXFzdlga3rOg6Hg/r6eoaGhsjMzMTtdo8SQu3t7ZSWlrJ48eIpVctni+PHj1NTU8P69evN98Dwcb/nvFDKRUNzJb97OY5Xa7Op9bsJDKtqSTtp/TAaMk50W6p1EheKJJ0U6cMCXJJCySfqWCcaAnmkwIZQHrcRkxKmsC29KnScrGCbsX6aFUPx6zpIkkJ//zLAgqYl0tycCCxAlttwu/v5298WEBfn4IorHFxxRSgKUFE0rNaZfXDav38/V155Jffccw833njjKfNzM1tI+kRllzBeeOEFLrvsMpYtW8bAwAAej4cnn3zS/Gq0ra3NXIwwV/T394dWSv+1D1xTXP0/X63Jo2G8tuoGp8LcRVt1QSzMRFt1pR/ectPX1zel1A/z743UPpAnOF/rh+6pX0cgmAuCwSADAwMcOnQIp9NJYWEhR44cibAtRYuxuDEYDNLT00NHRwcdHR3IskxmZiaZmZkkJyfT2NhIbW0ta9euJTNzdLrFfKDrOlVVVbS0tLBp06ZJU1QMH3d7ewd/26fxt5IsmgbctEnOSdcvhiPJoIcVenXtZEU7XGCHRwdadVDcxjyGjx9PYBuRfxLwWgB8wwfoNiw9CpYebdhrHfJbq6qGokQ2uJEkFYvlOIqSBKSHDd6D1drLCy+4Oeec2W9jfujQIS677DL+53/+h1tvvfWMF9gQQyV7z549fOlLX+Jb3/oWuq7z3e9+l8svv5wnn3ySD3zgA7M5R4FAIBAIBGPQ0dFBcXExubm5rFixgsHBwZiLXSMXONpsNrKyssjKykLTNFNwl5WVEQgEkCSJxYsXk5qaOhu3FDOaplFaWkp/f3/UCy/Dfdy3LYNPe720tx/nkedlHjuQS5s07A2eRAfKCqhhIlu2RNpMRlaYQxMOn0dYgslIgW3EBTJsD3FIMDQ8YLuO3isj2UKVbUUJDWK1Wke1hJflFjRNwmbTCJrJfd1IUj/XX99Pfr5MIGDHHm1LyClw+PBhLr/8cu64446zRmBDDCK7rKyMxx57DAj9cN5xxx3k5eVx5ZVX8vvf/55t27bN2iQFAoFAIBCMprOzk5UrV5KbmwucjN/TdT0qITOyg6OxAM1AlmXS0tJISkpiYGAAi8VCWloara2t1NbWkpqaSmZmJhkZGbMq0sYjGAxSUlKCqqps3759ynOIj4+nsLCAu26CO68P8Nybzdz7TBLlgy4UWR43oUQKe56xWkMCW5ZDx44psCHUonHkoscR4xtjhG+OS7WgeFWyqKPds5Qg8rBolpBlmY9+1ENpqYWKChuKEjorO9vP+98/wIEDTsrLjfz0biRpgM2bVT7/eRvHjx8326AbiS3x8fEzJoSPHj3KZZddxhe+8AW++tWvnjUCG2IQ2Q6Hg97e3oht11xzDbIs8+///u98//vfn+m5CQQCgUAgmIDVq1dHVK6tVqtZmZ5MzETbYMbj8VBcXIzL5WLTpk1YrVZze3t7O01NTZSXl5OcnGwKbqfTOXM3OQ5GDnhcXBwbN2405zVd7HY7l1+cyuUXg8/v5dd/D/DHfTbKepz4LNaTWljCrEobAlvSQyl9RsF4zLc0LOZEGqN6LUuwO0fla/8S4Bev2fi/WgtNQQlboszPvq5y5SX5LF+u09oaOkWW4Zvf9HPzzaGFjsFggD/+UefppyX+9391cnKWAtDa6ufGG+tpafEyOOjkH//IITHRwtKlS/H5fHR0dNDZ2UlNTQ0Oh8MU3MnJyVNe1FpRUcG//Mu/cOONN/K1r33trBLYEIMn+/3vfz/vf//7+dKXvjRq3+9+9zuuvfZaVFUVnuyZRHiyBWcawpMtEMwoRtSegaqqvPjii7znPe+ZsKobrcDu7u7m8OHD5OTksGzZsnGPM0Rae3s7PT09JCQkmD5ul8s14+JqcHCQoqIiUlNTWbVq1Zwkm2iazj/e9PHrFywcaHHSJ9uxDmlIGRJp6HxkncbNHxygruoQb9QU8mZTIYfaLHhG3LolAGr6cIqJPNyNcri4LctwbrLGC7f6IwR6Rz8cbZS4aE1Isu3aZeHgQRuyDN/9rp///M+JpZyiKBQVFSHLMhs3bsRiGb/rpKqqdHV1md01NU0jLS2NjIwM0tLSov62oLq6mt27d3P11Vdz3333nTLpM3NJ1I99n/nMZ9i7d++Y+66++mp0XefBBx+csYkJBAKBQCCYmJHi1RAyExW8oungCNDS0kJ5eTkrVqwgLy9vwnnExcWxcOFCFi5cSDAYNBdN1tXV4XA4TME9VlJJrPT09FBcXEx+fj6LFy+es+qoLEtcdoGTyy4AUCmq6OG3LylszGsi29VEfHw8NeV+UlJS+Or/y8JiCdkzXi2ReegVK6/Xy3RqEro8bAeRQQ3zY8syrHZqPPdF/6gKeEYSpsAGWLJEp7hY58c/DvD//t/kAvvQoUNYrVY2bNgwocCGkOXI+LzCG/2MtJWkp6eP+wBVX1/Pv/zLv3DFFVectQIbYqhkn4qISvaczGJiRCVbEAuiki0QzCiqqqIYfcOHefHFF9mxYwcJCZGJESMXOI70X4cfV11dTVNTE+vXryctLW1a8+vq6qK9vd1MKsnIyCAzM5PU1NSYxVdbWxtlZWUsX758UuE/l/T09FBUVITdbicQCGCz2Uy7RUpKinmfVc3w4As2XjphocYroQ17tyUJCmw6B+7w4XRMcjHg0UclHA7493+fWMIFg0GKioqiFtiTEW4r6e7uHtNW0tTUxPvf/34+8IEP8NOf/vSsFdgwhWY0r7zyyrjRQL/4xS9EpzKBQCAQCOYRq9U6Snjrum5Wr2F8ga2qKqWlpQwMDLB9+/Zpd+ALr4qGJ5UcPXoUVVVJT08nMzOTtLS0ST3VDQ0NVFdXs27duinngM8GfX19lJSUUFhYyKJFi8z7NLLEDbtFZmYmhZlp3Hc9QJCeQfj1XitPH7EwEJR4/bboBDbAJz4xeX00GAxy6NAh7HY7GzZsmBGxG/6NRbit5MiRI1RUVPCXv/yFxsZGdu7cyQMPPHBWC2yYQiXb4XBwyy23cM8995jtUzs7O7n++ut544036OnpmWSEmUNUsudkFhMjKtmCWBCVbIFgRjFyrcPZu3cva9asMSvQ4f5rSZLGFT5+v5/i4mJkWWbDhg2zmhZyMqc6VOEeGhoaN6kk1gzsuaSrq4uSkhKWLl1Kfn7+qP3hdouOjg48Hg8pKSlm9Xe2FogGAgEOHTpEXFwc69evn3Wxq+s6+/bt47//+7+pra2lt7eXz33uc9x///2zet1TnSlVsj/xiU/w4osv8sQTT1BXV8cnP/lJVqxYQXFx8SxMUSAQCAQCQbQYMX4Q/QLHgYEBiouLSUlJYfXq1bMuysJzqpctWzYqqcTtdpOZmUl6ejo1NTX09/ezbdu2aVfWZxKjUr1y5UpycnLGPCb8PpcuXYrX6zUXiFZWVpKQkGAK7sTExBnxlwcCAQ4ePEh8fDzr1q2bk2pyZ2cnt956K2vWrGHfvn2cOHGCrq6uWb/uqU7MInvnzp0UFxfz6U9/ms2bN6NpGt/4xje44447zrpoFoFAIBAITjUMu0i0Arujo4MjR46Ydof5+Lfc5XKxaNEiFi1aZPp+29raqKysRJZlFi5ciKZpUed/zzYtLS0cO3Ys5q6X8fHxFBQUUFBQQDAYpLOzk/b2do4fPz6ujzsWDIHtcrlYu3btnAjs7u5usyP4b3/7W6xWK3l5eaeUZ36+mFKoZGVlJe+++y55eXm0tLRQUVGB1+s9pZ4wBQKBYEK6hwDbBAcMzdVMBIIpM5bglGXZjPbTdX1cga3rOo2NjVRXV7N69WoWLFgwF1OelLi4ODIyMmhqaiIlJYUFCxbQ1dXF/v37ZzypZCoY3vANGzZMa1GozWYjOzub7OxsNE2ju7vb7Kypqqrp405LSzPtuRPh9/s5ePAgCQkJcyawe3t7+dd//Vfy8/P5wx/+ENU8zyZi/gS+/e1vs2PHDi655BJKS0vZv38/RUVFrF+/nrfeeiumse699162bdtGYmIimZmZfPjDH6aioiLWKQkEAoFAICAknC0WC11dXXi93nEXOGqaxrFjx6irq2PLli2njMCGUAb2gQMHSEpKYvPmzeTl5bFhwwZ27drF8uXLCQQCFBcXs3fvXo4ePUpnZ6e5oHM20XWdmpoaampq2LJly7QE9khkWSY9PZ1Vq1ZxwQUXsHnzZuLj46mrq+O1117j4MGDNDQ0MDQ09sO/IbCTkpLmTGD39/fzkY98hPT0dJ566ql56fh5qhPzwsfs7Gweeughdu/ebW4LBoP813/9F//7v/+L3++PeqwPfOAD/Md//Afbtm1DURT+67/+i9LSUo4ePRpVVVwsfJyTWUyMWPgoiIVTaeEjJ4CJzu8HFoiFj4JTGl3XCQQC5u9VVaW3t5e6ujq6u7sjmsIYkX7BYJAjR47g9/vZuHHjnHRnjJZoM7A1TaO3t5f29nba29sjKr/p6ekz1v3RQNd1KisrOXHiBFu2bBkVjzibGD7ujo4Oent7R/m4DYHtdrtZs2bNnFT3BwcHueKKK7Db7fzjH/84pX6GTiViFtmdnZ2kp6ePue+1117joosumvJkOjo6yMzM5LXXXuPCCy+c9HghsudkFhMjRLYgFoTIFghmHL/fbwpsw7MsSZLZFKa9vZ2uri6cTiepqal0dHQQHx/Phg0bZlyMToepZmCHJ3i0t7dPmFQyFTRNo7y8nJ6eHrPCPF+E+7i7urpM/73b7Z60k+NM4fV6+bd/+zd0XefZZ5+d0weOcPbs2cPdd98dsW3FihUcOzaZeJo7Yv7TNZ7ABqYlsCGUNQmQmpo65n6/3x9RKe/v75/W9QQCgUAgON0Zb4GjzWYjJyeHnJwcFEWhoaGB2tpaIOTlrq2tJSsri6SkpHlfTDidDOyRCR5GUklzc3NEUklmZmbMFVdN0zhy5Agej4etW7cSFxcX0/kzTbiP2+Px8O677xIXF4fH42Hv3r1m+/P09PRZ8Uf7fD6uvvpqgsEgzz333LwJbIM1a9bw0ksvma9PpYdGmOLCx9lA0zS++MUvct5557F27doxj7n33ntHPbUIBAKBQHC28tJLL/Hcc89x2WWXsXnz5gkTROrq6lixYgU5OTlmF8ZDhw5FNIxJSUmZU8EdnoG9ZcuWGcnAHiuppL29naqqKlwuV4R9ZqJ7VRSFkpISFEVh69atp5TneGhoiEOHDpGZmcnKlSsBzGp+fX09ZWVlM57H7ff7+fjHP05vby8vvvjiKfENn9VqPaXWE4zklBHZn/vc5ygtLeWNN94Y95g777yT2267zXzd39/PwoUL52J6AoFAIBCcciQmJtLQ0MBll11GWloal112GR/5yEfYtm0bsiyjaRp1dXU0NDSwYcMG89vo8C6M3d3dtLe3c/jwYSRJIiMjg6ysrCnHyEWLpmmUlZXR19c3axnY4R0Kw60W9fX1ZlKJ0RI8XHAb7chlWWbLli2nVIXU6/Vy8OBBMjIyWLFihTnv8Gr+0NDQjOZxBwIBrr32WlpbW3nppZdITk6ehTuLnaqqKnJycoiLi2PHjh3ce++9YzYFmi9i9mTPBp///Of5y1/+wt69e1m0aFHU5wlP9pzMYmKEJ1sQC8KTLRDMCl6vl+eff54//elP/OMf/8DlcvHBD36QyspKzj33XG677bZJv9ofazGhIbhTU1Nn1O8bDAY5fPgwwWCQTZs24XBE2U98hjBaghsLCo2Hi8zMTFwuF8XFxTidTtatWzcnPudo8Xg8HDx4kKysLJYvXx6VWDYeLjo6Oujs7Iw5jzsYDPLJT36SiooKXn755VOmpf0///lPBgcHWbFiBa2trdx99900NzdTWlpKYmLifE8PmGeRres6N998M08//TSvvvoqy5Yti+l8IbLnZBYTI0S2IBaEyBYIZh2fz8dTTz3F7bffTjAYxO128773vY8Pf/jDnH/++VF5dXVdp6+vj/b2dtra/v/27jwuynL94/hnAFlEREBAVAQDdwUx7CSUae4aMlaWWy540lOIkZkezTJzP5lpp6Nl5pJGpQLi3lELl3JjU1GDLMiNTUVkF5j5/eFvniMqigjMANf79eKlM/PM89wzjON37rme606jqKiIxo0b4+joSOPGjR8reBYUFBAbG4uZmRkeHh56nyW++8NFYWEh5ubmuLu7Y29vr/fx6egCdpMmTWjVqlWFynru7MedkZGhdGUpq467uLiYiRMncvLkSX766SeDLs24ceMGLi4uLF26lPHjx+t7OICey0UCAwMJCQkhIiICKysrUlNTgdtfeUg7GCGEEOLRmZubc/XqVXr27MmqVas4evQooaGhBAQEUFJSgp+fH/7+/vTo0aPMOmOVSkWjRo1o1KgRrVq1Ijs7m/T0dM6fP098fDyNGzdW2uU9ygl2OTk5xMbGYmtrS7t27aqln/PDGBkZYWtri6mpKWlpaTg6OmJhYUFSUhJnzpxRQqi9vX21z7jr5OTkEB0dTdOmTXF3d69w3byuH3fjxo1p27ZtmXXcDRs2xMrKiqCgIKKjo4mMjDTogA3QqFEjWrduzfnz5/U9FIVeZ7LLepGsXbuWsWPHPvT+MpNdLaN4MJnJFo9CZrKFqBZarVZZ7VGnuLiYw4cPs3nzZrZu3UpeXh4DBw7E39+f3r17l6tzhlarJTc3l7S0NNLT08nNzVX6Uz+sXZ6uB7azszNubm5672hyp6ysLGJjY2nevHmpseXm5iq1zbr3jop2KqkoXcBu1qxZlT5vd9Zxv/vuu1y5coWcnBw2btzIwIEDDer3dT85OTm0aNGCDz/8kMmTJ+t7OICB1GRXlITsahnFg0nIFo9CQrYQBqGkpIQjR46wZcsWwsPDyczMpH///qjVavr27VvuXtB5eXlK4M7OzsbGxkYJoXfO+la0B3Z1uH79OidPnuSJJ57AxcWlzO3u7FSSmZn5SJ1KKio7O5vo6Gjlg0l10Gg0TJkyhUOHDuHm5sbBgwfZsGED/v7+1XL88po6dSp+fn64uLhw5coVZs+eTVxcHGfPnjWYunEJ2YYQVMsiIVvUNhKyhTA4Go2GEydOKIE7NTWVPn36oFar6d+/f7lPItPNhKalpZGVlaXM+hYXF/PXX39VqAd2VcvIyOD06dO0adOGZs2alft+d3YquXr1KmZmZsqJk3d3KqkoXcDWrX5ZHTQaDe+99x6hoaH8/PPPtGrVisLCQlQqlUG1MAQYNmwYBw8e5Nq1a9jb2/PMM88wf/78avswUh4Ssg0hqJZFQraobSRkC2HQNBoNcXFxSuBOTk6md+/e+Pv7M3DgQKytrcsVIAsLC5VWeQUFBVhaWuLk5KR07zAEKSkpnD17lo4dO+Lo6Fjh/ZSUlChtEO/sVGJvb4+dnV2F6s5v3rxJTEwMLi4uj9R17XFotVrmzJnDhg0b+Pnnn5X+23WdbhXVipCQbQhBtSwSskVtIyFbiBpDq9Vy5swZtmzZQlhYGAkJCfTs2RN/f39eeOEFbG1tywwfd/bA7tixo7IK47Vr15QyC0dHRywtLfVS63vx4kV+//13PD09sbOzq7T96jqV6MpKdF1ZdCeJlqdTSVZWFjExMbRs2RJXV9dKG9uDaLVaFi5cyKpVq/jpp5/KXBSwrtEF7IMHD3Ls2DHi4+MZO3YsrVq1KlfZk4RsQwiqZZGQLWobCdlC1EharZbExERCQ0MJDQ3l1KlTPPvss6jVavz8/HBwcFDC8oN6YN9dZmFubq4E7oosklKRx5GcnExycjJeXl5VuqiKVqtVurKkp6eTl5eHra2tcpLo/TqV3Lhxg9jYWNzc3KptURWtVsvSpUtZtmwZ+/fvp3PnztVyXEOnC9jbt29n9OjRDBw4kKKiIn755RcGDhzIwoULlcWdyqL/3jlCCFFLHDx4ED8/P5o2bYpKpWLr1q0P3D4sLIw+ffooLbO6devGjz/+WD2DFeIRqFQq2rRpw8yZM4mKiuK3336jf//+hISE0Lp1awYMGMDKlSs5fvw406dPB8Db2/ueIFmvXj2cnJzw9PSkR48euLu7U1BQQFRUFIcPHyYhIYEbN25QFfN/uiXcL1y4gLe3d5WvWqhSqWjYsCHu7u74+PjQrVs3bG1tuXLlCocOHeLEiRMkJyeTl5cH/C9gu7u7V2vA/ve//82nn37Knj17DCZgL1q0CJVKRXBwsN7GoFKp+PPPP5kyZQqLFi3i22+/5dtvvyU9PR0XF5eHBmwwoGXVhRCipsvNzcXT05OAgABefPHFh25/8OBB+vTpw4IFC2jUqBFr167Fz8+PY8eO4eXlVQ0jFuLRqVQq3NzcmDZtGu+++y4XLlwgLCyMjRs3MnPmTNq3b0+LFi1o3LgxLVq0KHN22tjYGEdHRxwdHUvVNcfGxmJsbKx07mjUqNFj99PWarWcO3eOa9eu4e3trZe6cEtLSywtLXF1dVVq1jMyMjh//jzm5uYUFBTg4uJSbd1XtFotX375JYsWLWL37t107dq1Wo77MCdOnODLL7/Ew8ND30MhNzeXRo0aMWHCBP744w+ef/55xo0bx6xZswCIi4ujbdu2Zba/lHIRQyi5KIuUi4japg6Vi6hUKsLDw1Gr1Y90vw4dOvDqq6/ywQcfPPIxhdCXrKws3N3dGTlyJG5uboSHh3Po0CE8PT1Rq9X4+/vzxBNPlKscRKPRkJmZSVpaGhkZGWi1WiVw29raPnLg1mg0xMfHk5OTQ5cuXcrVD7w6paenc+rUKRo0aEBeXh716tUr9QGjKkpotFota9euZebMmezcuZNnn3220o9REbrf0YoVK5g3bx6dO3dm2bJl1Xb8kpISjI2N0Wg0GBkZsX//fgIDA4mMjOS5557Dx8eHr7/+GiMjI44cOcKXX37JrFmzcHd3v+/+ZCZbCCEe4ObNm6Uum5mZVdmqbxqNhuzsbGxtbatk/0JUFWtraw4cOED79u0BmDRpEunp6WzdupWwsDA++ugj2rVrpwTuNm3alBkejYyMsLOzw87ODq1Wy40bN0hLS+Ps2bOUlJQorfLs7Oweurx7SUkJJ0+e5NatW3h7extcG7pr164RHx9Pu3btaNasWakZ/ZMnTwIoj9fW1vaxlrPX0Wq1bNiwgRkzZrBt2zaDCdhweyXwQYMG0bt3b+bNm1etx9YF7OjoaNauXcvnn39Or169sLe3p2nTpgwbNoy1a9cq20dERHD+/HlsbGzK3KeEbCFEHXUGeNBXxrkAODs7l7p29uzZfPjhh1UyoiVLlpCTk8Mrr7xSJfsXoirpAjbc/ibH0dGRiRMnMmHCBDIzM4mIiCA0NJTFixfj5ubG4MGDGTJkCO3bty9zdlqlUmFjY4ONjQ1t2rTh5s2bpKenk5iYyK1btx7YuaOoqIi4uDjgdn14eTp7VKdr165x8uRJ2rZtS9OmTYHbJTS69n93dir57bfflE4l9vb2j7ycvY5Wq2XTpk1MnTqVsLAwevbsWdkPq8K+//57YmJiOHHiRLUfWxewY2Ji6N69O/n5+fTp0wd/f39mzJjBnDlzuHz5Mn/++Sd//fUXe/fuZcWKFfzyyy/Kh8H7fWg0rFecEEIYmIsXL5YqF6mqWeyQkBDmzJlDREQEDg4OVXIMIfRBpVJha2vLuHHjGDduHDdu3GD79u2EhYXRo0cPmjVrhlqtRq1W4+np+cDAbW1tjbW1Ne7u7uTk5JCWlsaff/7JmTNnSi3vrtVqiYmJwczMDA8Pj0qZAa5MV69e5dSpU7Rr1w4nJ6f7bmNkZIStrS22tra0bt1a6VSSnJzMmTNnHtqp5H7Cw8MJCgrihx9+oG/fvpX5kB7LxYsXeeutt9i7d2+1lPPcGYp1AfvUqVP4+voSFBTE8ePHlRNSe/XqRX5+Pp9++ikeHh40b94cOzs7fvrpJzp16qTc/36kJtsQ6prLIjXZorYxqJrs/Tx8JrtXtdRkf//99wQEBLB582YGDRr0yMcSoqbKzs5m165dhIaGsnv3bho3bqzMcHt7e5e7/jo3N1dZ3j0nJweVSkWDBg3w9PQ0uBps3SqT7du3p0mTJhXaR15entIa8ObNmzRs2FCp465fv/5977N9+3YCAgL49ttvH/lckaq2detWhgwZUiqslpSUoFKpMDIyorCwsFI/KF2+fLnUCp8JCQl4eXkRFBTE4sWLUavVdO/enSlTppS63/Hjx2nevDmmpqY0btz4gQEbZCZbCCH06rvvviMgIIDvv/9eAraoc6ysrHj11Vd59dVXycvLY8+ePYSGhqJWq7GysmLw4MGo1WqefvrpB4YZS0tLnnjiCRwdHYmKisLCwgKAw4cP06hRIyWA6jtwp6enc/r06cdeZbJ+/fq4uroqnUp0i9+cP38eS0tLpY5b13t89+7djB8/nnXr1hlcwIbbs8WnT58udd24ceNo27Yt06dPr9SAffbsWTp16kRiYiKurq4YGRnx2Wef8fbbbzN//nzgdqvJ2NhY4H8z3UVFRTz11FPKfrRa7UPHJSFbCCEqSU5ODufPn1cuJyUlERcXh62tLS1atGDGjBlcvnyZb775BrhdIjJmzBiWL1/O3/72N1JTUwGwsLD4/9l2IeqO+vXr8+KLL/Liiy9SUFDA3r17CQ0N5dVXX8XMzAw/Pz/UajW+vr73rUfWLUXerFkz3N3dUalUFBQUKDO+iYmJyoyvo6OjEsSriy5gd+rUqVJLwszMzGjevDnNmzdXFvvJyMggKiqKiIgI0tLS2LdvH6tWreLll1+utONWJisrq3tWmbS0tMTOzq7SV590dnbm0KFDuLm5kZ+fj4WFBUuXLsXMzEwpI3F3d+fs2bPA7Tr5zz77jH379hEaGqq89srT9UUWoxFCiEoSFRWFl5eX0uN6ypQpeHl5Ke34UlJSuHDhgrL9qlWrKC4uJjAwECcnJ+Xnrbfe0sv4hTAU5ubm+Pn5sW7dOlJTU1m3bh1arZaxY8fi7u7Om2++yd69e7l16xYAly5dIjo6GldXV1q1aqUEIHNzc1q0aIG3tzfdu3enadOmXL9+nV9++YWjR4+SlJREbm5ulT+etLQ04uPj8fDwqNJzLnSL/Xh4ePDcc8/h5ubGuXPnMDEx4e233yY0NLTKjl1TWFlZ4ePjQ25uLp06dWL58uVKTbuugrpdu3ZcuXIFgNWrVzNlyhRGjhz5yCebyky2EEJUkh49ejxwpbp169aVuhwZGVm1AxKiFjA1NaVfv37069ePlStXcvDgQbZs2cIbb7xBfn4+zzzzDIcOHWL79u24uro+cD93zvhmZGQoJ05aWFjg6OiIg4MDDRo0qNTe1KmpqUqJgr29faXt92GOHj3KggULWLJkCQEBARw5cqRUHbKhq4r3R13/a7j9ehgyZAjTpk3D1NSUN954Q7nNzMyMW7dusXbtWiZOnMj333/P0KFDS92/POTER0M4ebAscuKjqG3q0ImPQoiqVVJSwty5c5k/fz6tW7fm0qVL9O/fH7VaTZ8+fco8AfBuxcXFXL16VVmB0czMTAncDRs2fKzAnZKSwrlz5/Dw8CjXMtyV5fjx4/j7+zN//nwCAwOrZEGbmqa4uBgTExMKCgo4f/487dq1Q6PR8MknnzBz5kyWLVvG5MmTAThw4IDS3nDjxo2MGDGizDZ9DyLlIkIIIYSocYyMjEhKSiIiIoLTp0/z448/4uzszKxZs3B1dWXUqFFs2bKF7OzsB+7HxMSEJk2a4OHhQY8ePWjdujWFhYXExMRw+PBhEhISyMzMfOC3VPdz5coVzp07h6enZ7UG7JiYGIYMGcLs2bMlYP+/kpISTExMyM3NpUePHnz99dckJCRQr149Jk+ezOLFiwkODmbJkiUAPPvss3Tr1o0NGzYoAbsiZCbbEGaDyyIz2aK2kZlsIUQV02g0xMbGsmXLFsLCwrhw4QK9e/dGrVYzcODAcs9OazQarl+/rizvrlKplC4lNjY2DywbuHz5MgkJCXTu3LlaV3A9deoUAwcOZNq0aUyfPl0C9h2Kioro0qULbm5ufPzxx7Rs2bLUAkVLly5lxowZTJs2jblz5yrX62JyRZ5LCdmGEFTLIiFb1DYSsoUQ1Uir1RIfH8/mzZsJDw8nMTGR559/Hn9/fwYNGoStrW25A7dueff09HS0Wm2p5d3vDNyXLl0iMTGx2gP22bNnGTBgAEFBQbz//vt6DdgrV65k5cqVJCcnA9ChQwc++OADBgwYoLcxzZs3jx07dnD06FEArl+/TmRkJDdv3uT555+nRYsWfPrpp7zzzjvExsbSqVOnR6q/vh8J2WAYYbUsDwvaVcVQnhMJ8TVfZQTrO0nIFkJUgFar5bfffiM0NJSwsDDi4+N59tlnUavV+Pn5YW9vX65gqtVqycrKUgJ3cXGxsrx7QUEBf/zxB15eXtjY2FTDo7otISGBAQMGMH78eObNm6f3Gezt27djbGxMq1at0Gq1rF+/no8//pjY2Fg6dOiglzH961//Yv/+/axbt45t27Zx4MABduzYQZs2bTAyMmLXrl1YWVmRnJxM69atK+WYtSNk/5YOVuX8T/C3Byw9aijBsiz6CtxgmM+NBPDbKjvEGjoJ2aIOWrhwIWFhYfz2229YWFjg4+PD4sWLadOmjb6HViNptVr++OMPJXDHxMTQrVs31Go1gwcPxsnJqdyB++bNm6Snp3P58mWKioqwsbGhWbNm2NvblypHqCrnz59nwIABjBgxgsWLFz/27GtVsbW15eOPP2b8+PF6Of53333HjBkzMDU1RavVMn78eNRqNWfOnGHOnDns3r27VPeVipzoeLe618KvbeHtP+8XtnX9zg0xUAK0/f8/9RG27+wFbyjPT10Ll7VNRdcXuAUcqcyBCGH4Dhw4QGBgIF27dqW4uJiZM2fSt29fzp49i6Xlgz4sivvRLTgyffp0pk2bxoULF5TAPW3aNJ566in8/f3x9/fH2dm5zLClUqmwtrbmxo0baDQaOnbsSF5eHsnJyZw5cwY7OzscHR2xt7d/5B7L5ZGcnMwLL7zASy+9ZLABu6SkhM2bN5Obm0u3bt30No7hw4fTtGlTrly5Qs+ePbG1tcXU1JSkpCRUKhX5+fmltq+MbwPq3kz23R40s61v5Qmz+pzdrg6GEujF46usRbtu3YSvZSZb1G0ZGRk4ODhw4MABunfvru/h1BparZYrV64QFhZGaGgov/zyC507d0atVuPv70/Lli3vCV/JyckkJSXRpUuXUiu15ubmKqtNZmdnY2NjowRu3eInj+PixYv069eP/v37s2LFCoML2KdPn6Zbt24UFBTQoEEDQkJCGDhwoF7Gcr/+1levXuX06dO89NJLTJ06lZkzZ1b6cSVk6xhy2Ab9hk1DDfISwP+ncledNWwSsoXg/PnztGrVitOnT1f6stPiNq1WS1paGlu3biU0NJQDBw7Qvn17/P39UavVtG7dmt27d1O/fn26dOnywPeJ/Px8JXBnZWVhbW2t9OI2Nzd/5LGlpKTQr18/nnvuOVatWoWxsfHjPNQqcevWLS5cuEBWVhZbtmxh9erVynOoT1qtloyMDGbOnMmRI0d4+eWXmTNnjnJbZdaz14qQ3TLrKEYNG5T7fn9ccS/7RkMP26D/cGmooVvUTG0fvkkpBTdhuoRsUXdpNBoGDx7MjRs3OHz4sL6HUydotVquX7/O1q1bCQsLY9++fbi6upKSksKmTZt45plnyj2TXFhYqATuzMxMrKyslMBdngV0UlNTGTBgAH/7299Yu3atQQbs++nduzdubm58+eWX+h4KAL/++iuZmZkMGjQIuP9s9+OqezXZgFvT80AZYVtXs20Iygr8+q6PftRQVFES5muf6nrtCFGLBQYGEh8fLwG7GqlUKuzs7Bg/fjwBAQHMmDGDFStW4OPjw5AhQ3B2dsbf358hQ4bg4eHxwLBmZmaGs7Mzzs7O3Lp1S1ne/fz581haWpZa3v1uGRkZ+Pn54eXlxZo1a2pMwIbbIbawsPIzVklJyT3Pw/2uu5uPj0+py1XRkaVOhmwdXdiGh8xu68uDTtLUqepvCfU5a/6gQCYB/P4kxApRq02aNIkdO3Zw8OBBmjdvru/h1Em6wH3kyBE6dOjAzZs32blzJ2FhYfTt2xd7e3ulpMTb2/uBgdvU1JRmzZrRrFkzioqKuHr1KmlpaSQlJWFhYaEsfmNlZUVmZiZ+fn60adOGDRs2VEvnkoqaMWMGAwYMoEWLFmRnZxMSEkJkZCQ//vhjpR5Ho9EoYfro0aPk5+fz7LPPPvS50S2xDhAXF0fnzp2rJGTXinKR57O+w6Thw79iAfgDtwffbohh+06GUM6i73IVUbdVWrnIJ4DFA7bMB96RchFhELRaLUFBQYSHhxMZGUmrVq30PSRxH7m5uezZs4fQ0FB27tyJtbU1gwcPxt/fn6effrrcM8/FxcVcu3aNtLQ0EhMTmTFjBtbW1tja2rJv374K1XFXp/Hjx7N//35SUlKwtrbGw8OD6dOn06dPn0rZ/xtvvME777yDu/vtzDZq1Cj27dtHcXExtra2rF+/nqeffvq+wfnOWe6XX34Ze3t7li1bVikno97NcD8GVRE3/nho0DZobQv1H7Q7IkFbVK5H+UYmt8pGIYTBCgwMJCQkhIiICKysrEhNTQXA2toaC4sHfVgU1cnS0pKXXnqJl156ifz8fPbu3UtoaCivvvoq5ubm+Pn5oVar8fX1feBsq4mJCY6OjsqPu7s7Fy5c4MyZM7Rr146EhARMTU2r8ZE9mq+//rrK9n3t2jXCwsI4duwYoaGhHD9+nPj4eHbs2IGxsTHz5s3Dz8+PjRs30q9fv1JB+86A/dprr3Hq1Cn27t1bJQEbwLD6vQghhBDiHitXriQrK4sePXrg5OSk/Pzwww/VNoZFixahUqkIDg6utmPWZBYWFgwePJj169eTmprKmjVrKCkpYfTo0bi7uxMYGMi+ffu4detWmfvIycnhtddew8TEhLNnz5KWlsamTZsMOmBXNTs7O06dOoWRkRFDhw7l4sWLjB8/Hm9vb7y8vAgNDaVv374MGzaMXbt2odFogNIBe9y4cRw7dow9e/bg4uJSZWOVkC2EEEIYOK1We9+fsWPHVsvxT5w4wZdffomHh0e1HK+2MTU1pX///qxevZqUlBS+++47zMzMmDhxIk888QQTJ05k9+7dFBQUKPfJy8tj6NChGBsbExERgYWFBaampnTt2lWPj0S/dBXOjo6O7NmzB1NTU6ZNm0ZycnKp20NCQhgyZAgjRozghx9+KBWwX3/9dQ4dOsSOHTt44oknqnS8ErKFEEIIUaacnBxGjhzJV199hY2Njb6HU+OZmJjQq1cvvvjiCy5dukR4eDg2NjYEBwfTsmVLAgIC2LJlC6+88gpFRUVs3779vp1G6hqNRqOUfqSlpdG4cWN27txJnz592LRpEydPnixVGrJ27Vr69u3L/v37lYD93nvvsXfvXrZt20br1q2rfMwSsoUQQghRpsDAQAYNGkTv3r31PZRax9jYmOeee47PPvuMv/76i927d9OsWTPefvttTp48ya5du+TEa0r3sF6yZAkzZ87k2LFj2NjYsGnTJtzc3FCr1cTFxZW63+bNm1m9erVyuU2bNuzZs6faFsSRkC2EEEKI+/r++++JiYlh4cKF+h5KrWdkZISPjw+ffPIJKSkpnDx5kkaNGul1TAsXLqRr165YWVnh4OCAWq0mISGh2sehC9izZ89m0aJF9O/fnyZNmgC3T/7dvn077u7u+Pv7ExMTc8/9S0pKABg9ejRt21Zfr1sJ2UIIIYS4x8WLF3nrrbf49ttvDb5lXG1jampqEH3QDxw4QGBgIEePHmXv3r0UFRXRt29fcnOrv83TkSNH2LhxI5s2bWLo0KHKCYtarRYrKysiIiLo0KED3t7eJCYmlrqvvhbtqXMt/IQQQgjxcNHR0aSnp9OlSxflupKSEg4ePMjnn39OYWFhjVpxUDy6PXv2lLq8bt06HBwciI6Opnv37lV6bK1WW6rG+sqVK8Dtko+7tyksLKR+/fpEREQwd+7caqm3Lg8J2UIIIYS4R69evTh9+nSp68aNG0fbtm2ZPn26BOw6KCsrCwBbW9sq2f+dtde6gP3777/TqlUrSkpKKCkpUTqI3Hki5M6dO6lfvz79+/fno48+Asq3tHpVk3IRIYQQQtzDysqKjh07lvqxtLTEzs6Ojh0fZQUpURtoNBqCg4Px9fWtst+/kZERUVFR/Oc//wFg2bJl/P3vfyc7O5vu3buTlZXFhx9+qGyrUqkoKChg3bp1REdHl9qXvgM2yEy2EEIIIYR4iMDAQOLj4zl8+HCVHUOj0XDo0CHeeecdDh06xKZNm9i1axdWVlZYWVnxzTffMGrUKK5du8aYMWNQqVSsWrWKpKQkQkNDq2xcFSUz2UIIIYQol8jISJYtW1alx7h8+TKjRo3Czs4OCwsLOnXqRFRUVJUeUzzYpEmT2LFjBz///HOVnpBpZGTE22+/zZAhQ9i0aRNjxoyhf//+SomIn58fP/30E3/++SdTp07lvffeQ6VSERUVRb169ZQuIoZCZrKFEEIIYRAyMzPx9fWlZ8+e7N69G3t7e37//XdZBEdPtFotQUFBhIeHExkZScuWLavlmM7OzowaNYoNGzbg6urK7NmzASguLubJJ5/k+PHjZGZmUlRUhJOTEyYmJhQXF2NiYlix1rBGI4QQQog6a/HixTg7O7N27VrluuoIduL+AgMDCQkJISIiAisrK1JTU4HbvaktLCyq5JgqlYply5ah0Wjw8fFh0qRJFBUVMW/ePCVEx8bG8vTTTyv30Wg0BhewQc/lIgcPHsTPz4+mTZuiUqnYunWrPocjhBCP5VHf01JSUhgxYgStW7fGyMiI4ODgahmnEIZq27ZteHt7M3ToUBwcHPDy8uKrr77S97DqrJUrV5KVlUWPHj1wcnJSfn744YdKO4ZGowHgt99+4+effyYiIgK4XToSEBDAF198wccff8zUqVO5du0a//jHP/jnP/9Jfn6+sg9dRxJDo9fYn5ubi6enJwEBAbz44ov6HIoQQjy2R31PKywsxN7enlmzZvHpp59WwwiFMGx//vknK1euZMqUKcycOZMTJ04wefJkTE1NGTNmjL6HV+foaqGriq5l33//+1/eeOMN6tWrR0FBAQsXLmTTpk20aNGCsWPHYmlpyZgxY9i1axc5OTn88ssvWFhY3NNL29DoNWQPGDCAAQMG6HMIQghRaR71Pc3V1ZXly5cDsGbNmqoalhA1hkajwdvbmwULFgDg5eVFfHw8X3zxhYTsWsjIyIhjx44xbNgw5syZw4QJEzh16hR/+9vfeOmll/jmm29o164dw4cPp1u3bpw6dQpfX1/s7OwMsgb7boY9ursUFhZSWFioXNY1RS++mfdI+9GQU/aN2TcrNLZqlWum7xFAgb4HIGqVR1mhN+/2v9HHn2F52Iv49u03b5Z+TzAzM8PMzAD+DQpRCzk5OdG+fftS17Vr184g27OJx5eXl8fmzZv5xz/+QVBQEBkZGYwYMYKRI0eSmJjISy+9xKZNm+jYsSOurq64uroChluDfTfDH+EdFi5cyJw5c+65/qDzeD2MRgihT9nZ2VhbWz/y/UxNTWnSpAmpqe89dNsGDRrg7Oxc6rrZs2criyEIISqXr68vCQkJpa5LTEzExcVFTyMSVal+/fr4+vrSokUL8vPzGTJkCD4+Pqxfv56ffvqJ3r17079/f/bs2VNqARxDrcG+W40K2TNmzGDKlCnK5Rs3buDi4sKFCxcq9J9tXXDz5k2cnZ25ePEiDRs21PdwDI48Pw9naM+RVqslOzubpk2bVuj+5ubmJCUlcevWrXId6+56P5nFFqLqvP322/j4+LBgwQJeeeUVjh8/zqpVq1i1apW+hyYqwZ3LpusMGTIEuN2DvaCggGnTpgG332v9/f3RarU19n23RoXssr6mtba2Noj//A1Zw4YN5Tl6AHl+Hs6QnqPH/VBtbm6Oubl5JY1GCFFZunbtSnh4ODNmzOCjjz6iZcuWLFu2jJEjR+p7aDXawYMH+fjjj4mOjiYlJYXw8HDUanW1HDs/Px8LCwuKioqoV68ely5d4pdffsHa2pomTZrQuXNnAJKSkkhMTKRJkybKmBs0aMCaNWuUhWYMYan0R1Ez5tuFEEIIUSe88MILnD59moKCAs6dO8frr79e5ccsKSnh/fffp2XLllhYWODm5sbcuXOrvLtGddF1PvrPf/5Trcc9evQo06ZNIyEhgXr16pGQkEDnzp358MMPGTduHGq1msWLFwMwfPhwmjRpQqdOnejduzdz584lMDCQevXqAdS4gA16nsnOycnh/PnzyuWkpCTi4uKwtbWlRYsWehyZEEI8uoe9p82YMYPLly/zzTffKNvExcUp983IyCAuLg5TU9N7Tv4SQlSdxYsXs3LlStavX0+HDh2Iiopi3LhxWFtbM3nyZH0P77Hpq5vb0aNH+fHHHwF4/fXX+eSTT3jttdeYM2cOycnJ/Pjjj8ycOZO8vDzmzJnDgQMH+Pjjj7G0tGTRokV4e3vft8SkptBryI6KiqJnz57KZV299ZgxY1i3bt1D729mZsbs2bNrbK1OdZDn6MHk+Xk4eY7K72HvaSkpKVy4cKHUfby8vJS/R0dHExISgouLC8nJydUyZiHuVpNDTUX9+uuv+Pv7M2jQIOB2e83vvvuO48eP63lkNVtwcDDm5uZ89dVXGBsbk5aWxptvvknDhg3x8PDAzc0Nc3NzFi5cyPPPP89zzz3H0qVLlfNhavprUaWtLd+FCCGEEKLCMjIysLW1vedr+bJqYWt6ALrTggULWLVqFf/9739p3bo1J0+epG/fvixdurTW1YOrVKpqqcm+8/WxYsUKVq5cyblz5wgPD8fPz0/Z7sKFC/Tq1Ytp06ZVS2lQdaod/zqEEEII8VhWr15N586dSUlJKXX9nQE7JyeHtLQ0oOa0USuPf/7znwwbNoy2bdtSr149vLy8CA4OrnUBuzoZGRkpS6a/+eabzJw5E1dXVz7//HOio6OV7Vq0aEGTJk24evWqvoZaZWrPvxAhhBBCVFhQUBBXrlwhNjYWuN2LftasWUpNrVarZfv27fj7++Pl5cVHH33E9evX9TnkSrNp0ya+/fZbQkJCiImJYf369SxZsoT169fre2g12p1Be/jw4cyZM4erV68yd+5c9u3bR3JyMuvXr+fIkSP4+PjoebSVr0a18BNCCCFE1bCwsMDX15ddu3bh5ubGyJEjuX79Oh07dlRqZK2trQkKCuLrr79m9erV+Pr60qtXL30P/bG9++67ymw2QKdOnfjrr79YuHChLOf+mHRB28jIiJEjR2JsbMxHH33ECy+8QOfOnXFycmLjxo0899xz+h5qpZOQLYQQQtRxuh7GQ4cOZcKECZw5c4ZGjRrx448/Ymdnp2w3cOBAALZs2ULPnj3x9PQE7r9wU02Sl5d3T/mLsbGxMgtb01VXN7c7Xwd3/t3IyEi5PGzYMKysrAgODsbZ2ZkFCxbQqlWre+5TG9TIcpGFCxfStWtXrKyscHBwQK1W37MMq/ifRYsWoVKpCA4O1vdQDMrly5cZNWoUdnZ2WFhY0KlTJ6KiovQ9LINQ23vGCiH+p6SkhHr16pGSksKWLVsoLCykb9++7NixAzs7O0pKSgCUwHnu3DkuXLhA+/btady4MUCpYKTb/m6G/P7h5+fH/Pnz2blzJ8nJyYSHh7N06VJlNcKaLioqCi8vL6Wb0ZQpU/Dy8uKDDz6o1OPc+TpQqVSlXgsqlUp5DQwaNIi5c+fy+uuvKwH77vvXBjVyJvvAgQMEBgbStWtXiouLmTlzJn379uXs2bNYWlrqe3gG5cSJE3z55Zd4eHjoeygGJTMzE19fX3r27Mnu3buxt7fn999/x8bGRt9DMwi1vWesEOJ/jI2NOXLkCOPGjcPBwYFOnTphbW2trIqqO/FRF5D27t2LqakpTz75JHBvl5GHLRqyaNEisrKy+Oc///nYq7dWln//+9+8//77vPnmm6Snp9O0aVMmTpxY6SFUX3r06FFtH3K++OIL9u3bx5YtW+55LeiCtm5Gu7arkSF7z549pS6vW7cOBwcHoqOj6d69u55GZXhycnIYOXIkX331FfPmzdP3cAzK4sWLcXZ2Zu3atcp1LVu21OOIDIv0jBWibiguLiYoKIjdu3fTo0cPVq9ezfLly1mxYgVvvvlmqQCtC0wHDhzAxcXlnsmbnJwc3n//fQYPHlyqX7yOSqUiOzubqKgosrOzadiw4T3baDQaVCpVtc9oWllZsWzZMpYtW1atx62JHlTSUVhYSElJCQcPHiQqKgpvb+97tqlts9UPUiPLRe6WlZUFgK2trZ5HYlgCAwMZNGgQvXv31vdQDM62bdvw9vZm6NChODg44OXlxVdffaXvYRkMHx8f9u/fT2JiIgAnT57k8OHDelkxTAhRdVQqFR06dOCTTz7h66+/xsTEBE9PT3Jzc4mPj1cCtm4W9Pfff+evv/6iU6dOODg4AP9r5ZeSksLy5cu5cuXKPcfRlZrExsaSlpZGr169UKlUZGRkEBYWxv79+5V91aUQVtPcGbBXr17N1KlTef3119mzZw9FRUWYmZkxZswYjh8/fk/ALquMqDarkTPZd9JoNAQHB+Pr60vHjh31PRyD8f333xMTE8OJEyf0PRSD9Oeff7Jy5UqmTJnCzJkzOXHiBJMnT8bU1FTOJOd2z9ibN2/Stm1bjI2NKSkpYf78+dIzVohaxtjYmEmTJimXtVotvXv3pri4mLCwMOX/1YKCAiwsLNi/fz8mJiZKgLpzpvuJJ55g7969+Pr63nMcXTA7cuQIJSUlPPvsswCsX7+e8PBwsrKyuHjxImq1mjlz5uDq6lqVD1tUkO73OHnyZLZt20avXr04duwYsbGxGBsb06dPHxo0aECDBg2U+8TExNClSxeMjY1r3YmND1PjQ3ZgYCDx8fEcPnxY30MxGBcvXuStt95i7969Sk2dKE2j0eDt7c2CBQuA20tbx8fH88UXX0jIpnTP2A4dOhAXF0dwcDBNmzaV50eIWkwXgOLj40vNSD/55JO88MILREVF4ezsrJxAd3ctdlnt/FQqFXl5eZw8eRInJyeeeuopAEaPHk2/fv1o1qwZycnJTJkyhRUrVrBo0aJatdhNbbJ8+XK2b9/Orl27aN++PXD7289169bRp0+fUtumpaUxbNgwGjduzK+//lqnAjbU8JA9adIkduzYwcGDB2nevLm+h2MwoqOjSU9Pp0uXLsp1uhqpzz//nMLCwoeemFLbOTk5KW8OOu3atSM0NFRPIzIs0jNWiLrN2toaa2trNBoNWq2WcePGsW3bNiUoNWvWjBEjRihh+UFLrOtui42N5eLFiwwYMEBpj+fg4KCUndja2jJp0iSGDx/OW2+9RbNmzart8YrySUtLIyoqirfeeov27dtTWFiImZkZEydOZM2aNfdsb21tzaxZs2rlao7lUSNDtlarJSgoiPDwcCIjI+WEtbv06tWL06dPl7pu3LhxtG3blunTp9f5gA3g6+t7T9vHxMREXFxc9DQiw1Lbe8YKIcpH9z7w7rvv8u6771JQUMCmTZv47LPPyM/P56mnnkKj0fDtt9+yf/9+vvrqK+rVq1dqH3eWihQXF9+z6EhxcTEmJrfjSP369bGwsDDodn91WcOGDXF1dVVKgszMzIDbv7fk5GTy8vKwsLBApVKh0WgwNzdn+PDhymtCykVqgMDAQEJCQoiIiMDKyorU1FTg9icmCwsLPY9O/6ysrO6pT7e0tMTOzk7q1v/f22+/jY+PDwsWLOCVV17h+PHjrFq1ilWrVul7aAZB1zO2RYsWdOjQgdjYWJYuXUpAQIC+hyaE0CNzc3NGjx7N6NGjlesKCwvZvHkz6enp9wRsuB2yCwoKiIuLo0mTJnTt2hW4HeDvDNjbtm1j6tSpDB8+XL6dNjAlJSUYGxtjYWHB7Nmzld+ZLjTb2Ngov3uVSsWlS5dYs2YNU6ZMKVWfXZcCNtTQ7iIrV64kKyuLHj164OTkpPz88MMP+h6aqCG6du1KeHg43333HR07dmTu3LksW7ZMTuz7f//+9795+eWXefPNN2nXrh1Tp05l4sSJzJ07V99DE0IYGAsLC7Zt20ZYWNg9t+m+/Tp16hSXLl2iS5cumJqaKrebmJhw5swZJkyYwJgxYxg0aBCLFy+utrGL8tF9A75lyxaKioruuV03yVm/fn0uX77Mk08+SXp6eqmAXReptPKdjBBCCCGqgG6mc/78+YSFhbF06VKlXOTMmTN88sknREZG0q5dO2bNmkW3bt30PGJRlsOHD9O9e3f++usvnJ2dS932008/8Y9//IPt27czaNAgnnzySWXis66ViNypRs5kCyGEEMLw6cKVk5MTbdq0UVr/BQYG0r9/fwBCQkLYuXMn3bp1q5O9lA3V3XOw9vb2ODk5cevWrXu2NTMzIy0tDV9fXzp16qQE7JKSkjobsEFCthBCCCGqWEBAACEhIVhaWpKamsqqVau4fPkyGo2GnJwcJVzLifmGQxeOc3NzAWjTpg1NmzYlMjJS2UZXOmJubk52djZqtZrw8HDgf3XcdZmEbCGEEEJUC61WS5MmTSgqKuLIkSPk5eXx8ssvY2lpyYQJE+psqzdD9cEHH9CvXz9efPFFJk+eTG5uLsnJyWRmZgIoJzt27tyZNWvWsHr1akACto7UZAshhBBCrw4dOsTx48d58cUXpS2vAdmwYQMFBQXs37+fevXqERYWRn5+Pj179iQpKQkPDw8aNGjA3Llzld+bBOz/kZAthBBCCCEe6j//+Q9Llizh888/59y5c2RmZnL58mXWrVun76EZpBrZJ1sIIYQQQlS9O+diXV1dMTMzo1+/fgwaNKjUdg9a9bOukmdDCCGEEELcl0qlUn58fX25efMmv/766z3dRyRg30ueESGEEEII8VDGxsbk5eWRkpJSp1vzlZeEbFFrjR07FrVare9hCCGEELWClZUV//rXv3jllVf0PZQaQUK2MDgpKSmMGDGC1q1bY2RkRHBwcKXsd+HChXTt2hUrKyscHBxQq9UkJCRUyr6FEEKIumDChAmoVCqKi4v1PRSDJyFbGJzCwkLs7e2ZNWsWnp6elbbfAwcOEBgYyNGjR9m7dy9FRUX07dtXabQvhBBCiPIxMZHeGQ8jIVtUq4yMDJo0acKCBQuU63799VdMTU3Zv38/cPvs5eXLlzN69Gisra0r7dh79uxh7NixdOjQAU9PT9atW8eFCxeIjo6utGMIIYQQQoCEbFHN7O3tWbNmDR9++CFRUVFkZ2fz2muvMWnSJHr16lXu/URGRqJSqUhOTq7wWLKysgCwtbWt8D6EEEIIIe5H5vpFtRs4cCCvv/46I0eOxNvbG0tLSxYuXPhI+6hfvz5t2rRRlnR9VBqNhuDgYHx9fenYsWOF9iGEEEIIURYJ2UIvlixZQseOHdm8eTPR0dGYmZk90v2feuopfvvttwofPzAwkPj4eA4fPlzhfQghhBBClEXKRYRe/PHHH1y5cgWNRvNYJR8VMWnSJHbs2MHPP/9M8+bNq/XYQgghhKgbZCZbVLtbt24xatQoXn31Vdq0acPf//53Tp8+jYODQ5UeV6vVEhQURHh4OJGRkbRs2bJKjyeEEEKIuktmskW1e++998jKyuKzzz5j+vTptG7dmoCAgFLbxMXFERcXR05ODhkZGcTFxXH27Fnl9uPHj9O2bVsuX75c7uMGBgayceNGQkJCsLKyIjU1ldTUVPLz8yvtsQkhhBBCAKi0dy8+L0QVioyMpE+fPvz8888888wzACQnJ+Pp6cmiRYt44403AO67XKuLi4tSWhIZGUnPnj1JSkrC1dX1vscaO3YsN27cYOvWrWXuE2Dt2rWMHTv2sR6XEEIIIcSdJGQLIYQQQghRyaRcRAghhBBCiEomIVsIIYQQQohKJiFbCCGEEEKISiYhWwghhBBCiEomIVsIIYQQQohKJiFbCCGEEEKISiYhWwghhBBCiEomIVsIIYQQQohKJiFbCCGEEEKISiYhWwghhBBCiEomIVsIIYQQQohK9n/gamrSVWrDCwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 900x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#| echo: true\n",
        "#| label: fig-contour\n",
        "threshold = 0.025\n",
        "impo = spot_tuner.print_importance(threshold=threshold, print_screen=True)\n",
        "var_plots = [i for i, x in enumerate(impo) if x[1] > threshold]\n",
        "min_z = min(spot_tuner.y)\n",
        "max_z = max(spot_tuner.y)\n",
        "n = spot_tuner.k\n",
        "for i in var_plots:\n",
        "    for j in var_plots:\n",
        "        if j > i:\n",
        "            filename = \"./figures\" + experiment_name+\"_contour_\"+str(i)+\"_\"+str(j)+\".pdf\"\n",
        "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z, filename=filename)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Contour plot. Learning rate versus number of neurons in layer `l1`.](./figures/14-torch_bartz09_30min_10init_2023-05-14_14-45-25_contour_0_2.png){#fig-contour-0-2}\n",
        "\n",
        "![Contour plot. Batch size versus number of neurons in layer `l1`.](./figures/14-torch_bartz09_30min_10init_2023-05-14_14-45-25_contour_0_3.png){#fig-contour-0-3}\n",
        "\n",
        "![Contour plot. Batch size versus learning rate.](./figures/14-torch_bartz09_30min_10init_2023-05-14_14-45-25_contour_2_3.png){#fig-contour-2-3}\n",
        "\n",
        "@fig-contour-0-2 shows the contour plot of the loss as a function of the learning rate and the number of neurons in layer `l1`. The contour plot shows that the learning rate has a strong influence on the performance of the model. Too large values of the learning rate decrease the performance of the neural network. @fig-contour-0-3 and @fig-contour-2-3 indicate that the batch size should be increased. The batch size has a strong influence on the performance of the model. Too small values of the batch size decrease the performance of the neural network.\n",
        "\n",
        " `spotPython` provides additional tools for a visual inspection of the results and give valuable insights into the hyperparameter tuning process.\n",
        " This is especially useful for model explainability, transparency, and trustworthiness.\n",
        "In addition to the contour plots, @fig-parallel shows the parallel plot of the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "dimensions": [
                    {
                      "label": "l1",
                      "range": [
                        2,
                        9
                      ],
                      "values": [
                        6,
                        6,
                        8,
                        5,
                        8,
                        4,
                        3,
                        9,
                        7,
                        8,
                        5,
                        7,
                        2,
                        5,
                        6,
                        9,
                        4,
                        3,
                        2,
                        4,
                        9,
                        2,
                        2,
                        6,
                        2,
                        9,
                        9,
                        9,
                        9,
                        9,
                        2,
                        5,
                        9,
                        8,
                        7,
                        2,
                        9,
                        9,
                        6,
                        8,
                        9,
                        9,
                        9,
                        4,
                        8,
                        9,
                        6,
                        3,
                        2,
                        9,
                        9,
                        3,
                        5,
                        3,
                        9,
                        9,
                        3,
                        5,
                        3,
                        8,
                        2,
                        6,
                        5,
                        7,
                        6,
                        8,
                        6,
                        9,
                        2,
                        4,
                        9,
                        3,
                        9,
                        5,
                        2,
                        7,
                        4,
                        4,
                        2,
                        7,
                        6,
                        5,
                        3,
                        3,
                        7,
                        2,
                        7,
                        4,
                        5,
                        5,
                        4,
                        8,
                        3,
                        3,
                        3,
                        6,
                        7,
                        3,
                        6,
                        6,
                        3,
                        5,
                        5,
                        4,
                        6,
                        4,
                        3,
                        9,
                        5,
                        5,
                        6,
                        3,
                        6,
                        3,
                        6,
                        6,
                        9,
                        4,
                        6,
                        8,
                        6,
                        8,
                        5,
                        7,
                        4,
                        4,
                        6,
                        8,
                        5,
                        5,
                        5,
                        6,
                        3,
                        4,
                        4,
                        7,
                        5,
                        2,
                        7,
                        3,
                        7,
                        6,
                        7,
                        8,
                        5,
                        2,
                        7,
                        6,
                        4,
                        6,
                        8,
                        2,
                        3,
                        3,
                        5,
                        4,
                        9,
                        2,
                        6,
                        5,
                        4,
                        5,
                        9,
                        6,
                        3,
                        4,
                        3,
                        6,
                        8,
                        4,
                        4,
                        4,
                        8,
                        4,
                        8,
                        5,
                        4,
                        4,
                        6,
                        4,
                        7,
                        5,
                        4,
                        9,
                        5,
                        4,
                        7,
                        5,
                        8,
                        5,
                        5,
                        3,
                        4,
                        2,
                        2,
                        2,
                        8,
                        3,
                        4,
                        5,
                        7,
                        7,
                        6,
                        9,
                        5,
                        3,
                        7,
                        2,
                        5,
                        8,
                        6,
                        6,
                        7,
                        2,
                        9,
                        4,
                        7,
                        3,
                        5,
                        5,
                        3,
                        4,
                        4,
                        7,
                        7,
                        8,
                        6,
                        3,
                        4,
                        7,
                        3,
                        5,
                        8,
                        7,
                        7,
                        5,
                        6,
                        3,
                        6,
                        8,
                        2,
                        9,
                        4,
                        8,
                        6,
                        7,
                        3,
                        3,
                        7,
                        4,
                        2,
                        8,
                        6,
                        6,
                        7,
                        5,
                        5,
                        7,
                        3,
                        7,
                        9,
                        6,
                        6,
                        7,
                        7,
                        8,
                        9,
                        5,
                        9,
                        7,
                        6,
                        3,
                        8,
                        6,
                        6,
                        3,
                        4,
                        8,
                        4,
                        7,
                        8,
                        7,
                        3,
                        8,
                        8,
                        5,
                        7,
                        6,
                        8,
                        4,
                        9,
                        6,
                        4,
                        9,
                        2,
                        7,
                        2,
                        4,
                        8,
                        5,
                        5,
                        4,
                        8,
                        5,
                        5,
                        5,
                        5,
                        4,
                        9,
                        4,
                        6,
                        7,
                        4,
                        7,
                        7,
                        3,
                        2,
                        2,
                        8,
                        6,
                        9,
                        3,
                        5,
                        4,
                        5,
                        9,
                        3,
                        6,
                        6,
                        2,
                        8,
                        8,
                        6,
                        6,
                        6,
                        5,
                        3,
                        9,
                        3,
                        3,
                        3,
                        5,
                        3,
                        8,
                        5,
                        3,
                        5,
                        6,
                        6,
                        5,
                        4,
                        3,
                        9,
                        9,
                        3,
                        6,
                        7,
                        4,
                        3,
                        4,
                        8,
                        9,
                        5,
                        3,
                        5,
                        9
                      ]
                    },
                    {
                      "label": "l2",
                      "range": [
                        2,
                        9
                      ],
                      "values": [
                        2,
                        6,
                        4,
                        9,
                        8,
                        3,
                        8,
                        7,
                        6,
                        3,
                        3,
                        4,
                        8,
                        5,
                        6,
                        7,
                        5,
                        4,
                        8,
                        4,
                        2,
                        8,
                        8,
                        4,
                        5,
                        9,
                        6,
                        4,
                        3,
                        5,
                        5,
                        4,
                        9,
                        9,
                        3,
                        4,
                        5,
                        3,
                        4,
                        7,
                        2,
                        5,
                        5,
                        8,
                        5,
                        5,
                        4,
                        2,
                        2,
                        7,
                        8,
                        3,
                        5,
                        8,
                        8,
                        9,
                        2,
                        2,
                        5,
                        7,
                        3,
                        7,
                        8,
                        9,
                        7,
                        4,
                        8,
                        7,
                        3,
                        5,
                        7,
                        3,
                        8,
                        7,
                        7,
                        6,
                        5,
                        4,
                        5,
                        6,
                        6,
                        3,
                        7,
                        6,
                        6,
                        4,
                        5,
                        4,
                        9,
                        7,
                        4,
                        6,
                        9,
                        4,
                        4,
                        8,
                        7,
                        8,
                        7,
                        4,
                        6,
                        7,
                        6,
                        4,
                        6,
                        6,
                        3,
                        5,
                        3,
                        4,
                        7,
                        6,
                        6,
                        7,
                        8,
                        3,
                        7,
                        9,
                        6,
                        3,
                        3,
                        6,
                        4,
                        7,
                        4,
                        4,
                        6,
                        4,
                        3,
                        5,
                        7,
                        5,
                        6,
                        2,
                        3,
                        3,
                        5,
                        4,
                        5,
                        5,
                        8,
                        6,
                        8,
                        6,
                        6,
                        5,
                        6,
                        3,
                        3,
                        7,
                        3,
                        7,
                        3,
                        9,
                        7,
                        8,
                        3,
                        4,
                        3,
                        8,
                        7,
                        9,
                        7,
                        4,
                        4,
                        6,
                        8,
                        8,
                        6,
                        4,
                        3,
                        5,
                        9,
                        6,
                        7,
                        5,
                        6,
                        5,
                        8,
                        4,
                        6,
                        3,
                        4,
                        7,
                        4,
                        5,
                        9,
                        2,
                        5,
                        6,
                        6,
                        4,
                        3,
                        9,
                        8,
                        4,
                        3,
                        4,
                        3,
                        6,
                        3,
                        5,
                        6,
                        5,
                        7,
                        6,
                        7,
                        3,
                        6,
                        4,
                        6,
                        6,
                        6,
                        7,
                        7,
                        2,
                        3,
                        5,
                        6,
                        6,
                        8,
                        6,
                        6,
                        5,
                        5,
                        5,
                        5,
                        6,
                        5,
                        5,
                        9,
                        8,
                        4,
                        6,
                        7,
                        5,
                        5,
                        3,
                        6,
                        5,
                        3,
                        4,
                        4,
                        5,
                        3,
                        5,
                        6,
                        3,
                        3,
                        4,
                        5,
                        5,
                        6,
                        4,
                        6,
                        8,
                        5,
                        9,
                        2,
                        5,
                        3,
                        2,
                        7,
                        6,
                        6,
                        3,
                        5,
                        3,
                        2,
                        6,
                        7,
                        9,
                        4,
                        8,
                        3,
                        6,
                        4,
                        5,
                        6,
                        3,
                        2,
                        6,
                        8,
                        8,
                        7,
                        8,
                        7,
                        3,
                        3,
                        5,
                        6,
                        5,
                        4,
                        6,
                        6,
                        2,
                        4,
                        2,
                        8,
                        4,
                        5,
                        7,
                        8,
                        8,
                        2,
                        5,
                        9,
                        4,
                        3,
                        5,
                        5,
                        4,
                        6,
                        6,
                        3,
                        4,
                        5,
                        9,
                        5,
                        3,
                        6,
                        8,
                        9,
                        4,
                        4,
                        8,
                        8,
                        9,
                        8,
                        9,
                        6,
                        6,
                        2,
                        6,
                        3,
                        7,
                        6,
                        3,
                        6,
                        6,
                        7,
                        6,
                        8,
                        7,
                        5,
                        3,
                        2,
                        8,
                        9,
                        6,
                        6,
                        6,
                        4,
                        6,
                        4,
                        7,
                        5,
                        5,
                        4,
                        7,
                        7,
                        3,
                        6,
                        2,
                        7,
                        9
                      ]
                    },
                    {
                      "label": "batch_size",
                      "range": [
                        1,
                        5
                      ],
                      "values": [
                        4,
                        3,
                        3,
                        2,
                        3,
                        4,
                        4,
                        4,
                        4,
                        2,
                        3,
                        2,
                        2,
                        5,
                        1,
                        2,
                        1,
                        5,
                        3,
                        3,
                        5,
                        2,
                        1,
                        3,
                        4,
                        5,
                        4,
                        5,
                        5,
                        5,
                        5,
                        4,
                        2,
                        5,
                        3,
                        3,
                        3,
                        5,
                        4,
                        2,
                        5,
                        3,
                        5,
                        2,
                        4,
                        4,
                        3,
                        2,
                        4,
                        4,
                        4,
                        1,
                        5,
                        1,
                        3,
                        4,
                        1,
                        4,
                        3,
                        3,
                        2,
                        4,
                        4,
                        3,
                        4,
                        2,
                        3,
                        4,
                        5,
                        5,
                        5,
                        4,
                        2,
                        5,
                        5,
                        5,
                        5,
                        5,
                        3,
                        2,
                        5,
                        3,
                        2,
                        1,
                        1,
                        4,
                        2,
                        3,
                        3,
                        3,
                        3,
                        5,
                        1,
                        4,
                        2,
                        5,
                        5,
                        1,
                        1,
                        2,
                        2,
                        3,
                        1,
                        1,
                        4,
                        3,
                        5,
                        1,
                        4,
                        3,
                        4,
                        4,
                        4,
                        1,
                        4,
                        1,
                        2,
                        4,
                        4,
                        3,
                        2,
                        4,
                        5,
                        2,
                        3,
                        5,
                        5,
                        5,
                        4,
                        2,
                        4,
                        2,
                        2,
                        1,
                        3,
                        2,
                        2,
                        2,
                        1,
                        1,
                        5,
                        4,
                        2,
                        1,
                        2,
                        1,
                        4,
                        3,
                        3,
                        2,
                        2,
                        3,
                        5,
                        4,
                        3,
                        4,
                        5,
                        2,
                        4,
                        2,
                        3,
                        3,
                        1,
                        5,
                        5,
                        1,
                        4,
                        4,
                        2,
                        2,
                        4,
                        2,
                        1,
                        4,
                        4,
                        3,
                        5,
                        3,
                        4,
                        1,
                        2,
                        3,
                        3,
                        4,
                        2,
                        2,
                        1,
                        2,
                        2,
                        3,
                        2,
                        2,
                        4,
                        1,
                        1,
                        1,
                        4,
                        4,
                        3,
                        4,
                        1,
                        3,
                        2,
                        2,
                        3,
                        2,
                        4,
                        2,
                        4,
                        4,
                        4,
                        5,
                        4,
                        1,
                        2,
                        3,
                        1,
                        2,
                        3,
                        4,
                        4,
                        1,
                        2,
                        5,
                        2,
                        3,
                        2,
                        3,
                        4,
                        2,
                        2,
                        4,
                        2,
                        2,
                        4,
                        3,
                        3,
                        1,
                        4,
                        4,
                        3,
                        5,
                        2,
                        5,
                        2,
                        3,
                        4,
                        5,
                        3,
                        4,
                        2,
                        4,
                        4,
                        5,
                        4,
                        4,
                        5,
                        2,
                        1,
                        2,
                        2,
                        2,
                        4,
                        2,
                        3,
                        2,
                        3,
                        2,
                        3,
                        1,
                        2,
                        3,
                        1,
                        2,
                        3,
                        3,
                        3,
                        1,
                        5,
                        4,
                        4,
                        4,
                        2,
                        1,
                        1,
                        4,
                        5,
                        2,
                        1,
                        4,
                        5,
                        3,
                        2,
                        4,
                        2,
                        4,
                        3,
                        1,
                        4,
                        3,
                        1,
                        4,
                        5,
                        5,
                        2,
                        3,
                        2,
                        1,
                        3,
                        5,
                        4,
                        5,
                        4,
                        5,
                        3,
                        2,
                        1,
                        4,
                        3,
                        5,
                        2,
                        2,
                        2,
                        4,
                        3,
                        3,
                        1,
                        1,
                        1,
                        2,
                        3,
                        4,
                        5,
                        5,
                        5,
                        5,
                        4,
                        2,
                        5,
                        3,
                        4,
                        1,
                        2,
                        3,
                        2,
                        3,
                        4,
                        4,
                        4,
                        2,
                        4,
                        2,
                        5,
                        1,
                        3,
                        4,
                        4,
                        3,
                        4,
                        2,
                        3,
                        1,
                        3,
                        5,
                        1,
                        1
                      ]
                    },
                    {
                      "label": "epochs",
                      "range": [
                        3,
                        4
                      ],
                      "values": [
                        3,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        3,
                        3,
                        3,
                        4,
                        3,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        3,
                        4,
                        3,
                        4,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        3,
                        4,
                        4,
                        3,
                        4,
                        3,
                        4,
                        3,
                        4,
                        4,
                        3,
                        3,
                        4,
                        3,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        3,
                        3,
                        3,
                        4,
                        3,
                        4,
                        3,
                        4,
                        3,
                        4,
                        3,
                        4,
                        3,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        3,
                        4,
                        4,
                        3,
                        4,
                        4,
                        3,
                        3,
                        4,
                        3,
                        3,
                        4,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        3,
                        3,
                        4,
                        3,
                        4,
                        3,
                        3,
                        4,
                        3,
                        3,
                        4,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        3,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        4,
                        3,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        3,
                        4,
                        3,
                        4,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        4,
                        3,
                        4,
                        3,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        3,
                        4,
                        4,
                        3,
                        4,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        3,
                        4,
                        3,
                        4,
                        4,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        4,
                        3,
                        4,
                        3,
                        3,
                        3,
                        4,
                        3,
                        4,
                        3,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        4,
                        3,
                        3,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        3,
                        3,
                        3,
                        4,
                        3,
                        3,
                        3,
                        4,
                        4,
                        3,
                        4,
                        3,
                        3,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        4,
                        3,
                        4,
                        4,
                        4,
                        3,
                        4,
                        3,
                        4,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        3,
                        3,
                        4,
                        4
                      ]
                    },
                    {
                      "label": "optimizer",
                      "range": [
                        0,
                        9
                      ],
                      "values": [
                        5,
                        5,
                        1,
                        9,
                        7,
                        6,
                        5,
                        7,
                        4,
                        0,
                        2,
                        2,
                        8,
                        7,
                        4,
                        1,
                        2,
                        8,
                        4,
                        3,
                        2,
                        7,
                        6,
                        4,
                        7,
                        7,
                        4,
                        7,
                        7,
                        7,
                        6,
                        1,
                        1,
                        7,
                        6,
                        2,
                        3,
                        7,
                        4,
                        9,
                        7,
                        4,
                        7,
                        1,
                        4,
                        4,
                        7,
                        7,
                        4,
                        4,
                        4,
                        8,
                        8,
                        2,
                        4,
                        4,
                        2,
                        7,
                        1,
                        2,
                        2,
                        3,
                        2,
                        1,
                        4,
                        2,
                        8,
                        3,
                        4,
                        0,
                        4,
                        5,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        3,
                        6,
                        6,
                        9,
                        5,
                        1,
                        2,
                        1,
                        8,
                        9,
                        2,
                        7,
                        5,
                        5,
                        4,
                        3,
                        6,
                        4,
                        4,
                        6,
                        6,
                        1,
                        3,
                        2,
                        3,
                        4,
                        1,
                        2,
                        3,
                        5,
                        4,
                        6,
                        6,
                        4,
                        4,
                        5,
                        2,
                        1,
                        1,
                        4,
                        3,
                        3,
                        6,
                        7,
                        6,
                        2,
                        5,
                        2,
                        4,
                        9,
                        4,
                        5,
                        4,
                        4,
                        4,
                        8,
                        0,
                        4,
                        6,
                        4,
                        2,
                        1,
                        6,
                        4,
                        2,
                        6,
                        4,
                        1,
                        8,
                        8,
                        7,
                        7,
                        0,
                        4,
                        1,
                        8,
                        4,
                        7,
                        7,
                        1,
                        6,
                        8,
                        3,
                        6,
                        6,
                        3,
                        2,
                        7,
                        1,
                        4,
                        4,
                        7,
                        1,
                        6,
                        7,
                        5,
                        8,
                        4,
                        3,
                        2,
                        1,
                        7,
                        2,
                        7,
                        8,
                        0,
                        7,
                        7,
                        7,
                        7,
                        8,
                        4,
                        3,
                        8,
                        0,
                        8,
                        8,
                        5,
                        6,
                        6,
                        4,
                        4,
                        8,
                        4,
                        7,
                        5,
                        2,
                        2,
                        5,
                        1,
                        4,
                        7,
                        7,
                        6,
                        0,
                        5,
                        3,
                        1,
                        7,
                        0,
                        8,
                        5,
                        6,
                        1,
                        2,
                        6,
                        1,
                        2,
                        3,
                        2,
                        4,
                        1,
                        0,
                        1,
                        7,
                        5,
                        8,
                        5,
                        2,
                        5,
                        3,
                        4,
                        1,
                        8,
                        3,
                        1,
                        0,
                        4,
                        5,
                        8,
                        3,
                        0,
                        2,
                        4,
                        4,
                        3,
                        7,
                        7,
                        9,
                        3,
                        1,
                        4,
                        6,
                        4,
                        4,
                        1,
                        4,
                        4,
                        8,
                        7,
                        2,
                        4,
                        0,
                        2,
                        1,
                        3,
                        2,
                        3,
                        0,
                        6,
                        1,
                        1,
                        3,
                        5,
                        4,
                        0,
                        8,
                        5,
                        7,
                        5,
                        1,
                        3,
                        0,
                        5,
                        1,
                        8,
                        3,
                        1,
                        5,
                        3,
                        8,
                        8,
                        5,
                        3,
                        1,
                        4,
                        6,
                        2,
                        5,
                        8,
                        8,
                        7,
                        2,
                        9,
                        6,
                        0,
                        8,
                        0,
                        4,
                        6,
                        5,
                        3,
                        6,
                        5,
                        5,
                        0,
                        3,
                        7,
                        3,
                        5,
                        4,
                        1,
                        9,
                        7,
                        3,
                        0,
                        7,
                        0,
                        6,
                        3,
                        2,
                        8,
                        2,
                        9,
                        7,
                        6,
                        2,
                        4,
                        3,
                        8,
                        2,
                        3,
                        8,
                        7,
                        6,
                        3,
                        0,
                        3,
                        6,
                        2,
                        6,
                        9,
                        2,
                        5,
                        2,
                        2,
                        7,
                        6
                      ]
                    }
                  ],
                  "line": {
                    "cmax": 2.3118641943454743,
                    "cmin": 1.0989610620498658,
                    "color": [
                      1.671311504173279,
                      1.3226806262373925,
                      1.4172692937374114,
                      1.9340372748017312,
                      1.3040651526749134,
                      1.2026273607492446,
                      1.371904292154312,
                      1.3103908315896988,
                      1.181831344819069,
                      1.6336544196530827,
                      1.2144700831830502,
                      1.3405632294198964,
                      2.306141357088089,
                      1.1557198293685913,
                      1.3815186695398056,
                      1.2000089558571576,
                      1.5078460736438923,
                      2.30634944190979,
                      1.2699353729605676,
                      1.249595324808359,
                      1.9696523330688476,
                      1.4446669766560196,
                      2.303952686548233,
                      1.2213374953597784,
                      1.3456002076625824,
                      1.2571344835281373,
                      1.2325668345451355,
                      1.1287466134548187,
                      1.231221194076538,
                      1.1766207193374634,
                      1.3354455207824707,
                      1.417950362443924,
                      1.1948002507174387,
                      1.3385845083236694,
                      1.418431627011299,
                      1.4500638333022595,
                      1.2286950948894024,
                      1.1753483397483826,
                      1.200515614581108,
                      1.957746341884136,
                      1.3693450499534607,
                      1.3013626571379602,
                      1.3381314596176148,
                      1.2677442533120513,
                      1.1761459641456604,
                      1.2077047234296798,
                      1.2314919468611478,
                      1.3801229436323046,
                      1.433689385318756,
                      1.162273492860794,
                      1.2611822464227675,
                      2.3089644124746322,
                      1.7196956045150757,
                      1.478428796092694,
                      1.33684553720057,
                      1.2804337785720825,
                      1.5823679849728942,
                      1.4587310496330261,
                      1.5036097057819366,
                      1.2604726832643152,
                      1.5442393163621426,
                      1.1517569412946702,
                      1.1445624197006226,
                      1.1817648113131523,
                      1.1239832781791688,
                      1.4220168498474173,
                      2.30687046918869,
                      1.2643861521363258,
                      1.3143865483283996,
                      1.2788549817085266,
                      1.1522989460468291,
                      1.5098864966392518,
                      1.5649399952364402,
                      1.1151780983924866,
                      1.3833469765663147,
                      1.1200655667304993,
                      1.218412845993042,
                      1.2204048331260682,
                      1.3853180413484574,
                      1.4192125112782232,
                      1.2066986998558045,
                      1.8991223809719087,
                      1.2951246853001415,
                      1.5869001545637846,
                      1.4872552181518535,
                      1.5889479528427124,
                      2.304352142572403,
                      2.036530383729935,
                      1.221674622027576,
                      1.1649602625489235,
                      1.3698344056844711,
                      1.6820057426452637,
                      1.4089054837669497,
                      1.277518331003189,
                      2.303798386764526,
                      1.1511560496330262,
                      1.1549791073799134,
                      1.929871759050787,
                      1.7626865319354914,
                      1.400657526743412,
                      1.3748621870659292,
                      1.190584019652009,
                      1.5100973738883752,
                      1.4144033495693396,
                      1.2382981746673585,
                      1.1731590794563294,
                      1.2710563829421997,
                      1.416995603672322,
                      1.2088010674476624,
                      1.3830139803767205,
                      1.223903026652336,
                      1.1899700746536255,
                      1.2026748282432556,
                      1.3981458776691928,
                      1.2165845418453216,
                      1.5760355879671872,
                      1.16511638641553,
                      1.1550214302301407,
                      1.1892279219150543,
                      1.2943724615573884,
                      1.565678896933794,
                      1.1992963170289994,
                      1.144771109008789,
                      1.387200616992684,
                      1.4985460300683975,
                      1.2776759857177735,
                      1.1727241339683532,
                      2.007887244796753,
                      1.2010146763801575,
                      1.4347720643758775,
                      1.1376556176662445,
                      1.236137861765665,
                      1.2369382193591445,
                      2.30751236038208,
                      1.3938249544918537,
                      2.3030301584243773,
                      1.4452823349576442,
                      1.3223768081896008,
                      1.441870403451889,
                      1.57584217694439,
                      1.2084982520103456,
                      1.1114530757188796,
                      1.3604332412565825,
                      1.7426140279930635,
                      1.207207911168551,
                      1.8787746960163116,
                      2.305172007751465,
                      2.3037624966621397,
                      1.251974629715085,
                      1.2920117991585518,
                      1.5559264411006937,
                      1.2904726285338401,
                      1.850008839416504,
                      2.303080154418945,
                      1.1646192997455598,
                      1.2043298978567123,
                      1.3253433572769164,
                      1.625346475481987,
                      1.2324965363025666,
                      2.3062572593688966,
                      1.2301123309910298,
                      1.2927060495316982,
                      1.654421294391975,
                      1.1710249751091004,
                      1.3160739988327026,
                      1.4650310018519994,
                      1.428906838607788,
                      1.15967165453434,
                      1.2723599006139674,
                      1.2331455897878856,
                      1.49179454870224,
                      1.431450141568482,
                      1.6563402631822006,
                      1.4052669047355653,
                      2.3050164306640624,
                      1.1694412882447243,
                      1.2046834774017334,
                      1.168595176011324,
                      1.2931789595603942,
                      1.4349076241338454,
                      1.4033226922249422,
                      1.2355190081864595,
                      2.0152606115818026,
                      1.4162714557647704,
                      1.1980415782002731,
                      1.2741903034554793,
                      1.5426740544251478,
                      2.3029756976127627,
                      2.304660556411743,
                      1.138437969222665,
                      1.3508220045860857,
                      2.278197885298729,
                      1.3318281546115875,
                      2.3081029322862627,
                      2.309528663659096,
                      1.3938663620568812,
                      1.4085698402881621,
                      1.2957941490650178,
                      1.2601940600156785,
                      1.1237852289438248,
                      2.307781186437607,
                      1.2185343857005237,
                      1.2230782335994765,
                      1.3840094393864275,
                      1.229496594876051,
                      1.2906619865432383,
                      1.5183631890773772,
                      2.3028048062324524,
                      1.184821671295166,
                      1.188709452366829,
                      1.1824720607995987,
                      1.2576394115447997,
                      1.3501283897161485,
                      1.3369596785866655,
                      1.3204326523061667,
                      1.6064334547042847,
                      1.6487187149683924,
                      1.5838463577482849,
                      2.1507410233974458,
                      1.390372361946106,
                      1.2088771149158477,
                      1.3733779663685826,
                      1.302860150129348,
                      1.1901825585365295,
                      1.2659050039544701,
                      1.2217634515464306,
                      1.2239923438362776,
                      1.2261318247079849,
                      1.2105114710569382,
                      1.3153805195838213,
                      1.7223813940793276,
                      1.313908027601242,
                      1.3599822031513322,
                      1.2620856935918332,
                      2.3049634429931642,
                      1.50860059902668,
                      1.1867042482078076,
                      1.5596696622663178,
                      1.1352562084913254,
                      1.1317653287649154,
                      2.3027265412330626,
                      2.3034626373291016,
                      1.2734874800533056,
                      1.2996291444778443,
                      1.8474633663917892,
                      1.2068969598829746,
                      1.4127741965293885,
                      2.303476993560791,
                      1.276099622068554,
                      1.3561067677497864,
                      1.396679508651793,
                      1.1062979637861252,
                      1.1825446780204774,
                      1.0989610620498658,
                      1.233591024184227,
                      1.1535952755212784,
                      2.0595813249588013,
                      1.3876173727569636,
                      1.7552352060772478,
                      1.236380718271248,
                      1.5742134641017764,
                      1.308007786832191,
                      1.1534132308840752,
                      1.2890883934244513,
                      1.1426386052191257,
                      1.2585298459073528,
                      2.3045515835762025,
                      1.2955705938960425,
                      1.5798015952587128,
                      1.5297027861564192,
                      1.6639016122706234,
                      1.3013940046191215,
                      1.3770915191776352,
                      1.319725939744059,
                      1.2411882239341736,
                      1.324006092429161,
                      1.5250327778339385,
                      1.8068687059291544,
                      1.445077248764038,
                      1.4768732035636902,
                      1.44333525390625,
                      1.530587996006012,
                      1.242274902792275,
                      1.8982198383161926,
                      2.3118641943454743,
                      1.3800306380271912,
                      1.1407299230098724,
                      1.3179982271268964,
                      1.741878121562302,
                      1.191900940465927,
                      1.2650841888427735,
                      1.4778549068927764,
                      1.5161228376835585,
                      2.3053681562423707,
                      1.3661570167653263,
                      2.3028195817947386,
                      1.4657755815982818,
                      1.4840153528249291,
                      2.3048224634170533,
                      2.3037787652015687,
                      1.4586631808014587,
                      1.226029860663414,
                      1.2233245191574096,
                      1.1826919541835785,
                      1.3940222072958945,
                      1.3284536243498326,
                      1.3576274952620269,
                      2.3088520610809327,
                      2.305167899417877,
                      1.2123114210128785,
                      1.1899517424345016,
                      2.2312529209136964,
                      1.1945108407020568,
                      1.2415997797012328,
                      2.226771391391754,
                      1.5456344100613146,
                      1.3563466473846288,
                      1.4423472781658173,
                      1.4462989956855774,
                      1.1838021591186523,
                      1.4194070397250353,
                      1.4114988458693027,
                      1.2652347042381764,
                      1.2857928179264069,
                      1.2211942920684815,
                      1.2639981867488475,
                      1.5857056022727236,
                      1.3938069409629723,
                      1.4056828970070256,
                      1.4278822326421738,
                      1.9774009263038634,
                      1.2993029011249542,
                      1.3459361221313477,
                      1.263646462583542,
                      1.2024406298637391,
                      1.2835848495483397,
                      1.261670992875099,
                      1.3508589702086524,
                      1.1584958662986755,
                      2.3077146691322326,
                      1.302815075802803,
                      1.642074985215813,
                      1.4008426087904722,
                      1.3680869388759136,
                      1.3198228529788554,
                      1.2216629703164101,
                      1.4092948355674744,
                      1.852083815574646,
                      1.1996502252817154,
                      1.293618412310537,
                      2.30448764667511,
                      1.33953148997128,
                      1.2916202207565308,
                      1.5191606162780478,
                      1.4731742725014687,
                      1.1358662155389785,
                      1.1903771290302276,
                      1.193650727415085,
                      1.3049913212776183,
                      1.8521367456316948,
                      1.2585503623902798,
                      1.3823190921934965,
                      1.2080452667891979,
                      1.5015363671302795,
                      1.6083141253320627,
                      1.8068479383904328
                    ],
                    "colorscale": [
                      [
                        0,
                        "rgb(0,0,131)"
                      ],
                      [
                        0.2,
                        "rgb(0,60,170)"
                      ],
                      [
                        0.4,
                        "rgb(5,255,255)"
                      ],
                      [
                        0.6,
                        "rgb(255,255,0)"
                      ],
                      [
                        0.8,
                        "rgb(250,0,0)"
                      ],
                      [
                        1,
                        "rgb(128,0,0)"
                      ]
                    ],
                    "showscale": true
                  },
                  "type": "parcoords"
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#| echo: true\n",
        "#| label: fig-parallel\n",
        "spot_tuner.parallel_plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Parallel plot](./figures/parallel.png){#fig-parallel}\n",
        "\n",
        "\n",
        "# Summary and Outlook {#sec-summary}\n",
        "\n",
        "This tutorial presents the hyperparameter tuning open source software `spotPython` for `PyTorch`. To show its basic features, a comparison with the \"official\" `PyTorch` hyperparameter tuning tutorial [@pyto23a] is presented.\n",
        "Some of the advantages of `spotPython` are:\n",
        "\n",
        "- Numerical and categorical hyperparameters.\n",
        "- Powerful surrogate models.\n",
        "- Flexible approach and easy to use.\n",
        "- Simple JSON files for the specification of the hyperparameters.\n",
        "- Extension of default and user specified network classes.\n",
        "- Noise handling techniques.\n",
        "\n",
        "Currently, only rudimentary parallel and distributed neural network training is possible, but these capabilities will be extended in the future. The next version of `spotPython` will also include a more detailed documentation and more examples.\n",
        "\n",
        "::: {.callout-important}\n",
        "Important: This tutorial does not present a complete benchmarking study [@bart20gArxiv]. The results are only preliminary and highly dependent on the local configuration (hard- and software). Our goal is to provide a first impression of the performance of the hyperparameter tuning package `spotPython`. To demonstrate its capabilities, a quick comparison with `ray[tune]` was performed. `ray[tune]` was chosen, because it is presented as \"an industry standard tool for distributed hyperparameter tuning.\"  The results should be interpreted with care.\n",
        ":::\n",
        "\n",
        "\n",
        "# Appendix {#sec-appendix}\n",
        "\n",
        "## Sample Output From Ray Tune's Run {.unnumbered}\n",
        "\n",
        "The output from `ray[tune]` could look like this [@pyto23b]:\n",
        "\n",
        "```{raw}\n",
        "Number of trials: 10 (10 TERMINATED)\n",
        "------+------+-------------+--------------+---------+------------+--------------------+\n",
        "|   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |\n",
        "+------+------+-------------+--------------+---------+------------+--------------------|\n",
        "|   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |\n",
        "|   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |\n",
        "|    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |\n",
        "|    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |\n",
        "|   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |\n",
        "|    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |\n",
        "|  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |\n",
        "|   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |\n",
        "|   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |\n",
        "|  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |\n",
        "+-----+------+------+-------------+--------------+---------+------------+--------------------+\n",
        "Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}\n",
        "Best trial final validation loss: 1.181501\n",
        "Best trial final validation accuracy: 0.5836\n",
        "Best trial test set accuracy: 0.5806\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "{{< pagebreak >}}\n",
        "\n",
        "# References {.unnumbered}\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
