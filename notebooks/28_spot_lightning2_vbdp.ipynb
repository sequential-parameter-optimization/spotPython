{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HPT: PyTorch With VBDP {#sec-vbdp}\n",
        "\n",
        "In this tutorial, we will show how `spotPython` can be integrated into the `PyTorch`\n",
        "training workflow for a classifiaction task.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Data must be downloaded manually\n",
        "\n",
        "* Ensure that the correspondiing data is available as `./data/VBDP/train.csv`.\n",
        "\n",
        ":::\n",
        "\n",
        "This document refers to the following software versions:\n",
        "\n",
        "- ``python``: 3.10.10\n",
        "- ``torch``: 2.0.1\n",
        "- ``torchvision``: 0.15.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spotPython                 0.2.40\n",
            "spotRiver                  0.0.93\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip list | grep  \"spot[RiverPython]\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`spotPython` can be installed via pip. Alternatively, the source code can be downloaded from gitHub: [https://github.com/sequential-parameter-optimization/spotPython](https://github.com/sequential-parameter-optimization/spotPython).\n",
        "\n",
        "```{raw}\n",
        "!pip install spotPython\n",
        "```\n",
        "\n",
        "* Uncomment the following lines if you want to for (re-)installation the latest version of `spotPython` from gitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install --upgrade build\n",
        "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup {#sec-setup-25}\n",
        "\n",
        "Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Run time and initial design size should be increased for real experiments\n",
        "\n",
        "* MAX_TIME is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\n",
        "* INIT_SIZE is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-note}\n",
        "### Note: Device selection\n",
        "\n",
        "* The device can be selected by setting the variable `DEVICE`.\n",
        "* Since we are using a simple neural net, the setting `\"cpu\"` is preferred (on Mac).\n",
        "* If you have a GPU, you can use `\"cuda:0\"` instead.\n",
        "* If DEVICE is set to `None`, `spotPython` will automatically select the device.\n",
        "  * This might result in `\"mps\"` on Macs, which is not the best choice for simple neural nets.\n",
        "\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_TIME = 1\n",
        "INIT_SIZE = 5\n",
        "DEVICE = None # \"cpu\" # \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "from spotPython.utils.device import getDevice\n",
        "DEVICE = getDevice(DEVICE)\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25-torch_bartz09_1min_5init_2023-06-24_18-33-41\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "import socket\n",
        "from datetime import datetime\n",
        "from dateutil.tz import tzlocal\n",
        "start_time = datetime.now(tzlocal())\n",
        "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
        "experiment_name = '25-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
        "experiment_name = experiment_name.replace(':', '-')\n",
        "print(experiment_name)\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialization of the `fun_control` Dictionary\n",
        "\n",
        ":::{.callout-caution}\n",
        "### Caution: Tensorboard does not work under Windows\n",
        "* Since tensorboard does not work under Windows, we recommend setting the parameter `tensorboard_path` to `None` if you are working under Windows.\n",
        ":::\n",
        "\n",
        "`spotPython` uses a Python dictionary for storing the information required for the hyperparameter tuning process, which was described in @sec-initialization-fun-control-14, see [Initialization of the fun_control Dictionary](https://sequential-parameter-optimization.github.io/spotPython/14_spot_ray_hpt_torch_cifar10.html#sec-initialization-fun-control-14) in the documentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.utils.init import fun_control_init\n",
        "fun_control = fun_control_init(task=\"classification\",\n",
        "    tensorboard_path=None,\n",
        "    device=DEVICE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: PyTorch Data Loading {#sec-data-loading-25}\n",
        "\n",
        "### 1. Load VBDP Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "train_df = pd.read_csv('./data/VBDP/train.csv')\n",
        "# remove the id column\n",
        "train_df = train_df.drop(columns=['id'])\n",
        "n_samples = train_df.shape[0]\n",
        "n_features = train_df.shape[1] - 1\n",
        "target_column = \"prognosis\"\n",
        "# # Encoder our prognosis labels as integers for easier decoding later\n",
        "enc = OrdinalEncoder()\n",
        "train_df[target_column] = enc.fit_transform(train_df[[target_column]])\n",
        "train_df.head()\n",
        "\n",
        "# convert all entries to int for faster processing\n",
        "train_df = train_df.astype(int)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Add logical combinations (AND, OR, XOR) of the features to the data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/dw/pvtj6mt91znd0hftcztqb0k00000gn/T/ipykernel_41243/2916932135.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[target_column] = target\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sudden_fever</th>\n",
              "      <th>headache</th>\n",
              "      <th>mouth_bleed</th>\n",
              "      <th>nose_bleed</th>\n",
              "      <th>muscle_pain</th>\n",
              "      <th>joint_pain</th>\n",
              "      <th>vomiting</th>\n",
              "      <th>rash</th>\n",
              "      <th>diarrhea</th>\n",
              "      <th>hypotension</th>\n",
              "      <th>...</th>\n",
              "      <th>6039</th>\n",
              "      <th>6040</th>\n",
              "      <th>6041</th>\n",
              "      <th>6042</th>\n",
              "      <th>6043</th>\n",
              "      <th>6044</th>\n",
              "      <th>6045</th>\n",
              "      <th>6046</th>\n",
              "      <th>6047</th>\n",
              "      <th>prognosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6113 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
              "0             1         1            0           1            1           1  \\\n",
              "1             0         0            0           0            0           0   \n",
              "2             0         1            1           1            0           1   \n",
              "3             0         0            1           1            1           1   \n",
              "4             0         0            0           0            0           0   \n",
              "\n",
              "   vomiting  rash  diarrhea  hypotension  ...  6039  6040  6041  6042  6043   \n",
              "0         1     0         1            1  ...     0     0     0     0     0  \\\n",
              "1         1     0         1            0  ...     0     0     0     0     0   \n",
              "2         1     1         1            1  ...     1     1     0     1     1   \n",
              "3         0     1         0            1  ...     0     0     0     0     0   \n",
              "4         0     0         1            0  ...     0     1     1     0     1   \n",
              "\n",
              "   6044  6045  6046  6047  prognosis  \n",
              "0     0     0     0     0          3  \n",
              "1     0     0     0     0          7  \n",
              "2     0     1     1     0          3  \n",
              "3     0     0     0     0         10  \n",
              "4     1     0     0     0          6  \n",
              "\n",
              "[5 rows x 6113 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from spotPython.utils.convert import add_logical_columns\n",
        "df_new = train_df.copy()\n",
        "# save the target column using \"target_column\" as the column name\n",
        "target = train_df[target_column]\n",
        "# remove the target column\n",
        "df_new = df_new.drop(columns=[target_column])\n",
        "train_df = add_logical_columns(df_new)\n",
        "# add the target column back\n",
        "train_df[target_column] = target\n",
        "train_df = train_df.astype(int)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>...</th>\n",
              "      <th>x6104</th>\n",
              "      <th>x6105</th>\n",
              "      <th>x6106</th>\n",
              "      <th>x6107</th>\n",
              "      <th>x6108</th>\n",
              "      <th>x6109</th>\n",
              "      <th>x6110</th>\n",
              "      <th>x6111</th>\n",
              "      <th>x6112</th>\n",
              "      <th>prognosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6113 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x6104  x6105  x6106  x6107   \n",
              "0   1   1   0   1   1   1   1   0   1    1  ...      0      0      0      0  \\\n",
              "1   0   0   0   0   0   0   1   0   1    0  ...      0      0      0      0   \n",
              "2   0   1   1   1   0   1   1   1   1    1  ...      1      1      0      1   \n",
              "3   0   0   1   1   1   1   0   1   0    1  ...      0      0      0      0   \n",
              "4   0   0   0   0   0   0   0   0   1    0  ...      0      1      1      0   \n",
              "\n",
              "   x6108  x6109  x6110  x6111  x6112  prognosis  \n",
              "0      0      0      0      0      0          3  \n",
              "1      0      0      0      0      0          7  \n",
              "2      1      0      1      1      0          3  \n",
              "3      0      0      0      0      0         10  \n",
              "4      1      1      0      0      0          6  \n",
              "\n",
              "[5 rows x 6113 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "n_samples = train_df.shape[0]\n",
        "n_features = train_df.shape[1] - 1\n",
        "train_df.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "train_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check content of the target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     3\n",
              "1     7\n",
              "2     3\n",
              "3    10\n",
              "4     6\n",
              "Name: prognosis, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[target_column].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(707, 6113)\n",
            "(530, 6113)\n",
            "(177, 6113)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_df.drop(target_column, axis=1), train_df[target_column],\n",
        "                                                    random_state=42,\n",
        "                                                    test_size=0.25,\n",
        "                                                    stratify=train_df[target_column])\n",
        "trainset = pd.DataFrame(np.hstack((X_train, np.array(y_train).reshape(-1, 1))))\n",
        "testset = pd.DataFrame(np.hstack((X_test, np.array(y_test).reshape(-1, 1))))\n",
        "trainset.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "testset.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "print(train_df.shape)\n",
        "print(trainset.shape)\n",
        "print(testset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>...</th>\n",
              "      <th>x6104</th>\n",
              "      <th>x6105</th>\n",
              "      <th>x6106</th>\n",
              "      <th>x6107</th>\n",
              "      <th>x6108</th>\n",
              "      <th>x6109</th>\n",
              "      <th>x6110</th>\n",
              "      <th>x6111</th>\n",
              "      <th>x6112</th>\n",
              "      <th>prognosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6113 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x6104  x6105  x6106  x6107   \n",
              "0   1   0   0   0   0   0   0   0   0    0  ...      0      0      0      0  \\\n",
              "1   0   1   1   1   1   1   1   1   1    0  ...      0      0      0      0   \n",
              "2   0   0   0   1   1   1   0   0   0    0  ...      0      1      1      1   \n",
              "3   1   1   0   1   1   1   0   0   0    0  ...      0      0      0      0   \n",
              "4   0   0   0   1   0   0   1   1   0    0  ...      0      0      0      0   \n",
              "\n",
              "   x6108  x6109  x6110  x6111  x6112  prognosis  \n",
              "0      0      0      0      0      0          2  \n",
              "1      0      0      0      0      0          4  \n",
              "2      1      0      0      1      1          1  \n",
              "3      0      0      0      0      0          6  \n",
              "4      0      0      0      0      0          5  \n",
              "\n",
              "[5 rows x 6113 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from spotPython.torch.dataframedataset import DataFrameDataset\n",
        "dtype_x = torch.float32\n",
        "dtype_y = torch.long\n",
        "train_df = DataFrameDataset(train_df, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "train = DataFrameDataset(trainset, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "test = DataFrameDataset(testset, target_column=target_column, dtype_x=dtype_x, dtype_y=dtype_y)\n",
        "n_samples = len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<spotPython.torch.dataframedataset.DataFrameDataset at 0x2a3763f10>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add the dataset to the fun_control\n",
        "fun_control.update({\"data\": train_df, # full dataset,\n",
        "               \"train\": trainset,\n",
        "               \"test\": testset,\n",
        "               \"n_samples\": n_samples,\n",
        "               \"target_column\": target_column})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Specification of the Preprocessing Model {#sec-specification-of-preprocessing-model-25}\n",
        "\n",
        "After the training and test data are specified and added to the `fun_control` dictionary, `spotPython` allows the specification of a data preprocessing pipeline, e.g., for the scaling of the data or for the one-hot encoding of categorical variables, see @sec-specification-of-preprocessing-model-14. This feature is not used here, so we do not change the default value (which is `None`).\n",
        "\n",
        "## Step 5: Select `algorithm` and `core_model_hyper_dict` {#sec-selection-of-the-algorithm-25}\n",
        "\n",
        "### Implementing a Configurable Neural Network With spotPython \n",
        "\n",
        "`spotPython` includes the `Net_vbdp` class which is implemented in the file `netvbdp.py`.\n",
        "The class is imported here.\n",
        "\n",
        "This class  inherits from the class `Net_Core` which is implemented in the file `netcore.py`, see @sec-the-netcore-class-14.\n",
        "\n",
        "### Add the NN Model to the fun_control Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.lightning2.lightning2base import Lightning2Base\n",
        "from spotPython.data.lightning2_hyper_dict import Lightning2HyperDict\n",
        "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
        "fun_control = add_core_model_to_fun_control(core_model=Lightning2Base,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict= Lightning2HyperDict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The corresponding entries for the `core_model` class are shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'_L_in': {'type': 'int',\n",
              "  'default': 784,\n",
              "  'transform': 'None',\n",
              "  'lower': 784,\n",
              "  'upper': 784},\n",
              " '_L_out': {'type': 'int',\n",
              "  'default': 11,\n",
              "  'transform': 'None',\n",
              "  'lower': 11,\n",
              "  'upper': 11},\n",
              " 'l1': {'type': 'int',\n",
              "  'default': 3,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 3,\n",
              "  'upper': 8},\n",
              " 'epochs': {'type': 'int',\n",
              "  'default': 4,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 4,\n",
              "  'upper': 9},\n",
              " 'batch_size': {'type': 'int',\n",
              "  'default': 4,\n",
              "  'transform': 'transform_power_2_int',\n",
              "  'lower': 1,\n",
              "  'upper': 4},\n",
              " 'act_fn': {'levels': ['ReLU'],\n",
              "  'type': 'factor',\n",
              "  'default': 'ReLU',\n",
              "  'transform': 'None',\n",
              "  'class_name': 'torch.nn',\n",
              "  'core_model_parameter_type': 'instance()',\n",
              "  'lower': 0,\n",
              "  'upper': 0},\n",
              " 'optimizer': {'levels': ['Adadelta',\n",
              "   'Adagrad',\n",
              "   'Adam',\n",
              "   'AdamW',\n",
              "   'SparseAdam',\n",
              "   'Adamax',\n",
              "   'ASGD',\n",
              "   'NAdam',\n",
              "   'RAdam',\n",
              "   'RMSprop',\n",
              "   'Rprop',\n",
              "   'SGD'],\n",
              "  'type': 'factor',\n",
              "  'default': 'SGD',\n",
              "  'transform': 'None',\n",
              "  'class_name': 'torch.optim',\n",
              "  'core_model_parameter_type': 'str',\n",
              "  'lower': 0,\n",
              "  'upper': 12}}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fun_control['core_model_hyper_dict']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model` {#sec-modification-of-hyperparameters-25}\n",
        "\n",
        " `spotPython` provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions were described in @sec-modification-of-hyperparameters-14.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Small number of epochs for demonstration purposes\n",
        "\n",
        "* `epochs` and `patience` are set to small values for demonstration purposes. These values are too small for a real application.\n",
        "* More resonable values are, e.g.:\n",
        "  * `fun_control = modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[7, 9])` and\n",
        "  * `fun_control = modify_hyper_parameter_bounds(fun_control, \"patience\", bounds=[2, 7])`\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"_L_in\", bounds=[n_features, n_features])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"l1\", bounds=[6, 13])\n",
        "fun_control = modify_hyper_parameter_bounds(fun_control, \"epochs\", bounds=[2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import modify_hyper_parameter_levels\n",
        "fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\",[\"Adam\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
        "# fun_control = modify_hyper_parameter_levels(fun_control, \"optimizer\", [\"Adam\"])\n",
        "# fun_control[\"core_model_hyper_dict\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Selection of the Objective (Loss) Function\n",
        "\n",
        "### Evaluation  {#sec-selection-of-target-function-25}\n",
        "\n",
        "The evaluation procedure requires the specification of two elements:\n",
        "\n",
        "1. the way how the data is split into a train and a test set (see @sec-data-splitting-14)\n",
        "2. the loss function (and a metric).\n",
        "\n",
        "\n",
        "### Loss Functions and Metrics {#sec-loss-functions-and-metrics-25}\n",
        "\n",
        "The loss function is specified by the key `\"loss_function\"`.\n",
        "We will use CrossEntropy loss for the multiclass-classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.nn import CrossEntropyLoss\n",
        "# loss_function = CrossEntropyLoss()\n",
        "# fun_control.update({\"loss_function\": loss_function})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metric {#sec-metric-25}\n",
        "\n",
        "* We will use the MAP@k metric for the evaluation of the model. Here is an example how this metric is calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6250)\n"
          ]
        }
      ],
      "source": [
        "from spotPython.torch.mapk import MAPK\n",
        "import torch\n",
        "mapk = MAPK(k=2)\n",
        "target = torch.tensor([0, 1, 2, 2])\n",
        "preds = torch.tensor(\n",
        "    [\n",
        "        [0.5, 0.2, 0.2],  # 0 is in top 2\n",
        "        [0.3, 0.4, 0.2],  # 1 is in top 2\n",
        "        [0.2, 0.4, 0.3],  # 2 is in top 2\n",
        "        [0.7, 0.2, 0.1],  # 2 isn't in top 2\n",
        "    ]\n",
        ")\n",
        "mapk.update(preds, target)\n",
        "print(mapk.compute()) # tensor(0.6250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from spotPython.torch.mapk import MAPK\n",
        "# import torchmetrics\n",
        "# metric_torch = MAPK(k=3)\n",
        "# fun_control.update({\"metric_torch\": metric_torch})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Calling the SPOT Function\n",
        "\n",
        "### Preparing the SPOT Call {#sec-prepare-spot-call-25}\n",
        "\n",
        "The following code passes the information about the parameter ranges and bounds to `spot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract the variable types, names, and bounds\n",
        "from spotPython.hyperparameters.values import (get_bound_values,\n",
        "    get_var_name,\n",
        "    get_var_type,)\n",
        "var_type = get_var_type(fun_control)\n",
        "var_name = get_var_name(fun_control)\n",
        "fun_control.update({\"var_type\": var_type,\n",
        "                    \"var_name\": var_name})\n",
        "lower = get_bound_values(fun_control, \"lower\")\n",
        "upper = get_bound_values(fun_control, \"upper\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the dictionary `fun_control` contains all information needed for the hyperparameter tuning. Before the hyperparameter tuning is started, it is recommended to take a look at the experimental design. The method `gen_design_table` generates a design table as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "fig-label": "tbl-design-25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| name       | type   | default   |   lower |   upper | transform             |\n",
            "|------------|--------|-----------|---------|---------|-----------------------|\n",
            "| _L_in      | int    | 784       |    6112 |    6112 | None                  |\n",
            "| _L_out     | int    | 11        |      11 |      11 | None                  |\n",
            "| l1         | int    | 3         |       6 |      13 | transform_power_2_int |\n",
            "| epochs     | int    | 4         |       2 |       3 | transform_power_2_int |\n",
            "| batch_size | int    | 4         |       1 |       4 | transform_power_2_int |\n",
            "| act_fn     | factor | ReLU      |       0 |       0 | None                  |\n",
            "| optimizer  | factor | SGD       |       0 |       3 | None                  |\n"
          ]
        }
      ],
      "source": [
        "#| fig-cap: Experimental design for the hyperparameter tuning.\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This allows to check if all information is available and if the information is correct.\n",
        "\n",
        "### The Objective Function `fun_torch` {#sec-the-objective-function-25}\n",
        "\n",
        "The objective function `fun_torch` is selected next. It implements an interface from `PyTorch`'s training, validation, and  testing methods to `spotPython`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.fun.hyperlightning2 import HyperLightning2\n",
        "fun = HyperLightning2().fun_lightning2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[784,  11,   3,   4,   4,   0,  11]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from spotPython.hyperparameters.values import get_default_hyperparameters_as_array\n",
        "hyper_dict=Lightning2HyperDict().load()\n",
        "X_start = get_default_hyperparameters_as_array(fun_control, hyper_dict)\n",
        "X_start"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Starting the Hyperparameter Tuning {#sec-call-the-hyperparameter-tuner-25}\n",
        "\n",
        "The `spotPython` hyperparameter tuning is started by calling the `Spot` function as described in @sec-call-the-hyperparameter-tuner-14.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "config: {'_L_in': 6112, '_L_out': 11, 'l1': 512, 'epochs': 4, 'batch_size': 16, 'act_fn': ReLU(), 'optimizer': 'Adamax'}\n",
            "Starting train_model\n",
            "self.train:    x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x6104  x6105  x6106  x6107   \n",
            "0   1   0   0   0   0   0   0   0   0    0  ...      0      0      0      0  \\\n",
            "1   0   1   1   1   1   1   1   1   1    0  ...      0      0      0      0   \n",
            "2   0   0   0   1   1   1   0   0   0    0  ...      0      1      1      1   \n",
            "3   1   1   0   1   1   1   0   0   0    0  ...      0      0      0      0   \n",
            "4   0   0   0   1   0   0   1   1   0    0  ...      0      0      0      0   \n",
            "\n",
            "   x6108  x6109  x6110  x6111  x6112  prognosis  \n",
            "0      0      0      0      0      0          2  \n",
            "1      0      0      0      0      0          4  \n",
            "2      1      0      0      1      1          1  \n",
            "3      0      0      0      0      0          6  \n",
            "4      0      0      0      0      0          5  \n",
            "\n",
            "[5 rows x 6113 columns]\n",
            "model: Lightning2Base(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=6112, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=128, out_features=11, bias=True)\n",
            "  )\n",
            ")\n",
            "trainer initialized: <lightning.pytorch.trainer.trainer.Trainer object at 0x2d006f130>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name  | Type       | Params\n",
            "-------------------------------------\n",
            "0 | model | Sequential | 3.4 M \n",
            "-------------------------------------\n",
            "3.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.4 M     Total params\n",
            "13.445    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c58a11bac8be46ecb8b4a1d0bd0fad12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in fun_lightning2(). Call to train_model failed. err=TypeError(\"'DataFrame' object is not callable\"), type(err)=<class 'TypeError'>\n",
            "Setting df_eval to np.nan\n",
            "\n",
            "config: {'_L_in': 6112, '_L_out': 11, 'l1': 512, 'epochs': 8, 'batch_size': 4, 'act_fn': ReLU(), 'optimizer': 'Adam'}\n",
            "Starting train_model\n",
            "self.train:    x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x6104  x6105  x6106  x6107   \n",
            "0   1   0   0   0   0   0   0   0   0    0  ...      0      0      0      0  \\\n",
            "1   0   1   1   1   1   1   1   1   1    0  ...      0      0      0      0   \n",
            "2   0   0   0   1   1   1   0   0   0    0  ...      0      1      1      1   \n",
            "3   1   1   0   1   1   1   0   0   0    0  ...      0      0      0      0   \n",
            "4   0   0   0   1   0   0   1   1   0    0  ...      0      0      0      0   \n",
            "\n",
            "   x6108  x6109  x6110  x6111  x6112  prognosis  \n",
            "0      0      0      0      0      0          2  \n",
            "1      0      0      0      0      0          4  \n",
            "2      1      0      0      1      1          1  \n",
            "3      0      0      0      0      0          6  \n",
            "4      0      0      0      0      0          5  \n",
            "\n",
            "[5 rows x 6113 columns]\n",
            "model: Lightning2Base(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=6112, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=128, out_features=11, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name  | Type       | Params\n",
            "-------------------------------------\n",
            "0 | model | Sequential | 3.4 M \n",
            "-------------------------------------\n",
            "3.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.4 M     Total params\n",
            "13.445    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainer initialized: <lightning.pytorch.trainer.trainer.Trainer object at 0x2d00bd150>\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2614ff7962946dba02df1739ea530a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name  | Type       | Params\n",
            "-------------------------------------\n",
            "0 | model | Sequential | 3.4 M \n",
            "-------------------------------------\n",
            "3.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.4 M     Total params\n",
            "13.445    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in fun_lightning2(). Call to train_model failed. err=TypeError(\"'DataFrame' object is not callable\"), type(err)=<class 'TypeError'>\n",
            "Setting df_eval to np.nan\n",
            "\n",
            "config: {'_L_in': 6112, '_L_out': 11, 'l1': 64, 'epochs': 4, 'batch_size': 2, 'act_fn': ReLU(), 'optimizer': 'NAdam'}\n",
            "Starting train_model\n",
            "self.train:    x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x6104  x6105  x6106  x6107   \n",
            "0   1   0   0   0   0   0   0   0   0    0  ...      0      0      0      0  \\\n",
            "1   0   1   1   1   1   1   1   1   1    0  ...      0      0      0      0   \n",
            "2   0   0   0   1   1   1   0   0   0    0  ...      0      1      1      1   \n",
            "3   1   1   0   1   1   1   0   0   0    0  ...      0      0      0      0   \n",
            "4   0   0   0   1   0   0   1   1   0    0  ...      0      0      0      0   \n",
            "\n",
            "   x6108  x6109  x6110  x6111  x6112  prognosis  \n",
            "0      0      0      0      0      0          2  \n",
            "1      0      0      0      0      0          4  \n",
            "2      1      0      0      1      1          1  \n",
            "3      0      0      0      0      0          6  \n",
            "4      0      0      0      0      0          5  \n",
            "\n",
            "[5 rows x 6113 columns]\n",
            "model: Lightning2Base(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=6112, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=128, out_features=11, bias=True)\n",
            "  )\n",
            ")\n",
            "trainer initialized: <lightning.pytorch.trainer.trainer.Trainer object at 0x2d00d7e50>\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b1d68b346c74ae5a7035bcb8f962d56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name  | Type       | Params\n",
            "-------------------------------------\n",
            "0 | model | Sequential | 3.4 M \n",
            "-------------------------------------\n",
            "3.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.4 M     Total params\n",
            "13.445    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in fun_lightning2(). Call to train_model failed. err=TypeError(\"'DataFrame' object is not callable\"), type(err)=<class 'TypeError'>\n",
            "Setting df_eval to np.nan\n",
            "\n",
            "config: {'_L_in': 6112, '_L_out': 11, 'l1': 4096, 'epochs': 4, 'batch_size': 4, 'act_fn': ReLU(), 'optimizer': 'AdamW'}\n",
            "Starting train_model\n",
            "self.train:    x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x6104  x6105  x6106  x6107   \n",
            "0   1   0   0   0   0   0   0   0   0    0  ...      0      0      0      0  \\\n",
            "1   0   1   1   1   1   1   1   1   1    0  ...      0      0      0      0   \n",
            "2   0   0   0   1   1   1   0   0   0    0  ...      0      1      1      1   \n",
            "3   1   1   0   1   1   1   0   0   0    0  ...      0      0      0      0   \n",
            "4   0   0   0   1   0   0   1   1   0    0  ...      0      0      0      0   \n",
            "\n",
            "   x6108  x6109  x6110  x6111  x6112  prognosis  \n",
            "0      0      0      0      0      0          2  \n",
            "1      0      0      0      0      0          4  \n",
            "2      1      0      0      1      1          1  \n",
            "3      0      0      0      0      0          6  \n",
            "4      0      0      0      0      0          5  \n",
            "\n",
            "[5 rows x 6113 columns]\n",
            "model: Lightning2Base(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=6112, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=128, out_features=11, bias=True)\n",
            "  )\n",
            ")\n",
            "trainer initialized: <lightning.pytorch.trainer.trainer.Trainer object at 0x2d00d53c0>\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d66fdac706884f0295ef367ed8e4d596",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in fun_lightning2(). Call to train_model failed. err=TypeError(\"'DataFrame' object is not callable\"), type(err)=<class 'TypeError'>\n",
            "Setting df_eval to np.nan\n",
            "\n",
            "config: {'_L_in': 6112, '_L_out': 11, 'l1': 1024, 'epochs': 8, 'batch_size': 8, 'act_fn': ReLU(), 'optimizer': 'AdamW'}\n",
            "Starting train_model\n",
            "self.train:    x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x6104  x6105  x6106  x6107   \n",
            "0   1   0   0   0   0   0   0   0   0    0  ...      0      0      0      0  \\\n",
            "1   0   1   1   1   1   1   1   1   1    0  ...      0      0      0      0   \n",
            "2   0   0   0   1   1   1   0   0   0    0  ...      0      1      1      1   \n",
            "3   1   1   0   1   1   1   0   0   0    0  ...      0      0      0      0   \n",
            "4   0   0   0   1   0   0   1   1   0    0  ...      0      0      0      0   \n",
            "\n",
            "   x6108  x6109  x6110  x6111  x6112  prognosis  \n",
            "0      0      0      0      0      0          2  \n",
            "1      0      0      0      0      0          4  \n",
            "2      1      0      0      1      1          1  \n",
            "3      0      0      0      0      0          6  \n",
            "4      0      0      0      0      0          5  \n",
            "\n",
            "[5 rows x 6113 columns]\n",
            "model: Lightning2Base(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=6112, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=128, out_features=11, bias=True)\n",
            "  )\n",
            ")\n",
            "trainer initialized: <lightning.pytorch.trainer.trainer.Trainer object at 0x2d006fe80>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name  | Type       | Params\n",
            "-------------------------------------\n",
            "0 | model | Sequential | 3.4 M \n",
            "-------------------------------------\n",
            "3.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.4 M     Total params\n",
            "13.445    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3751b3c6cdf346e9a576bc65bac2d755",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in fun_lightning2(). Call to train_model failed. err=TypeError(\"'DataFrame' object is not callable\"), type(err)=<class 'TypeError'>\n",
            "Setting df_eval to np.nan\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "min() arg is an empty sequence",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 31\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmath\u001b[39;00m \u001b[39mimport\u001b[39;00m inf\n\u001b[1;32m      4\u001b[0m spot_tuner \u001b[39m=\u001b[39m spot\u001b[39m.\u001b[39mSpot(fun\u001b[39m=\u001b[39mfun,\n\u001b[1;32m      5\u001b[0m                    lower \u001b[39m=\u001b[39m lower,\n\u001b[1;32m      6\u001b[0m                    upper \u001b[39m=\u001b[39m upper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                       \u001b[39m\"\u001b[39m\u001b[39mlog_level\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m50\u001b[39m\n\u001b[1;32m     30\u001b[0m                                       })\n\u001b[0;32m---> 31\u001b[0m spot_tuner\u001b[39m.\u001b[39;49mrun(X_start\u001b[39m=\u001b[39;49mX_start)\n",
            "File \u001b[0;32m~/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py:322\u001b[0m, in \u001b[0;36mSpot.run\u001b[0;34m(self, X_start)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, X_start\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize_design(X_start)\n\u001b[1;32m    323\u001b[0m     \u001b[39m# (S-5) Calling the spotLoop Function\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[39m# and\u001b[39;00m\n\u001b[1;32m    325\u001b[0m     \u001b[39m# (S-9) Termination Criteria, Conditions:\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     timeout_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
            "File \u001b[0;32m~/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py:360\u001b[0m, in \u001b[0;36mSpot.initialize_design\u001b[0;34m(self, X_start)\u001b[0m\n\u001b[1;32m    358\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mNew y value: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my)\n\u001b[1;32m    359\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m remove_nan(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my)\n\u001b[0;32m--> 360\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_stats()\n\u001b[1;32m    361\u001b[0m \u001b[39m# (S-4): Imputation:\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m# Not implemented yet.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m# (S-11) Surrogate Fit:\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_surrogate()\n",
            "File \u001b[0;32m~/miniforge3/envs/spotCondaEnv/lib/python3.10/site-packages/spotPython/spot/spot.py:406\u001b[0m, in \u001b[0;36mSpot.update_stats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_stats\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    400\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m    Update the following stats: 1. `min_y` 2. `min_X` 3. `counter`\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39m    If `noise` is `True`, additionally the following stats are computed: 1. `mean_X`\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39m    2. `mean_y` 3. `min_mean_y` 4. `min_mean_X`.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_y \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my)\n\u001b[1;32m    407\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX[argmin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my)]\n\u001b[1;32m    408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my\u001b[39m.\u001b[39msize\n",
            "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from spotPython.spot import spot\n",
        "from math import inf\n",
        "spot_tuner = spot.Spot(fun=fun,\n",
        "                   lower = lower,\n",
        "                   upper = upper,\n",
        "                   fun_evals = inf,\n",
        "                   fun_repeats = 1,\n",
        "                   max_time = MAX_TIME,\n",
        "                   noise = False,\n",
        "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
        "                   var_type = var_type,\n",
        "                   var_name = var_name,\n",
        "                   infill_criterion = \"y\",\n",
        "                   n_points = 1,\n",
        "                   seed=123,\n",
        "                   log_level = 50,\n",
        "                   show_models= False,\n",
        "                   show_progress= True,\n",
        "                   fun_control = fun_control,\n",
        "                   design_control={\"init_size\": INIT_SIZE,\n",
        "                                   \"repeats\": 1},\n",
        "                   surrogate_control={\"noise\": True,\n",
        "                                      \"cod_type\": \"norm\",\n",
        "                                      \"min_theta\": -4,\n",
        "                                      \"max_theta\": 3,\n",
        "                                      \"n_theta\": len(var_name),\n",
        "                                      \"model_fun_evals\": 10_000,\n",
        "                                      \"log_level\": 50\n",
        "                                      })\n",
        "spot_tuner.run(X_start=X_start)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Tensorboard {#sec-tensorboard-25}\n",
        "\n",
        "The textual output shown in the console (or code cell) can be visualized with Tensorboard as described in @sec-tensorboard-14, see also the description in the documentation: [Tensorboard.](https://sequential-parameter-optimization.github.io/spotPython/14_spot_ray_hpt_torch_cifar10.html#sec-tensorboard-14)\n",
        "\n",
        "## Step 10: Results {#sec-results-25}\n",
        "\n",
        "After the hyperparameter tuning run is finished, the results can be analyzed as described in @sec-results-14."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-progress-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Progress plot. *Black* dots denote results from the initial design. *Red* dots  illustrate the improvement found by the surrogate model based optimization.\n",
        "spot_tuner.plot_progress(log_y=False, \n",
        "    filename=\"./figures/\" + experiment_name+\"_progress.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "tbl-results-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Results of the hyperparameter tuning.\n",
        "from spotPython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-importance-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: 'Variable importance plot, threshold 0.025.'\n",
        "spot_tuner.plot_importance(threshold=0.025,\n",
        "    filename=\"./figures/\" + experiment_name+\"_importance.png\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the Tuned Architecture {#sec-get-spot-results-25}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.hyperparameters.values import get_one_core_model_from_X\n",
        "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
        "model_spot = get_one_core_model_from_X(X, fun_control)\n",
        "model_spot"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of the Tuned Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.torch.traintest import (\n",
        "    train_tuned,\n",
        "    test_tuned,\n",
        "    )\n",
        "train_tuned(net=model_spot, train_dataset=train,\n",
        "        loss_function=fun_control[\"loss_function\"],\n",
        "        metric=fun_control[\"metric_torch\"],\n",
        "        shuffle=True,\n",
        "        device = fun_control[\"device\"],\n",
        "        path=None,\n",
        "        task=fun_control[\"task\"],)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If `path` is set to a filename, e.g., `path = \"model_spot_trained.pt\"`, the weights of the trained model will be loaded from this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_tuned(net=model_spot, test_dataset=test,\n",
        "            shuffle=False,\n",
        "            loss_function=fun_control[\"loss_function\"],\n",
        "            metric=fun_control[\"metric_torch\"],\n",
        "            device = fun_control[\"device\"],\n",
        "            task=fun_control[\"task\"],)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-validated Evaluations\n",
        "\n",
        "* This is the evaluation that will be used in the comparison.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Cross-validated Evaluations\n",
        "\n",
        "* The number of folds is set to 1 by default.\n",
        "* Here it was changed to 3 for demonstration purposes.\n",
        "* Set the number of folds to a reasonable value, e.g., 10.\n",
        "* This can be done by setting the `k_folds` attribute of the model as follows:\n",
        "* `setattr(model_spot, \"k_folds\",  10)`\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotPython.torch.traintest import evaluate_cv\n",
        "# modify k-kolds:\n",
        "setattr(model_spot, \"k_folds\",  3)\n",
        "df_eval, df_preds, df_metrics = evaluate_cv(net=model_spot,\n",
        "    dataset=fun_control[\"data\"],\n",
        "    loss_function=fun_control[\"loss_function\"],\n",
        "    metric=fun_control[\"metric_torch\"],\n",
        "    task=fun_control[\"task\"],\n",
        "    writer=fun_control[\"writer\"],\n",
        "    writerId=\"model_spot_cv\",\n",
        "    device = fun_control[\"device\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric_name = type(fun_control[\"metric_torch\"]).__name__\n",
        "print(f\"loss: {df_eval}, Cross-validated {metric_name}: {df_metrics}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Detailed Hyperparameter Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-contour-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Contour plots.\n",
        "filename = \"./figures/\" + experiment_name\n",
        "spot_tuner.plot_important_hyperparameter_contour(filename=filename)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallel Coordinates Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "fig-label": "fig-parallel-25"
      },
      "outputs": [],
      "source": [
        "#| fig-cap: Parallel coordinates plots\n",
        "spot_tuner.parallel_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# close tensorbaoard writer\n",
        "if fun_control[\"writer\"] is not None:\n",
        "    fun_control[\"writer\"].close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot all Combinations of Hyperparameters\n",
        "\n",
        "* Warning: this may take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PLOT_ALL = False\n",
        "if PLOT_ALL:\n",
        "    n = spot_tuner.k\n",
        "    for i in range(n-1):\n",
        "        for j in range(i+1, n):\n",
        "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
