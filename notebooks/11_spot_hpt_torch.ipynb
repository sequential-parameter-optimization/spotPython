{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"River Hyperparameter Tuning with SPOT HATR\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME = 1\n",
    "INIT_SIZE = 3\n",
    "CLASSIFICATION = True\n",
    "REGRESSION = False\n",
    "MOONS = True\n",
    "MAKE_CLF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11-torch_maans05_1min_3init_2023-04-26_15-45-08'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "start_time = datetime.now(tzlocal())\n",
    "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
    "experiment_name = '11-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
    "experiment_name = experiment_name.replace(':', '-')\n",
    "experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Sequential Parameter Optimization\n",
    "## Hyperparameter Tuning: sklearn decision tree with Regreession Data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook exemplifies hyperparameter tuning with SPOT (spotPython).\n",
    "* The hyperparameter software SPOT was developed in R (statistical programming language), see Open Access book \"Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide\", available here: [https://link.springer.com/book/10.1007/978-981-19-5170-1](https://link.springer.com/book/10.1007/978-981-19-5170-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython               0.0.41\n",
      "spotRiver                0.0.91\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep  \"spot[RiverPython]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: HATR Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import copy\n",
    "import warnings\n",
    "import numbers\n",
    "import json\n",
    "import calendar\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.hyperparameters.values import (\n",
    "    add_core_model_to_fun_control,\n",
    "    assign_values,\n",
    "    convert_keys,\n",
    "    get_bound_values,\n",
    "    get_default_hyperparameters_for_core_model,\n",
    "    get_default_hyperparameters_for_fun,\n",
    "    get_default_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    get_values_from_dict,\n",
    "    get_var_name,\n",
    "    get_var_type,\n",
    "    iterate_dict_values,\n",
    "    modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds,\n",
    "    replace_levels_with_positions,\n",
    "    return_conf_list_from_var_dict,\n",
    "    get_one_sklearn_model_from_X)\n",
    "from spotPython.hyperparameters.prepare import (\n",
    "    transform_hyper_parameter_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    convert_keys,\n",
    "    iterate_dict_values,\n",
    ")\n",
    "\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.utils.eda import (\n",
    "    get_stars,\n",
    "    gen_design_table)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "\n",
    "from spotPython.data.torch_hyper_dict import TorchHyperDict\n",
    "from spotPython.fun.hypertorch import HyperTorch\n",
    "from spotPython.utils.convert import get_Xy_from_df\n",
    "from spotPython.plot.validation import plot_cv_predictions, plot_roc, plot_confusion_matrix\n",
    "from spotPython.torch.net import Net_CIFAR10\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder , MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline , Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization of the Empty `fun_control` Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data: Random Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 250\n",
    "target_column = \"y\"\n",
    "n_train = 0.6 * n_samples\n",
    "n_features = 50\n",
    "# Create a random dataset\n",
    "X, y = make_regression(n_samples=n_samples, n_features=n_features, noise=1, random_state=42)\n",
    "# take X and y and make a pandas dataframe with column names X1, X2, y\n",
    "df = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))))\n",
    "df.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "# split into train and test\n",
    "train = df.iloc[:int(n_train), :]\n",
    "test = df.iloc[int(n_train):, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MOONS:\n",
    "    n_features = 2\n",
    "    n_samples = 250\n",
    "    ds =  make_moons(n_samples, noise=0.5, random_state=0)\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "    train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "    test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "    train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_CLF:\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=40,\n",
    "        n_redundant=2,\n",
    "        n_repeated=1,\n",
    "        n_classes=2,\n",
    "        flip_y=0.25,\n",
    "        random_state=0,\n",
    "        class_sep=0.025,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "    train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "    test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "    train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    train.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape, test.data.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train)\n",
    "# add the dataset to the fun_control\n",
    "fun_control.update({\"data\": None, # dataset,\n",
    "               \"train\": train,\n",
    "               \"test\": test,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"target_column\": None})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specification of the Preprocessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "prep_model = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "        ],\n",
    "        remainder=StandardScaler(),\n",
    "    )\n",
    "prep_model = None\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select `algorithm` and `core_model_hyper_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_model  = RidgeCV\n",
    "core_model = Net_CIFAR10\n",
    "fun_control = add_core_model_to_fun_control(core_model=core_model,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=TorchHyperDict,\n",
    "                              filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': None,\n",
       " 'train': Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " 'test': Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " 'n_samples': 50000,\n",
       " 'target_column': None,\n",
       " 'prep_model': None,\n",
       " 'core_model': spotPython.torch.net.Net_CIFAR10,\n",
       " 'core_model_hyper_dict': {'l1': {'type': 'int',\n",
       "   'default': 5,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 2,\n",
       "   'upper': 9},\n",
       "  'l2': {'type': 'int',\n",
       "   'default': 5,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 2,\n",
       "   'upper': 9}},\n",
       " 'META': {'lr': {'type': 'float',\n",
       "   'default': 0.001,\n",
       "   'transform': 'None',\n",
       "   'lower': 0.0001,\n",
       "   'upper': 0.1},\n",
       "  'batch_size': {'type': 'int',\n",
       "   'default': 4,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 1,\n",
       "   'upper': 4}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': None,\n",
       " 'train': Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " 'test': Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " 'n_samples': 50000,\n",
       " 'target_column': None,\n",
       " 'prep_model': None,\n",
       " 'core_model': spotPython.torch.net.Net_CIFAR10,\n",
       " 'core_model_hyper_dict': {'l1': {'type': 'int',\n",
       "   'default': 5,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 2,\n",
       "   'upper': 9},\n",
       "  'l2': {'type': 'int',\n",
       "   'default': 5,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 2,\n",
       "   'upper': 9}},\n",
       " 'META': {'lr': {'type': 'float',\n",
       "   'default': 0.001,\n",
       "   'transform': 'None',\n",
       "   'lower': 0.0001,\n",
       "   'upper': 0.1},\n",
       "  'batch_size': {'type': 'int',\n",
       "   'default': 4,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 1,\n",
       "   'upper': 4}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_control\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_model\", [\"LinearRegression\"])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type numeric and integer (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"delta\", bounds=[1e-10, 1e-6])\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[3, 20])\n",
    "#fun_control = modify_hyper_parameter_bounds(fun_control, \"merit_preprune\", bounds=[0, 0])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selection of the Objective (Loss) Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two metrics:\n",
    "\n",
    "    1. `metric` is used for the river based evaluation via `eval_oml_iter_progressive`.\n",
    "    2. `metric_sklearn` is used for the sklearn based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = HyperTorch(seed=123, log_level=50).fun_torch\n",
    "weights = -1.0\n",
    "horizon = 7*24\n",
    "oml_grace_period = 2\n",
    "step = 100\n",
    "weight_coeff = 1.0\n",
    "\n",
    "fun_control.update({\n",
    "               \"data_dir\": None,\n",
    "               \"checkpoint_dir\": None,\n",
    "               \"horizon\": horizon,\n",
    "               \"oml_grace_period\": oml_grace_period,\n",
    "               \"weights\": weights,\n",
    "               \"step\": step,\n",
    "               \"log_level\": 50,\n",
    "               \"weight_coeff\": weight_coeff,\n",
    "               \"metric\": None,\n",
    "               \"metric_sklearn\": roc_auc_score\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': None,\n",
       " 'train': Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " 'test': Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " 'n_samples': 50000,\n",
       " 'target_column': None,\n",
       " 'prep_model': None,\n",
       " 'core_model': spotPython.torch.net.Net_CIFAR10,\n",
       " 'core_model_hyper_dict': {'l1': {'type': 'int',\n",
       "   'default': 5,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 2,\n",
       "   'upper': 9},\n",
       "  'l2': {'type': 'int',\n",
       "   'default': 5,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 2,\n",
       "   'upper': 9}},\n",
       " 'META': {'lr': {'type': 'float',\n",
       "   'default': 0.001,\n",
       "   'transform': 'None',\n",
       "   'lower': 0.0001,\n",
       "   'upper': 0.1},\n",
       "  'batch_size': {'type': 'int',\n",
       "   'default': 4,\n",
       "   'transform': 'transform_power_2_int',\n",
       "   'lower': 1,\n",
       "   'upper': 4}},\n",
       " 'data_dir': None,\n",
       " 'checkpoint_dir': None,\n",
       " 'horizon': 168,\n",
       " 'oml_grace_period': 2,\n",
       " 'weights': -1.0,\n",
       " 'step': 100,\n",
       " 'log_level': 50,\n",
       " 'weight_coeff': 1.0,\n",
       " 'metric': None,\n",
       " 'metric_sklearn': <function sklearn.metrics._ranking.roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_control"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calling the SPOT Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SPOT Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get types and variable names as well as lower and upper bounds for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "fun_control.update({\"var_type\": var_type,\n",
    "                    \"var_name\": var_name})\n",
    "\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name   | type   |   default |   lower |   upper |\n",
      "|--------|--------|-----------|---------|---------|\n",
      "| l1     | int    |         5 |       2 |       9 |\n",
      "| l2     | int    |         5 |       2 |       9 |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `Spot` Optimizer\n",
    "\n",
    "* Run SPOT for approx. x mins (`max_time`).\n",
    "* Note: the run takes longer, because the evaluation time of initial design (here: `initi_size`, 20 points) is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.225\n",
      "[1,  4000] loss: 0.955\n",
      "[1,  6000] loss: 0.576\n",
      "[1,  8000] loss: 0.407\n",
      "[1, 10000] loss: 0.314\n",
      "[2,  2000] loss: 1.487\n",
      "[2,  4000] loss: 0.716\n",
      "[2,  6000] loss: 0.468\n",
      "[2,  8000] loss: 0.350\n",
      "[2, 10000] loss: 0.275\n",
      "[3,  2000] loss: 1.283\n",
      "[3,  4000] loss: 0.650\n",
      "[3,  6000] loss: 0.411\n",
      "[3,  8000] loss: 0.309\n",
      "[3, 10000] loss: 0.246\n",
      "[1,  2000] loss: 2.114\n",
      "[1,  4000] loss: 0.892\n",
      "[1,  6000] loss: 0.536\n",
      "[1,  8000] loss: 0.383\n",
      "[1, 10000] loss: 0.294\n",
      "[2,  2000] loss: 1.400\n",
      "[2,  4000] loss: 0.686\n",
      "[2,  6000] loss: 0.444\n",
      "[2,  8000] loss: 0.323\n",
      "[2, 10000] loss: 0.257\n",
      "[3,  2000] loss: 1.214\n",
      "[3,  4000] loss: 0.608\n",
      "[3,  6000] loss: 0.400\n",
      "[3,  8000] loss: 0.297\n",
      "[3, 10000] loss: 0.235\n",
      "[1,  2000] loss: 2.178\n",
      "[1,  4000] loss: 0.940\n",
      "[1,  6000] loss: 0.565\n",
      "[1,  8000] loss: 0.397\n",
      "[1, 10000] loss: 0.306\n",
      "[2,  2000] loss: 1.471\n",
      "[2,  4000] loss: 0.724\n",
      "[2,  6000] loss: 0.468\n",
      "[2,  8000] loss: 0.345\n",
      "[2, 10000] loss: 0.270\n",
      "[3,  2000] loss: 1.325\n",
      "[3,  4000] loss: 0.654\n",
      "[3,  6000] loss: 0.434\n",
      "[3,  8000] loss: 0.317\n",
      "[3, 10000] loss: 0.253\n",
      "[1,  2000] loss: 2.256\n",
      "[1,  4000] loss: 0.972\n",
      "[1,  6000] loss: 0.589\n",
      "[1,  8000] loss: 0.414\n",
      "[1, 10000] loss: 0.314\n",
      "[2,  2000] loss: 1.504\n",
      "[2,  4000] loss: 0.752\n",
      "[2,  6000] loss: 0.483\n",
      "[2,  8000] loss: 0.350\n",
      "[2, 10000] loss: 0.282\n",
      "[3,  2000] loss: 1.349\n",
      "[3,  4000] loss: 0.683\n",
      "[3,  6000] loss: 0.451\n",
      "[3,  8000] loss: 0.334\n",
      "[3, 10000] loss: 0.263\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x11b8286d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot_sklearn = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = MAX_TIME,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_sklearn.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "LOAD = False\n",
    "\n",
    "if SAVE:\n",
    "    result_file_name = \"res_\" + experiment_name + \".pkl\"\n",
    "    with open(result_file_name, 'wb') as f:\n",
    "        pickle.dump(spot_sklearn, f)\n",
    "\n",
    "if LOAD:\n",
    "    result_file_name = \"res_ch10-friedman-hpt-0_maans03_60min_20init_1K_2023-04-14_10-11-19.pkl\"\n",
    "    with open(result_file_name, 'rb') as f:\n",
    "        spot_sklearn =  pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress of the hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Figures.d/11-torch_maans05_1min_3init_2023-04-26_15-45-08_progress.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spot_sklearn\u001b[39m.\u001b[39;49mplot_progress(log_y\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, filename\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../Figures.d/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m experiment_name\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_progress.pdf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/spotPython/spot/spot.py:552\u001b[0m, in \u001b[0;36mSpot.plot_progress\u001b[0;34m(self, show, log_x, log_y, filename, style, dpi)\u001b[0m\n\u001b[1;32m    550\u001b[0m     ax\u001b[39m.\u001b[39mset_yscale(\u001b[39m\"\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    551\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     pylab\u001b[39m.\u001b[39;49msavefig(filename, dpi\u001b[39m=\u001b[39;49mdpi, bbox_inches\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtight\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    553\u001b[0m \u001b[39mif\u001b[39;00m show:\n\u001b[1;32m    554\u001b[0m     pylab\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[39m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msavefig\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[39m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49msavefig(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1024\u001b[0m     fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mdraw_idle()  \u001b[39m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/figure.py:3343\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3339\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes:\n\u001b[1;32m   3340\u001b[0m         stack\u001b[39m.\u001b[39menter_context(\n\u001b[1;32m   3341\u001b[0m             ax\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39m_cm_set(facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m-> 3343\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(fname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[1;32m   2367\u001b[0m             filename,\n\u001b[1;32m   2368\u001b[0m             facecolor\u001b[39m=\u001b[39;49mfacecolor,\n\u001b[1;32m   2369\u001b[0m             edgecolor\u001b[39m=\u001b[39;49medgecolor,\n\u001b[1;32m   2370\u001b[0m             orientation\u001b[39m=\u001b[39;49morientation,\n\u001b[1;32m   2371\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39;49m_bbox_inches_restore,\n\u001b[1;32m   2372\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2373\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[39m=\u001b[39m {  \u001b[39m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfacecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morientation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbbox_inches_restore\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[39m=\u001b[39m optional_kws \u001b[39m-\u001b[39m {\u001b[39m*\u001b[39minspect\u001b[39m.\u001b[39msignature(meth)\u001b[39m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mwraps(meth)(\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: meth(\n\u001b[1;32m   2233\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m skip}))\n\u001b[1;32m   2234\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[39m=\u001b[39m meth\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/backends/backend_pdf.py:2808\u001b[0m, in \u001b[0;36mFigureCanvasPdf.print_pdf\u001b[0;34m(self, filename, bbox_inches_restore, metadata)\u001b[0m\n\u001b[1;32m   2806\u001b[0m     file \u001b[39m=\u001b[39m filename\u001b[39m.\u001b[39m_file\n\u001b[1;32m   2807\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2808\u001b[0m     file \u001b[39m=\u001b[39m PdfFile(filename, metadata\u001b[39m=\u001b[39;49mmetadata)\n\u001b[1;32m   2809\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2810\u001b[0m     file\u001b[39m.\u001b[39mnewPage(width, height)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/backends/backend_pdf.py:713\u001b[0m, in \u001b[0;36mPdfFile.__init__\u001b[0;34m(self, filename, metadata)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_file_like \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell_base \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 713\u001b[0m fh, opened \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39;49mto_filehandle(filename, \u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m, return_opened\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m opened:\n\u001b[1;32m    715\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:489\u001b[0m, in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    487\u001b[0m         fh \u001b[39m=\u001b[39m bz2\u001b[39m.\u001b[39mBZ2File(fname, flag)\n\u001b[1;32m    488\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m         fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(fname, flag, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m    490\u001b[0m     opened \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mseek\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Figures.d/11-torch_maans05_1min_3init_2023-04-26_15-45-08_progress.pdf'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_sklearn.plot_progress(log_y=False, filename=\"../Figures.d/\" + experiment_name+\"_progress.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Parameter   |   Value |\n",
      "|-------------|---------|\n",
      "| l1          |       4 |\n",
      "| l2          |       4 |\n"
     ]
    }
   ],
   "source": [
    "res = spot_sklearn.print_results(print_screen=False)\n",
    "print(tabulate(\n",
    "   res,\n",
    "   headers=[\"Parameter\", \"Value\"],\n",
    "   numalign=\"right\",\n",
    "   tablefmt=\"github\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Figures.d/11-torch_maans05_1min_3init_2023-04-26_15-45-08_importance.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spot_sklearn\u001b[39m.\u001b[39;49mplot_importance(threshold\u001b[39m=\u001b[39;49m\u001b[39m0.025\u001b[39;49m, filename\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../Figures.d/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m experiment_name\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_importance.pdf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/spotPython/spot/spot.py:760\u001b[0m, in \u001b[0;36mSpot.plot_importance\u001b[0;34m(self, threshold, filename, dpi)\u001b[0m\n\u001b[1;32m    758\u001b[0m     plt\u001b[39m.\u001b[39mxticks(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(imp[idx])), var_name)\n\u001b[1;32m    759\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 760\u001b[0m     plt\u001b[39m.\u001b[39;49msavefig(filename, bbox_inches\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtight\u001b[39;49m\u001b[39m\"\u001b[39;49m, dpi\u001b[39m=\u001b[39;49mdpi)\n\u001b[1;32m    761\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[39m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msavefig\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[39m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49msavefig(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1024\u001b[0m     fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mdraw_idle()  \u001b[39m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/figure.py:3343\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3339\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes:\n\u001b[1;32m   3340\u001b[0m         stack\u001b[39m.\u001b[39menter_context(\n\u001b[1;32m   3341\u001b[0m             ax\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39m_cm_set(facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m-> 3343\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(fname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[1;32m   2367\u001b[0m             filename,\n\u001b[1;32m   2368\u001b[0m             facecolor\u001b[39m=\u001b[39;49mfacecolor,\n\u001b[1;32m   2369\u001b[0m             edgecolor\u001b[39m=\u001b[39;49medgecolor,\n\u001b[1;32m   2370\u001b[0m             orientation\u001b[39m=\u001b[39;49morientation,\n\u001b[1;32m   2371\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39;49m_bbox_inches_restore,\n\u001b[1;32m   2372\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2373\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[39m=\u001b[39m {  \u001b[39m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfacecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morientation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbbox_inches_restore\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[39m=\u001b[39m optional_kws \u001b[39m-\u001b[39m {\u001b[39m*\u001b[39minspect\u001b[39m.\u001b[39msignature(meth)\u001b[39m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mwraps(meth)(\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: meth(\n\u001b[1;32m   2233\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m skip}))\n\u001b[1;32m   2234\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[39m=\u001b[39m meth\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/backends/backend_pdf.py:2808\u001b[0m, in \u001b[0;36mFigureCanvasPdf.print_pdf\u001b[0;34m(self, filename, bbox_inches_restore, metadata)\u001b[0m\n\u001b[1;32m   2806\u001b[0m     file \u001b[39m=\u001b[39m filename\u001b[39m.\u001b[39m_file\n\u001b[1;32m   2807\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2808\u001b[0m     file \u001b[39m=\u001b[39m PdfFile(filename, metadata\u001b[39m=\u001b[39;49mmetadata)\n\u001b[1;32m   2809\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2810\u001b[0m     file\u001b[39m.\u001b[39mnewPage(width, height)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/backends/backend_pdf.py:713\u001b[0m, in \u001b[0;36mPdfFile.__init__\u001b[0;34m(self, filename, metadata)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_file_like \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell_base \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 713\u001b[0m fh, opened \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39;49mto_filehandle(filename, \u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m, return_opened\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m opened:\n\u001b[1;32m    715\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:489\u001b[0m, in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    487\u001b[0m         fh \u001b[39m=\u001b[39m bz2\u001b[39m.\u001b[39mBZ2File(fname, flag)\n\u001b[1;32m    488\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m         fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(fname, flag, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m    490\u001b[0m     opened \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mseek\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Figures.d/11-torch_maans05_1min_3init_2023-04-26_15-45-08_importance.pdf'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_sklearn.plot_importance(threshold=0.025, filename=\"../Figures.d/\" + experiment_name+\"_importance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name   | type   |   default |   lower |   upper |   tuned |   importance | stars   |\n",
      "|--------|--------|-----------|---------|---------|---------|--------------|---------|\n",
      "| l1     | int    |         5 |       2 |       9 |     4.0 |       100.00 | ***     |\n",
      "| l2     | int    |         5 |       2 |       9 |     4.0 |         0.00 |         |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_sklearn))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 32, 'l2': 32}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_default = get_default_hyperparameters_for_core_model(fun_control=fun_control,\n",
    "                                                   hyper_dict=TorchHyperDict)\n",
    "values_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_default = make_pipeline(fun_control[\"prep_model\"], fun_control[\"core_model\"](**values_default))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SPOT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spot_sklearn.to_all_dim(spot_sklearn.min_X.reshape(1,-1))\n",
    "model_spot = get_one_sklearn_model_from_X(X, fun_control)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Compare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REGRESSION:\n",
    "    plot_cv_predictions(model_spot, fun_control)\n",
    "    plot_cv_predictions(model_default, fun_control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_default' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_roc([model_spot, model_default], fun_control, model_names\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mSpot\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDefault\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m plot_roc([model_default, model_spot], fun_control, model_names\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mDefault\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSpot\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_default' is not defined"
     ]
    }
   ],
   "source": [
    "plot_roc([model_spot, model_default], fun_control, model_names=[\"Spot\", \"Default\"])\n",
    "plot_roc([model_default, model_spot], fun_control, model_names=[\"Default\", \"Spot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_default' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_confusion_matrix(model_default, fun_control, title \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDefault\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_default' is not defined"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(model_default, fun_control, title = \"Default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR10' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_confusion_matrix(model_spot, fun_control, title\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSPOT\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/spotPython/plot/validation.py:86\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(model, fun_control, target_names, title)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_confusion_matrix\u001b[39m(model, fun_control, target_names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, title\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     83\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m    Plotting a confusion matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     X_train, y_train \u001b[39m=\u001b[39m get_Xy_from_df(fun_control[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m], fun_control[\u001b[39m\"\u001b[39;49m\u001b[39mtarget_column\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     87\u001b[0m     X_test, y_test \u001b[39m=\u001b[39m get_Xy_from_df(fun_control[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m], fun_control[\u001b[39m\"\u001b[39m\u001b[39mtarget_column\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/spotPython/utils/convert.py:39\u001b[0m, in \u001b[0;36mget_Xy_from_df\u001b[0;34m(df, target_column)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_Xy_from_df\u001b[39m(df, target_column) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m:\n\u001b[1;32m     27\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get X and y from a dataframe.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m    Parameters:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m        df (pandas.DataFrame): The input dataframe.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m        >>> X, y = get_Xy_from_df(df, \"c\")\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39m[target_column])\n\u001b[1;32m     40\u001b[0m     y \u001b[39m=\u001b[39m df[target_column]\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m X, y\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CIFAR10' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(model_spot, fun_control, title=\"SPOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3369550338596106, -1.2500466358006002)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(spot_sklearn.y), max(spot_sklearn.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hyperparameter Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For productive use, you might want to select:\n",
    "  * `min_z=min(spot_sklearn.y)` and\n",
    "  * `max_z = max(spot_sklearn.y)`\n",
    "* These settings are not so colorful as visualizations that use `None` for the ranges, but give better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1:  100.0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.025\n",
    "impo = spot_sklearn.print_importance(threshold=threshold, print_screen=True)\n",
    "var_plots = [i for i, x in enumerate(impo) if x[1] > threshold]\n",
    "min_z = min(spot_sklearn.y)\n",
    "max_z = max(spot_sklearn.y)\n",
    "n = spot_sklearn.k\n",
    "for i in var_plots:\n",
    "    for j in var_plots:\n",
    "        if j > i:\n",
    "            filename = \"../Figures.d/\" + experiment_name+\"_contour_\"+str(i)+\"_\"+str(j)+\".pdf\"\n",
    "            spot_sklearn.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z, filename=filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_sklearn.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_sklearn.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
