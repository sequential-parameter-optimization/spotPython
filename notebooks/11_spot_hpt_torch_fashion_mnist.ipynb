{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"pytorch Hyperparameter Tuning with SPOT: fashionMNIST\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME = 1\n",
    "INIT_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11-torch_p040025_1min_5init_2023-04-28_10-44-04'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "start_time = datetime.now(tzlocal())\n",
    "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
    "experiment_name = '11-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
    "experiment_name = experiment_name.replace(':', '-')\n",
    "experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Sequential Parameter Optimization\n",
    "## Hyperparameter Tuning: pytorch with fashionMNIST Data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook exemplifies hyperparameter tuning with SPOT (spotPython).\n",
    "* The hyperparameter software SPOT was developed in R (statistical programming language), see Open Access book \"Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide\", available here: [https://link.springer.com/book/10.1007/978-981-19-5170-1](https://link.springer.com/book/10.1007/978-981-19-5170-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython                                0.0.45\n",
      "spotRiver                                 0.0.92\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep  \"spot[RiverPython]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "import warnings\n",
    "import numbers\n",
    "import json\n",
    "import calendar\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.hyperparameters.values import (\n",
    "    add_core_model_to_fun_control,\n",
    "    assign_values,\n",
    "    convert_keys,\n",
    "    get_bound_values,\n",
    "    get_default_hyperparameters_for_core_model,\n",
    "    get_default_hyperparameters_for_fun,\n",
    "    get_default_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    get_values_from_dict,\n",
    "    get_var_name,\n",
    "    get_var_type,\n",
    "    iterate_dict_values,\n",
    "    modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds,\n",
    "    replace_levels_with_positions,\n",
    "    return_conf_list_from_var_dict,\n",
    "    get_one_sklearn_model_from_X)\n",
    "from spotPython.hyperparameters.prepare import (\n",
    "    transform_hyper_parameter_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    convert_keys,\n",
    "    iterate_dict_values,\n",
    ")\n",
    "\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.utils.eda import (\n",
    "    get_stars,\n",
    "    gen_design_table)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "\n",
    "from spotPython.data.torch_hyper_dict import TorchHyperDict\n",
    "from spotPython.fun.hypertorch import HyperTorch\n",
    "from spotPython.utils.convert import get_Xy_from_df\n",
    "from spotPython.plot.validation import plot_cv_predictions, plot_roc, plot_confusion_matrix\n",
    "from spotPython.torch.netfashionMNIST import Net_fashionMNIST\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import partial\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "MPS device:  mps\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS device: \", mps_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization of the Empty `fun_control` Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load fashionMNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2.2%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape, test.data.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train)\n",
    "# add the dataset to the fun_control\n",
    "fun_control.update({\"data\": None, # dataset,\n",
    "               \"train\": train,\n",
    "               \"test\": test,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"target_column\": None})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specification of the Preprocessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns = []\n",
    "# one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "# prep_model = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "#         ],\n",
    "#         remainder=StandardScaler(),\n",
    "#     )\n",
    "prep_model = None\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select `algorithm` and `core_model_hyper_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_model  = RidgeCV\n",
    "core_model = Net_fashionMNIST\n",
    "fun_control = add_core_model_to_fun_control(core_model=core_model,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=TorchHyperDict,\n",
    "                              filename=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_model\", [\"LinearRegression\"])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type numeric and integer (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"delta\", bounds=[1e-10, 1e-6])\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[3, 20])\n",
    "#fun_control = modify_hyper_parameter_bounds(fun_control, \"merit_preprune\", bounds=[0, 0])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selection of the Objective (Loss) Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two metrics:\n",
    "\n",
    "    1. `metric` is used for the river based evaluation via `eval_oml_iter_progressive`.\n",
    "    2. `metric_sklearn` is used for the sklearn based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = HyperTorch(seed=123, log_level=50).fun_torch\n",
    "weights = 1.0\n",
    "horizon = 7*24\n",
    "oml_grace_period = 2\n",
    "step = 100\n",
    "weight_coeff = 1.0\n",
    "\n",
    "fun_control.update({\n",
    "               \"data_dir\": None,\n",
    "               \"checkpoint_dir\": None,\n",
    "               \"horizon\": horizon,\n",
    "               \"oml_grace_period\": oml_grace_period,\n",
    "               \"weights\": weights,\n",
    "               \"step\": step,\n",
    "               \"log_level\": 50,\n",
    "               \"weight_coeff\": weight_coeff,\n",
    "               \"metric\": None,\n",
    "               \"metric_sklearn\": None\n",
    "               })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calling the SPOT Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SPOT Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get types and variable names as well as lower and upper bounds for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "fun_control.update({\"var_type\": var_type,\n",
    "                    \"var_name\": var_name})\n",
    "\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |\n",
      "|------------|--------|-----------|---------|---------|\n",
      "| l1         | int    |     5     |  2      |     9   |\n",
      "| l2         | int    |     5     |  2      |     9   |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 |\n",
      "| batch_size | int    |     4     |  1      |     4   |\n",
      "| epochs     | int    |     3     |  1      |     4   |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `Spot` Optimizer\n",
    "\n",
    "* Run SPOT for approx. x mins (`max_time`).\n",
    "* Note: the run takes longer, because the evaluation time of initial design (here: `initi_size`, 20 points) is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "[1,  2000] loss: 2.326\n",
      "[1,  4000] loss: 1.164\n",
      "[2,  2000] loss: 2.330\n",
      "[2,  4000] loss: 1.165\n",
      "[3,  2000] loss: 2.329\n",
      "[3,  4000] loss: 1.166\n",
      "[4,  2000] loss: 2.331\n",
      "[4,  4000] loss: 1.166\n",
      "Accuracy of the network on the validation data: 0.10016666666666667\n",
      "Using mps device\n",
      "[1,  2000] loss: 2.361\n",
      "[1,  4000] loss: 1.183\n",
      "[1,  6000] loss: 0.789\n",
      "[1,  8000] loss: 0.591\n",
      "[1, 10000] loss: 0.473\n",
      "[1, 12000] loss: 0.393\n",
      "[1, 14000] loss: 0.339\n",
      "[1, 16000] loss: 0.296\n",
      "[1, 18000] loss: 0.263\n",
      "[2,  2000] loss: 2.361\n",
      "[2,  4000] loss: 1.182\n",
      "[2,  6000] loss: 0.788\n",
      "[2,  8000] loss: 0.592\n",
      "[2, 10000] loss: 0.473\n",
      "[2, 12000] loss: 0.395\n",
      "[2, 14000] loss: 0.337\n",
      "[2, 16000] loss: 0.295\n",
      "[2, 18000] loss: 0.262\n",
      "[3,  2000] loss: 2.362\n",
      "[3,  4000] loss: 1.183\n",
      "[3,  6000] loss: 0.788\n",
      "[3,  8000] loss: 0.590\n",
      "[3, 10000] loss: 0.473\n",
      "[3, 12000] loss: 0.393\n",
      "[3, 14000] loss: 0.338\n",
      "[3, 16000] loss: 0.296\n",
      "[3, 18000] loss: 0.264\n",
      "[4,  2000] loss: 2.365\n",
      "[4,  4000] loss: 1.185\n",
      "[4,  6000] loss: 0.789\n",
      "[4,  8000] loss: 0.591\n",
      "[4, 10000] loss: 0.473\n",
      "[4, 12000] loss: 0.394\n",
      "[4, 14000] loss: 0.337\n",
      "[4, 16000] loss: 0.296\n",
      "[4, 18000] loss: 0.262\n",
      "[5,  2000] loss: 2.366\n",
      "[5,  4000] loss: 1.188\n",
      "[5,  6000] loss: 0.786\n",
      "[5,  8000] loss: 0.591\n",
      "[5, 10000] loss: 0.474\n",
      "[5, 12000] loss: 0.394\n",
      "[5, 14000] loss: 0.338\n",
      "[5, 16000] loss: 0.295\n",
      "[5, 18000] loss: 0.263\n",
      "[6,  2000] loss: 2.356\n",
      "[6,  4000] loss: 1.181\n",
      "[6,  6000] loss: 0.787\n",
      "[6,  8000] loss: 0.591\n",
      "[6, 10000] loss: 0.473\n",
      "[6, 12000] loss: 0.394\n",
      "[6, 14000] loss: 0.338\n",
      "[6, 16000] loss: 0.296\n",
      "[6, 18000] loss: 0.262\n",
      "[7,  2000] loss: 2.368\n",
      "[7,  4000] loss: 1.184\n",
      "[7,  6000] loss: 0.788\n",
      "[7,  8000] loss: 0.591\n",
      "[7, 10000] loss: 0.472\n",
      "[7, 12000] loss: 0.394\n",
      "[7, 14000] loss: 0.338\n",
      "[7, 16000] loss: 0.295\n",
      "[7, 18000] loss: 0.263\n",
      "[8,  2000] loss: 2.360\n",
      "[8,  4000] loss: 1.184\n",
      "[8,  6000] loss: 0.790\n",
      "[8,  8000] loss: 0.591\n",
      "[8, 10000] loss: 0.473\n",
      "[8, 12000] loss: 0.394\n",
      "[8, 14000] loss: 0.338\n",
      "[8, 16000] loss: 0.296\n",
      "[8, 18000] loss: 0.262\n",
      "Accuracy of the network on the validation data: 0.09904166666666667\n",
      "Using mps device\n",
      "[1,  2000] loss: 0.773\n",
      "[1,  4000] loss: 0.249\n",
      "[2,  2000] loss: 0.432\n",
      "[2,  4000] loss: 0.211\n",
      "[3,  2000] loss: 0.387\n",
      "[3,  4000] loss: 0.180\n",
      "[4,  2000] loss: 0.349\n",
      "[4,  4000] loss: 0.177\n",
      "[5,  2000] loss: 0.328\n",
      "[5,  4000] loss: 0.163\n",
      "[6,  2000] loss: 0.313\n",
      "[6,  4000] loss: 0.155\n",
      "[7,  2000] loss: 0.286\n",
      "[7,  4000] loss: 0.151\n",
      "[8,  2000] loss: 0.279\n",
      "[8,  4000] loss: 0.145\n",
      "[9,  2000] loss: 0.271\n",
      "[9,  4000] loss: 0.140\n",
      "[10,  2000] loss: 0.259\n",
      "[10,  4000] loss: 0.130\n",
      "[11,  2000] loss: 0.246\n",
      "[11,  4000] loss: 0.125\n",
      "[12,  2000] loss: 0.237\n",
      "[12,  4000] loss: 0.120\n",
      "[13,  2000] loss: 0.234\n",
      "[13,  4000] loss: 0.117\n",
      "[14,  2000] loss: 0.227\n",
      "[14,  4000] loss: 0.113\n",
      "[15,  2000] loss: 0.227\n",
      "[15,  4000] loss: 0.111\n",
      "[16,  2000] loss: 0.208\n",
      "[16,  4000] loss: 0.109\n",
      "Accuracy of the network on the validation data: 0.8750416666666667\n",
      "Using mps device\n",
      "[1,  2000] loss: 2.318\n",
      "[1,  4000] loss: 1.161\n",
      "[1,  6000] loss: 0.774\n",
      "[1,  8000] loss: 0.580\n",
      "[2,  2000] loss: 2.324\n",
      "[2,  4000] loss: 1.161\n",
      "[2,  6000] loss: 0.775\n",
      "[2,  8000] loss: 0.580\n",
      "[3,  2000] loss: 2.325\n",
      "[3,  4000] loss: 1.162\n",
      "[3,  6000] loss: 0.774\n",
      "[3,  8000] loss: 0.581\n",
      "[4,  2000] loss: 2.320\n",
      "[4,  4000] loss: 1.161\n",
      "[4,  6000] loss: 0.774\n",
      "[4,  8000] loss: 0.581\n",
      "Accuracy of the network on the validation data: 0.10079166666666667\n",
      "Using mps device\n",
      "[1,  2000] loss: 1.478\n",
      "[2,  2000] loss: 1.698\n",
      "Accuracy of the network on the validation data: 0.296375\n",
      "Using mps device\n",
      "[1,  2000] loss: 0.780\n",
      "[1,  4000] loss: 0.259\n",
      "[2,  2000] loss: 0.434\n",
      "[2,  4000] loss: 0.209\n",
      "[3,  2000] loss: 0.385\n",
      "[3,  4000] loss: 0.189\n",
      "[4,  2000] loss: 0.351\n",
      "[4,  4000] loss: 0.177\n",
      "[5,  2000] loss: 0.332\n",
      "[5,  4000] loss: 0.165\n",
      "[6,  2000] loss: 0.312\n",
      "[6,  4000] loss: 0.160\n",
      "[7,  2000] loss: 0.290\n",
      "[7,  4000] loss: 0.154\n",
      "[8,  2000] loss: 0.282\n",
      "[8,  4000] loss: 0.141\n",
      "[9,  2000] loss: 0.274\n",
      "[9,  4000] loss: 0.136\n",
      "[10,  2000] loss: 0.264\n",
      "[10,  4000] loss: 0.132\n",
      "[11,  2000] loss: 0.248\n",
      "[11,  4000] loss: 0.127\n",
      "[12,  2000] loss: 0.237\n",
      "[12,  4000] loss: 0.124\n",
      "[13,  2000] loss: 0.229\n",
      "[13,  4000] loss: 0.119\n",
      "[14,  2000] loss: 0.225\n",
      "[14,  4000] loss: 0.117\n",
      "[15,  2000] loss: 0.220\n",
      "[15,  4000] loss: 0.111\n",
      "[16,  2000] loss: 0.214\n",
      "[16,  4000] loss: 0.106\n",
      "Accuracy of the network on the validation data: 0.8837083333333333\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x2c024c880>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot_torch = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = MAX_TIME,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_torch.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "LOAD = False\n",
    "\n",
    "if SAVE:\n",
    "    result_file_name = \"res_\" + experiment_name + \".pkl\"\n",
    "    with open(result_file_name, 'wb') as f:\n",
    "        pickle.dump(spot_torch, f)\n",
    "\n",
    "if LOAD:\n",
    "    result_file_name = \"res_ch10-friedman-hpt-0_maans03_60min_20init_1K_2023-04-14_10-11-19.pkl\"\n",
    "    with open(result_file_name, 'rb') as f:\n",
    "        spot_torch =  pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress of the hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_torch.plot_progress(log_y=False, filename=\"../Figures.d/\" + experiment_name+\"_progress.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Parameter   |      Value |\n",
      "|-------------|------------|\n",
      "| l1          |          8 |\n",
      "| l2          |          7 |\n",
      "| lr          | 0.00349051 |\n",
      "| batch_size  |          3 |\n",
      "| epochs      |          4 |\n"
     ]
    }
   ],
   "source": [
    "res = spot_torch.print_results(print_screen=False)\n",
    "print(tabulate(\n",
    "   res,\n",
    "   headers=[\"Parameter\", \"Value\"],\n",
    "   numalign=\"right\",\n",
    "   tablefmt=\"github\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_torch.plot_importance(threshold=0.025, filename=\"../Figures.d/\" + experiment_name+\"_importance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |                tuned |   importance | stars   |\n",
      "|------------|--------|-----------|---------|---------|----------------------|--------------|---------|\n",
      "| l1         | int    |       5.0 |     2.0 |     9.0 |                  8.0 |         0.00 |         |\n",
      "| l2         | int    |       5.0 |     2.0 |     9.0 |                  7.0 |         0.00 |         |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 | 0.003490512603690571 |         0.00 |         |\n",
      "| batch_size | int    |       4.0 |     1.0 |     4.0 |                  3.0 |         0.00 |         |\n",
      "| epochs     | int    |       3.0 |     1.0 |     4.0 |                  4.0 |       100.00 | ***     |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_torch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 8}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_default = get_default_hyperparameters_for_core_model(fun_control=fun_control,\n",
    "                                                   hyper_dict=TorchHyperDict)\n",
    "values_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default = fun_control[\"core_model\"](**values_default)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SPOT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spot_torch.to_all_dim(spot_torch.min_X.reshape(1,-1))\n",
    "model_spot = get_one_sklearn_model_from_X(X, fun_control)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0849"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spot.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3229413004290351, 2.3794507309397064)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(spot_torch.y), max(spot_torch.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hyperparameter Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For productive use, you might want to select:\n",
    "  * `min_z=min(spot_torch.y)` and\n",
    "  * `max_z = max(spot_torch.y)`\n",
    "* These settings are not so colorful as visualizations that use `None` for the ranges, but give better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  100.0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.025\n",
    "impo = spot_torch.print_importance(threshold=threshold, print_screen=True)\n",
    "var_plots = [i for i, x in enumerate(impo) if x[1] > threshold]\n",
    "min_z = min(spot_torch.y)\n",
    "max_z = max(spot_torch.y)\n",
    "n = spot_torch.k\n",
    "for i in var_plots:\n",
    "    for j in var_plots:\n",
    "        if j > i:\n",
    "            filename = \"../Figures.d/\" + experiment_name+\"_contour_\"+str(i)+\"_\"+str(j)+\".pdf\"\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z, filename=filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_torch.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
