{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"pytorch Hyperparameter Tuning with SPOT: fashionMNIST\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME = 1\n",
    "INIT_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11-torch_bartz09_1min_5init_2023-04-29_08-37-55'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "start_time = datetime.now(tzlocal())\n",
    "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
    "experiment_name = '11-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
    "experiment_name = experiment_name.replace(':', '-')\n",
    "experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Sequential Parameter Optimization\n",
    "## Hyperparameter Tuning: pytorch with fashionMNIST Data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook exemplifies hyperparameter tuning with SPOT (spotPython).\n",
    "* The hyperparameter software SPOT was developed in R (statistical programming language), see Open Access book \"Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide\", available here: [https://link.springer.com/book/10.1007/978-981-19-5170-1](https://link.springer.com/book/10.1007/978-981-19-5170-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython                                0.0.46\n",
      "spotRiver                                 0.0.92\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep  \"spot[RiverPython]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "import warnings\n",
    "import numbers\n",
    "import json\n",
    "import calendar\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.hyperparameters.values import (\n",
    "    add_core_model_to_fun_control,\n",
    "    assign_values,\n",
    "    convert_keys,\n",
    "    get_bound_values,\n",
    "    get_default_hyperparameters_for_core_model,\n",
    "    get_default_hyperparameters_for_fun,\n",
    "    get_default_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    get_values_from_dict,\n",
    "    get_var_name,\n",
    "    get_var_type,\n",
    "    iterate_dict_values,\n",
    "    modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds,\n",
    "    replace_levels_with_positions,\n",
    "    return_conf_list_from_var_dict,\n",
    "    get_one_core_model_from_X)\n",
    "from spotPython.hyperparameters.prepare import (\n",
    "    transform_hyper_parameter_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    convert_keys,\n",
    "    iterate_dict_values,\n",
    ")\n",
    "\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.utils.eda import (\n",
    "    get_stars,\n",
    "    gen_design_table)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "\n",
    "from spotPython.data.torch_hyper_dict import TorchHyperDict\n",
    "from spotPython.fun.hypertorch import HyperTorch\n",
    "from spotPython.utils.convert import get_Xy_from_df\n",
    "from spotPython.plot.validation import plot_cv_predictions, plot_roc, plot_confusion_matrix\n",
    "from spotPython.torch.netfashionMNIST import Net_fashionMNIST\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import partial\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "MPS device:  mps\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS device: \", mps_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization of the Empty `fun_control` Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load fashionMNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape, test.data.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train)\n",
    "# add the dataset to the fun_control\n",
    "fun_control.update({\"data\": None, # dataset,\n",
    "               \"train\": train,\n",
    "               \"test\": test,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"target_column\": None})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specification of the Preprocessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns = []\n",
    "# one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "# prep_model = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "#         ],\n",
    "#         remainder=StandardScaler(),\n",
    "#     )\n",
    "prep_model = None\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select `algorithm` and `core_model_hyper_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_model  = RidgeCV\n",
    "core_model = Net_fashionMNIST\n",
    "fun_control = add_core_model_to_fun_control(core_model=core_model,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=TorchHyperDict,\n",
    "                              filename=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_model\", [\"LinearRegression\"])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type numeric and integer (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"delta\", bounds=[1e-10, 1e-6])\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[3, 20])\n",
    "#fun_control = modify_hyper_parameter_bounds(fun_control, \"merit_preprune\", bounds=[0, 0])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selection of the Objective (Loss) Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two metrics:\n",
    "\n",
    "    1. `metric` is used for the river based evaluation via `eval_oml_iter_progressive`.\n",
    "    2. `metric_sklearn` is used for the sklearn based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = HyperTorch(seed=123, log_level=50).fun_torch\n",
    "weights = 1.0\n",
    "horizon = 7*24\n",
    "oml_grace_period = 2\n",
    "step = 100\n",
    "weight_coeff = 1.0\n",
    "\n",
    "fun_control.update({\n",
    "               \"data_dir\": None,\n",
    "               \"checkpoint_dir\": None,\n",
    "               \"horizon\": horizon,\n",
    "               \"oml_grace_period\": oml_grace_period,\n",
    "               \"weights\": weights,\n",
    "               \"step\": step,\n",
    "               \"log_level\": 50,\n",
    "               \"weight_coeff\": weight_coeff,\n",
    "               \"metric\": None,\n",
    "               \"metric_sklearn\": None\n",
    "               })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calling the SPOT Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SPOT Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get types and variable names as well as lower and upper bounds for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "fun_control.update({\"var_type\": var_type,\n",
    "                    \"var_name\": var_name})\n",
    "\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |\n",
      "|------------|--------|-----------|---------|---------|\n",
      "| l1         | int    |     5     |  2      |     9   |\n",
      "| l2         | int    |     5     |  2      |     9   |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 |\n",
      "| batch_size | int    |     4     |  1      |     4   |\n",
      "| epochs     | int    |     3     |  1      |     4   |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `Spot` Optimizer\n",
    "\n",
    "* Run SPOT for approx. x mins (`max_time`).\n",
    "* Note: the run takes longer, because the evaluation time of initial design (here: `initi_size`, 20 points) is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "[1,  2000] loss: 2.325\n",
      "[1,  4000] loss: 1.164\n",
      "[2,  2000] loss: 2.330\n",
      "[2,  4000] loss: 1.166\n",
      "[3,  2000] loss: 2.331\n",
      "[3,  4000] loss: 1.165\n",
      "[4,  2000] loss: 2.328\n",
      "[4,  4000] loss: 1.165\n",
      "Accuracy of the network on the validation data: 0.10195833333333333\n",
      "Using mps device\n",
      "[1,  2000] loss: 2.363\n",
      "[1,  4000] loss: 1.178\n",
      "[1,  6000] loss: 0.790\n",
      "[1,  8000] loss: 0.591\n",
      "[1, 10000] loss: 0.472\n",
      "[1, 12000] loss: 0.394\n",
      "[1, 14000] loss: 0.338\n",
      "[1, 16000] loss: 0.295\n",
      "[1, 18000] loss: 0.263\n",
      "[2,  2000] loss: 2.364\n",
      "[2,  4000] loss: 1.182\n",
      "[2,  6000] loss: 0.787\n",
      "[2,  8000] loss: 0.592\n",
      "[2, 10000] loss: 0.474\n",
      "[2, 12000] loss: 0.394\n",
      "[2, 14000] loss: 0.338\n",
      "[2, 16000] loss: 0.296\n",
      "[2, 18000] loss: 0.262\n",
      "[3,  2000] loss: 2.367\n",
      "[3,  4000] loss: 1.180\n",
      "[3,  6000] loss: 0.789\n",
      "[3,  8000] loss: 0.591\n",
      "[3, 10000] loss: 0.473\n",
      "[3, 12000] loss: 0.394\n",
      "[3, 14000] loss: 0.337\n",
      "[3, 16000] loss: 0.296\n",
      "[3, 18000] loss: 0.262\n",
      "[4,  2000] loss: 2.364\n",
      "[4,  4000] loss: 1.183\n",
      "[4,  6000] loss: 0.787\n",
      "[4,  8000] loss: 0.591\n",
      "[4, 10000] loss: 0.472\n",
      "[4, 12000] loss: 0.394\n",
      "[4, 14000] loss: 0.338\n",
      "[4, 16000] loss: 0.295\n",
      "[4, 18000] loss: 0.263\n",
      "[5,  2000] loss: 2.363\n",
      "[5,  4000] loss: 1.181\n",
      "[5,  6000] loss: 0.789\n",
      "[5,  8000] loss: 0.591\n",
      "[5, 10000] loss: 0.472\n",
      "[5, 12000] loss: 0.395\n",
      "[5, 14000] loss: 0.338\n",
      "[5, 16000] loss: 0.297\n",
      "[5, 18000] loss: 0.263\n",
      "[6,  2000] loss: 2.364\n",
      "[6,  4000] loss: 1.184\n",
      "[6,  6000] loss: 0.788\n",
      "[6,  8000] loss: 0.592\n",
      "[6, 10000] loss: 0.473\n",
      "[6, 12000] loss: 0.393\n",
      "[6, 14000] loss: 0.338\n",
      "[6, 16000] loss: 0.295\n",
      "[6, 18000] loss: 0.263\n",
      "[7,  2000] loss: 2.365\n",
      "[7,  4000] loss: 1.183\n",
      "[7,  6000] loss: 0.788\n",
      "[7,  8000] loss: 0.591\n",
      "[7, 10000] loss: 0.474\n",
      "[7, 12000] loss: 0.394\n",
      "[7, 14000] loss: 0.338\n",
      "[7, 16000] loss: 0.296\n",
      "[7, 18000] loss: 0.263\n",
      "[8,  2000] loss: 2.370\n",
      "[8,  4000] loss: 1.181\n",
      "[8,  6000] loss: 0.786\n",
      "[8,  8000] loss: 0.591\n",
      "[8, 10000] loss: 0.472\n",
      "[8, 12000] loss: 0.395\n",
      "[8, 14000] loss: 0.338\n",
      "[8, 16000] loss: 0.296\n",
      "[8, 18000] loss: 0.263\n",
      "Accuracy of the network on the validation data: 0.09983333333333333\n",
      "Using mps device\n",
      "[1,  2000] loss: 0.778\n",
      "[1,  4000] loss: 0.249\n",
      "[2,  2000] loss: 0.439\n",
      "[2,  4000] loss: 0.208\n",
      "[3,  2000] loss: 0.390\n",
      "[3,  4000] loss: 0.186\n",
      "[4,  2000] loss: 0.357\n",
      "[4,  4000] loss: 0.173\n",
      "[5,  2000] loss: 0.332\n",
      "[5,  4000] loss: 0.162\n",
      "[6,  2000] loss: 0.309\n",
      "[6,  4000] loss: 0.154\n",
      "[7,  2000] loss: 0.307\n",
      "[7,  4000] loss: 0.146\n",
      "[8,  2000] loss: 0.279\n",
      "[8,  4000] loss: 0.142\n",
      "[9,  2000] loss: 0.278\n",
      "[9,  4000] loss: 0.136\n",
      "[10,  2000] loss: 0.262\n",
      "[10,  4000] loss: 0.130\n",
      "[11,  2000] loss: 0.246\n",
      "[11,  4000] loss: 0.129\n",
      "[12,  2000] loss: 0.238\n",
      "[12,  4000] loss: 0.126\n",
      "[13,  2000] loss: 0.233\n",
      "[13,  4000] loss: 0.121\n",
      "[14,  2000] loss: 0.223\n",
      "[14,  4000] loss: 0.116\n",
      "[15,  2000] loss: 0.212\n",
      "[15,  4000] loss: 0.113\n",
      "[16,  2000] loss: 0.216\n",
      "[16,  4000] loss: 0.108\n",
      "Accuracy of the network on the validation data: 0.8813333333333333\n",
      "Using mps device\n",
      "[1,  2000] loss: 1.679\n",
      "[1,  4000] loss: 0.885\n",
      "[1,  6000] loss: 0.605\n",
      "[1,  8000] loss: 0.447\n",
      "[2,  2000] loss: 1.762\n",
      "[2,  4000] loss: 0.877\n",
      "[2,  6000] loss: 0.600\n",
      "[2,  8000] loss: 0.470\n",
      "[3,  2000] loss: 2.325\n",
      "[3,  4000] loss: 1.162\n",
      "[3,  6000] loss: 0.775\n",
      "[3,  8000] loss: 0.580\n",
      "[4,  2000] loss: 2.321\n",
      "[4,  4000] loss: 1.162\n",
      "[4,  6000] loss: 0.774\n",
      "[4,  8000] loss: 0.581\n",
      "Accuracy of the network on the validation data: 0.1\n",
      "Using mps device\n",
      "[1,  2000] loss: 1.222\n",
      "[2,  2000] loss: 1.523\n",
      "Accuracy of the network on the validation data: 0.296\n",
      "Using mps device\n",
      "[1,  2000] loss: 0.781\n",
      "[1,  4000] loss: 0.249\n",
      "[2,  2000] loss: 0.426\n",
      "[2,  4000] loss: 0.210\n",
      "[3,  2000] loss: 0.387\n",
      "[3,  4000] loss: 0.192\n",
      "[4,  2000] loss: 0.353\n",
      "[4,  4000] loss: 0.177\n",
      "[5,  2000] loss: 0.327\n",
      "[5,  4000] loss: 0.167\n",
      "[6,  2000] loss: 0.313\n",
      "[6,  4000] loss: 0.158\n",
      "[7,  2000] loss: 0.296\n",
      "[7,  4000] loss: 0.153\n",
      "[8,  2000] loss: 0.280\n",
      "[8,  4000] loss: 0.145\n",
      "[9,  2000] loss: 0.271\n",
      "[9,  4000] loss: 0.139\n",
      "[10,  2000] loss: 0.264\n",
      "[10,  4000] loss: 0.135\n",
      "[11,  2000] loss: 0.263\n",
      "[11,  4000] loss: 0.125\n",
      "[12,  2000] loss: 0.249\n",
      "[12,  4000] loss: 0.125\n",
      "[13,  2000] loss: 0.241\n",
      "[13,  4000] loss: 0.121\n",
      "[14,  2000] loss: 0.226\n",
      "[14,  4000] loss: 0.120\n",
      "[15,  2000] loss: 0.224\n",
      "[15,  4000] loss: 0.113\n",
      "[16,  2000] loss: 0.215\n",
      "[16,  4000] loss: 0.114\n",
      "Accuracy of the network on the validation data: 0.8733333333333333\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x2c809e8c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot_torch = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = MAX_TIME,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_torch.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "LOAD = False\n",
    "\n",
    "if SAVE:\n",
    "    result_file_name = \"res_\" + experiment_name + \".pkl\"\n",
    "    with open(result_file_name, 'wb') as f:\n",
    "        pickle.dump(spot_torch, f)\n",
    "\n",
    "if LOAD:\n",
    "    result_file_name = \"res_ch10-friedman-hpt-0_maans03_60min_20init_1K_2023-04-14_10-11-19.pkl\"\n",
    "    with open(result_file_name, 'rb') as f:\n",
    "        spot_torch =  pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress of the hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_torch.plot_progress(log_y=False, filename=\"../Figures.d/\" + experiment_name+\"_progress.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Parameter   |      Value |\n",
      "|-------------|------------|\n",
      "| l1          |          8 |\n",
      "| l2          |          7 |\n",
      "| lr          | 0.00361165 |\n",
      "| batch_size  |          3 |\n",
      "| epochs      |          4 |\n"
     ]
    }
   ],
   "source": [
    "res = spot_torch.print_results(print_screen=False)\n",
    "print(tabulate(\n",
    "   res,\n",
    "   headers=[\"Parameter\", \"Value\"],\n",
    "   numalign=\"right\",\n",
    "   tablefmt=\"github\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_torch.plot_importance(threshold=0.025, filename=\"../Figures.d/\" + experiment_name+\"_importance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |                tuned |   importance | stars   |\n",
      "|------------|--------|-----------|---------|---------|----------------------|--------------|---------|\n",
      "| l1         | int    |       5.0 |     2.0 |     9.0 |                  8.0 |         0.00 |         |\n",
      "| l2         | int    |       5.0 |     2.0 |     9.0 |                  7.0 |         0.00 |         |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 | 0.003611652909973722 |         0.00 |         |\n",
      "| batch_size | int    |       4.0 |     1.0 |     4.0 |                  3.0 |         0.00 |         |\n",
      "| epochs     | int    |       3.0 |     1.0 |     4.0 |                  4.0 |       100.00 | ***     |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_torch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 8}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_default = get_default_hyperparameters_for_core_model(fun_control=fun_control,\n",
    "                                                   hyper_dict=TorchHyperDict)\n",
    "values_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_fashionMNIST(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default = fun_control[\"core_model\"](**values_default)\n",
    "model_default\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SPOT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.00000000e+00 7.00000000e+00 3.61165291e-03 3.00000000e+00\n",
      "  4.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = spot_torch.to_all_dim(spot_torch.min_X.reshape(1,-1))\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_fashionMNIST(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spot = get_one_core_model_from_X(X, fun_control)\n",
    "model_spot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1302"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(x, fun_control):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "    x.to(device)\n",
    "\n",
    "    # trainset, testset = load_data()\n",
    "    testset = fun_control[\"test\"]\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=x.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = x(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1018"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spot.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34905356251782843, 2.342028640627861)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(spot_torch.y), max(spot_torch.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hyperparameter Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For productive use, you might want to select:\n",
    "  * `min_z=min(spot_torch.y)` and\n",
    "  * `max_z = max(spot_torch.y)`\n",
    "* These settings are not so colorful as visualizations that use `None` for the ranges, but give better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  100.0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.025\n",
    "impo = spot_torch.print_importance(threshold=threshold, print_screen=True)\n",
    "var_plots = [i for i, x in enumerate(impo) if x[1] > threshold]\n",
    "min_z = min(spot_torch.y)\n",
    "max_z = max(spot_torch.y)\n",
    "n = spot_torch.k\n",
    "for i in var_plots:\n",
    "    for j in var_plots:\n",
    "        if j > i:\n",
    "            filename = \"../Figures.d/\" + experiment_name+\"_contour_\"+str(i)+\"_\"+str(j)+\".pdf\"\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z, filename=filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_torch.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3),\n",
    "      nn.ReLU(),\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(26 * 26 * 10, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 10)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "  \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "  \n",
    "  # Configuration options\n",
    "  k_folds = 5\n",
    "  num_epochs = 1\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "  \n",
    "  # For fold results\n",
    "  results = {}\n",
    "  \n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "  \n",
    "  # Prepare MNIST dataset by concatenating Train/Test part; we split later.\n",
    "  dataset_train_part = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor(), train=True)\n",
    "  dataset_test_part = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor(), train=False)\n",
    "  dataset = ConcatDataset([dataset_train_part, dataset_test_part])\n",
    "  \n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    \n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    \n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=10, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=10, sampler=test_subsampler)\n",
    "    \n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "    \n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "        \n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "            \n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "    \n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "    \n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
