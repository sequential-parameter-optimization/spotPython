{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"pytorch Hyperparameter Tuning with SPOT \"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME = 720\n",
    "INIT_SIZE = 20\n",
    "CLASSIFICATION = True\n",
    "REGRESSION = False\n",
    "MOONS = False\n",
    "MAKE_CLF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11-torch_s7cfd16_720min_20init_2023-04-27_15-16-12'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "start_time = datetime.now(tzlocal())\n",
    "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
    "experiment_name = '11-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
    "experiment_name = experiment_name.replace(':', '-')\n",
    "experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Sequential Parameter Optimization\n",
    "## Hyperparameter Tuning: pytorch wth cifar10 Data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook exemplifies hyperparameter tuning with SPOT (spotPython).\n",
    "* The hyperparameter software SPOT was developed in R (statistical programming language), see Open Access book \"Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide\", available here: [https://link.springer.com/book/10.1007/978-981-19-5170-1](https://link.springer.com/book/10.1007/978-981-19-5170-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython                   0.0.44\n",
      "spotRiver                    0.0.79\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep  \"spot[RiverPython]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: HATR Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "import warnings\n",
    "import numbers\n",
    "import json\n",
    "import calendar\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.hyperparameters.values import (\n",
    "    add_core_model_to_fun_control,\n",
    "    assign_values,\n",
    "    convert_keys,\n",
    "    get_bound_values,\n",
    "    get_default_hyperparameters_for_core_model,\n",
    "    get_default_hyperparameters_for_fun,\n",
    "    get_default_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    get_values_from_dict,\n",
    "    get_var_name,\n",
    "    get_var_type,\n",
    "    iterate_dict_values,\n",
    "    modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds,\n",
    "    replace_levels_with_positions,\n",
    "    return_conf_list_from_var_dict,\n",
    "    get_one_sklearn_model_from_X)\n",
    "from spotPython.hyperparameters.prepare import (\n",
    "    transform_hyper_parameter_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    convert_keys,\n",
    "    iterate_dict_values,\n",
    ")\n",
    "\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.utils.eda import (\n",
    "    get_stars,\n",
    "    gen_design_table)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "\n",
    "from spotPython.data.torch_hyper_dict import TorchHyperDict\n",
    "from spotPython.fun.hypertorch import HyperTorch\n",
    "from spotPython.utils.convert import get_Xy_from_df\n",
    "from spotPython.plot.validation import plot_cv_predictions, plot_roc, plot_confusion_matrix\n",
    "from spotPython.torch.net import Net_CIFAR10\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n",
      "MPS not available because the current PyTorch install was not built with MPS enabled.\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS device: \", mps_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization of the Empty `fun_control` Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data: Random Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REGRESSION:\n",
    "    n_samples = 250\n",
    "    target_column = \"y\"\n",
    "    n_train = 0.6 * n_samples\n",
    "    n_features = 50\n",
    "    # Create a random dataset\n",
    "    X, y = make_regression(n_samples=n_samples, n_features=n_features, noise=1, random_state=42)\n",
    "    # take X and y and make a pandas dataframe with column names X1, X2, y\n",
    "    df = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))))\n",
    "    df.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    # split into train and test\n",
    "    train = df.iloc[:int(n_train), :]\n",
    "    test = df.iloc[int(n_train):, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MOONS:\n",
    "    n_features = 2\n",
    "    n_samples = 250\n",
    "    ds =  make_moons(n_samples, noise=0.5, random_state=0)\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "    train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "    test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "    train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_CLF:\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=40,\n",
    "        n_redundant=2,\n",
    "        n_repeated=1,\n",
    "        n_classes=2,\n",
    "        flip_y=0.25,\n",
    "        random_state=0,\n",
    "        class_sep=0.025,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "    train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "    test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "    train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    train.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape, test.data.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train)\n",
    "# add the dataset to the fun_control\n",
    "fun_control.update({\"data\": None, # dataset,\n",
    "               \"train\": train,\n",
    "               \"test\": test,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"target_column\": None})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specification of the Preprocessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns = []\n",
    "# one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "# prep_model = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "#         ],\n",
    "#         remainder=StandardScaler(),\n",
    "#     )\n",
    "prep_model = None\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select `algorithm` and `core_model_hyper_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_model  = RidgeCV\n",
    "core_model = Net_CIFAR10\n",
    "fun_control = add_core_model_to_fun_control(core_model=core_model,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=TorchHyperDict,\n",
    "                              filename=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_model\", [\"LinearRegression\"])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type numeric and integer (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"delta\", bounds=[1e-10, 1e-6])\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[3, 20])\n",
    "#fun_control = modify_hyper_parameter_bounds(fun_control, \"merit_preprune\", bounds=[0, 0])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selection of the Objective (Loss) Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two metrics:\n",
    "\n",
    "    1. `metric` is used for the river based evaluation via `eval_oml_iter_progressive`.\n",
    "    2. `metric_sklearn` is used for the sklearn based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = HyperTorch(seed=123, log_level=50).fun_torch\n",
    "weights = 1.0\n",
    "horizon = 7*24\n",
    "oml_grace_period = 2\n",
    "step = 100\n",
    "weight_coeff = 1.0\n",
    "\n",
    "fun_control.update({\n",
    "               \"data_dir\": None,\n",
    "               \"checkpoint_dir\": None,\n",
    "               \"horizon\": horizon,\n",
    "               \"oml_grace_period\": oml_grace_period,\n",
    "               \"weights\": weights,\n",
    "               \"step\": step,\n",
    "               \"log_level\": 50,\n",
    "               \"weight_coeff\": weight_coeff,\n",
    "               \"metric\": None,\n",
    "               \"metric_sklearn\": None\n",
    "               })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calling the SPOT Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SPOT Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get types and variable names as well as lower and upper bounds for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "fun_control.update({\"var_type\": var_type,\n",
    "                    \"var_name\": var_name})\n",
    "\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |\n",
      "|------------|--------|-----------|---------|---------|\n",
      "| l1         | int    |     5     |  2      |     9   |\n",
      "| l2         | int    |     5     |  2      |     9   |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 |\n",
      "| batch_size | int    |     4     |  1      |     4   |\n",
      "| epochs     | int    |     3     |  1      |     4   |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `Spot` Optimizer\n",
    "\n",
    "* Run SPOT for approx. x mins (`max_time`).\n",
    "* Note: the run takes longer, because the evaluation time of initial design (here: `initi_size`, 20 points) is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.345\n",
      "[1,  4000] loss: 1.174\n",
      "[1,  6000] loss: 0.783\n",
      "[1,  8000] loss: 0.587\n",
      "[1, 10000] loss: 0.470\n",
      "[2,  2000] loss: 2.348\n",
      "[2,  4000] loss: 1.173\n",
      "[2,  6000] loss: 0.783\n",
      "[2,  8000] loss: 0.587\n",
      "[2, 10000] loss: 0.470\n",
      "[3,  2000] loss: 2.348\n",
      "[3,  4000] loss: 1.176\n",
      "[3,  6000] loss: 0.781\n",
      "[3,  8000] loss: 0.587\n",
      "[3, 10000] loss: 0.469\n",
      "[4,  2000] loss: 2.345\n",
      "[4,  4000] loss: 1.174\n",
      "[4,  6000] loss: 0.783\n",
      "[4,  8000] loss: 0.586\n",
      "[4, 10000] loss: 0.470\n",
      "[5,  2000] loss: 2.347\n",
      "[5,  4000] loss: 1.173\n",
      "[5,  6000] loss: 0.782\n",
      "[5,  8000] loss: 0.586\n",
      "[5, 10000] loss: 0.469\n",
      "[6,  2000] loss: 2.346\n",
      "[6,  4000] loss: 1.176\n",
      "[6,  6000] loss: 0.783\n",
      "[6,  8000] loss: 0.587\n",
      "[6, 10000] loss: 0.471\n",
      "[7,  2000] loss: 2.349\n",
      "[7,  4000] loss: 1.173\n",
      "[7,  6000] loss: 0.782\n",
      "[7,  8000] loss: 0.587\n",
      "[7, 10000] loss: 0.469\n",
      "[8,  2000] loss: 2.346\n",
      "[8,  4000] loss: 1.175\n",
      "[8,  6000] loss: 0.783\n",
      "[8,  8000] loss: 0.586\n",
      "[8, 10000] loss: 0.470\n",
      "Accuracy of the network on the validation data: 0.0993\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.057\n",
      "[2,  2000] loss: 2.039\n",
      "[3,  2000] loss: 2.134\n",
      "[4,  2000] loss: 2.307\n",
      "[5,  2000] loss: 2.250\n",
      "[6,  2000] loss: 2.204\n",
      "[7,  2000] loss: 2.157\n",
      "[8,  2000] loss: 2.158\n",
      "Accuracy of the network on the validation data: 0.1691\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.337\n",
      "[1,  4000] loss: 1.169\n",
      "[1,  6000] loss: 0.778\n",
      "[1,  8000] loss: 0.584\n",
      "[1, 10000] loss: 0.467\n",
      "[2,  2000] loss: 2.334\n",
      "[2,  4000] loss: 1.168\n",
      "[2,  6000] loss: 0.779\n",
      "[2,  8000] loss: 0.584\n",
      "[2, 10000] loss: 0.467\n",
      "Accuracy of the network on the validation data: 0.0954\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.245\n",
      "[1,  4000] loss: 1.108\n",
      "[1,  6000] loss: 0.729\n",
      "[1,  8000] loss: 0.539\n",
      "[1, 10000] loss: 0.440\n",
      "[2,  2000] loss: 2.164\n",
      "[2,  4000] loss: 1.075\n",
      "[2,  6000] loss: 0.772\n",
      "[2,  8000] loss: 0.579\n",
      "[2, 10000] loss: 0.463\n",
      "[3,  2000] loss: 2.317\n",
      "[3,  4000] loss: 1.158\n",
      "[3,  6000] loss: 0.772\n",
      "[3,  8000] loss: 0.579\n",
      "[3, 10000] loss: 0.463\n",
      "[4,  2000] loss: 2.316\n",
      "[4,  4000] loss: 1.159\n",
      "[4,  6000] loss: 0.773\n",
      "[4,  8000] loss: 0.580\n",
      "[4, 10000] loss: 0.463\n",
      "[5,  2000] loss: 2.317\n",
      "[5,  4000] loss: 1.158\n",
      "[5,  6000] loss: 0.772\n",
      "[5,  8000] loss: 0.579\n",
      "[5, 10000] loss: 0.463\n",
      "[6,  2000] loss: 2.317\n",
      "[6,  4000] loss: 1.158\n",
      "[6,  6000] loss: 0.773\n",
      "[6,  8000] loss: 0.580\n",
      "[6, 10000] loss: 0.464\n",
      "[7,  2000] loss: 2.314\n",
      "[7,  4000] loss: 1.159\n",
      "[7,  6000] loss: 0.772\n",
      "[7,  8000] loss: 0.579\n",
      "[7, 10000] loss: 0.463\n",
      "[8,  2000] loss: 2.316\n",
      "[8,  4000] loss: 1.157\n",
      "[8,  6000] loss: 0.772\n",
      "[8,  8000] loss: 0.579\n",
      "[8, 10000] loss: 0.463\n",
      "[9,  2000] loss: 2.317\n",
      "[9,  4000] loss: 1.157\n",
      "[9,  6000] loss: 0.772\n",
      "[9,  8000] loss: 0.579\n",
      "[9, 10000] loss: 0.463\n",
      "[10,  2000] loss: 2.315\n",
      "[10,  4000] loss: 1.158\n",
      "[10,  6000] loss: 0.773\n",
      "[10,  8000] loss: 0.579\n",
      "[10, 10000] loss: 0.463\n",
      "[11,  2000] loss: 2.314\n",
      "[11,  4000] loss: 1.157\n",
      "[11,  6000] loss: 0.772\n",
      "[11,  8000] loss: 0.579\n",
      "[11, 10000] loss: 0.463\n",
      "[12,  2000] loss: 2.318\n",
      "[12,  4000] loss: 1.158\n",
      "[12,  6000] loss: 0.771\n",
      "[12,  8000] loss: 0.579\n",
      "[12, 10000] loss: 0.464\n",
      "[13,  2000] loss: 2.316\n",
      "[13,  4000] loss: 1.157\n",
      "[13,  6000] loss: 0.773\n",
      "[13,  8000] loss: 0.579\n",
      "[13, 10000] loss: 0.464\n",
      "[14,  2000] loss: 2.313\n",
      "[14,  4000] loss: 1.159\n",
      "[14,  6000] loss: 0.772\n",
      "[14,  8000] loss: 0.579\n",
      "[14, 10000] loss: 0.463\n",
      "[15,  2000] loss: 2.316\n",
      "[15,  4000] loss: 1.158\n",
      "[15,  6000] loss: 0.772\n",
      "[15,  8000] loss: 0.580\n",
      "[15, 10000] loss: 0.463\n",
      "[16,  2000] loss: 2.316\n",
      "[16,  4000] loss: 1.158\n",
      "[16,  6000] loss: 0.772\n",
      "[16,  8000] loss: 0.579\n",
      "[16, 10000] loss: 0.463\n",
      "Accuracy of the network on the validation data: 0.1039\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.315\n",
      "[1,  4000] loss: 1.160\n",
      "[2,  2000] loss: 2.319\n",
      "[2,  4000] loss: 1.159\n",
      "[3,  2000] loss: 2.317\n",
      "[3,  4000] loss: 1.159\n",
      "[4,  2000] loss: 2.317\n",
      "[4,  4000] loss: 1.160\n",
      "[5,  2000] loss: 2.315\n",
      "[5,  4000] loss: 1.159\n",
      "[6,  2000] loss: 2.316\n",
      "[6,  4000] loss: 1.159\n",
      "[7,  2000] loss: 2.318\n",
      "[7,  4000] loss: 1.160\n",
      "[8,  2000] loss: 2.317\n",
      "[8,  4000] loss: 1.159\n",
      "Accuracy of the network on the validation data: 0.1011\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.327\n",
      "[1,  4000] loss: 1.163\n",
      "[2,  2000] loss: 2.328\n",
      "[2,  4000] loss: 1.164\n",
      "[3,  2000] loss: 2.328\n",
      "[3,  4000] loss: 1.163\n",
      "[4,  2000] loss: 2.330\n",
      "[4,  4000] loss: 1.163\n",
      "[5,  2000] loss: 2.327\n",
      "[5,  4000] loss: 1.164\n",
      "[6,  2000] loss: 2.329\n",
      "[6,  4000] loss: 1.164\n",
      "[7,  2000] loss: 2.327\n",
      "[7,  4000] loss: 1.165\n",
      "[8,  2000] loss: 2.328\n",
      "[8,  4000] loss: 1.163\n",
      "Accuracy of the network on the validation data: 0.1022\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.270\n",
      "[2,  2000] loss: 2.285\n",
      "[3,  2000] loss: 2.312\n",
      "[4,  2000] loss: 2.311\n",
      "[5,  2000] loss: 2.312\n",
      "[6,  2000] loss: 2.312\n",
      "[7,  2000] loss: 2.313\n",
      "[8,  2000] loss: 2.312\n",
      "Accuracy of the network on the validation data: 0.0998\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.385\n",
      "[1,  4000] loss: 1.191\n",
      "[1,  6000] loss: 0.791\n",
      "[1,  8000] loss: 0.595\n",
      "[1, 10000] loss: 0.476\n",
      "[1, 12000] loss: 0.396\n",
      "[1, 14000] loss: 0.341\n",
      "[1, 16000] loss: 0.297\n",
      "[1, 18000] loss: 0.265\n",
      "[1, 20000] loss: 0.238\n",
      "[2,  2000] loss: 2.388\n",
      "[2,  4000] loss: 1.189\n",
      "[2,  6000] loss: 0.794\n",
      "[2,  8000] loss: 0.596\n",
      "[2, 10000] loss: 0.478\n",
      "[2, 12000] loss: 0.396\n",
      "[2, 14000] loss: 0.341\n",
      "[2, 16000] loss: 0.298\n",
      "[2, 18000] loss: 0.265\n",
      "[2, 20000] loss: 0.239\n",
      "[3,  2000] loss: 2.379\n",
      "[3,  4000] loss: 1.187\n",
      "[3,  6000] loss: 0.796\n",
      "[3,  8000] loss: 0.595\n",
      "[3, 10000] loss: 0.477\n",
      "[3, 12000] loss: 0.399\n",
      "[3, 14000] loss: 0.341\n",
      "[3, 16000] loss: 0.298\n",
      "[3, 18000] loss: 0.265\n",
      "[3, 20000] loss: 0.239\n",
      "[4,  2000] loss: 2.388\n",
      "[4,  4000] loss: 1.193\n",
      "[4,  6000] loss: 0.793\n",
      "[4,  8000] loss: 0.598\n",
      "[4, 10000] loss: 0.477\n",
      "[4, 12000] loss: 0.398\n",
      "[4, 14000] loss: 0.340\n",
      "[4, 16000] loss: 0.298\n",
      "[4, 18000] loss: 0.265\n",
      "[4, 20000] loss: 0.238\n",
      "[5,  2000] loss: 2.380\n",
      "[5,  4000] loss: 1.189\n",
      "[5,  6000] loss: 0.795\n",
      "[5,  8000] loss: 0.597\n",
      "[5, 10000] loss: 0.477\n",
      "[5, 12000] loss: 0.397\n",
      "[5, 14000] loss: 0.340\n",
      "[5, 16000] loss: 0.298\n",
      "[5, 18000] loss: 0.265\n",
      "[5, 20000] loss: 0.238\n",
      "[6,  2000] loss: 2.380\n",
      "[6,  4000] loss: 1.192\n",
      "[6,  6000] loss: 0.796\n",
      "[6,  8000] loss: 0.596\n",
      "[6, 10000] loss: 0.476\n",
      "[6, 12000] loss: 0.397\n",
      "[6, 14000] loss: 0.340\n",
      "[6, 16000] loss: 0.297\n",
      "[6, 18000] loss: 0.265\n",
      "[6, 20000] loss: 0.239\n",
      "[7,  2000] loss: 2.384\n",
      "[7,  4000] loss: 1.190\n",
      "[7,  6000] loss: 0.795\n",
      "[7,  8000] loss: 0.597\n",
      "[7, 10000] loss: 0.476\n",
      "[7, 12000] loss: 0.398\n",
      "[7, 14000] loss: 0.341\n",
      "[7, 16000] loss: 0.299\n",
      "[7, 18000] loss: 0.265\n",
      "[7, 20000] loss: 0.238\n",
      "[8,  2000] loss: 2.381\n",
      "[8,  4000] loss: 1.189\n",
      "[8,  6000] loss: 0.795\n",
      "[8,  8000] loss: 0.595\n",
      "[8, 10000] loss: 0.475\n",
      "[8, 12000] loss: 0.397\n",
      "[8, 14000] loss: 0.340\n",
      "[8, 16000] loss: 0.298\n",
      "[8, 18000] loss: 0.266\n",
      "[8, 20000] loss: 0.238\n",
      "Accuracy of the network on the validation data: 0.0956\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.347\n",
      "[1,  4000] loss: 1.176\n",
      "[1,  6000] loss: 0.782\n",
      "[1,  8000] loss: 0.587\n",
      "[1, 10000] loss: 0.470\n",
      "[2,  2000] loss: 2.346\n",
      "[2,  4000] loss: 1.172\n",
      "[2,  6000] loss: 0.784\n",
      "[2,  8000] loss: 0.588\n",
      "[2, 10000] loss: 0.470\n",
      "[3,  2000] loss: 2.356\n",
      "[3,  4000] loss: 1.175\n",
      "[3,  6000] loss: 0.783\n",
      "[3,  8000] loss: 0.587\n",
      "[3, 10000] loss: 0.470\n",
      "[4,  2000] loss: 2.353\n",
      "[4,  4000] loss: 1.174\n",
      "[4,  6000] loss: 0.784\n",
      "[4,  8000] loss: 0.587\n",
      "[4, 10000] loss: 0.469\n",
      "Accuracy of the network on the validation data: 0.0964\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.226\n",
      "[1,  4000] loss: 1.120\n",
      "[1,  6000] loss: 0.753\n",
      "[1,  8000] loss: 0.578\n",
      "[1, 10000] loss: 0.462\n",
      "[2,  2000] loss: 2.311\n",
      "[2,  4000] loss: 1.155\n",
      "[2,  6000] loss: 0.770\n",
      "[2,  8000] loss: 0.578\n",
      "[2, 10000] loss: 0.462\n",
      "Accuracy of the network on the validation data: 0.0998\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.307\n",
      "[1,  4000] loss: 1.158\n",
      "[2,  2000] loss: 2.316\n",
      "[2,  4000] loss: 1.158\n",
      "[3,  2000] loss: 2.315\n",
      "[3,  4000] loss: 1.158\n",
      "[4,  2000] loss: 2.314\n",
      "[4,  4000] loss: 1.158\n",
      "Accuracy of the network on the validation data: 0.098\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.335\n",
      "[1,  4000] loss: 1.169\n",
      "[1,  6000] loss: 0.780\n",
      "[1,  8000] loss: 0.585\n",
      "[1, 10000] loss: 0.468\n",
      "[1, 12000] loss: 0.389\n",
      "[1, 14000] loss: 0.334\n",
      "[1, 16000] loss: 0.292\n",
      "[1, 18000] loss: 0.260\n",
      "[1, 20000] loss: 0.234\n",
      "[2,  2000] loss: 2.338\n",
      "[2,  4000] loss: 1.168\n",
      "[2,  6000] loss: 0.780\n",
      "[2,  8000] loss: 0.584\n",
      "[2, 10000] loss: 0.467\n",
      "[2, 12000] loss: 0.389\n",
      "[2, 14000] loss: 0.334\n",
      "[2, 16000] loss: 0.292\n",
      "[2, 18000] loss: 0.260\n",
      "[2, 20000] loss: 0.234\n",
      "[3,  2000] loss: 2.336\n",
      "[3,  4000] loss: 1.169\n",
      "[3,  6000] loss: 0.779\n",
      "[3,  8000] loss: 0.584\n",
      "[3, 10000] loss: 0.467\n",
      "[3, 12000] loss: 0.390\n",
      "[3, 14000] loss: 0.334\n",
      "[3, 16000] loss: 0.293\n",
      "[3, 18000] loss: 0.260\n",
      "[3, 20000] loss: 0.234\n",
      "[4,  2000] loss: 2.340\n",
      "[4,  4000] loss: 1.171\n",
      "[4,  6000] loss: 0.778\n",
      "[4,  8000] loss: 0.585\n",
      "[4, 10000] loss: 0.468\n",
      "[4, 12000] loss: 0.390\n",
      "[4, 14000] loss: 0.334\n",
      "[4, 16000] loss: 0.293\n",
      "[4, 18000] loss: 0.260\n",
      "[4, 20000] loss: 0.234\n",
      "Accuracy of the network on the validation data: 0.1004\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.317\n",
      "[1,  4000] loss: 1.155\n",
      "[2,  2000] loss: 2.311\n",
      "[2,  4000] loss: 1.155\n",
      "[3,  2000] loss: 2.310\n",
      "[3,  4000] loss: 1.155\n",
      "[4,  2000] loss: 2.311\n",
      "[4,  4000] loss: 1.156\n",
      "[5,  2000] loss: 2.311\n",
      "[5,  4000] loss: 1.155\n",
      "[6,  2000] loss: 2.311\n",
      "[6,  4000] loss: 1.155\n",
      "[7,  2000] loss: 2.310\n",
      "[7,  4000] loss: 1.155\n",
      "[8,  2000] loss: 2.311\n",
      "[8,  4000] loss: 1.155\n",
      "[9,  2000] loss: 2.310\n",
      "[9,  4000] loss: 1.156\n",
      "[10,  2000] loss: 2.310\n",
      "[10,  4000] loss: 1.155\n",
      "[11,  2000] loss: 2.311\n",
      "[11,  4000] loss: 1.155\n",
      "[12,  2000] loss: 2.311\n",
      "[12,  4000] loss: 1.155\n",
      "[13,  2000] loss: 2.310\n",
      "[13,  4000] loss: 1.155\n",
      "[14,  2000] loss: 2.311\n",
      "[14,  4000] loss: 1.155\n",
      "[15,  2000] loss: 2.311\n",
      "[15,  4000] loss: 1.155\n",
      "[16,  2000] loss: 2.310\n",
      "[16,  4000] loss: 1.155\n",
      "Accuracy of the network on the validation data: 0.1019\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.315\n",
      "[2,  2000] loss: 2.317\n",
      "[3,  2000] loss: 2.315\n",
      "[4,  2000] loss: 2.316\n",
      "[5,  2000] loss: 2.315\n",
      "[6,  2000] loss: 2.316\n",
      "[7,  2000] loss: 2.315\n",
      "[8,  2000] loss: 2.316\n",
      "Accuracy of the network on the validation data: 0.1002\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.126\n",
      "[1,  4000] loss: 0.946\n",
      "[1,  6000] loss: 0.602\n",
      "[1,  8000] loss: 0.453\n",
      "[1, 10000] loss: 0.351\n",
      "[1, 12000] loss: 0.293\n",
      "[1, 14000] loss: 0.246\n",
      "[1, 16000] loss: 0.215\n",
      "[1, 18000] loss: 0.191\n",
      "[1, 20000] loss: 0.171\n",
      "[2,  2000] loss: 1.662\n",
      "[2,  4000] loss: 0.856\n",
      "[2,  6000] loss: 0.564\n",
      "[2,  8000] loss: 0.429\n",
      "[2, 10000] loss: 0.338\n",
      "[2, 12000] loss: 0.288\n",
      "[2, 14000] loss: 0.246\n",
      "[2, 16000] loss: 0.210\n",
      "[2, 18000] loss: 0.190\n",
      "[2, 20000] loss: 0.171\n",
      "[3,  2000] loss: 1.631\n",
      "[3,  4000] loss: 0.840\n",
      "[3,  6000] loss: 0.557\n",
      "[3,  8000] loss: 0.424\n",
      "[3, 10000] loss: 0.344\n",
      "[3, 12000] loss: 0.288\n",
      "[3, 14000] loss: 0.245\n",
      "[3, 16000] loss: 0.217\n",
      "[3, 18000] loss: 0.195\n",
      "[3, 20000] loss: 0.177\n",
      "[4,  2000] loss: 1.755\n",
      "[4,  4000] loss: 0.879\n",
      "[4,  6000] loss: 0.580\n",
      "[4,  8000] loss: 0.429\n",
      "[4, 10000] loss: 0.350\n",
      "[4, 12000] loss: 0.280\n",
      "[4, 14000] loss: 0.244\n",
      "[4, 16000] loss: 0.217\n",
      "[4, 18000] loss: 0.197\n",
      "[4, 20000] loss: 0.178\n",
      "Accuracy of the network on the validation data: 0.3818\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.007\n",
      "[1,  4000] loss: 0.933\n",
      "[2,  2000] loss: 1.818\n",
      "[2,  4000] loss: 0.900\n",
      "Accuracy of the network on the validation data: 0.3108\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.982\n",
      "[1,  4000] loss: 0.877\n",
      "[2,  2000] loss: 1.697\n",
      "[2,  4000] loss: 0.845\n",
      "[3,  2000] loss: 1.687\n",
      "[3,  4000] loss: 0.844\n",
      "[4,  2000] loss: 1.684\n",
      "[4,  4000] loss: 0.855\n",
      "Accuracy of the network on the validation data: 0.3546\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.332\n",
      "[1,  4000] loss: 1.166\n",
      "[2,  2000] loss: 2.330\n",
      "[2,  4000] loss: 1.164\n",
      "[3,  2000] loss: 2.330\n",
      "[3,  4000] loss: 1.166\n",
      "[4,  2000] loss: 2.330\n",
      "[4,  4000] loss: 1.165\n",
      "[5,  2000] loss: 2.331\n",
      "[5,  4000] loss: 1.165\n",
      "[6,  2000] loss: 2.330\n",
      "[6,  4000] loss: 1.166\n",
      "[7,  2000] loss: 2.332\n",
      "[7,  4000] loss: 1.167\n",
      "[8,  2000] loss: 2.331\n",
      "[8,  4000] loss: 1.165\n",
      "[9,  2000] loss: 2.331\n",
      "[9,  4000] loss: 1.165\n",
      "[10,  2000] loss: 2.330\n",
      "[10,  4000] loss: 1.166\n",
      "[11,  2000] loss: 2.331\n",
      "[11,  4000] loss: 1.165\n",
      "[12,  2000] loss: 2.331\n",
      "[12,  4000] loss: 1.165\n",
      "[13,  2000] loss: 2.330\n",
      "[13,  4000] loss: 1.166\n",
      "[14,  2000] loss: 2.331\n",
      "[14,  4000] loss: 1.165\n",
      "[15,  2000] loss: 2.329\n",
      "[15,  4000] loss: 1.166\n",
      "[16,  2000] loss: 2.332\n",
      "[16,  4000] loss: 1.166\n",
      "Accuracy of the network on the validation data: 0.1011\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.338\n",
      "[1,  4000] loss: 1.169\n",
      "[1,  6000] loss: 0.779\n",
      "[1,  8000] loss: 0.585\n",
      "[1, 10000] loss: 0.468\n",
      "[2,  2000] loss: 2.338\n",
      "[2,  4000] loss: 1.170\n",
      "[2,  6000] loss: 0.779\n",
      "[2,  8000] loss: 0.584\n",
      "[2, 10000] loss: 0.468\n",
      "[3,  2000] loss: 2.338\n",
      "[3,  4000] loss: 1.170\n",
      "[3,  6000] loss: 0.779\n",
      "[3,  8000] loss: 0.585\n",
      "[3, 10000] loss: 0.467\n",
      "[4,  2000] loss: 2.337\n",
      "[4,  4000] loss: 1.170\n",
      "[4,  6000] loss: 0.780\n",
      "[4,  8000] loss: 0.585\n",
      "[4, 10000] loss: 0.468\n",
      "Accuracy of the network on the validation data: 0.0969\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.328\n",
      "[1,  4000] loss: 1.165\n",
      "[1,  6000] loss: 0.776\n",
      "[1,  8000] loss: 0.583\n",
      "[1, 10000] loss: 0.466\n",
      "[2,  2000] loss: 2.329\n",
      "[2,  4000] loss: 1.164\n",
      "[2,  6000] loss: 0.776\n",
      "[2,  8000] loss: 0.582\n",
      "[2, 10000] loss: 0.466\n",
      "[3,  2000] loss: 2.327\n",
      "[3,  4000] loss: 1.165\n",
      "[3,  6000] loss: 0.776\n",
      "[3,  8000] loss: 0.582\n",
      "[3, 10000] loss: 0.466\n",
      "[4,  2000] loss: 2.328\n",
      "[4,  4000] loss: 1.165\n",
      "[4,  6000] loss: 0.776\n",
      "[4,  8000] loss: 0.582\n",
      "[4, 10000] loss: 0.466\n",
      "Accuracy of the network on the validation data: 0.0952\n",
      "We will use 4 GPUs!\n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.305\n",
      "[1,  4000] loss: 1.152\n",
      "[2,  2000] loss: 2.299\n",
      "[2,  4000] loss: 1.147\n",
      "Accuracy of the network on the validation data: 0.1592\n",
      "We will use 4 GPUs![----------] 0.11% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 2.054\n",
      "[1,  4000] loss: 0.879\n",
      "[1,  6000] loss: 0.562\n",
      "[1,  8000] loss: 0.405\n",
      "[1, 10000] loss: 0.322\n",
      "[2,  2000] loss: 1.567\n",
      "[2,  4000] loss: 0.776\n",
      "[2,  6000] loss: 0.526\n",
      "[2,  8000] loss: 0.393\n",
      "[2, 10000] loss: 0.314\n",
      "[3,  2000] loss: 1.516\n",
      "[3,  4000] loss: 0.762\n",
      "[3,  6000] loss: 0.508\n",
      "[3,  8000] loss: 0.387\n",
      "[3, 10000] loss: 0.309\n",
      "[4,  2000] loss: 1.513\n",
      "[4,  4000] loss: 0.764\n",
      "[4,  6000] loss: 0.509\n",
      "[4,  8000] loss: 0.387\n",
      "[4, 10000] loss: 0.311\n",
      "Accuracy of the network on the validation data: 0.4505\n",
      "We will use 4 GPUs![----------] 0.52% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.941\n",
      "[1,  4000] loss: 0.803\n",
      "[2,  2000] loss: 1.479\n",
      "[2,  4000] loss: 0.736\n",
      "[3,  2000] loss: 1.405\n",
      "[3,  4000] loss: 0.695\n",
      "[4,  2000] loss: 1.339\n",
      "[4,  4000] loss: 0.683\n",
      "Accuracy of the network on the validation data: 0.4893\n",
      "We will use 4 GPUs![----------] 0.72% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.891\n",
      "[2,  2000] loss: 1.498\n",
      "[3,  2000] loss: 1.424\n",
      "[4,  2000] loss: 1.386\n",
      "Accuracy of the network on the validation data: 0.4646\n",
      "We will use 4 GPUs![----------] 0.85% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.879\n",
      "[1,  4000] loss: 0.798\n",
      "[2,  2000] loss: 1.508\n",
      "[2,  4000] loss: 0.740\n",
      "[3,  2000] loss: 1.432\n",
      "[3,  4000] loss: 0.706\n",
      "[4,  2000] loss: 1.407\n",
      "[4,  4000] loss: 0.705\n",
      "Accuracy of the network on the validation data: 0.5173\n",
      "We will use 4 GPUs![----------] 1.07% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.897\n",
      "[1,  4000] loss: 0.823\n",
      "[2,  2000] loss: 1.553\n",
      "[2,  4000] loss: 0.770\n",
      "[3,  2000] loss: 1.471\n",
      "[3,  4000] loss: 0.744\n",
      "[4,  2000] loss: 1.465\n",
      "[4,  4000] loss: 0.728\n",
      "Accuracy of the network on the validation data: 0.4702\n",
      "We will use 4 GPUs![----------] 1.29% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.963\n",
      "[1,  4000] loss: 0.817\n",
      "[2,  2000] loss: 1.527\n",
      "[2,  4000] loss: 0.747\n",
      "[3,  2000] loss: 1.453\n",
      "[3,  4000] loss: 0.721\n",
      "[4,  2000] loss: 1.391\n",
      "[4,  4000] loss: 0.707\n",
      "Accuracy of the network on the validation data: 0.4901\n",
      "We will use 4 GPUs![----------] 1.51% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.892\n",
      "[1,  4000] loss: 0.810\n",
      "[2,  2000] loss: 1.515\n",
      "[2,  4000] loss: 0.749\n",
      "[3,  2000] loss: 1.418\n",
      "[3,  4000] loss: 0.714\n",
      "[4,  2000] loss: 1.370\n",
      "[4,  4000] loss: 0.700\n",
      "Accuracy of the network on the validation data: 0.5163\n",
      "We will use 4 GPUs![----------] 1.71% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.921\n",
      "[1,  4000] loss: 0.820\n",
      "[2,  2000] loss: 1.555\n",
      "[2,  4000] loss: 0.776\n",
      "[3,  2000] loss: 1.489\n",
      "[3,  4000] loss: 0.762\n",
      "[4,  2000] loss: 1.493\n",
      "[4,  4000] loss: 0.754\n",
      "Accuracy of the network on the validation data: 0.4532\n",
      "We will use 4 GPUs![----------] 1.94% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.930\n",
      "[1,  4000] loss: 0.799\n",
      "[2,  2000] loss: 1.481\n",
      "[2,  4000] loss: 0.701\n",
      "[3,  2000] loss: 1.339\n",
      "[3,  4000] loss: 0.676\n",
      "[4,  2000] loss: 1.273\n",
      "[4,  4000] loss: 0.653\n",
      "Accuracy of the network on the validation data: 0.5167\n",
      "We will use 4 GPUs![----------] 2.17% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.791\n",
      "[2,  2000] loss: 1.364\n",
      "[3,  2000] loss: 1.215\n",
      "[4,  2000] loss: 1.098\n",
      "Accuracy of the network on the validation data: 0.5699\n",
      "We will use 4 GPUs![----------] 2.30% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.789\n",
      "[2,  2000] loss: 1.359\n",
      "[3,  2000] loss: 1.187\n",
      "[4,  2000] loss: 1.061\n",
      "Accuracy of the network on the validation data: 0.6034\n",
      "We will use 4 GPUs![----------] 2.44% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.859\n",
      "[2,  2000] loss: 1.403\n",
      "[3,  2000] loss: 1.237\n",
      "[4,  2000] loss: 1.115\n",
      "Accuracy of the network on the validation data: 0.5866\n",
      "We will use 4 GPUs![----------] 2.56% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.793\n",
      "[2,  2000] loss: 1.354\n",
      "[3,  2000] loss: 1.188\n",
      "[4,  2000] loss: 1.062\n",
      "Accuracy of the network on the validation data: 0.6093\n",
      "We will use 4 GPUs![----------] 2.69% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.879\n",
      "[2,  2000] loss: 1.418\n",
      "[3,  2000] loss: 1.253\n",
      "[4,  2000] loss: 1.137\n",
      "Accuracy of the network on the validation data: 0.6049\n",
      "We will use 4 GPUs![----------] 2.83% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.941\n",
      "[2,  2000] loss: 1.424\n",
      "[3,  2000] loss: 1.262\n",
      "[4,  2000] loss: 1.140\n",
      "Accuracy of the network on the validation data: 0.5813\n",
      "We will use 4 GPUs![----------] 2.96% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.888\n",
      "[2,  2000] loss: 1.427\n",
      "[3,  2000] loss: 1.255\n",
      "[4,  2000] loss: 1.138\n",
      "Accuracy of the network on the validation data: 0.5784\n",
      "We will use 4 GPUs![----------] 3.09% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.823\n",
      "[2,  2000] loss: 1.365\n",
      "[3,  2000] loss: 1.206\n",
      "[4,  2000] loss: 1.091\n",
      "Accuracy of the network on the validation data: 0.5726\n",
      "We will use 4 GPUs![----------] 3.22% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.828\n",
      "[2,  2000] loss: 1.387\n",
      "[3,  2000] loss: 1.234\n",
      "[4,  2000] loss: 1.104\n",
      "Accuracy of the network on the validation data: 0.6017\n",
      "We will use 4 GPUs![----------] 3.36% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.794\n",
      "[2,  2000] loss: 1.382\n",
      "[3,  2000] loss: 1.216\n",
      "[4,  2000] loss: 1.082\n",
      "Accuracy of the network on the validation data: 0.5952\n",
      "We will use 4 GPUs![----------] 3.50% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.822\n",
      "[2,  2000] loss: 1.389\n",
      "[3,  2000] loss: 1.226\n",
      "[4,  2000] loss: 1.112\n",
      "Accuracy of the network on the validation data: 0.5937\n",
      "We will use 4 GPUs![----------] 3.63% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.840\n",
      "[2,  2000] loss: 1.395\n",
      "[3,  2000] loss: 1.225\n",
      "[4,  2000] loss: 1.110\n",
      "Accuracy of the network on the validation data: 0.593\n",
      "We will use 4 GPUs![----------] 3.77% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.847\n",
      "[2,  2000] loss: 1.413\n",
      "[3,  2000] loss: 1.246\n",
      "[4,  2000] loss: 1.118\n",
      "Accuracy of the network on the validation data: 0.5858\n",
      "We will use 4 GPUs![----------] 3.91% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.860\n",
      "[2,  2000] loss: 1.409\n",
      "[3,  2000] loss: 1.239\n",
      "[4,  2000] loss: 1.108\n",
      "Accuracy of the network on the validation data: 0.5729\n",
      "We will use 4 GPUs![----------] 4.04% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.815\n",
      "[2,  2000] loss: 1.365\n",
      "[3,  2000] loss: 1.185\n",
      "[4,  2000] loss: 1.061\n",
      "Accuracy of the network on the validation data: 0.5939\n",
      "We will use 4 GPUs![----------] 4.18% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.840\n",
      "[2,  2000] loss: 1.378\n",
      "[3,  2000] loss: 1.198\n",
      "[4,  2000] loss: 1.082\n",
      "Accuracy of the network on the validation data: 0.6093\n",
      "We will use 4 GPUs![----------] 4.33% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.816\n",
      "[2,  2000] loss: 1.375\n",
      "[3,  2000] loss: 1.202\n",
      "[4,  2000] loss: 1.068\n",
      "Accuracy of the network on the validation data: 0.599\n",
      "We will use 4 GPUs![----------] 4.46% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.876\n",
      "[2,  2000] loss: 1.391\n",
      "[3,  2000] loss: 1.231\n",
      "[4,  2000] loss: 1.120\n",
      "Accuracy of the network on the validation data: 0.5775\n",
      "We will use 4 GPUs![----------] 4.60% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.822\n",
      "[2,  2000] loss: 1.369\n",
      "[3,  2000] loss: 1.202\n",
      "[4,  2000] loss: 1.072\n",
      "Accuracy of the network on the validation data: 0.5942\n",
      "We will use 4 GPUs![----------] 4.74% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.813\n",
      "[2,  2000] loss: 1.414\n",
      "[3,  2000] loss: 1.244\n",
      "[4,  2000] loss: 1.125\n",
      "Accuracy of the network on the validation data: 0.5708\n",
      "We will use 4 GPUs![----------] 4.88% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.863\n",
      "[2,  2000] loss: 1.406\n",
      "[3,  2000] loss: 1.235\n",
      "[4,  2000] loss: 1.103\n",
      "Accuracy of the network on the validation data: 0.6002\n",
      "We will use 4 GPUs![#---------] 5.02% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.884\n",
      "[2,  2000] loss: 1.412\n",
      "[3,  2000] loss: 1.254\n",
      "[4,  2000] loss: 1.133\n",
      "Accuracy of the network on the validation data: 0.5849\n",
      "We will use 4 GPUs![#---------] 5.16% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.843\n",
      "[2,  2000] loss: 1.392\n",
      "[3,  2000] loss: 1.238\n",
      "[4,  2000] loss: 1.111\n",
      "Accuracy of the network on the validation data: 0.5738\n",
      "We will use 4 GPUs![#---------] 5.32% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.819\n",
      "[2,  2000] loss: 1.358\n",
      "[3,  2000] loss: 1.201\n",
      "[4,  2000] loss: 1.088\n",
      "Accuracy of the network on the validation data: 0.605\n",
      "We will use 4 GPUs![#---------] 5.46% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.827\n",
      "[2,  2000] loss: 1.395\n",
      "[3,  2000] loss: 1.248\n",
      "[4,  2000] loss: 1.129\n",
      "Accuracy of the network on the validation data: 0.5905\n",
      "We will use 4 GPUs![#---------] 5.60% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.869\n",
      "[2,  2000] loss: 1.393\n",
      "[3,  2000] loss: 1.218\n",
      "[4,  2000] loss: 1.086\n",
      "Accuracy of the network on the validation data: 0.5969\n",
      "We will use 4 GPUs![#---------] 5.74% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.844\n",
      "[2,  2000] loss: 1.407\n",
      "[3,  2000] loss: 1.229\n",
      "[4,  2000] loss: 1.104\n",
      "Accuracy of the network on the validation data: 0.5848\n",
      "We will use 4 GPUs![#---------] 5.88% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.860\n",
      "[2,  2000] loss: 1.395\n",
      "[3,  2000] loss: 1.220\n",
      "[4,  2000] loss: 1.087\n",
      "Accuracy of the network on the validation data: 0.6076\n",
      "We will use 4 GPUs![#---------] 6.02% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.835\n",
      "[2,  2000] loss: 1.395\n",
      "[3,  2000] loss: 1.221\n",
      "[4,  2000] loss: 1.097\n",
      "Accuracy of the network on the validation data: 0.5732\n",
      "We will use 4 GPUs![#---------] 6.16% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.836\n",
      "[2,  2000] loss: 1.386\n",
      "[3,  2000] loss: 1.215\n",
      "[4,  2000] loss: 1.091\n",
      "Accuracy of the network on the validation data: 0.604\n",
      "We will use 4 GPUs![#---------] 6.31% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.830\n",
      "[2,  2000] loss: 1.369\n",
      "[3,  2000] loss: 1.209\n",
      "[4,  2000] loss: 1.087\n",
      "Accuracy of the network on the validation data: 0.5943\n",
      "We will use 4 GPUs![#---------] 6.47% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.813\n",
      "[2,  2000] loss: 1.383\n",
      "[3,  2000] loss: 1.203\n",
      "[4,  2000] loss: 1.081\n",
      "Accuracy of the network on the validation data: 0.6031\n",
      "We will use 4 GPUs![#---------] 6.61% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.866\n",
      "[2,  2000] loss: 1.403\n",
      "[3,  2000] loss: 1.221\n",
      "[4,  2000] loss: 1.090\n",
      "Accuracy of the network on the validation data: 0.5927\n",
      "We will use 4 GPUs![#---------] 6.76% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.816\n",
      "[2,  2000] loss: 1.416\n",
      "[3,  2000] loss: 1.238\n",
      "[4,  2000] loss: 1.106\n",
      "Accuracy of the network on the validation data: 0.5874\n",
      "We will use 4 GPUs![#---------] 7.43% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.829\n",
      "[2,  2000] loss: 1.383\n",
      "[3,  2000] loss: 1.218\n",
      "[4,  2000] loss: 1.091\n",
      "Accuracy of the network on the validation data: 0.5894\n",
      "We will use 4 GPUs![#---------] 8.16% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.835\n",
      "[2,  2000] loss: 1.383\n",
      "[3,  2000] loss: 1.209\n",
      "[4,  2000] loss: 1.077\n",
      "Accuracy of the network on the validation data: 0.5763\n",
      "We will use 4 GPUs![#---------] 8.78% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.872\n",
      "[2,  2000] loss: 1.423\n",
      "[3,  2000] loss: 1.260\n",
      "[4,  2000] loss: 1.135\n",
      "Accuracy of the network on the validation data: 0.5883\n",
      "We will use 4 GPUs![#---------] 9.55% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.827\n",
      "[2,  2000] loss: 1.382\n",
      "[3,  2000] loss: 1.207\n",
      "[4,  2000] loss: 1.083\n",
      "Accuracy of the network on the validation data: 0.5943\n",
      "We will use 4 GPUs![#---------] 10.43% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.809\n",
      "[2,  2000] loss: 1.386\n",
      "[3,  2000] loss: 1.228\n",
      "[4,  2000] loss: 1.109\n",
      "Accuracy of the network on the validation data: 0.5734\n",
      "We will use 4 GPUs![#---------] 11.20% \n",
      "Using cuda device\n",
      "[1,  2000] loss: 1.813\n",
      "[2,  2000] loss: 1.392\n",
      "[3,  2000] loss: 1.222\n",
      "[4,  2000] loss: 1.101\n",
      "Accuracy of the network on the validation data: 0.5966\n"
     ]
    }
   ],
   "source": [
    "spot_torch = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = MAX_TIME,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_torch.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "LOAD = False\n",
    "\n",
    "if SAVE:\n",
    "    result_file_name = \"res_\" + experiment_name + \".pkl\"\n",
    "    with open(result_file_name, 'wb') as f:\n",
    "        pickle.dump(spot_torch, f)\n",
    "\n",
    "if LOAD:\n",
    "    result_file_name = \"res_ch10-friedman-hpt-0_maans03_60min_20init_1K_2023-04-14_10-11-19.pkl\"\n",
    "    with open(result_file_name, 'rb') as f:\n",
    "        spot_torch =  pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress of the hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_torch.plot_progress(log_y=False, filename=\"../Figures.d/\" + experiment_name+\"_progress.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = spot_torch.print_results(print_screen=False)\n",
    "print(tabulate(\n",
    "   res,\n",
    "   headers=[\"Parameter\", \"Value\"],\n",
    "   numalign=\"right\",\n",
    "   tablefmt=\"github\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_torch.plot_importance(threshold=0.025, filename=\"../Figures.d/\" + experiment_name+\"_importance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_torch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_default = get_default_hyperparameters_for_core_model(fun_control=fun_control,\n",
    "                                                   hyper_dict=TorchHyperDict)\n",
    "values_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default = fun_control[\"core_model\"](**values_default)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SPOT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spot_torch.to_all_dim(spot_torch.min_X.reshape(1,-1))\n",
    "model_spot = get_one_sklearn_model_from_X(X, fun_control)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spot.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(spot_torch.y), max(spot_torch.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hyperparameter Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For productive use, you might want to select:\n",
    "  * `min_z=min(spot_torch.y)` and\n",
    "  * `max_z = max(spot_torch.y)`\n",
    "* These settings are not so colorful as visualizations that use `None` for the ranges, but give better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.025\n",
    "impo = spot_torch.print_importance(threshold=threshold, print_screen=True)\n",
    "var_plots = [i for i, x in enumerate(impo) if x[1] > threshold]\n",
    "min_z = min(spot_torch.y)\n",
    "max_z = max(spot_torch.y)\n",
    "n = spot_torch.k\n",
    "for i in var_plots:\n",
    "    for j in var_plots:\n",
    "        if j > i:\n",
    "            filename = \"../Figures.d/\" + experiment_name+\"_contour_\"+str(i)+\"_\"+str(j)+\".pdf\"\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z, filename=filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_torch.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
