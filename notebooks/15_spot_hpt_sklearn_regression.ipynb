{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"River Hyperparameter Tuning with SPOT Sklearn\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME = 10\n",
    "INIT_SIZE = 50\n",
    "CLASSIFICATION = True\n",
    "REGRESSION = False\n",
    "MOONS = True\n",
    "MAKE_CLF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10-sklearn_maans03_10min_50init_2023-05-09_11-57-59'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "start_time = datetime.now(tzlocal())\n",
    "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
    "experiment_name = '10-sklearn' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
    "experiment_name = experiment_name.replace(':', '-')\n",
    "experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Sequential Parameter Optimization\n",
    "## Hyperparameter Tuning: sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook exemplifies hyperparameter tuning with SPOT (spotPython).\n",
    "* The hyperparameter software SPOT was developed in R (statistical programming language), see Open Access book \"Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide\", available here: [https://link.springer.com/book/10.1007/978-981-19-5170-1](https://link.springer.com/book/10.1007/978-981-19-5170-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython                        0.0.63\n",
      "spotRiver                         0.0.92\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep  \"spot[RiverPython]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import copy\n",
    "import warnings\n",
    "import numbers\n",
    "import json\n",
    "import calendar\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder , MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline , Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, roc_curve, roc_auc_score, log_loss, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.hyperparameters.values import (\n",
    "    add_core_model_to_fun_control,\n",
    "    assign_values,\n",
    "    convert_keys,\n",
    "    get_bound_values,\n",
    "    get_default_hyperparameters_for_core_model,\n",
    "    get_default_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    get_values_from_dict,\n",
    "    get_var_name,\n",
    "    get_var_type,\n",
    "    iterate_dict_values,\n",
    "    modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds,\n",
    "    replace_levels_with_positions,\n",
    "    return_conf_list_from_var_dict,\n",
    "    get_one_core_model_from_X,\n",
    "    transform_hyper_parameter_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    convert_keys,\n",
    "    iterate_dict_values,\n",
    "    get_one_sklearn_model_from_X\n",
    ")\n",
    "\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.utils.eda import (\n",
    "    get_stars,\n",
    "    gen_design_table)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "from spotPython.utils.convert import get_Xy_from_df\n",
    "from spotPython.plot.validation import plot_cv_predictions, plot_roc, plot_confusion_matrix\n",
    "from spotPython.utils.init import fun_control_init\n",
    "\n",
    "from spotPython.data.sklearn_hyper_dict import SklearnHyperDict\n",
    "from spotPython.fun.hypersklearn import HyperSklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization of the Empty `fun_control` Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = fun_control_init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data: Random Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REGRESSION:\n",
    "    n_samples = 250\n",
    "    target_column = \"y\"\n",
    "    n_train = 0.6 * n_samples\n",
    "    n_features = 50\n",
    "    # Create a random dataset\n",
    "    X, y = make_regression(n_samples=n_samples, n_features=n_features, noise=1, random_state=42)\n",
    "    # take X and y and make a pandas dataframe with column names X1, X2, y\n",
    "    df = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))))\n",
    "    df.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    # split into train and test\n",
    "    train = df.iloc[:int(n_train), :]\n",
    "    test = df.iloc[int(n_train):, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MOONS:\n",
    "    n_features = 2\n",
    "    n_samples = 250\n",
    "    target_column = \"y\"\n",
    "    ds =  make_moons(n_samples, noise=0.5, random_state=0)\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "    train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "    test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "    train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_CLF:\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=40,\n",
    "        n_redundant=2,\n",
    "        n_repeated=1,\n",
    "        n_classes=2,\n",
    "        flip_y=0.25,\n",
    "        random_state=0,\n",
    "        class_sep=0.025,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "    train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "    test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "    train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train)\n",
    "# add the dataset to the fun_control\n",
    "fun_control.update({\"data\": None, # dataset,\n",
    "               \"train\": train,\n",
    "               \"test\": test,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"target_column\": target_column})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specification of the Preprocessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "prep_model = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "        ],\n",
    "        remainder=StandardScaler(),\n",
    "    )\n",
    "prep_model = None\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select `algorithm` and `core_model_hyper_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_model  = RidgeCV\n",
    "# core_model = GradientBoostingRegressor\n",
    "# core_model = ElasticNet\n",
    "core_model = RandomForestClassifier\n",
    "# core_model = SVC\n",
    "# core_model = LogisticRegression\n",
    "# core_model = KNeighborsClassifier\n",
    "# core_model = GradientBoostingClassifier\n",
    "fun_control = add_core_model_to_fun_control(core_model=core_model,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=SklearnHyperDict,\n",
    "                              filename=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_model\", [\"LinearRegression\"])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type numeric and integer (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"delta\", bounds=[1e-10, 1e-6])\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[3, 20])\n",
    "#fun_control = modify_hyper_parameter_bounds(fun_control, \"merit_preprune\", bounds=[0, 0])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selection of the Objective (Loss) Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two metrics:\n",
    "\n",
    "    1. `metric` is used for the river based evaluation via `eval_oml_iter_progressive`.\n",
    "    2. `metric_sklearn` is used for the sklearn based evaluation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**:\n",
    "\n",
    "* `spotPython` performs minimization by default.\n",
    "* If accuracy or roc/auc should be maximized, then the objective function has to be multiplied by -1. Therefore, `weights` is set to -1 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = HyperSklearn(seed=123, log_level=50).fun_sklearn\n",
    "# metric_sklearn = roc_auc_score\n",
    "# weights = -1.0\n",
    "metric_sklearn = log_loss\n",
    "weights = 1.0\n",
    "\n",
    "fun_control.update({\n",
    "               \"horizon\": None,\n",
    "               \"oml_grace_period\": None,\n",
    "               \"weights\": weights,\n",
    "               \"step\": None,\n",
    "               \"log_level\": 50,\n",
    "               \"weight_coeff\": None,\n",
    "               \"metric\": None,\n",
    "               \"metric_sklearn\": metric_sklearn\n",
    "               })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calling the SPOT Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SPOT Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get types and variable names as well as lower and upper bounds for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "fun_control.update({\"var_type\": var_type,\n",
    "                    \"var_name\": var_name})\n",
    "\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                     | type   | default   |   lower |   upper | transform              |\n",
      "|--------------------------|--------|-----------|---------|---------|------------------------|\n",
      "| n_estimators             | int    | 7         |       5 |    9    | transform_power_2_int  |\n",
      "| criterion                | factor | gini      |       0 |    2    | None                   |\n",
      "| max_depth                | int    | 10        |       1 |   20    | transform_power_2_int  |\n",
      "| min_samples_split        | int    | 2         |       2 |  100    | None                   |\n",
      "| min_samples_leaf         | int    | 1         |       1 |   10    | None                   |\n",
      "| min_weight_fraction_leaf | float  | 0.0       |       0 |    0.01 | None                   |\n",
      "| max_features             | factor | sqrt      |       0 |    1    | transform_none_to_None |\n",
      "| max_leaf_nodes           | int    | 10        |       7 |   12    | transform_power_2_int  |\n",
      "| min_impurity_decrease    | float  | 0.0       |       0 |    0.01 | None                   |\n",
      "| bootstrap                | factor | 1         |       0 |    1    | None                   |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `Spot` Optimizer\n",
    "\n",
    "* Run SPOT for approx. x mins (`max_time`).\n",
    "* Note: the run takes longer, because the evaluation time of initial design (here: `initi_size`, 20 points) is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0., 10.,  2.,  1.,  0.,  0., 10.,  0.,  1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.hyperparameters.values import get_default_hyperparameters_as_array\n",
    "hyper_dict=SklearnHyperDict().load()\n",
    "X_start = get_default_hyperparameters_as_array(fun_control, hyper_dict)\n",
    "X_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: [----------] 3.18% \r"
     ]
    }
   ],
   "source": [
    "spot_tuner = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = MAX_TIME,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_tuner.run(X_start=X_start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "LOAD = False\n",
    "\n",
    "if SAVE:\n",
    "    result_file_name = \"res_\" + experiment_name + \".pkl\"\n",
    "    with open(result_file_name, 'wb') as f:\n",
    "        pickle.dump(spot_tuner, f)\n",
    "\n",
    "if LOAD:\n",
    "    result_file_name = \"res_ch10-friedman-hpt-0_maans03_60min_20init_1K_2023-04-14_10-11-19.pkl\"\n",
    "    with open(result_file_name, 'rb') as f:\n",
    "        spot_tuner =  pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress of the hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.plot_progress(log_y=False, filename=\"../Figures.d/\" + experiment_name+\"_progress.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.plot_importance(threshold=0.025, filename=\"../Figures.d/\" + experiment_name+\"_importance.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_default = get_default_values(fun_control)\n",
    "values_default = transform_hyper_parameter_values(fun_control=fun_control, hyper_parameter_values=values_default)\n",
    "values_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default = make_pipeline(fun_control[\"prep_model\"], fun_control[\"core_model\"](**values_default))\n",
    "model_default"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SPOT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_dict = assign_values(X, fun_control[\"var_name\"])\n",
    "return_conf_list_from_var_dict(var_dict=v_dict, fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spot = get_one_sklearn_model_from_X(X, fun_control)\n",
    "model_spot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Compare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REGRESSION:\n",
    "    plot_cv_predictions(model_spot, fun_control)\n",
    "    plot_cv_predictions(model_default, fun_control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([model_default, model_spot], fun_control, model_names=[\"Default\", \"Spot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_default, fun_control, title = \"Default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_spot, fun_control, title=\"SPOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(spot_tuner.y), max(spot_tuner.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hyperparameter Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For productive use, you might want to select:\n",
    "  * `min_z=min(spot_tuner.y)` and\n",
    "  * `max_z = max(spot_tuner.y)`\n",
    "* These settings are not so colorful as visualizations that use `None` for the ranges, but give better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.025\n",
    "impo = spot_tuner.print_importance(threshold=threshold, print_screen=True)\n",
    "var_plots = [i for i, x in enumerate(impo) if x[1] > threshold]\n",
    "min_z = min(spot_tuner.y)\n",
    "max_z = max(spot_tuner.y)\n",
    "n = spot_tuner.k\n",
    "for i in var_plots:\n",
    "    for j in var_plots:\n",
    "        if j > i:\n",
    "            filename = \"../Figures.d/\" + experiment_name+\"_contour_\"+str(i)+\"_\"+str(j)+\".pdf\"\n",
    "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z, filename=filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Coordinates Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.parallel_plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_tuner.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
