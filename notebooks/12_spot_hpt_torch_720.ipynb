{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"pytorch Hyperparameter Tuning with SPOT \"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME = 1\n",
    "INIT_SIZE = 5\n",
    "CLASSIFICATION = True\n",
    "REGRESSION = False\n",
    "MOONS = False\n",
    "MAKE_CLF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-torch_p040025_1min_5init_2023-04-28_10-23-47'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "start_time = datetime.now(tzlocal())\n",
    "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
    "experiment_name = '12-torch' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
    "experiment_name = experiment_name.replace(':', '-')\n",
    "experiment_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Sequential Parameter Optimization\n",
    "## Hyperparameter Tuning: pytorch wth cifar10 Data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook exemplifies hyperparameter tuning with SPOT (spotPython).\n",
    "* The hyperparameter software SPOT was developed in R (statistical programming language), see Open Access book \"Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide\", available here: [https://link.springer.com/book/10.1007/978-981-19-5170-1](https://link.springer.com/book/10.1007/978-981-19-5170-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython                                0.0.45\n",
      "spotRiver                                 0.0.92\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep  \"spot[RiverPython]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall spotPython\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: HATR Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "import warnings\n",
    "import numbers\n",
    "import json\n",
    "import calendar\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.hyperparameters.values import (\n",
    "    add_core_model_to_fun_control,\n",
    "    assign_values,\n",
    "    convert_keys,\n",
    "    get_bound_values,\n",
    "    get_default_hyperparameters_for_core_model,\n",
    "    get_default_hyperparameters_for_fun,\n",
    "    get_default_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    get_values_from_dict,\n",
    "    get_var_name,\n",
    "    get_var_type,\n",
    "    iterate_dict_values,\n",
    "    modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds,\n",
    "    replace_levels_with_positions,\n",
    "    return_conf_list_from_var_dict,\n",
    "    get_one_sklearn_model_from_X)\n",
    "from spotPython.hyperparameters.prepare import (\n",
    "    transform_hyper_parameter_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    convert_keys,\n",
    "    iterate_dict_values,\n",
    ")\n",
    "\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.utils.eda import (\n",
    "    get_stars,\n",
    "    gen_design_table)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "\n",
    "from spotPython.data.torch_hyper_dict import TorchHyperDict\n",
    "from spotPython.fun.hypertorch import HyperTorch\n",
    "from spotPython.utils.convert import get_Xy_from_df\n",
    "from spotPython.plot.validation import plot_cv_predictions, plot_roc, plot_confusion_matrix\n",
    "from spotPython.torch.netcifar10 import Net_CIFAR10\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "MPS device:  mps\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS device: \", mps_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization of the Empty `fun_control` Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data: Random Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REGRESSION:\n",
    "    n_samples = 250\n",
    "    target_column = \"y\"\n",
    "    n_train = 0.6 * n_samples\n",
    "    n_features = 50\n",
    "    # Create a random dataset\n",
    "    X, y = make_regression(n_samples=n_samples, n_features=n_features, noise=1, random_state=42)\n",
    "    # take X and y and make a pandas dataframe with column names X1, X2, y\n",
    "    df = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))))\n",
    "    df.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    # split into train and test\n",
    "    train = df.iloc[:int(n_train), :]\n",
    "    test = df.iloc[int(n_train):, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MOONS:\n",
    "    n_features = 2\n",
    "    n_samples = 250\n",
    "    ds =  make_moons(n_samples, noise=0.5, random_state=0)\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "    train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "    test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "    train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_CLF:\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=40,\n",
    "        n_redundant=2,\n",
    "        n_repeated=1,\n",
    "        n_classes=2,\n",
    "        flip_y=0.25,\n",
    "        random_state=0,\n",
    "        class_sep=0.025,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "    train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "    test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
    "    train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "    train.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape, test.data.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train)\n",
    "# add the dataset to the fun_control\n",
    "fun_control.update({\"data\": None, # dataset,\n",
    "               \"train\": train,\n",
    "               \"test\": test,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"target_column\": None})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specification of the Preprocessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns = []\n",
    "# one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "# prep_model = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "#         ],\n",
    "#         remainder=StandardScaler(),\n",
    "#     )\n",
    "prep_model = None\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select `algorithm` and `core_model_hyper_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_model  = RidgeCV\n",
    "core_model = Net_CIFAR10\n",
    "fun_control = add_core_model_to_fun_control(core_model=core_model,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=TorchHyperDict,\n",
    "                              filename=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_levels(fun_control, \"leaf_model\", [\"LinearRegression\"])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify hyperparameter of type numeric and integer (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"delta\", bounds=[1e-10, 1e-6])\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[3, 20])\n",
    "#fun_control = modify_hyper_parameter_bounds(fun_control, \"merit_preprune\", bounds=[0, 0])\n",
    "# fun_control[\"core_model_hyper_dict\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selection of the Objective (Loss) Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two metrics:\n",
    "\n",
    "    1. `metric` is used for the river based evaluation via `eval_oml_iter_progressive`.\n",
    "    2. `metric_sklearn` is used for the sklearn based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = HyperTorch(seed=123, log_level=50).fun_torch\n",
    "weights = 1.0\n",
    "horizon = 7*24\n",
    "oml_grace_period = 2\n",
    "step = 100\n",
    "weight_coeff = 1.0\n",
    "\n",
    "fun_control.update({\n",
    "               \"data_dir\": None,\n",
    "               \"checkpoint_dir\": None,\n",
    "               \"horizon\": horizon,\n",
    "               \"oml_grace_period\": oml_grace_period,\n",
    "               \"weights\": weights,\n",
    "               \"step\": step,\n",
    "               \"log_level\": 50,\n",
    "               \"weight_coeff\": weight_coeff,\n",
    "               \"metric\": None,\n",
    "               \"metric_sklearn\": None\n",
    "               })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calling the SPOT Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SPOT Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get types and variable names as well as lower and upper bounds for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "fun_control.update({\"var_type\": var_type,\n",
    "                    \"var_name\": var_name})\n",
    "\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |\n",
      "|------------|--------|-----------|---------|---------|\n",
      "| l1         | int    |     5     |  2      |     9   |\n",
      "| l2         | int    |     5     |  2      |     9   |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 |\n",
      "| batch_size | int    |     4     |  1      |     4   |\n",
      "| epochs     | int    |     3     |  1      |     4   |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `Spot` Optimizer\n",
    "\n",
    "* Run SPOT for approx. x mins (`max_time`).\n",
    "* Note: the run takes longer, because the evaluation time of initial design (here: `initi_size`, 20 points) is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "[1,  2000] loss: 2.329\n",
      "[1,  4000] loss: 1.165\n",
      "[2,  2000] loss: 2.329\n",
      "[2,  4000] loss: 1.165\n",
      "[3,  2000] loss: 2.330\n",
      "[3,  4000] loss: 1.166\n",
      "[4,  2000] loss: 2.330\n",
      "[4,  4000] loss: 1.164\n",
      "Accuracy of the network on the validation data: 0.106\n",
      "Using mps device\n",
      "[1,  2000] loss: 2.365\n",
      "[1,  4000] loss: 1.183\n",
      "[1,  6000] loss: 0.788\n",
      "[1,  8000] loss: 0.591\n",
      "[1, 10000] loss: 0.472\n",
      "[1, 12000] loss: 0.394\n",
      "[1, 14000] loss: 0.337\n",
      "[1, 16000] loss: 0.295\n",
      "[1, 18000] loss: 0.262\n",
      "[1, 20000] loss: 0.237\n",
      "[2,  2000] loss: 2.367\n",
      "[2,  4000] loss: 1.181\n",
      "[2,  6000] loss: 0.787\n",
      "[2,  8000] loss: 0.590\n",
      "[2, 10000] loss: 0.473\n",
      "[2, 12000] loss: 0.393\n",
      "[2, 14000] loss: 0.338\n",
      "[2, 16000] loss: 0.295\n",
      "[2, 18000] loss: 0.263\n",
      "[2, 20000] loss: 0.237\n",
      "[3,  2000] loss: 2.367\n",
      "[3,  4000] loss: 1.187\n",
      "[3,  6000] loss: 0.789\n",
      "[3,  8000] loss: 0.593\n",
      "[3, 10000] loss: 0.473\n",
      "[3, 12000] loss: 0.394\n",
      "[3, 14000] loss: 0.338\n",
      "[3, 16000] loss: 0.296\n",
      "[3, 18000] loss: 0.263\n",
      "[3, 20000] loss: 0.236\n",
      "[4,  2000] loss: 2.363\n",
      "[4,  4000] loss: 1.183\n",
      "[4,  6000] loss: 0.787\n",
      "[4,  8000] loss: 0.591\n",
      "[4, 10000] loss: 0.472\n",
      "[4, 12000] loss: 0.395\n",
      "[4, 14000] loss: 0.338\n",
      "[4, 16000] loss: 0.295\n",
      "[4, 18000] loss: 0.262\n",
      "[4, 20000] loss: 0.236\n",
      "[5,  2000] loss: 2.364\n",
      "[5,  4000] loss: 1.180\n",
      "[5,  6000] loss: 0.788\n",
      "[5,  8000] loss: 0.591\n",
      "[5, 10000] loss: 0.474\n",
      "[5, 12000] loss: 0.393\n",
      "[5, 14000] loss: 0.338\n",
      "[5, 16000] loss: 0.296\n",
      "[5, 18000] loss: 0.262\n",
      "[5, 20000] loss: 0.236\n",
      "[6,  2000] loss: 2.364\n",
      "[6,  4000] loss: 1.179\n",
      "[6,  6000] loss: 0.789\n",
      "[6,  8000] loss: 0.593\n",
      "[6, 10000] loss: 0.473\n",
      "[6, 12000] loss: 0.394\n",
      "[6, 14000] loss: 0.337\n",
      "[6, 16000] loss: 0.296\n",
      "[6, 18000] loss: 0.262\n",
      "[6, 20000] loss: 0.236\n",
      "[7,  2000] loss: 2.368\n",
      "[7,  4000] loss: 1.180\n",
      "[7,  6000] loss: 0.788\n",
      "[7,  8000] loss: 0.591\n",
      "[7, 10000] loss: 0.472\n",
      "[7, 12000] loss: 0.394\n",
      "[7, 14000] loss: 0.338\n",
      "[7, 16000] loss: 0.296\n",
      "[7, 18000] loss: 0.262\n",
      "[7, 20000] loss: 0.237\n",
      "[8,  2000] loss: 2.368\n",
      "[8,  4000] loss: 1.182\n",
      "[8,  6000] loss: 0.788\n",
      "[8,  8000] loss: 0.592\n",
      "[8, 10000] loss: 0.474\n",
      "[8, 12000] loss: 0.394\n",
      "[8, 14000] loss: 0.337\n",
      "[8, 16000] loss: 0.295\n",
      "[8, 18000] loss: 0.262\n",
      "[8, 20000] loss: 0.237\n",
      "Accuracy of the network on the validation data: 0.1004\n",
      "Using mps device\n",
      "[1,  2000] loss: 1.966\n",
      "[1,  4000] loss: 0.795\n",
      "[2,  2000] loss: 1.398\n",
      "[2,  4000] loss: 0.673\n",
      "[3,  2000] loss: 1.231\n",
      "[3,  4000] loss: 0.615\n",
      "[4,  2000] loss: 1.117\n",
      "[4,  4000] loss: 0.567\n",
      "[5,  2000] loss: 1.036\n",
      "[5,  4000] loss: 0.532\n",
      "[6,  2000] loss: 0.960\n",
      "[6,  4000] loss: 0.509\n",
      "[7,  2000] loss: 0.888\n",
      "[7,  4000] loss: 0.487\n",
      "[8,  2000] loss: 0.845\n",
      "[8,  4000] loss: 0.466\n",
      "[9,  2000] loss: 0.815\n",
      "[9,  4000] loss: 0.446\n",
      "[10,  2000] loss: 0.787\n",
      "[10,  4000] loss: 0.423\n",
      "[11,  2000] loss: 0.756\n",
      "[11,  4000] loss: 0.421\n",
      "[12,  2000] loss: 0.727\n",
      "[12,  4000] loss: 0.405\n",
      "[13,  2000] loss: 0.741\n",
      "[13,  4000] loss: 0.400\n",
      "[14,  2000] loss: 0.716\n",
      "[14,  4000] loss: 0.385\n",
      "[15,  2000] loss: 0.692\n",
      "[15,  4000] loss: 0.382\n",
      "[16,  2000] loss: 0.687\n",
      "[16,  4000] loss: 0.383\n",
      "Accuracy of the network on the validation data: 0.5665\n",
      "Using mps device\n",
      "[1,  2000] loss: 2.301\n",
      "[1,  4000] loss: 1.162\n",
      "[1,  6000] loss: 0.774\n",
      "[1,  8000] loss: 0.581\n",
      "[1, 10000] loss: 0.465\n",
      "[2,  2000] loss: 2.321\n",
      "[2,  4000] loss: 1.162\n",
      "[2,  6000] loss: 0.774\n",
      "[2,  8000] loss: 0.581\n",
      "[2, 10000] loss: 0.465\n",
      "[3,  2000] loss: 2.319\n",
      "[3,  4000] loss: 1.162\n",
      "[3,  6000] loss: 0.774\n",
      "[3,  8000] loss: 0.581\n",
      "[3, 10000] loss: 0.464\n",
      "[4,  2000] loss: 2.322\n",
      "[4,  4000] loss: 1.162\n",
      "[4,  6000] loss: 0.775\n",
      "[4,  8000] loss: 0.580\n",
      "[4, 10000] loss: 0.464\n",
      "Accuracy of the network on the validation data: 0.1004\n",
      "Using mps device\n",
      "[1,  2000] loss: 2.183\n",
      "[2,  2000] loss: 2.129\n",
      "Accuracy of the network on the validation data: 0.2105\n",
      "Using mps device\n",
      "[1,  2000] loss: 1.879\n",
      "[1,  4000] loss: 0.781\n",
      "[2,  2000] loss: 1.401\n",
      "[2,  4000] loss: 0.688\n",
      "[3,  2000] loss: 1.260\n",
      "[3,  4000] loss: 0.634\n",
      "[4,  2000] loss: 1.172\n",
      "[4,  4000] loss: 0.585\n",
      "[5,  2000] loss: 1.082\n",
      "[5,  4000] loss: 0.567\n",
      "[6,  2000] loss: 1.001\n",
      "[6,  4000] loss: 0.541\n",
      "[7,  2000] loss: 0.972\n",
      "[7,  4000] loss: 0.511\n",
      "[8,  2000] loss: 0.928\n",
      "[8,  4000] loss: 0.497\n",
      "[9,  2000] loss: 0.896\n",
      "[9,  4000] loss: 0.475\n",
      "[10,  2000] loss: 0.867\n",
      "[10,  4000] loss: 0.479\n",
      "[11,  2000] loss: 0.840\n",
      "[11,  4000] loss: 0.462\n",
      "[12,  2000] loss: 0.839\n",
      "[12,  4000] loss: 0.461\n",
      "[13,  2000] loss: 0.821\n",
      "[13,  4000] loss: 0.454\n",
      "[14,  2000] loss: 0.824\n",
      "[14,  4000] loss: 0.443\n",
      "[15,  2000] loss: 0.814\n",
      "[15,  4000] loss: 0.453\n",
      "[16,  2000] loss: 0.800\n",
      "[16,  4000] loss: 0.451\n",
      "Accuracy of the network on the validation data: 0.568\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x2a7487a30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot_torch = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = MAX_TIME,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_torch.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "LOAD = False\n",
    "\n",
    "if SAVE:\n",
    "    result_file_name = \"res_\" + experiment_name + \".pkl\"\n",
    "    with open(result_file_name, 'wb') as f:\n",
    "        pickle.dump(spot_torch, f)\n",
    "\n",
    "if LOAD:\n",
    "    result_file_name = \"res_ch10-friedman-hpt-0_maans03_60min_20init_1K_2023-04-14_10-11-19.pkl\"\n",
    "    with open(result_file_name, 'rb') as f:\n",
    "        spot_torch =  pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress of the hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu0AAAD9CAYAAAAI90nVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaAElEQVR4nO3dfWzV5f3/8deh2FMY7RHmSk97OooiN0NbcNxYSAWVQYCwNYTIGLFssMXNMktQDGQJjGxLgS9TWWCIc8KyQFCaFhfGYFVsC1gmIM0oGKZQpUApzsxzeuMKaa/fH/w4rNDT9pzenKs9z0dyoudwXTnv887b+PLjdT7HYYwxAgAAAGCtPuEuAAAAAEDrCO0AAACA5QjtAAAAgOUI7QAAAIDlCO0AAACA5QjtAAAAgOUI7QAAAIDl+oa7gPZoamrSlStXFBsbK4fDEe5yAAAAgA4zxqimpkaJiYnq06f1a+k9IrRfuXJFycnJ4S4DAAAA6HSVlZXyeDytrukRoT02NlbSzQ8UFxcX5moAAACAjvP5fEpOTvZn3db0iNB+60hMXFwcoR0AAAC9SnuOf/NFVAAAAMByhHYAAADAcj3ieEw4NTY26vDhw6qqqpLb7VZGRoaioqLCXRZ6OeYOAAD8L0J7K/Lz85WTk6NLly75X/N4PNq0aZPmzp0bxsrQmzF3AADgThyPCSA/P1/z5s1rFpwk6fLly5o3b57y8/PDVBl6M+YOAAC0xGGMMeEuoi0+n08ul0ter7db7h7T2NiolJSUu4LTLQ6HQx6PRxUVFRxZQKdh7gAAiCzBZFyutLfg8OHDAYOTdPPXqyorK3X48OFurAq9HXMHAAACIbS3oKqqqlPXAe3B3AEAgEAI7S1wu92dug5oD+YOAAAEQmhvQUZGhjweT8Bfp3I4HEpOTlZGRkY3V4bejLkDAACBENpbEBUVpU2bNkm6+2dlbz1/5ZVX+DIgOhVzBwAAAiG0BzB37lzl5eUpKSmp2esej0d5eXncLxtdgrkDAAAt4ZaPbeCXKREOzB0AAL1fMBmX0A4AAACEAfdpBwAAAHoRQjsAAABgOUI7AAAAYDlCOwAAAGA5QjsAAABgOUI7AAAAYDlCOwAAAGA5QjsAAABgOUI7AAAAYDlCOwAAAGA5QjsAAABgOUI7AAAAYDlCOwAAAGA5QjsAAABgOUI7AAAAYDlCOwAAAGA5QjsAAABgOUI7AAAAYLmgQntubq7Gjx+v2NhYxcfHKzMzU+fOnWt1zx/+8AdlZGRo4MCBGjhwoKZNm6YPPvigQ0UDAAAAkSSo0F5cXKzs7GwdO3ZMhYWFunHjhqZPn666urqAe4qKirRgwQK99957Ki0tVXJysqZPn67Lly93uHgAAAAgEjiMMSbUzZ9//rni4+NVXFysxx57rF17GhsbNXDgQG3evFlZWVktrmloaFBDQ4P/uc/nU3Jysrxer+Li4kItFwAAALCGz+eTy+VqV8bt0Jl2r9crSRo0aFC799TX1+vGjRut7snNzZXL5fI/kpOTO1ImAAAA0KOFfKW9qalJ3/3ud/Xll1/qyJEj7d737LPP6uDBgzpz5oxiYmJaXMOVdgAAAPR2wVxp7xvqm2RnZ6u8vDyowL5u3Trt3r1bRUVFAQO7JDmdTjmdzlBLAwAAAHqVkEL70qVLtW/fPpWUlMjj8bRrz8aNG7Vu3Tq98847Sk1NDeVtAQAAgIgUVGg3xujnP/+5CgoKVFRUpKFDh7Zr34YNG/Sb3/xGBw8e1Lhx40IqFAAAAIhUQYX27Oxs7dq1S2+//bZiY2N19epVSZLL5VK/fv0kSVlZWUpKSlJubq4kaf369Vq9erV27dqllJQU/54BAwZowIABnflZAAAAgF4pqLvHbN26VV6vV1OnTpXb7fY/3nzzTf+aixcvqqqqqtme69eva968ec32bNy4sfM+BQAAANCLBX08pi1FRUXNnn/66afBvAUAAACAO3ToPu0AAAAAuh6hHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsByhHQAAALAcoR0AAACwHKEdAAAAsFxQoT03N1fjx49XbGys4uPjlZmZqXPnzrW5b8+ePRo5cqRiYmL08MMPa//+/SEXDAAAAESaoEJ7cXGxsrOzdezYMRUWFurGjRuaPn266urqAu55//33tWDBAi1ZskSnTp1SZmamMjMzVV5e3uHiAQAAgEjgMMaYUDd//vnnio+PV3FxsR577LEW18yfP191dXXat2+f/7VHH31UY8aM0auvvtqu9/H5fHK5XPJ6vYqLiwu1XAAAAMAawWTcDp1p93q9kqRBgwYFXFNaWqpp06Y1e23GjBkqLS0NuKehoUE+n6/ZAwAAAIhUIYf2pqYmLVu2TJMnT9ZDDz0UcN3Vq1c1ePDgZq8NHjxYV69eDbgnNzdXLpfL/0hOTg61TAAAAKDHCzm0Z2dnq7y8XLt37+7MeiRJq1atktfr9T8qKys7/T0AAACAnqJvKJuWLl2qffv2qaSkRB6Pp9W1CQkJqq6ubvZadXW1EhISAu5xOp1yOp2hlAYAAAD0OkFdaTfGaOnSpSooKNChQ4c0dOjQNvekp6fr3XffbfZaYWGh0tPTg6sUAAAAiFBBXWnPzs7Wrl279Pbbbys2NtZ/Lt3lcqlfv36SpKysLCUlJSk3N1eSlJOToylTpui3v/2tZs+erd27d+vEiRN67bXXOvmjAAAAAL1TUFfat27dKq/Xq6lTp8rtdvsfb775pn/NxYsXVVVV5X8+adIk7dq1S6+99prS0tKUl5envXv3tvrlVQAAAAC3deg+7d2F+7QDAACgt+m2+7QDAAAA6HqEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByQYf2kpISzZkzR4mJiXI4HNq7d2+be3bu3Km0tDT1799fbrdbixcv1hdffBFKvQAAAEDECTq019XVKS0tTVu2bGnX+qNHjyorK0tLlizRmTNntGfPHn3wwQf6yU9+EnSxAAAAQCTqG+yGmTNnaubMme1eX1paqpSUFD333HOSpKFDh+qZZ57R+vXrg31rAAAAICJ1+Zn29PR0VVZWav/+/TLGqLq6Wnl5eZo1a1bAPQ0NDfL5fM0eAAAAQKTq8tA+efJk7dy5U/Pnz1d0dLQSEhLkcrlaPV6Tm5srl8vlfyQnJ3d1mQAAAIC1ujy0nz17Vjk5OVq9erVOnjypAwcO6NNPP9VPf/rTgHtWrVolr9frf1RWVnZ1mQAAAIC1gj7THqzc3FxNnjxZK1askCSlpqbqa1/7mjIyMvTrX/9abrf7rj1Op1NOp7OrSwMAAAB6hC6/0l5fX68+fZq/TVRUlCTJGNPVbw8AAAD0eEGH9traWpWVlamsrEySVFFRobKyMl28eFHSzaMtWVlZ/vVz5sxRfn6+tm7dqgsXLujo0aN67rnnNGHCBCUmJnbOpwAAAAB6saCPx5w4cUKPP/64//ny5cslSYsWLdKOHTtUVVXlD/CS9MMf/lA1NTXavHmznn/+ed1777164oknuOUjAAAA0E4O0wPOqPh8PrlcLnm9XsXFxYW7HAAAAKDDgsm4XX6mHQAAAEDHENoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAyxHaAQAAAMsR2gEAAADLEdoBAAAAywUd2ktKSjRnzhwlJibK4XBo7969be5paGjQL37xCw0ZMkROp1MpKSl64403QqkXAAAAiDh9g91QV1entLQ0LV68WHPnzm3XnqeeekrV1dX64x//qGHDhqmqqkpNTU1BFwsAAABEoqBD+8yZMzVz5sx2rz9w4ICKi4t14cIFDRo0SJKUkpIS7NsCAAAAEavLz7T/5S9/0bhx47RhwwYlJSVp+PDheuGFF/TVV18F3NPQ0CCfz9fsAQAAAESqoK+0B+vChQs6cuSIYmJiVFBQoH//+9969tln9cUXX2j79u0t7snNzdXatWu7ujQAAACgR+jyK+1NTU1yOBzauXOnJkyYoFmzZumll17Sn/70p4BX21etWiWv1+t/VFZWdnWZAAAAgLW6/Eq72+1WUlKSXC6X/7VRo0bJGKNLly7pwQcfvGuP0+mU0+ns6tIAAACAHqHLr7RPnjxZV65cUW1trf+1f/3rX+rTp488Hk9Xvz0AAADQ4wUd2mtra1VWVqaysjJJUkVFhcrKynTx4kVJN4+2ZGVl+df/4Ac/0Ne//nX96Ec/0tmzZ1VSUqIVK1Zo8eLF6tevX+d8CgAAAKAXCzq0nzhxQmPHjtXYsWMlScuXL9fYsWO1evVqSVJVVZU/wEvSgAEDVFhYqC+//FLjxo3TwoULNWfOHP3ud7/rpI8AAAAA9G4OY4wJdxFt8fl8crlc8nq9iouLC3c5AAAAQIcFk3G7/Ew7AAAAgI4htAMAAACWI7QDAAAAliO0AwAAAJbr8h9XAgD0HI2NjTp8+LCqqqrkdruVkZGhqKiocJeFXo65Q7g0Xr+u07//verPn1f/Bx7Qw88+q6jo6HCX1SJCOwBAkpSfn6+cnBxdunTJ/5rH49GmTZs0d+7cMFaG3oy5Q7gce/FFffOllzSmsdH/2pUXXtDF5cv16IYNYaysZdzyEQCg/Px8zZs3T3f+K8HhcEiS8vLyCFDodMwdwuXYiy9qwv/9n6TmZ8Wb/v9fP1ixoluCezAZl9DeBmOM6uvru/U9AaA7NTY2atSoUbpy5UrANUlJSTp79ixHFtBpmDuES+P166q97z4lNDW1+OXOJklVUVFKqK/v8qMywWRcjse0ob6+XgMGDAh3GQAQVpcvX5bL5Qp3GYgwzB26whRJRa38eR9JSY2NKvv97zVm2bJuqak9uHsMAAAAIoa7nevqz5/v0jqCxZX2NvTv31+1tbXhLgMAukxJSYlmzZrV5rr9+/frscce64aKEAmYO4RL+ebN0sqVba7r/8AD3VBN+3GmHQAiXGNjo1JSUnT58uW7vhAo3fxSoMfjUUVFBWeL0WmYO4RL4/Xrqu7fXwmNjT3qTDvHYwAgwkVFRWnTpk2Sbt+145Zbz1955RWCEzoVc4dwiYqO1sXlyyXdvlvMLbeeVy5fbt392gntAADNnTtXeXl5SkpKava6x+PhtnvoMswdwuXRDRv0wYoVunrHfxRWRUV12+0eg8XxGACAH79MiXBg7hAu4f5FVO7TDgAAAFiOM+0AAABAL9Ijbvl4638G+Hy+MFcCAAAAdI5b2bY9B196RGivqamRJCUnJ4e5EgAAAKBz1dTUtPnrvz3iTHtTU5OuXLmi2NjYu24L1R18Pp+Sk5NVWVnJmfog0bvQ0bvQ0buOoX+ho3eho3eho3cdE87+GWNUU1OjxMRE9enT+qn1HnGlvU+fPvJ4POEuQ3FxcfzDECJ6Fzp6Fzp61zH0L3T0LnT0LnT0rmPC1b+2rrDfwhdRAQAAAMsR2gEAAADLEdrbwel0as2aNXI6neEupcehd6Gjd6Gjdx1D/0JH70JH70JH7zqmp/SvR3wRFQAAAIhkXGkHAAAALEdoBwAAACxHaAcAAAAsR2gHAAAALEdoBwAAACwX8aG9pKREc+bMUWJiohwOh/bu3dvmnqKiIj3yyCNyOp0aNmyYduzY0eV12ijY3hUVFcnhcNz1uHr1avcUbJHc3FyNHz9esbGxio+PV2Zmps6dO9fmvj179mjkyJGKiYnRww8/rP3793dDtXYJpXc7duy4a+5iYmK6qWK7bN26Vampqf5f/ktPT9ff/va3VvcwdzcF2zvmLrB169bJ4XBo2bJlra5j9u7Wnt4xe7f98pe/vKsXI0eObHWPrXMX8aG9rq5OaWlp2rJlS7vWV1RUaPbs2Xr88cdVVlamZcuW6cc//rEOHjzYxZXaJ9je3XLu3DlVVVX5H/Hx8V1Uob2Ki4uVnZ2tY8eOqbCwUDdu3ND06dNVV1cXcM/777+vBQsWaMmSJTp16pQyMzOVmZmp8vLybqw8/ELpnXTz56n/d+4+++yzbqrYLh6PR+vWrdPJkyd14sQJPfHEE/re976nM2fOtLieubst2N5JzF1Ljh8/rm3btik1NbXVdcze3drbO4nZ+1+jR49u1osjR44EXGv13Bn4STIFBQWtrnnxxRfN6NGjm702f/58M2PGjC6szH7t6d17771nJJn//Oc/3VJTT3Lt2jUjyRQXFwdc89RTT5nZs2c3e23ixInmmWee6eryrNae3m3fvt24XK7uK6qHGThwoHn99ddb/DPmrnWt9Y65u1tNTY158MEHTWFhoZkyZYrJyckJuJbZay6Y3jF7t61Zs8akpaW1e73NcxfxV9qDVVpaqmnTpjV7bcaMGSotLQ1TRT3PmDFj5Ha79Z3vfEdHjx4NdzlW8Hq9kqRBgwYFXMPstaw9vZOk2tpaDRkyRMnJyW1eHY0UjY2N2r17t+rq6pSent7iGuauZe3pncTc3Sk7O1uzZ8++a6Zawuw1F0zvJGbvf3388cdKTEzU/fffr4ULF+rixYsB19o8d33DXUBPc/XqVQ0ePLjZa4MHD5bP59NXX32lfv36haky+7ndbr366qsaN26cGhoa9Prrr2vq1Kn6xz/+oUceeSTc5YVNU1OTli1bpsmTJ+uhhx4KuC7Q7EXidwJuaW/vRowYoTfeeEOpqanyer3auHGjJk2apDNnzsjj8XRjxXY4ffq00tPT9d///lcDBgxQQUGBvvWtb7W4lrlrLpjeMXfN7d69Wx9++KGOHz/ervXM3m3B9o7Zu23ixInasWOHRowYoaqqKq1du1YZGRkqLy9XbGzsXettnjtCO7rNiBEjNGLECP/zSZMm6fz583r55Zf15z//OYyVhVd2drbKy8tbPWOHlrW3d+np6c2uhk6aNEmjRo3Stm3b9Ktf/aqry7TOiBEjVFZWJq/Xq7y8PC1atEjFxcUBwyduC6Z3zN1tlZWVysnJUWFhYcR+ITJUofSO2btt5syZ/r9PTU3VxIkTNWTIEL311ltasmRJGCsLHqE9SAkJCaqurm72WnV1teLi4rjKHoIJEyZEdFhdunSp9u3bp5KSkjavfgSavYSEhK4s0VrB9O5O99xzj8aOHatPPvmki6qzW3R0tIYNGyZJ+va3v63jx49r06ZN2rZt211rmbvmgundnSJ57k6ePKlr1641+7+qjY2NKikp0ebNm9XQ0KCoqKhme5i9m0Lp3Z0iefbudO+992r48OEBe2Hz3HGmPUjp6el69913m71WWFjY6plGBFZWVia32x3uMrqdMUZLly5VQUGBDh06pKFDh7a5h9m7KZTe3amxsVGnT5+OyNlrSVNTkxoaGlr8M+auda317k6RPHdPPvmkTp8+rbKyMv9j3LhxWrhwocrKyloMnczeTaH07k6RPHt3qq2t1fnz5wP2wuq5C/c3YcOtpqbGnDp1ypw6dcpIMi+99JI5deqU+eyzz4wxxqxcudI8/fTT/vUXLlww/fv3NytWrDAfffSR2bJli4mKijIHDhwI10cIm2B79/LLL5u9e/eajz/+2Jw+fdrk5OSYPn36mHfeeSdcHyFsfvaznxmXy2WKiopMVVWV/1FfX+9f8/TTT5uVK1f6nx89etT07dvXbNy40Xz00UdmzZo15p577jGnT58Ox0cIm1B6t3btWnPw4EFz/vx5c/LkSfP973/fxMTEmDNnzoTjI4TVypUrTXFxsamoqDD//Oc/zcqVK43D4TB///vfjTHMXWuC7R1z17o774DC7LVfW71j9m57/vnnTVFRkamoqDBHjx4106ZNM/fdd5+5du2aMaZnzV3Eh/ZbtyG887Fo0SJjjDGLFi0yU6ZMuWvPmDFjTHR0tLn//vvN9u3bu71uGwTbu/Xr15sHHnjAxMTEmEGDBpmpU6eaQ4cOhaf4MGupb5KazdKUKVP8vbzlrbfeMsOHDzfR0dFm9OjR5q9//Wv3Fm6BUHq3bNky881vftNER0ebwYMHm1mzZpkPP/yw+4u3wOLFi82QIUNMdHS0+cY3vmGefPJJf+g0hrlrTbC9Y+5ad2fwZPbar63eMXu3zZ8/37jdbhMdHW2SkpLM/PnzzSeffOL/8540dw5jjOm+6/oAAAAAgsWZdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcoR2AAAAwHKEdgAAAMByhHYAAADAcv8PjH+sZJswv2MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_torch.plot_progress(log_y=False, filename=\"../Figures.d/\" + experiment_name+\"_progress.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Parameter   |      Value |\n",
      "|-------------|------------|\n",
      "| l1          |          8 |\n",
      "| l2          |          7 |\n",
      "| lr          | 0.00361165 |\n",
      "| batch_size  |          3 |\n",
      "| epochs      |          4 |\n"
     ]
    }
   ],
   "source": [
    "res = spot_torch.print_results(print_screen=False)\n",
    "print(tabulate(\n",
    "   res,\n",
    "   headers=[\"Parameter\", \"Value\"],\n",
    "   numalign=\"right\",\n",
    "   tablefmt=\"github\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_torch.plot_importance(threshold=0.025, filename=\"../Figures.d/\" + experiment_name+\"_importance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name       | type   |   default |   lower |   upper |                tuned |   importance | stars   |\n",
      "|------------|--------|-----------|---------|---------|----------------------|--------------|---------|\n",
      "| l1         | int    |       5.0 |     2.0 |     9.0 |                  8.0 |         0.00 |         |\n",
      "| l2         | int    |       5.0 |     2.0 |     9.0 |                  7.0 |         0.00 |         |\n",
      "| lr         | float  |     0.001 |  0.0001 |     0.1 | 0.003611652909973722 |         0.00 |         |\n",
      "| batch_size | int    |       4.0 |     1.0 |     4.0 |                  3.0 |         0.00 |         |\n",
      "| epochs     | int    |       3.0 |     1.0 |     4.0 |                  4.0 |       100.00 | ***     |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_torch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 32, 'l2': 32, 'lr': 0.001, 'batch_size': 16, 'epochs': 8}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_default = get_default_hyperparameters_for_core_model(fun_control=fun_control,\n",
    "                                                   hyper_dict=TorchHyperDict)\n",
    "values_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default = fun_control[\"core_model\"](**values_default)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SPOT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spot_torch.to_all_dim(spot_torch.min_X.reshape(1,-1))\n",
    "model_spot = get_one_sklearn_model_from_X(X, fun_control)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0929"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1106"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spot.test_accuracy(fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5344858591496944, 2.3616226649522782)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(spot_torch.y), max(spot_torch.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hyperparameter Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For productive use, you might want to select:\n",
    "  * `min_z=min(spot_torch.y)` and\n",
    "  * `max_z = max(spot_torch.y)`\n",
    "* These settings are not so colorful as visualizations that use `None` for the ranges, but give better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  100.00000000000001\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.025\n",
    "impo = spot_torch.print_importance(threshold=threshold, print_screen=True)\n",
    "var_plots = [i for i, x in enumerate(impo) if x[1] > threshold]\n",
    "min_z = min(spot_torch.y)\n",
    "max_z = max(spot_torch.y)\n",
    "n = spot_torch.k\n",
    "for i in var_plots:\n",
    "    for j in var_plots:\n",
    "        if j > i:\n",
    "            filename = \"../Figures.d/\" + experiment_name+\"_contour_\"+str(i)+\"_\"+str(j)+\".pdf\"\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z, filename=filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_torch.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_torch.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
